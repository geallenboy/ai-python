#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
n8nå·¥ä½œæµçˆ¬å–å·¥å…·çš„Streamlitå¯è§†åŒ–ç•Œé¢
ç”¨äºç®¡ç†å’Œæ‰§è¡Œçˆ¬å–æ“ä½œï¼ŒæŸ¥çœ‹åˆ†ç±»çŠ¶æ€å’Œè¿›åº¦
"""

import streamlit as st
import json
import os
import asyncio
import time
import subprocess
from pathlib import Path
import sys
from typing import Dict, List, Tuple
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib
from matplotlib.font_manager import FontProperties
import n8n_workflow_main as scraper_module
from n8n_workflow_main import N8nWorkflowScraper

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="n8nå·¥ä½œæµçˆ¬å–å·¥å…·",
    page_icon="ğŸ•¸ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# æ·»åŠ CSSæ ·å¼
st.markdown("""
<style>
    .main-title {
        font-size: 2.5rem;
        font-weight: bold;
        margin-bottom: 1rem;
        color: #1E88E5;
    }
    .category-card {
        background-color: #f0f2f6;
        border-radius: 10px;
        padding: 1rem;
        margin-bottom: 1rem;
        border-left: 4px solid #1E88E5;
    }
    .category-name {
        font-weight: bold;
        font-size: 1.2rem;
        margin-bottom: 0.5rem;
    }
    .status-complete {
        color: #4CAF50;
        font-weight: bold;
    }
    .status-incomplete {
        color: #FFC107;
        font-weight: bold;
    }
    .status-not-crawled {
        color: #F44336;
        font-weight: bold;
    }
    .progress-container {
        margin-top: 0.5rem;
    }
    .progress-bar {
        color: #000; 
        background-color: #4CAF50;
        text-align: center;
        line-height: 20px;
        font-weight: bold;
    }
</style>
""", unsafe_allow_html=True)

# å…¨å±€å˜é‡
DATA_DIR = Path("data/workflow")
LOGS_DIR = Path("logs")

# ç¡®ä¿å¿…è¦çš„ç›®å½•å­˜åœ¨
def ensure_directories():
    """ç¡®ä¿æ•°æ®å’Œæ—¥å¿—ç›®å½•å­˜åœ¨"""
    if not DATA_DIR.exists():
        DATA_DIR.mkdir(parents=True, exist_ok=True)
    if not LOGS_DIR.exists():
        LOGS_DIR.mkdir(parents=True, exist_ok=True)

# åŠ è½½åˆ†ç±»æ•°æ®
def load_categories() -> List[Dict]:
    """
    ä»n8n_categories.jsonæ–‡ä»¶åŠ è½½åˆ†ç±»ä¿¡æ¯
    
    Returns:
        åˆ†ç±»ä¿¡æ¯åˆ—è¡¨
    """
    categories_file = DATA_DIR / "n8n_categories.json"
    
    if not categories_file.exists():
        st.warning("æœªæ‰¾åˆ°åˆ†ç±»æ•°æ®æ–‡ä»¶ã€‚è¯·å…ˆè¿è¡Œçˆ¬è™«è·å–åˆ†ç±»ä¿¡æ¯ã€‚")
        return []
    
    try:
        with open(categories_file, "r", encoding="utf-8") as f:
            categories = json.load(f)
        return categories
    except Exception as e:
        st.error(f"åŠ è½½åˆ†ç±»æ•°æ®æ—¶å‡ºé”™: {e}")
        return []

# åŠ è½½å·²çˆ¬å–çš„åˆ†ç±»è®°å½•
def load_crawled_categories() -> Dict:
    """
    åŠ è½½å·²çˆ¬å–çš„åˆ†ç±»è®°å½•
    
    Returns:
        å·²çˆ¬å–çš„åˆ†ç±»è®°å½•ï¼Œæ ¼å¼ä¸º {category_name: {'last_crawled': timestamp, 'count': count}}
    """
    crawled_file = LOGS_DIR / "crawled_categories.json"
    
    if not crawled_file.exists():
        return {}
    
    try:
        with open(crawled_file, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception as e:
        st.warning(f"è¯»å–å·²çˆ¬å–åˆ†ç±»è®°å½•å‡ºé”™: {e}")
        return {}

# è·å–åˆ†ç±»ç›®å½•ä¸­çš„æ–‡ä»¶æ•°é‡
def get_category_file_count(category_name: str) -> int:
    """
    è·å–æŒ‡å®šåˆ†ç±»ç›®å½•ä¸­çš„JSONæ–‡ä»¶æ•°é‡
    
    Args:
        category_name: åˆ†ç±»åç§°
        
    Returns:
        ç›®å½•ä¸­çš„JSONæ–‡ä»¶æ•°é‡
    """
    # åˆ›å»ºå®‰å…¨çš„ç›®å½•å
    safe_name = "".join([c if c.isalnum() or c == ' ' else '_' for c in category_name])
    safe_name = safe_name.replace(' ', '_')
    
    category_dir = DATA_DIR / safe_name
    
    if not category_dir.exists():
        return 0
    
    # è®¡ç®—ç›®å½•ä¸­çš„JSONæ–‡ä»¶æ•°é‡
    return sum(1 for f in category_dir.glob("*.json") if f.is_file())

# è¿è¡Œçˆ¬è™«ä»»åŠ¡
async def run_crawler(category_name: str, max_workflows: int = None, headless: bool = True):
    """
    è¿è¡Œçˆ¬è™«ä»»åŠ¡çˆ¬å–æŒ‡å®šåˆ†ç±»
    
    Args:
        category_name: è¦çˆ¬å–çš„åˆ†ç±»åç§°
        max_workflows: æœ€å¤šçˆ¬å–çš„å·¥ä½œæµæ•°é‡
        headless: æ˜¯å¦ä½¿ç”¨æ— å¤´æ¨¡å¼
    """
    try:
        # åˆ›å»ºçˆ¬è™«å®ä¾‹
        scraper = N8nWorkflowScraper(
            headless=headless,
            use_proxies=False,
            max_retries=3
        )
        
        # è¿è¡Œçˆ¬è™«
        await scraper.run(
            max_workflows_per_category=max_workflows,
            categories_to_crawl=[category_name],
            force_update=True
        )
        
        return True
    except Exception as e:
        st.error(f"çˆ¬è™«è¿è¡Œå‡ºé”™: {e}")
        return False

# ä½¿ç”¨subprocessè¿è¡Œçˆ¬è™«ï¼ˆç”¨äºä¸é˜»å¡Streamlitç•Œé¢ï¼‰
def run_crawler_subprocess(category_name: str, max_workflows: int = None, headless: bool = True):
    """
    ä½¿ç”¨å­è¿›ç¨‹è¿è¡Œçˆ¬è™«
    
    Args:
        category_name: è¦çˆ¬å–çš„åˆ†ç±»åç§°
        max_workflows: æœ€å¤šçˆ¬å–çš„å·¥ä½œæµæ•°é‡
        headless: æ˜¯å¦ä½¿ç”¨æ— å¤´æ¨¡å¼
    """
    cmd = [
        sys.executable, 
        'n8n_workflow_main.py',
        '--categories', category_name,
        '--force-update'
    ]
    
    if max_workflows is not None:
        cmd.extend(['--max-workflows', str(max_workflows)])
    
    if headless:
        cmd.append('--headless')
    
    process = subprocess.Popen(
        cmd,
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE,
        text=True,
        bufsize=1,
        env=os.environ.copy(),  # ä¼ é€’å½“å‰ç¯å¢ƒå˜é‡
        cwd=os.path.dirname(os.path.abspath(__file__))  # ç¡®ä¿åœ¨æ­£ç¡®çš„å·¥ä½œç›®å½•
    )
    
    return process

# è·å–åˆ†ç±»æ•°æ®åˆ†æ
def get_category_analysis() -> pd.DataFrame:
    """
    åˆ†ææ‰€æœ‰åˆ†ç±»æ•°æ®å¹¶è¿”å›DataFrame
    
    Returns:
        åŒ…å«åˆ†ç±»åˆ†æçš„DataFrame
    """
    categories = load_categories()
    crawled_info = load_crawled_categories()
    
    analysis_data = []
    
    for cat in categories:
        name = cat.get('category_name', '')
        if not name:
            continue
            
        # ä»çˆ¬è™«è®°å½•ä¸­è·å–ä¿¡æ¯
        crawled_data = crawled_info.get(name, {})
        last_crawled = crawled_data.get('last_crawled_date', 'æœªçˆ¬å–')
        expected_count = crawled_data.get('count', 0)
        
        # è·å–å®é™…æ–‡ä»¶æ•°é‡
        actual_count = get_category_file_count(name)
        
        # è®¡ç®—ä¸€è‡´æ€§
        if expected_count == 0:
            consistency = "æœªçˆ¬å–"
        else:
            consistency = f"{(actual_count / expected_count * 100):.1f}%" if expected_count > 0 else "N/A"
        
        # ç¡®å®šçŠ¶æ€
        if expected_count == 0:
            status = "æœªçˆ¬å–"
        elif actual_count >= expected_count:
            status = "å®Œæ•´"
        else:
            status = "ä¸å®Œæ•´"
            
        analysis_data.append({
            "åˆ†ç±»åç§°": name,
            "æœ€åçˆ¬å–æ—¶é—´": last_crawled,
            "é¢„æœŸæ•°é‡": expected_count,
            "å®é™…æ•°é‡": actual_count,
            "ä¸€è‡´æ€§": consistency,
            "çŠ¶æ€": status
        })
    
    return pd.DataFrame(analysis_data)

# ä¸»ç•Œé¢
def main():
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    ensure_directories()
    
    # æ˜¾ç¤ºæ ‡é¢˜
    st.markdown("<div class='main-title'>n8nå·¥ä½œæµçˆ¬å–å·¥å…·</div>", unsafe_allow_html=True)
    
    # ä¾§è¾¹æ  - æ“ä½œæ§åˆ¶
    with st.sidebar:
        st.header("æ“ä½œæ§åˆ¶")
        
        # åŠŸèƒ½é€‰æ‹©
        function = st.radio(
            "é€‰æ‹©åŠŸèƒ½",
            ["åˆ†ç±»çŠ¶æ€æ¦‚è§ˆ", "çˆ¬å–ç®¡ç†", "æ•°æ®åˆ†æ"]
        )
        
        # çˆ¬å–è®¾ç½®
        st.subheader("çˆ¬å–è®¾ç½®")
        headless = st.checkbox("æ— å¤´æ¨¡å¼", value=True, help="å¼€å¯æ— å¤´æ¨¡å¼åæµè§ˆå™¨å°†åœ¨åå°è¿è¡Œï¼Œä¸ä¼šæ˜¾ç¤ºç•Œé¢")
        max_workflows = st.number_input("æ¯ä¸ªåˆ†ç±»æœ€å¤šçˆ¬å–æ•°é‡", 
                                      min_value=1, 
                                      value=100, 
                                      help="è®¾ç½®ä¸ºè¾ƒå¤§çš„æ•°ä»¥çˆ¬å–å…¨éƒ¨å·¥ä½œæµ")
        
        # è·å–åˆ†ç±»ä¿¡æ¯çš„æŒ‰é’®
        if st.button("è·å–/æ›´æ–°åˆ†ç±»åˆ—è¡¨"):
            with st.spinner("æ­£åœ¨è·å–åˆ†ç±»ä¿¡æ¯..."):
                # ä½¿ç”¨å­è¿›ç¨‹è¿è¡Œçˆ¬è™«ï¼Œåªè·å–åˆ†ç±»ä¿¡æ¯
                process = subprocess.Popen(
                    [sys.executable, 'n8n_workflow_main.py', '--list-categories', '--headless'],
                    stdout=subprocess.PIPE,
                    stderr=subprocess.PIPE,
                    text=True
                )
                stdout, stderr = process.communicate()
                
                if process.returncode == 0:
                    st.success("åˆ†ç±»ä¿¡æ¯è·å–æˆåŠŸï¼")
                    st.text_area("è¾“å‡ºæ—¥å¿—", stdout, height=200)
                else:
                    st.error("åˆ†ç±»ä¿¡æ¯è·å–å¤±è´¥ï¼")
                    st.text_area("é”™è¯¯ä¿¡æ¯", stderr, height=200)
    
    # ä¸»å†…å®¹åŒºåŸŸ
    if function == "åˆ†ç±»çŠ¶æ€æ¦‚è§ˆ":
        show_categories_overview()
    elif function == "çˆ¬å–ç®¡ç†":
        show_crawl_management()
    elif function == "æ•°æ®åˆ†æ":
        show_data_analysis()

# åˆ†ç±»çŠ¶æ€æ¦‚è§ˆé¡µé¢
def show_categories_overview():
    st.header("åˆ†ç±»çŠ¶æ€æ¦‚è§ˆ")
    
    # è·å–åˆ†ææ•°æ®
    df = get_category_analysis()
    
    if df.empty:
        st.warning("æ²¡æœ‰æ‰¾åˆ°åˆ†ç±»æ•°æ®ã€‚è¯·ç‚¹å‡»ä¾§è¾¹æ ä¸­çš„'è·å–/æ›´æ–°åˆ†ç±»åˆ—è¡¨'æŒ‰é’®ã€‚")
        return
    
    # æ˜¾ç¤ºçŠ¶æ€ç»Ÿè®¡
    col1, col2, col3 = st.columns(3)
    
    with col1:
        complete_count = len(df[df["çŠ¶æ€"] == "å®Œæ•´"])
        st.metric("å®Œæ•´åˆ†ç±»", complete_count, f"{complete_count/len(df)*100:.1f}%")
        
    with col2:
        incomplete_count = len(df[df["çŠ¶æ€"] == "ä¸å®Œæ•´"])
        st.metric("ä¸å®Œæ•´åˆ†ç±»", incomplete_count, f"{incomplete_count/len(df)*100:.1f}%")
        
    with col3:
        not_crawled_count = len(df[df["çŠ¶æ€"] == "æœªçˆ¬å–"])
        st.metric("æœªçˆ¬å–åˆ†ç±»", not_crawled_count, f"{not_crawled_count/len(df)*100:.1f}%")
    
    # æ•°æ®è¿‡æ»¤é€‰é¡¹
    status_filter = st.multiselect(
        "æŒ‰çŠ¶æ€ç­›é€‰", 
        ["å®Œæ•´", "ä¸å®Œæ•´", "æœªçˆ¬å–"], 
        default=["å®Œæ•´", "ä¸å®Œæ•´", "æœªçˆ¬å–"]
    )
    
    # åº”ç”¨è¿‡æ»¤
    filtered_df = df[df["çŠ¶æ€"].isin(status_filter)]
    
    # æ˜¾ç¤ºåˆ†ç±»çŠ¶æ€è¡¨æ ¼
    st.subheader("åˆ†ç±»çŠ¶æ€è¯¦æƒ…")
    st.dataframe(filtered_df, use_container_width=True)
    
    # æ˜¾ç¤ºæŸ±çŠ¶å›¾
    st.subheader("åˆ†ç±»æ•°æ®ç»Ÿè®¡")
    
    # åªé€‰æ‹©å‰10ä¸ªåˆ†ç±»ï¼Œé¿å…å›¾è¡¨è¿‡äºæ‹¥æŒ¤å¯¼è‡´ä¹±ç 
    display_df = df.head(10) if len(df) > 10 else df
    
    fig, ax = plt.subplots(figsize=(10, 6))
    x = display_df["åˆ†ç±»åç§°"]
    y1 = display_df["é¢„æœŸæ•°é‡"]
    y2 = display_df["å®é™…æ•°é‡"]
    
    x_pos = range(len(x))
    width = 0.35
    
    ax.bar([p - width/2 for p in x_pos], y1, width, label='é¢„æœŸæ•°é‡')
    ax.bar([p + width/2 for p in x_pos], y2, width, label='å®é™…æ•°é‡')
    
    ax.set_xticks(x_pos)
    # å¢åŠ å­—ä½“å¤§å°å’Œæ—‹è½¬è§’åº¦ï¼Œæé«˜å¯è¯»æ€§
    ax.set_xticklabels(x, rotation=45, ha="right", fontsize=9)
    ax.legend(prop={'size': 10})
    
    ax.set_ylabel('æ•°é‡')
    ax.set_title('å„åˆ†ç±»é¢„æœŸæ•°é‡ä¸å®é™…æ•°é‡å¯¹æ¯”ï¼ˆå‰10ä¸ªï¼‰')
    plt.tight_layout()
    
    st.pyplot(fig)
    
    # å¦‚æœåˆ†ç±»æ•°é‡è¶…è¿‡10ä¸ªï¼Œæ˜¾ç¤ºå®Œæ•´æ•°æ®è¡¨æ ¼
    if len(df) > 10:
        st.info("ç”±äºåˆ†ç±»æ•°é‡è¾ƒå¤šï¼Œå›¾è¡¨ä»…æ˜¾ç¤ºå‰10ä¸ªåˆ†ç±»ã€‚å®Œæ•´æ•°æ®è¯·æŸ¥çœ‹ä¸Šæ–¹è¡¨æ ¼ã€‚")

# çˆ¬å–ç®¡ç†é¡µé¢
def show_crawl_management():
    st.header("çˆ¬å–ç®¡ç†")
    
    # è·å–åˆ†ç±»æ•°æ®
    categories = load_categories()
    
    if not categories:
        st.warning("æ²¡æœ‰æ‰¾åˆ°åˆ†ç±»æ•°æ®ã€‚è¯·ç‚¹å‡»ä¾§è¾¹æ ä¸­çš„'è·å–/æ›´æ–°åˆ†ç±»åˆ—è¡¨'æŒ‰é’®ã€‚")
        return
    
    # è·å–çˆ¬å–è®°å½•å’Œåˆ†æ
    crawled_info = load_crawled_categories()
    df = get_category_analysis()
    
    # åˆ›å»ºä¸¤åˆ—å¸ƒå±€
    col1, col2 = st.columns([3, 1])
    
    with col1:
        # æŒ‰çŠ¶æ€ç­›é€‰
        status_filter = st.multiselect(
            "æŒ‰çŠ¶æ€ç­›é€‰", 
            ["å®Œæ•´", "ä¸å®Œæ•´", "æœªçˆ¬å–"], 
            default=["ä¸å®Œæ•´", "æœªçˆ¬å–"]
        )
        filtered_df = df[df["çŠ¶æ€"].isin(status_filter)]
        
        # æŒ‰å…³é”®è¯æœç´¢
        search_term = st.text_input("æœç´¢åˆ†ç±»åç§°")
        if search_term:
            filtered_df = filtered_df[filtered_df["åˆ†ç±»åç§°"].str.contains(search_term, case=False)]
    
    with col2:
        # æ‰¹é‡æ“ä½œ
        st.subheader("æ‰¹é‡æ“ä½œ")
        
        if st.button("çˆ¬å–æ‰€æœ‰ä¸å®Œæ•´åˆ†ç±»"):
            incomplete_categories = df[df["çŠ¶æ€"] == "ä¸å®Œæ•´"]["åˆ†ç±»åç§°"].tolist()
            if incomplete_categories:
                st.session_state.batch_categories = incomplete_categories
                st.session_state.batch_index = 0
                st.success(f"å·²æ·»åŠ  {len(incomplete_categories)} ä¸ªåˆ†ç±»åˆ°çˆ¬å–é˜Ÿåˆ—")
            else:
                st.info("æ²¡æœ‰ä¸å®Œæ•´çš„åˆ†ç±»éœ€è¦çˆ¬å–")
                
        if st.button("çˆ¬å–æ‰€æœ‰æœªçˆ¬å–åˆ†ç±»"):
            not_crawled_categories = df[df["çŠ¶æ€"] == "æœªçˆ¬å–"]["åˆ†ç±»åç§°"].tolist()
            if not_crawled_categories:
                st.session_state.batch_categories = not_crawled_categories
                st.session_state.batch_index = 0
                st.success(f"å·²æ·»åŠ  {len(not_crawled_categories)} ä¸ªåˆ†ç±»åˆ°çˆ¬å–é˜Ÿåˆ—")
            else:
                st.info("æ²¡æœ‰æœªçˆ¬å–çš„åˆ†ç±»")
    
    # æ˜¾ç¤ºåˆ†ç±»åˆ—è¡¨
    st.subheader("åˆ†ç±»åˆ—è¡¨")
    
    # åˆå§‹åŒ–æ‰¹é‡çˆ¬å–çŠ¶æ€
    if "batch_categories" not in st.session_state:
        st.session_state.batch_categories = []
    if "batch_index" not in st.session_state:
        st.session_state.batch_index = 0
    if "crawling" not in st.session_state:
        st.session_state.crawling = False
    if "current_process" not in st.session_state:
        st.session_state.current_process = None
    
    # æ‰¹é‡çˆ¬å–è¿›åº¦
    if st.session_state.batch_categories:
        batch_progress = st.progress(0.0)
        batch_status = st.empty()
        
        total = len(st.session_state.batch_categories)
        current = st.session_state.batch_index
        
        if current < total:
            progress_val = current / total
            batch_progress.progress(progress_val)
            current_cat = st.session_state.batch_categories[current]
            batch_status.info(f"æ­£åœ¨çˆ¬å– ({current}/{total}): {current_cat}")
            
            # å¦‚æœæ²¡æœ‰æ­£åœ¨è¿›è¡Œçš„çˆ¬å–ï¼Œå¯åŠ¨ä¸‹ä¸€ä¸ª
            if not st.session_state.crawling and st.session_state.current_process is None:
                st.session_state.crawling = True
                max_workflows = int(st.sidebar.number_input("æ¯ä¸ªåˆ†ç±»æœ€å¤šçˆ¬å–æ•°é‡", key="batch_max"))
                headless = st.sidebar.checkbox("æ— å¤´æ¨¡å¼", value=True, key="batch_headless")
                
                # å¯åŠ¨çˆ¬è™«è¿›ç¨‹
                process = run_crawler_subprocess(current_cat, max_workflows, headless)
                st.session_state.current_process = process
                
                # åˆ›å»ºä¸€ä¸ªå ä½ç¬¦æ¥æ˜¾ç¤ºå®æ—¶è¾“å‡º
                output_placeholder = st.empty()
                
                # æ¨¡æ‹Ÿå¼‚æ­¥æ£€æŸ¥è¿›ç¨‹çŠ¶æ€
                def check_process():
                    process = st.session_state.current_process
                    if process is not None:
                        output = ""
                        # ä½¿ç”¨éé˜»å¡æ–¹å¼è¯»å–è¾“å‡º
                        while True:
                            line = process.stdout.readline()
                            if not line and process.poll() is not None:
                                break
                            if line:
                                output += line + "\n"
                                output_placeholder.text_area("çˆ¬è™«è¾“å‡º", output, height=200)
                                time.sleep(0.1)  # å°çš„å»¶è¿Ÿé˜²æ­¢è¿‡åº¦åˆ·æ–°
                        
                        # æ£€æŸ¥è¿›ç¨‹æ˜¯å¦ç»“æŸ
                        if process.poll() is not None:
                            if process.returncode == 0:
                                batch_status.success(f"çˆ¬å–å®Œæˆ: {current_cat}")
                            else:
                                stderr = process.stderr.read()
                                batch_status.error(f"çˆ¬å–å¤±è´¥: {current_cat}\n{stderr}")
                            
                            # æ›´æ–°çŠ¶æ€
                            st.session_state.crawling = False
                            st.session_state.current_process = None
                            st.session_state.batch_index += 1
                            
                            # å¦‚æœæ‰€æœ‰åˆ†ç±»éƒ½çˆ¬å–å®Œæ¯•ï¼Œæ¸…ç©ºé˜Ÿåˆ—
                            if st.session_state.batch_index >= total:
                                st.session_state.batch_categories = []
                                st.session_state.batch_index = 0
                                batch_status.success("æ‰€æœ‰åˆ†ç±»çˆ¬å–å®Œæˆï¼")
                            
                            # å¼ºåˆ¶é‡æ–°åŠ è½½é¡µé¢ä»¥æ›´æ–°çŠ¶æ€
                            st.rerun()
                
                # å¯åŠ¨æ£€æŸ¥è¿›ç¨‹çš„çº¿ç¨‹
                import threading
                threading.Thread(target=check_process).start()
        else:
            batch_progress.progress(1.0)
            batch_status.success(f"æ‰¹é‡çˆ¬å–å®Œæˆï¼å…±çˆ¬å– {total} ä¸ªåˆ†ç±»ã€‚")
    
    # æ˜¾ç¤ºåˆ†ç±»å¡ç‰‡
    if not filtered_df.empty:
        for index, row in filtered_df.iterrows():
            category_name = row["åˆ†ç±»åç§°"]
            expected_count = row["é¢„æœŸæ•°é‡"]
            actual_count = row["å®é™…æ•°é‡"]
            last_crawled = row["æœ€åçˆ¬å–æ—¶é—´"]
            status = row["çŠ¶æ€"]
            
            # ç¡®å®šçŠ¶æ€æ ·å¼
            if status == "å®Œæ•´":
                status_class = "status-complete"
            elif status == "ä¸å®Œæ•´":
                status_class = "status-incomplete"
            else:
                status_class = "status-not-crawled"
            
            # åˆ›å»ºåˆ†ç±»å¡ç‰‡
            st.markdown(f"""
            <div class='category-card'>
                <div class='category-name'>{category_name}</div>
                <div>çŠ¶æ€: <span class='{status_class}'>{status}</span></div>
                <div>æœ€åçˆ¬å–: {last_crawled}</div>
                <div>æ–‡ä»¶æ•°é‡: {actual_count} / {expected_count}</div>
                <div class='progress-container'>
                    <div class='progress'>
                        <div class='progress-bar' role='progressbar' style='width: {(actual_count/expected_count*100) if expected_count > 0 else 0}%;' 
                            aria-valuenow='{actual_count}' aria-valuemin='0' aria-valuemax='{expected_count}'>
                        </div>
                    </div>
                </div>
            </div>
            """, unsafe_allow_html=True)
            
            # æ·»åŠ çˆ¬å–æŒ‰é’®
            col1, col2 = st.columns([3, 1])
            with col1:
                max_to_crawl = expected_count - actual_count if expected_count > actual_count else 1
                max_to_crawl = max(1, max_to_crawl)  # ç¡®ä¿è‡³å°‘ä¸º1
                to_crawl = st.number_input(f"çˆ¬å–æ•°é‡ ({category_name})", 
                                         min_value=1, 
                                         max_value=1000, 
                                         value=max_to_crawl,
                                         key=f"input_{index}")
            
            with col2:
                if st.button("å¼€å§‹çˆ¬å–", key=f"crawl_{index}"):
                    # æ£€æŸ¥æ˜¯å¦æœ‰æ­£åœ¨è¿›è¡Œçš„çˆ¬å–
                    if st.session_state.crawling:
                        st.warning("æœ‰æ­£åœ¨è¿›è¡Œçš„çˆ¬å–ä»»åŠ¡ï¼Œè¯·ç­‰å¾…å®Œæˆåå†è¯•")
                    else:
                        st.session_state.crawling = True
                        max_workflows = int(to_crawl)
                        headless = st.sidebar.checkbox("æ— å¤´æ¨¡å¼", value=True)
                        
                        # æ˜¾ç¤ºçˆ¬å–çŠ¶æ€
                        status_placeholder = st.empty()
                        status_placeholder.info(f"æ­£åœ¨çˆ¬å– {category_name}...")
                        
                        # å¯åŠ¨çˆ¬è™«è¿›ç¨‹
                        process = run_crawler_subprocess(category_name, max_workflows, headless)
                        st.session_state.current_process = process
                        
                        # åˆ›å»ºä¸€ä¸ªå ä½ç¬¦æ¥æ˜¾ç¤ºå®æ—¶è¾“å‡º
                        output_placeholder = st.empty()
                        
                        # æ£€æŸ¥è¿›ç¨‹çŠ¶æ€
                        def check_single_process():
                            process = st.session_state.current_process
                            if process is not None:
                                output = ""
                                # è¯»å–è¾“å‡º
                                for line in iter(process.stdout.readline, ""):
                                    if not line:
                                        break
                                    output += line + "\n"
                                    output_placeholder.text_area("çˆ¬è™«è¾“å‡º", output, height=200)
                                
                                # æ£€æŸ¥è¿›ç¨‹æ˜¯å¦ç»“æŸ
                                if process.poll() is not None:
                                    if process.returncode == 0:
                                        status_placeholder.success(f"çˆ¬å–å®Œæˆ: {category_name}")
                                    else:
                                        stderr = process.stderr.read()
                                        status_placeholder.error(f"çˆ¬å–å¤±è´¥: {category_name}\n{stderr}")
                                    
                                    # æ›´æ–°çŠ¶æ€
                                    st.session_state.crawling = False
                                    st.session_state.current_process = None
                                    
                                    # å¼ºåˆ¶é‡æ–°åŠ è½½é¡µé¢ä»¥æ›´æ–°çŠ¶æ€
                                    st.rerun()
                        
                        # å¯åŠ¨æ£€æŸ¥è¿›ç¨‹çš„çº¿ç¨‹
                        import threading
                        threading.Thread(target=check_single_process).start()

# æ•°æ®åˆ†æé¡µé¢
def show_data_analysis():
    st.header("æ•°æ®åˆ†æ")
    
    # è·å–åˆ†ææ•°æ®
    df = get_category_analysis()
    
    if df.empty:
        st.warning("æ²¡æœ‰æ‰¾åˆ°åˆ†ç±»æ•°æ®ã€‚è¯·ç‚¹å‡»ä¾§è¾¹æ ä¸­çš„'è·å–/æ›´æ–°åˆ†ç±»åˆ—è¡¨'æŒ‰é’®ã€‚")
        return
    
    # æ€»è®¡ç»Ÿè®¡
    total_categories = len(df)
    total_expected = df["é¢„æœŸæ•°é‡"].sum()
    total_actual = df["å®é™…æ•°é‡"].sum()
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("æ€»åˆ†ç±»æ•°", total_categories)
    with col2:
        st.metric("é¢„æœŸæ€»å·¥ä½œæµ", int(total_expected))
    with col3:
        st.metric("å®é™…å·²çˆ¬å–", int(total_actual), f"{total_actual/total_expected*100:.1f}%" if total_expected > 0 else "N/A")
    
    # åˆ†ç±»çŠ¶æ€é¥¼å›¾
    st.subheader("åˆ†ç±»çŠ¶æ€åˆ†å¸ƒ")
    
    status_counts = df["çŠ¶æ€"].value_counts()
    
    fig1, ax1 = plt.subplots(figsize=(8, 8))
    # ä½¿ç”¨æ›´é²œæ˜çš„é¢œè‰²
    colors = ['#4CAF50', '#FFC107', '#F44336']
    ax1.pie(status_counts, labels=status_counts.index, autopct='%1.1f%%', 
            startangle=90, colors=colors, textprops={'fontsize': 12})
    ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.
    
    st.pyplot(fig1)
    
    # æœ€å¤§çš„åˆ†ç±»
    st.subheader("æ•°é‡æœ€å¤šçš„åˆ†ç±»")
    
    top_df = df.sort_values("å®é™…æ•°é‡", ascending=False).head(10)
    
    fig2, ax2 = plt.subplots(figsize=(10, 6))
    bars = ax2.barh(top_df["åˆ†ç±»åç§°"], top_df["å®é™…æ•°é‡"], color='#1E88E5')
    
    # ä¸ºæ¯ä¸ªæ¡å½¢æ·»åŠ æ•°å­—æ ‡ç­¾
    for bar in bars:
        width = bar.get_width()
        ax2.text(width + 1, bar.get_y() + bar.get_height()/2, 
                 f'{int(width)}', ha='left', va='center', fontsize=9)
    
    ax2.set_xlabel('å·¥ä½œæµæ•°é‡')
    ax2.set_ylabel('åˆ†ç±»åç§°')
    ax2.set_title('å·¥ä½œæµæ•°é‡æœ€å¤šçš„10ä¸ªåˆ†ç±»')
    # å¢åŠ Yè½´æ ‡ç­¾å­—ä½“å¤§å°
    plt.yticks(fontsize=10)
    plt.tight_layout()
    
    st.pyplot(fig2)
    
    # æœ€è¿‘çˆ¬å–çš„åˆ†ç±»
    st.subheader("æœ€è¿‘çˆ¬å–çš„åˆ†ç±»")
    
    # è¿‡æ»¤å‡ºæœ‰çˆ¬å–è®°å½•çš„åˆ†ç±»
    crawled_df = df[df["æœ€åçˆ¬å–æ—¶é—´"] != "æœªçˆ¬å–"].copy()
    
    if not crawled_df.empty:
        # å°è¯•å°†æ—¥æœŸå­—ç¬¦ä¸²è½¬æ¢ä¸ºæ—¥æœŸæ—¶é—´å¯¹è±¡ç”¨äºæ’åº
        try:
            crawled_df["çˆ¬å–æ—¥æœŸ"] = pd.to_datetime(crawled_df["æœ€åçˆ¬å–æ—¶é—´"])
            recent_df = crawled_df.sort_values("çˆ¬å–æ—¥æœŸ", ascending=False).head(10)
            recent_df = recent_df[["åˆ†ç±»åç§°", "æœ€åçˆ¬å–æ—¶é—´", "å®é™…æ•°é‡"]]
            st.dataframe(recent_df, use_container_width=True)
        except:
            st.dataframe(crawled_df[["åˆ†ç±»åç§°", "æœ€åçˆ¬å–æ—¶é—´", "å®é™…æ•°é‡"]].head(10), use_container_width=True)
    else:
        st.info("æ²¡æœ‰æ‰¾åˆ°çˆ¬å–è®°å½•")

# è®¾ç½®matplotlibä¸­æ–‡å­—ä½“æ”¯æŒ
# å°è¯•ä½¿ç”¨ç³»ç»Ÿä¸­å¸¸è§çš„ä¸­æ–‡å­—ä½“
def set_matplotlib_chinese_font():
    try:
        # å°è¯•ç³»ç»Ÿå¸¸è§çš„ä¸­æ–‡å­—ä½“
        font_list = ['SimHei', 'Microsoft YaHei', 'PingFang SC', 'Hiragino Sans GB', 'Heiti SC', 'STHeiti', 'WenQuanYi Micro Hei']
        
        # åœ¨macOSä¸Šç‰¹åˆ«å¸¸è§çš„å­—ä½“
        if sys.platform == 'darwin':  # macOS
            font_list = ['PingFang SC', 'Hiragino Sans GB', 'STHeiti', 'Apple LiGothic Medium'] + font_list
            
        # å°è¯•è®¾ç½®å­—ä½“ï¼Œç›´åˆ°æ‰¾åˆ°å¯ç”¨çš„å­—ä½“
        for font_name in font_list:
            try:
                matplotlib.rcParams['font.family'] = [font_name]
                matplotlib.rcParams['axes.unicode_minus'] = False  # ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºè´Ÿå·
                # æµ‹è¯•å­—ä½“æ˜¯å¦å¯ç”¨
                font = FontProperties(family=font_name)
                if font.get_name() != 'DejaVu Sans':  # DejaVu Sans é€šå¸¸æ˜¯å½“æ‰¾ä¸åˆ°å­—ä½“æ—¶çš„å›é€€é€‰é¡¹
                    break
            except:
                continue
                
        # å¦‚æœæ— æ³•è®¾ç½®ä¸­æ–‡å­—ä½“ï¼Œä½¿ç”¨é€šç”¨è®¾ç½®
        if matplotlib.rcParams['font.family'] == ['DejaVu Sans']:
            matplotlib.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans', 'Bitstream Vera Sans', 'sans-serif']
            matplotlib.rcParams['axes.unicode_minus'] = False
    except Exception as e:
        st.warning(f"è®¾ç½®ä¸­æ–‡å­—ä½“æ—¶å‡ºé”™: {e}")
        # ä½¿ç”¨æœ€ç®€å•çš„è®¾ç½®ï¼Œç¡®ä¿ä¸ä¼šå‡ºé”™
        matplotlib.rcParams['font.sans-serif'] = ['SimHei']
        matplotlib.rcParams['axes.unicode_minus'] = False

# è°ƒç”¨å‡½æ•°è®¾ç½®ä¸­æ–‡å­—ä½“
set_matplotlib_chinese_font()

if __name__ == "__main__":
    main()