{
  "url": "https://blog.n8n.io/local-llm/",
  "title": "How to Run a Local LLM: Complete Guide to Setup & Best Models (2025)",
  "excerpt": "Learn how to run LLMs locally, explore top tools like Ollama & GPT4All, and integrate them with n8n for private, cost-effective AI workflows.",
  "thumbnail": "https://blog.n8n.io/content/images/size/w1200/2024/08/llamas3a.png",
  "tags": [
    "AI",
    "Guide"
  ],
  "html": "<p>Have you ever worried about the costs of using ChatGPT for your projects? Or perhaps you work in a field with strict data governance rules, making it difficult to use cloud-based AI solutions?</p><p>If so, running Large Language Models (LLMs) locally could be the answer you've been looking for.</p><p>Local LLMs offer a cost-effective and secure alternative to cloud-based options. By running models on your own hardware, you can avoid the recurring costs of API calls and keep your sensitive data within your own infrastructure. This is particularly beneficial in industries like healthcare, finance, and legal, where data privacy is paramount.</p><p>Experimenting and tinkering with LLMs on your local machine can also be a fantastic learning opportunity, deepening your understanding of AI and its applications.</p>\n<!--kg-card-begin: html-->\n<script>\n  workflowBanner([2341, 2339, 2335, 2333], document.currentScript, { \n      workflowsHeader: \"Local LLM workflows to experiment with:\"\n  });\n</script><div class=\"workflows\">\n    \n    <h3>Local LLM workflows to experiment with:</h3>\n  <div class=\"workflow\">\n      <div class=\"workflow-content\">\n        <div class=\"workflow-nodes\">\n          \n          <i class=\"fa fa-mouse-pointer\" aria-hidden=\"true\" style=\"color:#909298\"></i>\n        <img src=\"data:image/svg+xml;base64,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\" alt=\"HTTP Request\" title=\"HTTP Request\"><img src=\"data:image/svg+xml;base64,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\" alt=\"Code\" title=\"Code\"><img src=\"data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iNDAiIGhlaWdodD0iNDAiIHZpZXdCb3g9IjAgMCA0MCA0MCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggZD0iTTguNjQwNjIgMEgxMC40Mzc1VjEuNzgxMjVIMTIuMDkzN1YwSDEzLjg5MDZWNS4zOTA2MkgxMi4wOTM3VjMuNTkzNzVIMTAuNDUzMVY1LjM5MDYySDguNjQwNjJNMTYuMjY1NiAxLjc5Njg3SDE0LjY3OTdWMEgxOS42NTYyVjEuNzk2ODdIMTguMDYyNVY1LjM5MDYySDE2LjI2NTZNMjAuNDQ1MyAwSDIyLjMyODFMMjMuNDg0NCAxLjg5ODQ0TDI0LjY0MDYgMEgyNi41MjM0VjUuMzkwNjJIMjQuNzI2NlYyLjcxODc1TDIzLjQ2ODcgNC42NTYyNUwyMi4yMTA5IDIuNzE4NzVWNS4zOTA2MkgyMC40NDUzTTI3LjQxNDEgMEgyOS4yMTA5VjMuNjA5MzdIMzEuNzU3OFY1LjM5MDYySDI3LjQxNDEiIGZpbGw9ImJsYWNrIi8+CjxwYXRoIGQ9Ik04LjU3ODEyIDM2Ljc5NjlMNiA3Ljg1OTM4SDM0LjM0MzdMMzEuNzY1NiAzNi43ODEyTDIwLjE0ODQgNDAiIGZpbGw9IiNFNDREMjYiLz4KPHBhdGggZD0iTTIwLjE3MTkgMzcuNTM5MVYxMC4yMzQ0SDMxLjc1NzhMMjkuNTQ2OSAzNC45MjE5IiBmaWxsPSIjRjE2NTI5Ii8+CjxwYXRoIGQ9Ik0xMS4yNjU2IDEzLjc3MzRIMjAuMTcxOVYxNy4zMjAzSDE1LjE1NjJMMTUuNDg0NCAyMC45NTMxSDIwLjE3MTlWMjQuNDkyMkgxMi4yMzQ0TTEyLjM5MDYgMjYuMjczNEgxNS45NTMxTDE2LjIwMzEgMjkuMTA5NEwyMC4xNzE5IDMwLjE3MTlWMzMuODc1TDEyLjg5MDYgMzEuODQzNyIgZmlsbD0iI0VCRUJFQiIvPgo8cGF0aCBkPSJNMjkuMDQ2OSAxMy43NzM0SDIwLjE1NjJWMTcuMzIwM0gyOC43MTg3TTI4LjM5ODQgMjAuOTUzMUgyMC4xNTYyVjI0LjVIMjQuNTMxMkwyNC4xMTcyIDI5LjEwOTRMMjAuMTU2MiAzMC4xNzE5VjMzLjg1OTRMMjcuNDIxOSAzMS44NDM3IiBmaWxsPSJ3aGl0ZSIvPgo8L3N2Zz4K\" alt=\"HTML\" title=\"HTML\">\n          <i class=\"fa fa-pen\" aria-hidden=\"true\"></i>\n        \n          <span>+5</span>\n        </div>\n        <div class=\"workflow-details\">\n          <p class=\"workflow-details-name\">\n            <a href=\"https://n8n.io/workflows/2333-recipe-recommendations-with-qdrant-and-mistral/\" class=\"blog-banner-workflow\">Recipe Recommendations with Qdrant and Mistral</a>\n          </p>\n          <p class=\"workflow-details-stats\">\n          <svg xmlns=\"http://www.w3.org/2000/svg\" width=\"12\" height=\"10\" fill=\"none\" viewBox=\"0 0 12 10\"><path fill=\"#707183\" d=\"M4.94 6.06a1.5 1.5 0 1 1 2.121-2.12 1.5 1.5 0 0 1-2.12 2.12Z\"></path><path fill=\"#707183\" fill-rule=\"evenodd\" d=\"M.462 6.143C1.38 7.135 3.294 9.2 6 9.2s4.62-2.065 5.539-3.057a1.703 1.703 0 0 0 0-2.332l-.001-.002C10.703 2.907 8.749.8 6 .8 3.256.8 1.304 2.903.466 3.806l-.004.005a1.703 1.703 0 0 0 0 2.332ZM3.77 3.305c.689-.38 1.447-.62 2.23-.705a5.88 5.88 0 0 1 3.972 2.17.301.301 0 0 1 0 .414A5.88 5.88 0 0 1 6 7.4 6.216 6.216 0 0 1 1.996 5.24a.3.3 0 0 1-.01-.423A5.937 5.937 0 0 1 3.77 3.305Z\" clip-rule=\"evenodd\"></path></svg>\n          5571 <span>â€¢</span> <strong>by jimleuk</strong> <span>â€¢</span> 10 months\n        </p>\n        </div>\n      </div>\n      <a href=\"https://n8n.io/workflows/2333-recipe-recommendations-with-qdrant-and-mistral/\" class=\"global-button blog-banner-workflow\">\n        Use this workflow\n      </a>\n    </div><div class=\"workflow\">\n      <div class=\"workflow-content\">\n        <div class=\"workflow-nodes\">\n          \n          <i class=\"fa fa-mouse-pointer\" aria-hidden=\"true\" style=\"color:#909298\"></i>\n        <img src=\"data:image/svg+xml;base64,<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<svg
   width="216"
   height="216"
   version="1.1"
   id="svg41"
   sodipodi:docname="mistral.svg"
   inkscape:version="1.3.2 (091e20ef0f, 2023-11-25, custom)"
   xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"
   xmlns:sodipodi="http://sodipodi.sourceforge.net/DTD/sodipodi-0.dtd"
   xmlns:xlink="http://www.w3.org/1999/xlink"
   xmlns="http://www.w3.org/2000/svg"
   xmlns:svg="http://www.w3.org/2000/svg">
  <sodipodi:namedview
     id="namedview41"
     pagecolor="#ffffff"
     bordercolor="#000000"
     borderopacity="0.25"
     inkscape:showpageshadow="2"
     inkscape:pageopacity="0.0"
     inkscape:pagecheckerboard="0"
     inkscape:deskcolor="#d1d1d1"
     inkscape:zoom="1.936488"
     inkscape:cx="197.78072"
     inkscape:cy="79.00901"
     inkscape:window-width="1920"
     inkscape:window-height="1017"
     inkscape:window-x="0"
     inkscape:window-y="0"
     inkscape:window-maximized="1"
     inkscape:current-layer="svg41" />
  <style
     id="style1"><![CDATA[.I{fill:#ff7000}.J{fill:#ff4900}.K{fill:#ffa300}.L{fill:#1c1c1b icc-color(adobe-rgb-1998, 0.13299561, 0.13299561, 0.1289978)}]]></style>
  <defs
     id="defs10">
    <clipPath
       id="A">
      <path
         d="M 0,184.252 H 481.89 V 0 H 0 Z"
         transform="translate(-206.251,-140.139)"
         id="path1" />
    </clipPath>
    <clipPath
       id="B">
      <path
         d="M 0,184.252 H 481.89 V 0 H 0 Z"
         transform="translate(-247.436,-104.865)"
         id="path2" />
    </clipPath>
    <clipPath
       id="C">
      <path
         d="M 0,184.252 H 481.89 V 0 H 0 Z"
         transform="translate(-285.938,-102.089)"
         id="path3" />
    </clipPath>
    <clipPath
       id="D">
      <path
         d="M 0,184.252 H 481.89 V 0 H 0 Z"
         transform="translate(-337.769,-131.877)"
         id="path4" />
    </clipPath>
    <clipPath
       id="E">
      <path
         d="M 0,184.252 H 481.89 V 0 H 0 Z"
         transform="translate(-377.247,-132.319)"
         id="path5" />
    </clipPath>
    <clipPath
       id="F">
      <path
         d="M 0,184.252 H 481.89 V 0 H 0 Z"
         transform="translate(-418.107,-114.634)"
         id="path6" />
    </clipPath>
    <clipPath
       id="G">
      <path
         d="M 0,184.252 H 481.89 V 0 H 0 Z"
         transform="translate(-450.023,-140.139)"
         id="path7" />
    </clipPath>
    <clipPath
       id="H">
      <path
         d="M 0,184.252 H 481.89 V 0 H 0 Z"
         transform="translate(-217.694,-44.794)"
         id="path8" />
    </clipPath>
    <clipPath
       id="I">
      <path
         d="M 0,184.252 H 481.89 V 0 H 0 Z"
         transform="translate(-247.436,-35.025)"
         id="path9" />
    </clipPath>
    <clipPath
       id="J">
      <path
         d="M 0,184.252 H 481.89 V 0 H 0 Z"
         id="path10" />
    </clipPath>
    <path
       id="K"
       d="m 173.987,134.362 h -37.795 l 9.633,-37.776 h 37.796 z" />
  </defs>
  <g
     transform="matrix(1,0,0.254535,1,-51.362792,-7.4725007)"
     id="g32">
    <g
       class="L"
       id="g22">
      <path
         d="M 98.397,134.362 H 60.602 l 9.633,-37.776 h 37.796 z"
         id="path11" />
      <path
         d="M 126.558,172.138 H 88.763 l 9.633,-37.776 h 37.796 z"
         id="path12" />
      <path
         d="M 136.192,134.362 H 98.397 l 9.633,-37.776 h 37.796 z"
         id="path13" />
      <use
         xlink:href="#K"
         id="use13" />
      <path
         d="M 108.031,96.585 H 70.236 l 9.633,-37.776 h 37.796 z"
         id="path14" />
      <use
         xlink:href="#K"
         x="9.6339998"
         y="-37.777"
         id="use14" />
      <path
         d="M 60.602,134.362 H 22.807 L 32.44,96.586 h 37.796 z"
         id="path15" />
      <path
         d="M 70.236,96.585 H 32.441 L 42.074,58.809 H 79.87 Z"
         id="path16" />
      <path
         d="M 79.87,58.809 H 42.075 l 9.633,-37.776 h 37.796 z"
         id="path17" />
      <use
         xlink:href="#K"
         x="57.063"
         y="-75.553001"
         id="use17" />
      <path
         d="M 50.968,172.138 H 13.173 l 9.633,-37.776 h 37.796 z"
         id="path18" />
      <path
         d="M 41.334,209.915 H 3.539 l 9.633,-37.776 h 37.796 z"
         id="path19" />
      <use
         xlink:href="#K"
         x="37.794998"
         id="use19" />
      <use
         xlink:href="#K"
         x="47.429001"
         y="-37.777"
         id="use20" />
      <use
         xlink:href="#K"
         x="28.160999"
         y="37.776001"
         id="use21" />
      <use
         xlink:href="#K"
         x="18.527"
         y="75.553001"
         id="use22" />
    </g>
    <path
       d="M 114.115,134.359 H 76.321 l 9.633,-37.776 h 37.796 z"
       class="I"
       id="path22" />
    <use
       xlink:href="#K"
       x="-31.709999"
       y="37.772999"
       class="J"
       id="use23" />
    <g
       class="I"
       id="g25">
      <use
         xlink:href="#K"
         x="-22.076"
         y="-0.003"
         id="use24" />
      <use
         xlink:href="#K"
         x="15.719"
         y="-0.003"
         id="use25" />
    </g>
    <g
       class="K"
       id="g26">
      <path
         d="M 123.749,96.582 H 85.955 l 9.633,-37.776 h 37.796 z"
         id="path25" />
      <use
         xlink:href="#K"
         x="25.353001"
         y="-37.779999"
         id="use26" />
    </g>
    <path
       d="M 76.32,134.359 H 38.526 l 9.633,-37.776 h 37.796 z"
       class="I"
       id="path26" />
    <path
       d="M 85.954,96.582 H 48.16 l 9.633,-37.776 h 37.796 z"
       class="K"
       id="path27" />
    <g
       fill="#ffce00"
       id="g28">
      <path
         d="M 95.588,58.806 H 57.794 L 67.427,21.03 h 37.796 z"
         id="path28" />
      <use
         xlink:href="#K"
         x="72.781998"
         y="-75.556"
         id="use28" />
    </g>
    <path
       d="M 66.686,172.135 H 28.892 l 9.633,-37.776 h 37.796 z"
       class="J"
       id="path29" />
    <path
       d="M 57.052,209.912 H 19.258 l 9.633,-37.776 h 37.796 z"
       fill="#ff0107"
       id="path30" />
    <use
       xlink:href="#K"
       x="53.514"
       y="-0.003"
       class="I"
       id="use30" />
    <path
       d="M 237.135,96.582 H 199.34 l 9.633,-37.776 h 37.796 z"
       class="K"
       id="path31" />
    <use
       xlink:href="#K"
       x="43.880001"
       y="37.772999"
       class="J"
       id="use31" />
    <use
       xlink:href="#K"
       x="34.245998"
       y="75.550003"
       fill="#ff0107"
       id="use32" />
  </g>
</svg>
\" alt=\"Embeddings Mistral Cloud\" title=\"Embeddings Mistral Cloud\"><img src=\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSI3NjgiIGhlaWdodD0iMTAyNCI+PHBhdGggZmlsbD0iIzdEN0Q4NyIgZD0iTTAgOTYwVjY0aDU3NmwxOTIgMTkydjcwNHptNzA0LTY0MEw1MTIgMTI4SDY0djc2OGg2NDB6TTMyMCA1MTJIMTI4VjI1NmgxOTJ6bS02NC0xOTJoLTY0djEyOGg2NHptMCA0NDhoNjR2NjRIMTI4di02NGg2NFY2NDBoLTY0di02NGgxMjh6bTI1Ni0zMjBoNjR2NjRIMzg0di02NGg2NFYzMjBoLTY0di02NGgxMjh6bTY0IDM4NEgzODRWNTc2aDE5MnptLTY0LTE5MmgtNjR2MTI4aDY0eiIvPjwvc3ZnPg==\" alt=\"Default Data Loader\" title=\"Default Data Loader\">\n          <i class=\"fa fa-grip-lines-vertical\" aria-hidden=\"true\"></i>\n        <img src=\"data:image/svg+xml;base64,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\" alt=\"HTTP Request\" title=\"HTTP Request\">\n          <span>+5</span>\n        </div>\n        <div class=\"workflow-details\">\n          <p class=\"workflow-details-name\">\n            <a href=\"https://n8n.io/workflows/2341-build-a-tax-code-assistant-with-qdrant-mistralai-and-openai/\" class=\"blog-banner-workflow\">Build a Tax Code Assistant with Qdrant, Mistral.ai and OpenAI</a>\n          </p>\n          <p class=\"workflow-details-stats\">\n          <svg xmlns=\"http://www.w3.org/2000/svg\" width=\"12\" height=\"10\" fill=\"none\" viewBox=\"0 0 12 10\"><path fill=\"#707183\" d=\"M4.94 6.06a1.5 1.5 0 1 1 2.121-2.12 1.5 1.5 0 0 1-2.12 2.12Z\"></path><path fill=\"#707183\" fill-rule=\"evenodd\" d=\"M.462 6.143C1.38 7.135 3.294 9.2 6 9.2s4.62-2.065 5.539-3.057a1.703 1.703 0 0 0 0-2.332l-.001-.002C10.703 2.907 8.749.8 6 .8 3.256.8 1.304 2.903.466 3.806l-.004.005a1.703 1.703 0 0 0 0 2.332ZM3.77 3.305c.689-.38 1.447-.62 2.23-.705a5.88 5.88 0 0 1 3.972 2.17.301.301 0 0 1 0 .414A5.88 5.88 0 0 1 6 7.4 6.216 6.216 0 0 1 1.996 5.24a.3.3 0 0 1-.01-.423A5.937 5.937 0 0 1 3.77 3.305Z\" clip-rule=\"evenodd\"></path></svg>\n          8215 <span>â€¢</span> <strong>by jimleuk</strong> <span>â€¢</span> 10 months\n        </p>\n        </div>\n      </div>\n      <a href=\"https://n8n.io/workflows/2341-build-a-tax-code-assistant-with-qdrant-mistralai-and-openai/\" class=\"global-button blog-banner-workflow\">\n        Use this workflow\n      </a>\n    </div><div class=\"workflow\">\n      <div class=\"workflow-content\">\n        <div class=\"workflow-nodes\">\n          \n          <i class=\"fa fa-folder-open\" aria-hidden=\"true\" style=\"color:#404040\"></i>\n        \n          <i class=\"fa fa-mouse-pointer\" aria-hidden=\"true\" style=\"color:#909298\"></i>\n        \n          <i class=\"fa fa-pen\" aria-hidden=\"true\"></i>\n        \n          <i class=\"fa fa-sticky-note\" aria-hidden=\"true\" style=\"color:#FFD233\"></i>\n        <img src=\"data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iNTEyIiBoZWlnaHQ9IjUxMiIgdmlld0JveD0iMCAwIDUxMiA1MTIiIGZpbGw9Im5vbmUiIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyI+CjxnIGNsaXAtcGF0aD0idXJsKCNjbGlwMF8xMTQxXzE1NDcpIj4KPHBhdGggZD0iTTAgMTJDMCA1LjM3MjU4IDUuMzcyNTggMCAxMiAwSDE1OVYxNTRDMTU5IDE2MC42MjcgMTY0LjM3MyAxNjYgMTcxIDE2NkgzMjVWMjQySDIyOC41NjJDMjEwLjg5NSAyNDIgMTk0LjY1NiAyNTEuNzA1IDE4Ni4yODggMjY3LjI2NEwxMjkuMjAzIDM3My40MDdDMTI1LjEzMSAzODAuOTc4IDEyMyAzODkuNDQgMTIzIDM5OC4wMzdWNDM0SDEyQzUuMzcyNTcgNDM0IDAgNDI4LjYyNyAwIDQyMlYxMloiIGZpbGw9IiM0NEFBNDQiLz4KPHBhdGggZD0iTTMyNSAxMzRWMTI3LjQwMUMzMjUgMTI0LjIyMyAzMjMuNzQgMTIxLjE3NSAzMjEuNDk1IDExOC45MjVMMjA2LjM2OSAzLjUyNDgxQzIwNC4xMTggMS4yNjgyIDIwMS4wNjEgMCAxOTcuODczIDBIMTkxVjEzNEgzMjVaIiBmaWxsPSIjNDRBQTQ0Ii8+CjxwYXRoIGZpbGwtcnVsZT0iZXZlbm9kZCIgY2xpcC1ydWxlPSJldmVub2RkIiBkPSJNMjI4LjU2MyAyNzRDMjIyLjY3NCAyNzQgMjE3LjI2MSAyNzcuMjM1IDIxNC40NzIgMjgyLjQyMUwxNzIuMjExIDM2MUg0OTIuNjRMNDQ0LjY3IDI4MS43MTdDNDQxLjc3MiAyNzYuOTI3IDQzNi41OCAyNzQgNDMwLjk4MSAyNzRIMjI4LjU2M1oiIGZpbGw9IiM0NEFBNDQiLz4KPHBhdGggZmlsbC1ydWxlPSJldmVub2RkIiBjbGlwLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik0xNTUgNDA5QzE1NSA0MDAuMTYzIDE2Mi4xNjMgMzkzIDE3MSAzOTNINDk2QzUwNC44MzcgMzkzIDUxMiA0MDAuMTYzIDUxMiA0MDlWNDk2QzUxMiA1MDQuODM3IDUwNC44MzcgNTEyIDQ5NiA1MTJIMTcxQzE2Mi4xNjMgNTEyIDE1NSA1MDQuODM3IDE1NSA0OTZWNDA5Wk0zOTcgNDUzQzM5NyA0NjYuMjU1IDM4Ni4yNTUgNDc3IDM3MyA0NzdDMzU5Ljc0NSA0NzcgMzQ5IDQ2Ni4yNTUgMzQ5IDQ1M0MzNDkgNDM5Ljc0NSAzNTkuNzQ1IDQyOSAzNzMgNDI5QzM4Ni4yNTUgNDI5IDM5NyA0MzkuNzQ1IDM5NyA0NTNaTTQ0NSA0NzdDNDU4LjI1NSA0NzcgNDY5IDQ2Ni4yNTUgNDY5IDQ1M0M0NjkgNDM5Ljc0NSA0NTguMjU1IDQyOSA0NDUgNDI5QzQzMS43NDUgNDI5IDQyMSA0MzkuNzQ1IDQyMSA0NTNDNDIxIDQ2Ni4yNTUgNDMxLjc0NSA0NzcgNDQ1IDQ3N1oiIGZpbGw9IiM0NEFBNDQiLz4KPC9nPgo8ZGVmcz4KPGNsaXBQYXRoIGlkPSJjbGlwMF8xMTQxXzE1NDciPgo8cmVjdCB3aWR0aD0iNTEyIiBoZWlnaHQ9IjUxMiIgZmlsbD0id2hpdGUiLz4KPC9jbGlwUGF0aD4KPC9kZWZzPgo8L3N2Zz4K\" alt=\"Read/Write Files from Disk\" title=\"Read/Write Files from Disk\">\n          <span>+5</span>\n        </div>\n        <div class=\"workflow-details\">\n          <p class=\"workflow-details-name\">\n            <a href=\"https://n8n.io/workflows/2335-build-a-financial-documents-assistant-using-qdrant-and-mistralai/\" class=\"blog-banner-workflow\">Build a Financial Documents Assistant using Qdrant and Mistral.ai</a>\n          </p>\n          <p class=\"workflow-details-stats\">\n          <svg xmlns=\"http://www.w3.org/2000/svg\" width=\"12\" height=\"10\" fill=\"none\" viewBox=\"0 0 12 10\"><path fill=\"#707183\" d=\"M4.94 6.06a1.5 1.5 0 1 1 2.121-2.12 1.5 1.5 0 0 1-2.12 2.12Z\"></path><path fill=\"#707183\" fill-rule=\"evenodd\" d=\"M.462 6.143C1.38 7.135 3.294 9.2 6 9.2s4.62-2.065 5.539-3.057a1.703 1.703 0 0 0 0-2.332l-.001-.002C10.703 2.907 8.749.8 6 .8 3.256.8 1.304 2.903.466 3.806l-.004.005a1.703 1.703 0 0 0 0 2.332ZM3.77 3.305c.689-.38 1.447-.62 2.23-.705a5.88 5.88 0 0 1 3.972 2.17.301.301 0 0 1 0 .414A5.88 5.88 0 0 1 6 7.4 6.216 6.216 0 0 1 1.996 5.24a.3.3 0 0 1-.01-.423A5.937 5.937 0 0 1 3.77 3.305Z\" clip-rule=\"evenodd\"></path></svg>\n          15287 <span>â€¢</span> <strong>by jimleuk</strong> <span>â€¢</span> 10 months\n        </p>\n        </div>\n      </div>\n      <a href=\"https://n8n.io/workflows/2335-build-a-financial-documents-assistant-using-qdrant-and-mistralai/\" class=\"global-button blog-banner-workflow\">\n        Use this workflow\n      </a>\n    </div><div class=\"workflow\">\n      <div class=\"workflow-content\">\n        <div class=\"workflow-nodes\">\n          \n          <i class=\"fa fa-folder-open\" aria-hidden=\"true\" style=\"color:#404040\"></i>\n        <img src=\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSI3NjgiIGhlaWdodD0iMTAyNCI+PHBhdGggZmlsbD0iIzdEN0Q4NyIgZD0iTTAgOTYwVjY0aDU3NmwxOTIgMTkydjcwNHptNzA0LTY0MEw1MTIgMTI4SDY0djc2OGg2NDB6TTMyMCA1MTJIMTI4VjI1NmgxOTJ6bS02NC0xOTJoLTY0djEyOGg2NHptMCA0NDhoNjR2NjRIMTI4di02NGg2NFY2NDBoLTY0di02NGgxMjh6bTI1Ni0zMjBoNjR2NjRIMzg0di02NGg2NFYzMjBoLTY0di02NGgxMjh6bTY0IDM4NEgzODRWNTc2aDE5MnptLTY0LTE5MmgtNjR2MTI4aDY0eiIvPjwvc3ZnPg==\" alt=\"Default Data Loader\" title=\"Default Data Loader\">\n          <i class=\"fa fa-grip-lines-vertical\" aria-hidden=\"true\"></i>\n        <img src=\"data:image/svg+xml;base64,<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<svg
   width="216"
   height="216"
   version="1.1"
   id="svg41"
   sodipodi:docname="mistral.svg"
   inkscape:version="1.3.2 (091e20ef0f, 2023-11-25, custom)"
   xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"
   xmlns:sodipodi="http://sodipodi.sourceforge.net/DTD/sodipodi-0.dtd"
   xmlns:xlink="http://www.w3.org/1999/xlink"
   xmlns="http://www.w3.org/2000/svg"
   xmlns:svg="http://www.w3.org/2000/svg">
  <sodipodi:namedview
     id="namedview41"
     pagecolor="#ffffff"
     bordercolor="#000000"
     borderopacity="0.25"
     inkscape:showpageshadow="2"
     inkscape:pageopacity="0.0"
     inkscape:pagecheckerboard="0"
     inkscape:deskcolor="#d1d1d1"
     inkscape:zoom="1.936488"
     inkscape:cx="197.78072"
     inkscape:cy="79.00901"
     inkscape:window-width="1920"
     inkscape:window-height="1017"
     inkscape:window-x="0"
     inkscape:window-y="0"
     inkscape:window-maximized="1"
     inkscape:current-layer="svg41" />
  <style
     id="style1"><![CDATA[.I{fill:#ff7000}.J{fill:#ff4900}.K{fill:#ffa300}.L{fill:#1c1c1b icc-color(adobe-rgb-1998, 0.13299561, 0.13299561, 0.1289978)}]]></style>
  <defs
     id="defs10">
    <clipPath
       id="A">
      <path
         d="M 0,184.252 H 481.89 V 0 H 0 Z"
         transform="translate(-206.251,-140.139)"
         id="path1" />
    </clipPath>
    <clipPath
       id="B">
      <path
         d="M 0,184.252 H 481.89 V 0 H 0 Z"
         transform="translate(-247.436,-104.865)"
         id="path2" />
    </clipPath>
    <clipPath
       id="C">
      <path
         d="M 0,184.252 H 481.89 V 0 H 0 Z"
         transform="translate(-285.938,-102.089)"
         id="path3" />
    </clipPath>
    <clipPath
       id="D">
      <path
         d="M 0,184.252 H 481.89 V 0 H 0 Z"
         transform="translate(-337.769,-131.877)"
         id="path4" />
    </clipPath>
    <clipPath
       id="E">
      <path
         d="M 0,184.252 H 481.89 V 0 H 0 Z"
         transform="translate(-377.247,-132.319)"
         id="path5" />
    </clipPath>
    <clipPath
       id="F">
      <path
         d="M 0,184.252 H 481.89 V 0 H 0 Z"
         transform="translate(-418.107,-114.634)"
         id="path6" />
    </clipPath>
    <clipPath
       id="G">
      <path
         d="M 0,184.252 H 481.89 V 0 H 0 Z"
         transform="translate(-450.023,-140.139)"
         id="path7" />
    </clipPath>
    <clipPath
       id="H">
      <path
         d="M 0,184.252 H 481.89 V 0 H 0 Z"
         transform="translate(-217.694,-44.794)"
         id="path8" />
    </clipPath>
    <clipPath
       id="I">
      <path
         d="M 0,184.252 H 481.89 V 0 H 0 Z"
         transform="translate(-247.436,-35.025)"
         id="path9" />
    </clipPath>
    <clipPath
       id="J">
      <path
         d="M 0,184.252 H 481.89 V 0 H 0 Z"
         id="path10" />
    </clipPath>
    <path
       id="K"
       d="m 173.987,134.362 h -37.795 l 9.633,-37.776 h 37.796 z" />
  </defs>
  <g
     transform="matrix(1,0,0.254535,1,-51.362792,-7.4725007)"
     id="g32">
    <g
       class="L"
       id="g22">
      <path
         d="M 98.397,134.362 H 60.602 l 9.633,-37.776 h 37.796 z"
         id="path11" />
      <path
         d="M 126.558,172.138 H 88.763 l 9.633,-37.776 h 37.796 z"
         id="path12" />
      <path
         d="M 136.192,134.362 H 98.397 l 9.633,-37.776 h 37.796 z"
         id="path13" />
      <use
         xlink:href="#K"
         id="use13" />
      <path
         d="M 108.031,96.585 H 70.236 l 9.633,-37.776 h 37.796 z"
         id="path14" />
      <use
         xlink:href="#K"
         x="9.6339998"
         y="-37.777"
         id="use14" />
      <path
         d="M 60.602,134.362 H 22.807 L 32.44,96.586 h 37.796 z"
         id="path15" />
      <path
         d="M 70.236,96.585 H 32.441 L 42.074,58.809 H 79.87 Z"
         id="path16" />
      <path
         d="M 79.87,58.809 H 42.075 l 9.633,-37.776 h 37.796 z"
         id="path17" />
      <use
         xlink:href="#K"
         x="57.063"
         y="-75.553001"
         id="use17" />
      <path
         d="M 50.968,172.138 H 13.173 l 9.633,-37.776 h 37.796 z"
         id="path18" />
      <path
         d="M 41.334,209.915 H 3.539 l 9.633,-37.776 h 37.796 z"
         id="path19" />
      <use
         xlink:href="#K"
         x="37.794998"
         id="use19" />
      <use
         xlink:href="#K"
         x="47.429001"
         y="-37.777"
         id="use20" />
      <use
         xlink:href="#K"
         x="28.160999"
         y="37.776001"
         id="use21" />
      <use
         xlink:href="#K"
         x="18.527"
         y="75.553001"
         id="use22" />
    </g>
    <path
       d="M 114.115,134.359 H 76.321 l 9.633,-37.776 h 37.796 z"
       class="I"
       id="path22" />
    <use
       xlink:href="#K"
       x="-31.709999"
       y="37.772999"
       class="J"
       id="use23" />
    <g
       class="I"
       id="g25">
      <use
         xlink:href="#K"
         x="-22.076"
         y="-0.003"
         id="use24" />
      <use
         xlink:href="#K"
         x="15.719"
         y="-0.003"
         id="use25" />
    </g>
    <g
       class="K"
       id="g26">
      <path
         d="M 123.749,96.582 H 85.955 l 9.633,-37.776 h 37.796 z"
         id="path25" />
      <use
         xlink:href="#K"
         x="25.353001"
         y="-37.779999"
         id="use26" />
    </g>
    <path
       d="M 76.32,134.359 H 38.526 l 9.633,-37.776 h 37.796 z"
       class="I"
       id="path26" />
    <path
       d="M 85.954,96.582 H 48.16 l 9.633,-37.776 h 37.796 z"
       class="K"
       id="path27" />
    <g
       fill="#ffce00"
       id="g28">
      <path
         d="M 95.588,58.806 H 57.794 L 67.427,21.03 h 37.796 z"
         id="path28" />
      <use
         xlink:href="#K"
         x="72.781998"
         y="-75.556"
         id="use28" />
    </g>
    <path
       d="M 66.686,172.135 H 28.892 l 9.633,-37.776 h 37.796 z"
       class="J"
       id="path29" />
    <path
       d="M 57.052,209.912 H 19.258 l 9.633,-37.776 h 37.796 z"
       fill="#ff0107"
       id="path30" />
    <use
       xlink:href="#K"
       x="53.514"
       y="-0.003"
       class="I"
       id="use30" />
    <path
       d="M 237.135,96.582 H 199.34 l 9.633,-37.776 h 37.796 z"
       class="K"
       id="path31" />
    <use
       xlink:href="#K"
       x="43.880001"
       y="37.772999"
       class="J"
       id="use31" />
    <use
       xlink:href="#K"
       x="34.245998"
       y="75.550003"
       fill="#ff0107"
       id="use32" />
  </g>
</svg>
\" alt=\"Embeddings Mistral Cloud\" title=\"Embeddings Mistral Cloud\"><img src=\"data:image/svg+xml;base64,<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<svg
   width="216"
   height="216"
   version="1.1"
   id="svg41"
   sodipodi:docname="mistral.svg"
   inkscape:version="1.3.2 (091e20ef0f, 2023-11-25, custom)"
   xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"
   xmlns:sodipodi="http://sodipodi.sourceforge.net/DTD/sodipodi-0.dtd"
   xmlns:xlink="http://www.w3.org/1999/xlink"
   xmlns="http://www.w3.org/2000/svg"
   xmlns:svg="http://www.w3.org/2000/svg">
  <sodipodi:namedview
     id="namedview41"
     pagecolor="#ffffff"
     bordercolor="#000000"
     borderopacity="0.25"
     inkscape:showpageshadow="2"
     inkscape:pageopacity="0.0"
     inkscape:pagecheckerboard="0"
     inkscape:deskcolor="#d1d1d1"
     inkscape:zoom="1.936488"
     inkscape:cx="197.78072"
     inkscape:cy="79.00901"
     inkscape:window-width="1920"
     inkscape:window-height="1017"
     inkscape:window-x="0"
     inkscape:window-y="0"
     inkscape:window-maximized="1"
     inkscape:current-layer="svg41" />
  <style
     id="style1"><![CDATA[.I{fill:#ff7000}.J{fill:#ff4900}.K{fill:#ffa300}.L{fill:#1c1c1b icc-color(adobe-rgb-1998, 0.13299561, 0.13299561, 0.1289978)}]]></style>
  <defs
     id="defs10">
    <clipPath
       id="A">
      <path
         d="M 0,184.252 H 481.89 V 0 H 0 Z"
         transform="translate(-206.251,-140.139)"
         id="path1" />
    </clipPath>
    <clipPath
       id="B">
      <path
         d="M 0,184.252 H 481.89 V 0 H 0 Z"
         transform="translate(-247.436,-104.865)"
         id="path2" />
    </clipPath>
    <clipPath
       id="C">
      <path
         d="M 0,184.252 H 481.89 V 0 H 0 Z"
         transform="translate(-285.938,-102.089)"
         id="path3" />
    </clipPath>
    <clipPath
       id="D">
      <path
         d="M 0,184.252 H 481.89 V 0 H 0 Z"
         transform="translate(-337.769,-131.877)"
         id="path4" />
    </clipPath>
    <clipPath
       id="E">
      <path
         d="M 0,184.252 H 481.89 V 0 H 0 Z"
         transform="translate(-377.247,-132.319)"
         id="path5" />
    </clipPath>
    <clipPath
       id="F">
      <path
         d="M 0,184.252 H 481.89 V 0 H 0 Z"
         transform="translate(-418.107,-114.634)"
         id="path6" />
    </clipPath>
    <clipPath
       id="G">
      <path
         d="M 0,184.252 H 481.89 V 0 H 0 Z"
         transform="translate(-450.023,-140.139)"
         id="path7" />
    </clipPath>
    <clipPath
       id="H">
      <path
         d="M 0,184.252 H 481.89 V 0 H 0 Z"
         transform="translate(-217.694,-44.794)"
         id="path8" />
    </clipPath>
    <clipPath
       id="I">
      <path
         d="M 0,184.252 H 481.89 V 0 H 0 Z"
         transform="translate(-247.436,-35.025)"
         id="path9" />
    </clipPath>
    <clipPath
       id="J">
      <path
         d="M 0,184.252 H 481.89 V 0 H 0 Z"
         id="path10" />
    </clipPath>
    <path
       id="K"
       d="m 173.987,134.362 h -37.795 l 9.633,-37.776 h 37.796 z" />
  </defs>
  <g
     transform="matrix(1,0,0.254535,1,-51.362792,-7.4725007)"
     id="g32">
    <g
       class="L"
       id="g22">
      <path
         d="M 98.397,134.362 H 60.602 l 9.633,-37.776 h 37.796 z"
         id="path11" />
      <path
         d="M 126.558,172.138 H 88.763 l 9.633,-37.776 h 37.796 z"
         id="path12" />
      <path
         d="M 136.192,134.362 H 98.397 l 9.633,-37.776 h 37.796 z"
         id="path13" />
      <use
         xlink:href="#K"
         id="use13" />
      <path
         d="M 108.031,96.585 H 70.236 l 9.633,-37.776 h 37.796 z"
         id="path14" />
      <use
         xlink:href="#K"
         x="9.6339998"
         y="-37.777"
         id="use14" />
      <path
         d="M 60.602,134.362 H 22.807 L 32.44,96.586 h 37.796 z"
         id="path15" />
      <path
         d="M 70.236,96.585 H 32.441 L 42.074,58.809 H 79.87 Z"
         id="path16" />
      <path
         d="M 79.87,58.809 H 42.075 l 9.633,-37.776 h 37.796 z"
         id="path17" />
      <use
         xlink:href="#K"
         x="57.063"
         y="-75.553001"
         id="use17" />
      <path
         d="M 50.968,172.138 H 13.173 l 9.633,-37.776 h 37.796 z"
         id="path18" />
      <path
         d="M 41.334,209.915 H 3.539 l 9.633,-37.776 h 37.796 z"
         id="path19" />
      <use
         xlink:href="#K"
         x="37.794998"
         id="use19" />
      <use
         xlink:href="#K"
         x="47.429001"
         y="-37.777"
         id="use20" />
      <use
         xlink:href="#K"
         x="28.160999"
         y="37.776001"
         id="use21" />
      <use
         xlink:href="#K"
         x="18.527"
         y="75.553001"
         id="use22" />
    </g>
    <path
       d="M 114.115,134.359 H 76.321 l 9.633,-37.776 h 37.796 z"
       class="I"
       id="path22" />
    <use
       xlink:href="#K"
       x="-31.709999"
       y="37.772999"
       class="J"
       id="use23" />
    <g
       class="I"
       id="g25">
      <use
         xlink:href="#K"
         x="-22.076"
         y="-0.003"
         id="use24" />
      <use
         xlink:href="#K"
         x="15.719"
         y="-0.003"
         id="use25" />
    </g>
    <g
       class="K"
       id="g26">
      <path
         d="M 123.749,96.582 H 85.955 l 9.633,-37.776 h 37.796 z"
         id="path25" />
      <use
         xlink:href="#K"
         x="25.353001"
         y="-37.779999"
         id="use26" />
    </g>
    <path
       d="M 76.32,134.359 H 38.526 l 9.633,-37.776 h 37.796 z"
       class="I"
       id="path26" />
    <path
       d="M 85.954,96.582 H 48.16 l 9.633,-37.776 h 37.796 z"
       class="K"
       id="path27" />
    <g
       fill="#ffce00"
       id="g28">
      <path
         d="M 95.588,58.806 H 57.794 L 67.427,21.03 h 37.796 z"
         id="path28" />
      <use
         xlink:href="#K"
         x="72.781998"
         y="-75.556"
         id="use28" />
    </g>
    <path
       d="M 66.686,172.135 H 28.892 l 9.633,-37.776 h 37.796 z"
       class="J"
       id="path29" />
    <path
       d="M 57.052,209.912 H 19.258 l 9.633,-37.776 h 37.796 z"
       fill="#ff0107"
       id="path30" />
    <use
       xlink:href="#K"
       x="53.514"
       y="-0.003"
       class="I"
       id="use30" />
    <path
       d="M 237.135,96.582 H 199.34 l 9.633,-37.776 h 37.796 z"
       class="K"
       id="path31" />
    <use
       xlink:href="#K"
       x="43.880001"
       y="37.772999"
       class="J"
       id="use31" />
    <use
       xlink:href="#K"
       x="34.245998"
       y="75.550003"
       fill="#ff0107"
       id="use32" />
  </g>
</svg>
\" alt=\"Mistral Cloud Chat Model\" title=\"Mistral Cloud Chat Model\">\n          <span>+5</span>\n        </div>\n        <div class=\"workflow-details\">\n          <p class=\"workflow-details-name\">\n            <a href=\"https://n8n.io/workflows/2339-breakdown-documents-into-study-notes-using-templating-mistralai-and-qdrant/\" class=\"blog-banner-workflow\">Breakdown Documents into Study Notes using Templating MistralAI and Qdrant</a>\n          </p>\n          <p class=\"workflow-details-stats\">\n          <svg xmlns=\"http://www.w3.org/2000/svg\" width=\"12\" height=\"10\" fill=\"none\" viewBox=\"0 0 12 10\"><path fill=\"#707183\" d=\"M4.94 6.06a1.5 1.5 0 1 1 2.121-2.12 1.5 1.5 0 0 1-2.12 2.12Z\"></path><path fill=\"#707183\" fill-rule=\"evenodd\" d=\"M.462 6.143C1.38 7.135 3.294 9.2 6 9.2s4.62-2.065 5.539-3.057a1.703 1.703 0 0 0 0-2.332l-.001-.002C10.703 2.907 8.749.8 6 .8 3.256.8 1.304 2.903.466 3.806l-.004.005a1.703 1.703 0 0 0 0 2.332ZM3.77 3.305c.689-.38 1.447-.62 2.23-.705a5.88 5.88 0 0 1 3.972 2.17.301.301 0 0 1 0 .414A5.88 5.88 0 0 1 6 7.4 6.216 6.216 0 0 1 1.996 5.24a.3.3 0 0 1-.01-.423A5.937 5.937 0 0 1 3.77 3.305Z\" clip-rule=\"evenodd\"></path></svg>\n          19670 <span>â€¢</span> <strong>by jimleuk</strong> <span>â€¢</span> 10 months\n        </p>\n        </div>\n      </div>\n      <a href=\"https://n8n.io/workflows/2339-breakdown-documents-into-study-notes-using-templating-mistralai-and-qdrant/\" class=\"global-button blog-banner-workflow\">\n        Use this workflow\n      </a>\n    </div>\n    <div class=\"workflows-button\">\n      <a href=\"https://app.n8n.cloud/register\" class=\"global-button blog-banner-signup\">\n        Get started\n      </a>\n    </div>\n  </div>\n<!--kg-card-end: html-->\n<h2 id=\"what-is-a-local-llm\">What is a local LLM?</h2><p>A local LLM is simply a large language model that runs locally, on your computer, eliminating the need to send your data to a cloud provider. This means you can harness the power of an LLM while maintaining full control over your sensitive information, ensuring privacy and security.</p><p>By running an LLM locally, you have the freedom to experiment, customize, and fine-tune the model to your specific needs without external dependencies. You can choose from a wide range of open-source models, tailor them to your specific tasks, and even experiment with different configurations to optimize performance.</p><p>While there might be upfront costs for suitable hardware, you can avoid the recurring expenses associated with API calls, potentially leading to significant savings in the long run. This makes local LLMs a more cost-effective solution, especially for high-volume usage.</p><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-emoji\">ðŸ’¡</div><div class=\"kg-callout-text\">Looking for the fastest way to build your own self-hosted AI workflows? Use&nbsp;<a href=\"https://blog.n8n.io/self-hosted-ai/\">this self-hosted AI kit</a>, an easy-to-deploy docker compose template that includes n8n and a selection of best-in-class local AI tools.&nbsp;</div></div><h2 id=\"can-i-run-llm-locally\">Can I run LLM locally?</h2><p>So, you're probably wondering, \"Can I actually run an LLM on my local workstation?\". The good news is that you likely can do so if you have a relatively modern laptop or desktop! However, some hardware considerations can significantly impact the speed of prompt answering and overall performance.</p><p>Letâ€™s look at 3 components youâ€™ll need to experiment with local LLMs.</p><h3 id=\"hardware-requirements\">Hardware requirements</h3><p>While not strictly necessary, having a PC or laptop with a dedicated graphics card is highly recommended. This will significantly improve the performance of LLMs, as they can leverage the GPU for faster computations. Without a dedicated GPU, LLMs might run quite slowly, making them impractical for real-world use.</p><p>The GPU's video RAM (vRAM) plays a pivotal role here: it determines the maximum size and complexity of the LLM that can be loaded and processed efficiently. More vRAM allows larger models to fit entirely on the GPU, leading to significantly faster speeds, as accessing model parameters from vRAM is orders of magnitude quicker than from standard system RAM.</p><p>LLMs can be quite resource-intensive, so it's essential to have enough RAM and storage space to accommodate them. The exact requirements will vary depending on the specific LLM you choose, but having at least 16GB of RAM and a decent amount of free disk space is a good starting point.</p><h3 id=\"software-requirements\">Software requirements</h3><p>Besides the hardware, you also need the right software to effectively run and manage LLMs locally. This software generally falls into three categories:</p><ul><li>Servers: these run and manage LLMs in the background, handling tasks like loading models, processing requests, and generating responses. They provide the essential infrastructure for your LLMs. Some examples are&nbsp;<a href=\"https://ollama.com/?ref=blog.n8n.io\" rel=\"noopener\" target=\"_blank\">Ollama</a>&nbsp;and&nbsp;<a href=\"https://github.com/Mozilla-Ocho/llamafile?ref=blog.n8n.io\" rel=\"noopener\" target=\"_blank\">Lalamafile</a>.</li><li>User interfaces: these provide a visual way to interact with your LLMs. They allow you to input prompts, view generated text, and potentially customize the model's behavior. User interfaces make it easier to experiment with LLMs. Some examples are&nbsp;<a href=\"https://openwebui.com/?ref=blog.n8n.io\" rel=\"noopener\" target=\"_blank\">OpenWebUI</a>&nbsp;and&nbsp;<a href=\"https://github.com/lobehub/lobe-chat?ref=blog.n8n.io\" rel=\"noopener\" target=\"_blank\">LobeChat</a>.</li><li>Full-stack solutions: these are all-in-one tools that combine the server and the user interface components. They handle everything from model management to processing and provide a built-in visual interface for interacting with the LLMs. They are particularly suitable for users who prefer a simplified setup. Some examples are&nbsp;<a href=\"https://www.nomic.ai/gpt4all?ref=blog.n8n.io\" rel=\"noopener\" target=\"_blank\">GPT4All</a>&nbsp;and&nbsp;<a href=\"https://jan.ai/?ref=blog.n8n.io\" rel=\"noopener\" target=\"_blank\">Jan</a>.</li></ul><h3 id=\"open-source-llms\">Open source LLMs</h3><p>Last, but not least, you need the LLMs themselves. These are the large language models that will process your prompts and generate text. There are many different LLMs available, each with its own strengths and weaknesses. Some are better at generating creative text formats, while others are suited for writing code.</p><p>Where can you download the LLMs from? One popular source for open-source LLMs is Hugging Face. They have a large repository of models that you can download and use for free.</p><p>Next, let's look at what are some of the most popular LLMs to get started with.</p><h2 id=\"which-llms-to-run-locally\">Which LLMs to run locally?</h2><p>The landscape of LLMs you can run on your own hardware is rapidly expanding, with newer, more capable, or more specialized models being released every day!</p><p>Many powerful open-source models are available, catering to a wide range of tasks and computational resources. Let's explore some popular options, categorized by their general capabilities and specializations!</p><h3 id=\"general-purpose-model-families\">General-purpose model families</h3><p>Several families of models have gained significant popularity in the open-source community due to their strong performance across various benchmarks and tasks.</p><ul><li><strong>Llama (Meta AI):</strong> The Llama series, particularly Llama 3 and its variants, are highly capable models known for their strong reasoning and general text generation abilities. They come in various sizes, making them adaptable to different hardware setups. The newest iteration, Llama 4, has been released, however, its size exceeds the capabilities of standard hardware for now.</li><li><strong>Qwen (Alibaba Cloud):</strong> The Qwen family offers a range of models, including multilingual capabilities and versions optimized for coding. They are recognized for their performance, and tool calling abilities. Qwen 2.5 has extremely good performance, especially compared to its size. The recently launched Qwen 3 is even better across benchmarks!</li><li><strong>DeepSeek:</strong> DeepSeek models, including the DeepSeek-R1 series, are often highlighted for their reasoning and coding proficiency. They provide strong open-source alternatives with competitive performance.</li><li><strong>Phi (Microsoft):</strong> Microsoft's Phi models focus on achieving high performance with smaller parameter counts, making them excellent candidates for resource-constrained local setups while still offering surprising capabilities, particularly in reasoning and coding.</li><li><strong>Gemma (Google):</strong> Gemma models represent a family of lightweight, state-of-the-art open models built from the same research and technology used to create Gemini models. They are designed to run on a single GPU making them ideal for local deployment! The latest iteration, Gemma 3, offers various sizes (e.g., 1B, 4B, 12B and 27B parameters) and is known for strong general performance, especially considering model size.</li><li><strong>Mistral (Mistral AI)</strong>: Mistral AI, a French company, offers a popular family of powerful and efficient open-source models (many under Apache 2.0 license), including the influential Mistral 7B and various Mixtral (Mixture of Experts) versions. These models are known for strong performance in reasoning and coding, come in diverse sizes suitable for local setups, and are praised for their efficiency.</li><li><strong>Granite (IBM):</strong> IBM's Granite models are another family available for open use. The Granite 3.3 iteration, for example, offers variants with 2B and 8B parameters, providing options suitable for different local hardware configurations.</li></ul><h3 id=\"models-with-advanced-capabilities\">Models with advanced capabilities</h3><p>Beyond general text generation, many open-source models excel in specific advanced capabilities:</p><ul><li><strong>Reasoning models:</strong> Models like DeepSeek-R1 and specific fine-tunes of Llama or Mistral are often optimized for complex reasoning, problem-solving, and logical deduction tasks. Microsoftâ€™s Phi family of models also offer reasoning variants, in the form of <code>phi4-reasoning</code> and <code>phi4-mini-reasoning</code>.</li><li><strong>Mixture-of-experts (MoE):</strong> This architecture allows models to scale efficiently by activating only relevant \"expert\" parts of the network for a given input. Qwen 3 is a MoE model, and Granite also has a MoE variant in the form of <code>granite3.1-moe</code>.</li><li><strong>Tool calling models:</strong> The ability for an LLM to use external tools (like APIs or functions) is fundamental to building agentic AI systems. Models are increasingly being trained or fine-tuned with tool-calling capabilities, allowing them to interact with external systems to gather information or perform actions. Frameworks like LangChain or LlamaIndex often facilitate this when running models locally. Examples include <code>qwen3</code>, <code>granite3.3</code>, <code>mistral-small3.1</code> and <code>phi4-mini</code>.</li><li><strong>Vision models:</strong> sometimes also called <strong>multimodal </strong>models, are models that can understand and interpret images alongside text. They are becoming more common in the open-source space. Examples include Granite3.2-vision, <code>llama3.2-vision</code>, <code>llava-phi3</code>, and <code>BakLLaVA</code> (which is derived from Mistral 7B).</li></ul><h3 id=\"models-that-excel-at-specific-tasks\">Models that excel at specific tasks</h3><p>Sometimes, you need a model fine-tuned for a particular domain or task for optimal performance.</p><ol><li>Coding assistants:</li></ol><ul><li><strong>DeepCoder: </strong>A fully open-source family (1.5B and 14B parameters) aimed at high-performance code generation.</li><li><strong>OpenCoder</strong>: An open and reproducible code LLM family (1.5B and 8B models) supporting chat in English and Chinese.</li><li><strong>Qwen2.5-Coder</strong>: Part of the Qwen family, specifically optimized for code-related tasks.</li></ul><ol start=\"2\"><li>Math and research</li></ol><ul><li><strong>Starling-LM-11B-alpha</strong>: Mistral-based model for research and instruction-following.</li><li><strong>Mathstral</strong>: Specialized Mistral AI model for advanced mathematical reasoning.</li><li><strong>Qwen2-math: </strong>Part of the Qwen family, specifically optimized for complex mathematical problem-solving.</li></ul><ol start=\"3\"><li>Creative writing</li></ol><ul><li><strong>Mistral-7B-OpenOrca</strong>: A fine-tuned version of Mistral AI's base Mistral-7B model, specifically enhanced by training on a curated selection of the OpenOrca dataset.</li></ul><p>Choosing the right open-source model depends heavily on your specific needs, the tasks you want to perform, and the hardware you have available. Experimenting with different models is often the best way to find the perfect fit for your local LLM setup.</p><h2 id=\"how-to-run-llms-locally\">How to run LLMs locally?</h2><p>To run LLMs locally, the first step is choosing which model best fits your needs. Once you've selected a model, the next decision is how to run itâ€”most commonly using software like Ollama. However, Ollama isnâ€™t your only option. There are several other powerful and user-friendly tools available for running local LLMs, each with its own strengths.</p><p>Letâ€™s explore some of the most popular choices below!</p><h3 id=\"ollama-openwebui\">Ollama (+ OpenWebUI)</h3><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://blog.n8n.io/content/images/2025/05/ollama.webp\" class=\"kg-image lightense-target\" alt=\"Ollama homepage\" loading=\"lazy\" width=\"2000\" height=\"1202\" srcset=\"https://blog.n8n.io/content/images/size/w600/2025/05/ollama.webp 600w, https://blog.n8n.io/content/images/size/w1000/2025/05/ollama.webp 1000w, https://blog.n8n.io/content/images/size/w1600/2025/05/ollama.webp 1600w, https://blog.n8n.io/content/images/size/w2400/2025/05/ollama.webp 2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">Ollama homepage</span></figcaption></figure><p><a href=\"https://ollama.com/?ref=blog.n8n.io\" rel=\"noopener\" target=\"_blank\">Ollama&nbsp;</a>is a command-line tool that simplifies the process of downloading and running LLMs locally. It has a simple set of commands for managing models, making it easy to get started.</p><p>Ollama is ideal for quickly trying out different open-source LLMs, especially for users comfortable with the command line. Itâ€™s also the go-to tool for homelab and self-hosting enthusiasts who can use Ollama as an AI backend for various applications.</p><p>While Ollama itself is primarily a command-line tool, you can enhance its usability by pairing it with&nbsp;<a href=\"https://github.com/open-webui/open-webui?ref=blog.n8n.io\" rel=\"noopener\" target=\"_blank\">OpenWebUI</a>, which provides a graphical interface for interacting with your LLMs.</p><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-emoji\">ðŸ’¡</div><div class=\"kg-callout-text\">Connect your local Ollama setup to n8n and start using your downloaded LLMs in any of your automation workflows! Check out this YouTube video to see <a href=\"https://www.youtube.com/watch?v=y9m3i12qkms&amp;ref=blog.n8n.io\" target=\"_blank\" rel=\"noopener\"><u>how to create a local AI agent for free with n8n and Ollama</u></a>.</div></div><h4 id=\"pros\">Pros</h4><ul><li>Simple and easy to use</li><li>Supports a wide range of open-source models</li><li>Runs on most hardware and major operating systems</li></ul><h4 id=\"cons\">Cons</h4><ul><li>Primarily command-line based (without OpenWebUI), which may not be suitable for all users.</li></ul><h3 id=\"lm-studio\">LM Studio</h3><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://blog.n8n.io/content/images/2025/05/lmstudio.webp\" class=\"kg-image lightense-target\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"1007\" srcset=\"https://blog.n8n.io/content/images/size/w600/2025/05/lmstudio.webp 600w, https://blog.n8n.io/content/images/size/w1000/2025/05/lmstudio.webp 1000w, https://blog.n8n.io/content/images/size/w1600/2025/05/lmstudio.webp 1600w, https://blog.n8n.io/content/images/size/w2400/2025/05/lmstudio.webp 2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">LM Studio homepage</span></figcaption></figure><p><a href=\"https://lmstudio.ai/?ref=blog.n8n.io\" rel=\"noopener\" target=\"_blank\">LM Studio</a>&nbsp;is a platform designed to make it easy to run and experiment with LLMs locally. It offers a range of tools for customizing and fine-tuning your LLMs, allowing you to optimize their performance for specific tasks.</p><p>It is excellent for customizing and fine-tuning LLMs for specific tasks, making it a favorite among researchers and developers seeking granular control over their AI solutions.</p><h4 id=\"pros-1\">Pros</h4><ul><li>Model customization options</li><li>Ability to fine-tune LLMs</li><li>Track and compare the performance of different models and configurations to identify the best approach for your use case.</li><li>Runs on most hardware and major operating systems</li></ul><h4 id=\"cons-1\">Cons</h4><ul><li>Steeper learning curve compared to other tools</li><li>Fine-tuning and experimenting with LLMs can demand significant computational resources.</li></ul><h3 id=\"jan\">Jan</h3><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://blog.n8n.io/content/images/2025/05/jan.webp\" class=\"kg-image lightense-target\" alt=\"Jan chat interface\" loading=\"lazy\" width=\"2000\" height=\"1109\" srcset=\"https://blog.n8n.io/content/images/size/w600/2025/05/jan.webp 600w, https://blog.n8n.io/content/images/size/w1000/2025/05/jan.webp 1000w, https://blog.n8n.io/content/images/size/w1600/2025/05/jan.webp 1600w, https://blog.n8n.io/content/images/size/w2400/2025/05/jan.webp 2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">Jan chat interface</span></figcaption></figure><p><a href=\"https://jan.ai/?ref=blog.n8n.io\" rel=\"noopener\" target=\"_blank\">Jan</a>&nbsp;is another noteworthy option for running LLMs locally. It places a strong emphasis on privacy and security. It can be used to interact with both local and remote (cloud-based) LLMs.</p><p>One of Jan's unique features is its flexibility in terms of server options. While it offers its own local server, Jan can also integrate with Ollama and LM Studio, utilizing them as remote servers. This is particularly useful when you want to use Jan as a client and have LLMs running on a more powerful server.</p><h4 id=\"pros-2\">Pros</h4><ul><li>Strong focus on privacy and security</li><li>Flexible server options, including integration with Ollama and LM Studio</li><li>Jan offers a user-friendly experience, even for those new to running LLMs locally</li></ul><h4 id=\"cons-2\">Cons</h4><ul><li>While compatible with most hardware, support for AMD GPUs is still in development.</li></ul><h3 id=\"gpt4all\">GPT4All</h3><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://blog.n8n.io/content/images/2025/05/gpt4all.webp\" class=\"kg-image lightense-target\" alt=\"GPT4All chat interface\" loading=\"lazy\" width=\"2000\" height=\"1386\" srcset=\"https://blog.n8n.io/content/images/size/w600/2025/05/gpt4all.webp 600w, https://blog.n8n.io/content/images/size/w1000/2025/05/gpt4all.webp 1000w, https://blog.n8n.io/content/images/size/w1600/2025/05/gpt4all.webp 1600w, https://blog.n8n.io/content/images/size/w2400/2025/05/gpt4all.webp 2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">GPT4All chat interface</span></figcaption></figure><p><a href=\"https://www.nomic.ai/gpt4all?ref=blog.n8n.io\" rel=\"noopener\" target=\"_blank\">GPT4All&nbsp;</a>is designed to be user-friendly, offering a chat-based interface that makes it easy to interact with the LLMs. It has out-of-the-box support for â€œLocalDocsâ€, a feature allowing you to chat privately and locally with your documents.</p><h4 id=\"pros-3\">Pros</h4><ul><li>Intuitive chat-based interface</li><li>Runs on most hardware and major operating systems</li><li>Open-source and community-driven</li><li>Enterprise edition available</li></ul><h4 id=\"cons-3\">Cons</h4><ul><li>May not be as feature-rich as some other options, lacking in areas such as model customization and fine-tuning.</li></ul><h3 id=\"nextchat\">NextChat</h3><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://blog.n8n.io/content/images/2025/05/nextchat.dev_.webp\" class=\"kg-image lightense-target\" alt=\"nextchat homepage\" loading=\"lazy\" width=\"2000\" height=\"1333\" srcset=\"https://blog.n8n.io/content/images/size/w600/2025/05/nextchat.dev_.webp 600w, https://blog.n8n.io/content/images/size/w1000/2025/05/nextchat.dev_.webp 1000w, https://blog.n8n.io/content/images/size/w1600/2025/05/nextchat.dev_.webp 1600w, https://blog.n8n.io/content/images/size/w2400/2025/05/nextchat.dev_.webp 2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">nextchat homepage</span></figcaption></figure><p><a href=\"https://nextchat.dev/?ref=blog.n8n.io\" rel=\"noopener\" target=\"_blank\">NextChat</a>&nbsp;is a versatile platform designed for building and deploying conversational AI experiences. Unlike the other options on this list, which primarily focus on running open-source LLMs locally, NextChat excels at integrating with closed-source models like ChatGPT and Google Gemini.</p><h4 id=\"pros-4\">Pros</h4><ul><li>Compatibility with a wide range of LLMs, including closed-source models</li><li>Robust tools for building and deploying conversational AI experiences</li><li>Enterprise-focused features and integrations</li></ul><h4 id=\"cons-4\">Cons</h4><ul><li>May be overkill for simple local LLM experimentation</li><li>Geared towards more complex conversational AI applications.</li></ul><h2 id=\"how-to-run-a-local-llm-with-n8n\">How to run a local LLM with n8n?</h2><p>Now that youâ€™re familiar with what local LLMs are, the hardware and software they require, and the most popular tools for running them on your machine, the next step is putting that power to work.</p><p>If you're looking to automate tasks, build intelligent workflows, or integrate LLMs into broader systems, <strong>n8n</strong> offers a flexible way to do just that.</p><p>In the following section, weâ€™ll walk through how to run a local LLM with n8nâ€”connecting your model, setting up a workflow, and chatting with it seamlessly using tools like Ollama.</p><div class=\"kg-card kg-callout-card kg-callout-card-blue\"><div class=\"kg-callout-emoji\">ðŸ’¡</div><div class=\"kg-callout-text\">To run a local LLM with n8n, use <a href=\"https://blog.n8n.io/self-hosted-ai/\" rel=\"noreferrer\">the <b><strong style=\"white-space: pre-wrap;\">Self-Hosted AI Starter Kit</strong></b></a>â€”a Docker Compose setup that bundles n8n with tools like Ollama and Qdrant. It offers easy installation, workflow templates, and flexible configurations, giving you full control over your local AI workflows and data.</div></div><p>n8n uses&nbsp;<a href=\"https://www.langchain.com/?ref=blog.n8n.io\" rel=\"noopener\" target=\"_blank\">LangChain</a>&nbsp;to simplify the development of complex interactions with LLMs such as chaining multiple prompts together, implementing decision making and interacting with external data sources. The low-code approach that n8n uses, fits perfectly with the modular nature of LangChain, allowing users to assemble and customize LLM workflows without extensive coding.</p><p>Now, let's also explore a quick local LLM workflow!</p><p>With this n8n workflow, you can easily chat with your self-hosted Large Language Models (LLMs) through a simple, user-friendly interface. By hooking up to Ollama, a handy tool for managing local LLMs, you can send prompts and get AI-generated responses right within n8n:</p>\n<!--kg-card-begin: html-->\n<script>\n  workflowBanner(2384, document.currentScript);\n</script><div class=\"workflow\">\n      <div class=\"workflow-content\">\n        <div class=\"workflow-nodes\">\n          \n          <i class=\"fa fa-comments\" aria-hidden=\"true\"></i>\n        <img src=\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNDEuMzMzIiBoZWlnaHQ9IjM0MS4zMzMiIHZlcnNpb249IjEuMCIgdmlld0JveD0iMCAwIDE4MSAyNTYiPjxnIGZpbGw9IiM3RDdEODciPjxwYXRoIGQ9Ik0zNy43IDE5LjVjLTUuMiAxLjgtOC4zIDQuOS0xMS43IDExLjYtNC41IDguOS02LjIgMTkuMi01LjggMzUuNWwuMyAxNC4yLTUuOCA2LjFjLTE0LjggMTUuNS0xOC41IDM4LjctOS4yIDU3LjRsMy40IDYuOS0yIDQuNGMtMy40IDguMi01IDE2LjQtNSAyNi4zIDAgMTAuOCAxLjggMTkgNS44IDI2LjJsMi42IDQuOC0yLjEgNC45Yy0xLjIgMi43LTIuNiA3LjEtMy4yIDkuOC0xLjQgNi4yLTEuNSAyMi4xLS4xIDI1LjcgMSAyLjYgMS40IDIuNyA3LjYgMi43IDcuMyAwIDcgLjQgNS4zLTguNi0xLjUtOC4yLjItMTguOCA0LjItMjYuNiAzLjctNyAzLjgtMTAuNC41LTE0LjgtNC43LTYuNC02LjgtMTMuNi02LjktMjQtLjEtMTAuMyAxLjQtMTYgNi42LTI2LjEgMy4xLTYuMSAyLjktOC43LTEtMTIuMi0xLjEtMS0zLjEtNC4yLTQuMy03LTEuOS00LjItMi40LTYuOS0yLjMtMTQuMiAwLTExLjQgMi41LTE4LjMgOS41LTI2IDctNy42IDE0LjItMTEgMjMuOS0xMS4yIDQuMSAwIDcuOC0uMiA4LjItLjIuNC0uMSAxLjctMi4yIDIuOS00LjcgMy01LjkgOS42LTExLjkgMTYuNy0xNS4yIDQuOS0yLjMgNy0yLjcgMTQuNy0yLjcgNy45IDAgOS43LjQgMTQuOSAyLjkgNi44IDMuMyAxMy4zIDkuNCAxNS45IDE0LjggMSAyIDIuMyA0LjEgMyA0LjUuNi40IDQuNi44IDguNy44IDYuNy4xIDguMy41IDE0IDMuNiAxMi4zIDYuOCAxOS4zIDE4LjcgMTkuMyAzMy40LjEgNi43LS40IDktMi43IDE0LjItMS42IDMuNS0zLjUgNi44LTQuMyA3LjUtMy40IDIuOC0zLjUgNS44LS41IDExLjcgNS4yIDEwLjEgNi43IDE1LjggNi42IDI2LjEtLjEgMTAuNC0yLjIgMTcuNi02LjkgMjQtMy4zIDQuNC0zLjIgNy44LjUgMTQuOCA0IDcuOCA1LjcgMTguNCA0LjIgMjYuNi0xLjcgOS0yIDguNiA1LjMgOC42IDYuMiAwIDYuNi0uMSA3LjYtMi43IDEuNC0zLjYgMS4zLTE5LjUtLjEtMjUuNy0uNi0yLjctMi03LjEtMy4yLTkuOGwtMi4xLTQuOSAyLjYtNC44YzcuNi0xMy45IDcuOS0zNS45LjYtNTIuOGwtMi00LjcgMi41LTQuNmM5LjktMTguMyA2LjQtNDMuOS04LjEtNTkuMWwtNS44LTYuMS4zLTE0LjJjLjQtMTYuNC0xLjMtMjYuNi01LjgtMzUuNy02LjQtMTIuNi0xNy4yLTE1LjktMjYuMy03LjktNS40IDQuNy05LjIgMTMuOC0xMi4zIDI5LjgtLjMgMS40LTEgMi4yLTEuNyAxLjgtMTguMi04LTI5LjctOC41LTQ0LjMtMi4xTDY1IDU0LjlsLS40LTIuMkM2MSAzNC4yIDU2LjEgMjQuMiA0OSAyMC41Yy00LjMtMi4xLTcuNC0yLjQtMTEuMy0xbTcuNyAxNi44YzQuMiA3LjEgOC4xIDMwLjEgNS43IDMzLjYtLjUuOC0zLjEgMS42LTUuOCAxLjgtMi42LjItNi4yLjgtOCAxLjNsLTMuMS44LS43LTQuOWMtLjgtNS45LjItMTcuMiAyLjItMjQuOEMzNy4xIDM4LjQgNDAuNSAzMiA0MiAzMmMuNSAwIDIgMS45IDMuNCA0LjNtOTYuNS0xYzQgNi41IDYuOSAyMy45IDUuNiAzMy42bC0uNyA0LjktMy4xLS44Yy0xLjgtLjUtNS40LTEuMS04LTEuMy0yLjctLjItNS4zLTEtNS44LTEuOC0xLjItMS43LS4zLTE0LjEgMS43LTIyLjkgMS41LTYuNCA1LjctMTUgNy40LTE1IC40IDAgMS44IDEuNSAyLjkgMy4zIi8+PHBhdGggZD0iTTc3LjggMTE5LjljLTcuMyAyLjQtMTEuNiA1LjEtMTYuNSAxMC40LTUuNSA2LTcuNiAxMi03LjEgMjAuMS41IDcuNiAzLjUgMTIuOSAxMC42IDE4LjMgNi4yIDQuNyAxMi43IDYuMyAyNS43IDYuMyAxNy4yIDAgMjUuOC0zLjYgMzIuOS0xMy44IDQuMi01LjkgNC44LTE1LjUgMS42LTIzLTIuOS02LjgtMTEuMS0xNC4zLTE4LjgtMTcuMy04LTMuMS0yMC43LTMuNi0yOC40LTFtMjUuNyAxMGMxNi4xIDcuMSAxOS40IDIzLjIgNi42IDMxLjgtNC45IDMuMy05LjQgNC4zLTE5LjYgNC4zcy0xNC43LTEtMTkuNi00LjNjLTE3LjgtMTItMy4yLTM1LjYgMjEuMS0zNC4zIDMuOS4yIDguNiAxLjIgMTEuNSAyLjUiLz48cGF0aCBkPSJNODMuOCAxNDAuMWMtMi41IDEuNC0yLjIgNC40LjcgNi43IDIgMS42IDIuNCAyLjYgMS45IDQuOS0uNyAzLjYgMS41IDUuOCA1LjEgNC45IDIuMS0uNSAyLjUtMS4yIDIuNS00LjYgMC0yLjkuNS00LjIgMi01IDIuNy0xLjUgMi43LTYuNiAwLTcuNS0xLS4zLTIuOC0uMS00IC41LTEuNC43LTIuNi44LTMuOSAwLTIuMy0xLjItMi4yLTEuMi00LjMuMW0tNDQuMS0xOC45Yy0uOS43LTIuMyAzLTMuMiA1LTIuMSA1LjMtLjEgMTAuMyA0LjcgMTEuNiA0LjMgMS4xIDYgLjYgOS4yLTIuNyA0LTQuMSA0LjMtOC4xIDEuMS0xMS45LTIuMS0yLjUtMy40LTMuMi02LjQtMy4yLTIgMC00LjUuNi01LjQgMS4ybTg5LjggMmMtMy4yIDMuOC0yLjkgNy44IDEuMSAxMS45IDMuMiAzLjMgNC45IDMuOCA5LjIgMi43IDQuOS0xLjMgNi44LTYuMiA0LjYtMTEuOC0xLjktNC43LTMuOC02LTguNy02LTIuNyAwLTQuMS43LTYuMiAzLjIiLz48L2c+PC9zdmc+\" alt=\"Ollama Chat Model\" title=\"Ollama Chat Model\">\n          <i class=\"fa fa-sticky-note\" aria-hidden=\"true\" style=\"color:#FFD233\"></i>\n        \n          <i class=\"fa fa-link\" aria-hidden=\"true\" style=\"color:#909298\"></i>\n        \n          \n        </div>\n        <div class=\"workflow-details\">\n          <p class=\"workflow-details-name\">\n            <a href=\"https://n8n.io/workflows/2384-chat-with-local-llms-using-n8n-and-ollama/\" class=\"blog-banner-workflow\">Chat with local LLMs using n8n and Ollama</a>\n          </p>\n          <p class=\"workflow-details-stats\">by mihailtd</p>\n        </div>\n      </div>\n      <a href=\"https://n8n.io/workflows/2384-chat-with-local-llms-using-n8n-and-ollama/\" class=\"global-button blog-banner-workflow\">\n        Use this workflow\n      </a>\n    </div>\n<!--kg-card-end: html-->\n<h3 id=\"step-1-install-ollama-and-run-a-model\">Step 1: Install Ollama and run a model</h3><p>Installing Ollama is straightforward, just&nbsp;<a href=\"https://ollama.com/download?ref=blog.n8n.io\" rel=\"noopener\" target=\"_blank\">download the Ollama installer</a>&nbsp;for your operating system. You can install Ollama on Windows, Mac or Linux.</p><p>After youâ€™ve installed Ollama, you can pull a model such as Llama3, with the&nbsp;<code>ollama pull llama3</code>&nbsp;command:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://blog.n8n.io/content/images/2025/05/ollama_cli.webp\" class=\"kg-image lightense-target\" alt=\"terminal command for running Ollama\" loading=\"lazy\" width=\"1845\" height=\"1069\" srcset=\"https://blog.n8n.io/content/images/size/w600/2025/05/ollama_cli.webp 600w, https://blog.n8n.io/content/images/size/w1000/2025/05/ollama_cli.webp 1000w, https://blog.n8n.io/content/images/size/w1600/2025/05/ollama_cli.webp 1600w, https://blog.n8n.io/content/images/2025/05/ollama_cli.webp 1845w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">terminal command for running Ollama</span></figcaption></figure><p>Depending on the model, the download can take some time. This version of Llama3, for example, is 4.7 Gb.After the download is complete, run&nbsp;<code>ollama run llama3</code>&nbsp;and you can start chatting with the model right from the command line!</p><h3 id=\"step-2-set-up-a-chat-workflow\">Step 2: Set up a chat workflow</h3><p>Letâ€™s now set up a simple n8n workflow that uses your local LLM running with Ollama. Here is a sneak peek of the workflow we will build:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://blog.n8n.io/content/images/2025/05/n8n_ollama_integration.webp\" class=\"kg-image lightense-target\" alt=\"n8n workflow with local LLM using Ollama\" loading=\"lazy\" width=\"1900\" height=\"910\" srcset=\"https://blog.n8n.io/content/images/size/w600/2025/05/n8n_ollama_integration.webp 600w, https://blog.n8n.io/content/images/size/w1000/2025/05/n8n_ollama_integration.webp 1000w, https://blog.n8n.io/content/images/size/w1600/2025/05/n8n_ollama_integration.webp 1600w, https://blog.n8n.io/content/images/2025/05/n8n_ollama_integration.webp 1900w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">n8n workflow with local LLM using Ollama</span></figcaption></figure><p>Start by adding a&nbsp;<a href=\"https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-langchain.chattrigger/?ref=blog.n8n.io&amp;_gl=1*15sckhc*_gcl_aw*R0NMLjE3NDIyMDExMjAuQ2owS0NRandrTi0tQmhEa0FSSXNBRF9tbklxd1dsSnNMTWRFUjRHdzdHd01ERUo4VXlZa055WDZTSFdUMlc3MHVCODJCR3lxZ3F4NjM0SWFBcF9ORUFMd193Y0I.*_gcl_au*MTQ3NjA3MzYzMi4xNzM5ODI5NDY5*_ga*MjEzOTMyNzI5OC4xNzQ3MTcyNDg5*_ga_0SC4FF2FH9*czE3NDcyNDc0NDQkbzYkZzEkdDE3NDcyNDg5MTIkajYwJGwwJGgw\" rel=\"noopener\" target=\"_blank\">Chat trigger node</a>, which is the workflow starting point for building chat interfaces with n8n. Then we need to connect the chat trigger to a&nbsp;<a href=\"https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.chainllm/?ref=blog.n8n.io\" rel=\"noopener\" target=\"_blank\">Basic LLM Chain</a>&nbsp;where we will set the prompt and configure the LLM to use.</p><h3 id=\"step-3-connect-n8n-with-ollama\">Step 3: Connect n8n with Ollama</h3><p>Connecting Ollama with n8n couldnâ€™t be easier thanks to the&nbsp;<a href=\"https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmollama/?ref=blog.n8n.io\" rel=\"noopener\" target=\"_blank\">Ollama Model sub-node</a>! Ollama is a background process running on your computer and exposes an API on port 11434. You can check if the Ollama API is running by opening a browser window and accessing <code>http://localhost :11434</code>, and you should see a message saying â€œOllama is runningâ€.</p><p>For n8n to be able to communicate with Ollamaâ€™s API via localhost, both applications need to be on the same network. If you are running n8n in Docker, you would need to start the Docker container with the <code>--network=host</code> parameter. That way the n8n container can access any port on the hostâ€™s machine.</p><p>To set a connection between n8n and Ollama, we simply leave everything as default in the Ollama connection window:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://blog.n8n.io/content/images/2025/05/n8n_ollama_connection.webp\" class=\"kg-image lightense-target\" alt=\"n8n Ollama connection setup\" loading=\"lazy\" width=\"1915\" height=\"913\" srcset=\"https://blog.n8n.io/content/images/size/w600/2025/05/n8n_ollama_connection.webp 600w, https://blog.n8n.io/content/images/size/w1000/2025/05/n8n_ollama_connection.webp 1000w, https://blog.n8n.io/content/images/size/w1600/2025/05/n8n_ollama_connection.webp 1600w, https://blog.n8n.io/content/images/2025/05/n8n_ollama_connection.webp 1915w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">n8n Ollama connection setup</span></figcaption></figure><p>After the connection to the Ollama API is successful, in the&nbsp;<strong>Model</strong>&nbsp;dropdown you should not see all the models youâ€™ve downloaded. Just pick the&nbsp;<code>llama3:latest</code>&nbsp;model weâ€™ve downloaded earlier.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://blog.n8n.io/content/images/2025/05/n8n_ollama_configuration.webp\" class=\"kg-image lightense-target\" alt=\"choosing a local model to use with n8n\" loading=\"lazy\" width=\"1911\" height=\"909\" srcset=\"https://blog.n8n.io/content/images/size/w600/2025/05/n8n_ollama_configuration.webp 600w, https://blog.n8n.io/content/images/size/w1000/2025/05/n8n_ollama_configuration.webp 1000w, https://blog.n8n.io/content/images/size/w1600/2025/05/n8n_ollama_configuration.webp 1600w, https://blog.n8n.io/content/images/2025/05/n8n_ollama_configuration.webp 1911w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">choosing a local model to use with n8n</span></figcaption></figure><h3 id=\"step-4-chat-with-llama3\">Step 4: Chat with Llama3</h3><p>Next, let's chat with our local LLM! Click the&nbsp;<strong>Chat</strong>&nbsp;button on the bottom of the workflow page to test it out. Type any message and your local LLM should respond. Itâ€™s that easy!</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://blog.n8n.io/content/images/2025/05/n8n_chat_interface.webp\" class=\"kg-image lightense-target\" alt=\"chatting with local LLMs in n8n\" loading=\"lazy\" width=\"1906\" height=\"912\" srcset=\"https://blog.n8n.io/content/images/size/w600/2025/05/n8n_chat_interface.webp 600w, https://blog.n8n.io/content/images/size/w1000/2025/05/n8n_chat_interface.webp 1000w, https://blog.n8n.io/content/images/size/w1600/2025/05/n8n_chat_interface.webp 1600w, https://blog.n8n.io/content/images/2025/05/n8n_chat_interface.webp 1906w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">chatting with local LLMs in n8n</span></figcaption></figure><h2 id=\"faq\">FAQ</h2><div class=\"kg-card kg-toggle-card\" data-kg-toggle-state=\"close\">\n            <div class=\"kg-toggle-heading\">\n                <h4 class=\"kg-toggle-heading-text\"><span style=\"white-space: pre-wrap;\">Are local LLMs as good as ChatGPT?</span></h4>\n                <button class=\"kg-toggle-card-icon\" aria-label=\"Expand toggle to read content\">\n                    <svg id=\"Regular\" xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                        <path class=\"cls-1\" d=\"M23.25,7.311,12.53,18.03a.749.749,0,0,1-1.06,0L.75,7.311\"></path>\n                    </svg>\n                </button>\n            </div>\n            <div class=\"kg-toggle-content\"><p><span style=\"white-space: pre-wrap;\">Local LLMs are getting incredibly good, very quickly! Many of them, like some versions of Llama, Qwen, or Gemma, can be amazing for specific jobs you want them to do. If you want an AI that's private because all your data stays with you, a local LLM can be just as good, or even better for that particular need!</span></p><p><span style=\"white-space: pre-wrap;\">Plus, running an LLM locally means you can often use it even without an internet connection, customize it to your heart's content, and you don't have to worry about ongoing subscription fees.</span></p><p><span style=\"white-space: pre-wrap;\">While ChatGPT is an extremely good LLM, local LLMs can be just as good if not better in specific scenarios.</span></p></div>\n        </div><div class=\"kg-card kg-toggle-card\" data-kg-toggle-state=\"close\">\n            <div class=\"kg-toggle-heading\">\n                <h4 class=\"kg-toggle-heading-text\"><span style=\"white-space: pre-wrap;\">What is the difference between local LLM and online LLM?</span></h4>\n                <button class=\"kg-toggle-card-icon\" aria-label=\"Expand toggle to read content\">\n                    <svg id=\"Regular\" xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                        <path class=\"cls-1\" d=\"M23.25,7.311,12.53,18.03a.749.749,0,0,1-1.06,0L.75,7.311\"></path>\n                    </svg>\n                </button>\n            </div>\n            <div class=\"kg-toggle-content\"><p><span style=\"white-space: pre-wrap;\">The core difference is where the computation happens and who controls the data</span></p><p><b><strong style=\"white-space: pre-wrap;\">Local LLMs:</strong></b></p><ul><li value=\"1\"><span style=\"white-space: pre-wrap;\">Run directly on your own computer or server.</span></li><li value=\"2\"><span style=\"white-space: pre-wrap;\">You control the hardware and software setup.</span></li><li value=\"3\"><span style=\"white-space: pre-wrap;\">Your data (prompts, documents, etc.) remains entirely within your infrastructure.</span></li><li value=\"4\"><span style=\"white-space: pre-wrap;\">Costs are primarily related to hardware; no per-request fees.</span></li></ul><p><b><strong style=\"white-space: pre-wrap;\">Online (Cloud-based) LLMs:</strong></b></p><ul><li value=\"1\"><span style=\"white-space: pre-wrap;\">Run on powerful servers managed by a third-party provider (e.g., OpenAI, Google).</span></li><li value=\"2\"><span style=\"white-space: pre-wrap;\">You access the model usually through an API or web interface.</span></li><li value=\"3\"><span style=\"white-space: pre-wrap;\">Your prompts and potentially other data are sent to the provider's servers for processing.</span></li><li value=\"4\"><span style=\"white-space: pre-wrap;\">Costs are typically based on usage (per token, subscription fees).</span></li><li value=\"5\"><span style=\"white-space: pre-wrap;\">The provider manages the complex infrastructure.</span></li></ul></div>\n        </div><div class=\"kg-card kg-toggle-card\" data-kg-toggle-state=\"close\">\n            <div class=\"kg-toggle-heading\">\n                <h4 class=\"kg-toggle-heading-text\"><span style=\"white-space: pre-wrap;\">How to run LLM locally for free?</span></h4>\n                <button class=\"kg-toggle-card-icon\" aria-label=\"Expand toggle to read content\">\n                    <svg id=\"Regular\" xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                        <path class=\"cls-1\" d=\"M23.25,7.311,12.53,18.03a.749.749,0,0,1-1.06,0L.75,7.311\"></path>\n                    </svg>\n                </button>\n            </div>\n            <div class=\"kg-toggle-content\"><p><span style=\"white-space: pre-wrap;\">For those looking for a straightforward way to get started with running LLMs locally, Ollama offers a user-friendly experience. After installing Ollama (available for macOS, Windows, and Linux), you can easily download and run a wide variety of open-source models directly from the command line. For instance, to use a model like Deepseek R1, you would typically open your terminal and use a simple command such as </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>ollama pull deepseek-r1:14b</span></code><span style=\"white-space: pre-wrap;\"> to download the 14b parameter varian. Once downloaded, another straightforward command like </span><code spellcheck=\"false\" style=\"white-space: pre-wrap;\"><span>ollama run deepseek-r1</span></code><span style=\"white-space: pre-wrap;\"> allows you to start interacting with the model immediately from the command line.</span></p><p><span style=\"white-space: pre-wrap;\">Ollama manages the model files and provides a simple API, abstracting away much of the underlying complexity. You can find a list of available models on the </span><a href=\"https://ollama.com/library?ref=blog.n8n.io\" target=\"_blank\" rel=\"noopener\"><u><span class=\"underline\" style=\"white-space: pre-wrap;\">Ollama library page</span></u></a><span style=\"white-space: pre-wrap;\">.</span></p></div>\n        </div><div class=\"kg-card kg-toggle-card\" data-kg-toggle-state=\"close\">\n            <div class=\"kg-toggle-heading\">\n                <h4 class=\"kg-toggle-heading-text\"><span style=\"white-space: pre-wrap;\">What is the cheapest LLM?</span></h4>\n                <button class=\"kg-toggle-card-icon\" aria-label=\"Expand toggle to read content\">\n                    <svg id=\"Regular\" xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                        <path class=\"cls-1\" d=\"M23.25,7.311,12.53,18.03a.749.749,0,0,1-1.06,0L.75,7.311\"></path>\n                    </svg>\n                </button>\n            </div>\n            <div class=\"kg-toggle-content\"><p><span style=\"white-space: pre-wrap;\">While many open-source LLMs are free to download, the real cost of running LLMs locally lies in the hardware needed to run them effectively and the electricity costs. \"Cheaper\" models in this context are those with lower hardware requirements, which often correlates with the number of parameters they have.</span></p><p><span style=\"white-space: pre-wrap;\">The model itself (or at least significant parts of it) needs to fit into the Video RAM (VRAM) of your graphics card (GPU) for optimal performance. Larger models require more VRAM. For example, running a model that's around 20GB in size efficiently would typically require a graphics card with at least 24GB of VRAM, such as an NVIDIA GeForce RTX 4090 or RTX 3090.</span></p><p><span style=\"white-space: pre-wrap;\">Models with fewer parameters (e.g., 1 billion to 8 billion) are generally \"cheaper\" to run because they require less VRAM and processing power. They can perform well and quickly on mid-tier consumer hardware. Here are some examples of liter models:</span></p><ul><li value=\"1\"><span style=\"white-space: pre-wrap;\">Llama 3.2 with either 1B or 3B parameters</span></li><li value=\"2\"><span style=\"white-space: pre-wrap;\">Qwen 3 has 0.6B, 1.7B, 4B and 8B parameter versions available</span></li><li value=\"3\"><span style=\"white-space: pre-wrap;\">DeepSeek-R1 (distilled): 1.5B, 7B or 8B parameter models</span></li></ul><p><span style=\"white-space: pre-wrap;\">Models with significantly more parameters (e.g., 14 billion+) offer potentially higher capability but demand more substantial hardware. High-end consumer graphics cards like the NVIDIA GeForce RTX 4090 (24GB), RTX 5090 (32GB) or AMD Radeon RX 7900 XTX (24GB) are often needed. For the very largest models, you might require professional GPUs (like NVIDIA A100/H100) or even multiple GPUs working together, significantly increasing the cost of running local LLMs.</span></p><p><span style=\"white-space: pre-wrap;\">GPUs like NVIDIA GeForce RTX 3060 (12GB), RTX 4060 Ti (16GB), or RTX 4070 (12GB) can often handle these models well. Even some modern integrated graphics or Apple Silicon chips (M-series) can run smaller models, albeit slower than dedicated GPUs.</span></p><p><span style=\"white-space: pre-wrap;\">Cloud-based LLMs follow a similar pattern regarding cost and capability. Providers often offer different tiers:</span></p><ul><li value=\"1\"><span style=\"white-space: pre-wrap;\">Cheaper/Faster Models: Usually smaller or optimized versions (e.g., OpenAI's gpt-4o-mini, Google's gemini-2.0-flash). They are less expensive per token/request but may be less capable for complex reasoning or nuanced tasks.</span></li><li value=\"2\"><span style=\"white-space: pre-wrap;\">More Expensive/Capable Models: State-of-the-art, larger models (e.g., OpenAI's gpt-4o, Google's gemini-2.5-pro). They offer higher performance but come at a higher usage cost.</span></li></ul></div>\n        </div><div class=\"kg-card kg-toggle-card\" data-kg-toggle-state=\"close\">\n            <div class=\"kg-toggle-heading\">\n                <h4 class=\"kg-toggle-heading-text\"><span style=\"white-space: pre-wrap;\">Is there any open-source LLM?</span></h4>\n                <button class=\"kg-toggle-card-icon\" aria-label=\"Expand toggle to read content\">\n                    <svg id=\"Regular\" xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n                        <path class=\"cls-1\" d=\"M23.25,7.311,12.53,18.03a.749.749,0,0,1-1.06,0L.75,7.311\"></path>\n                    </svg>\n                </button>\n            </div>\n            <div class=\"kg-toggle-content\"><p><span style=\"white-space: pre-wrap;\">Yes, absolutely! The open-source LLM landscape is vast and growing rapidly. Many leading AI companies and research institutions release models under open-source licenses.</span></p><p><span style=\"white-space: pre-wrap;\">Popular examples include:</span></p><ul><li value=\"1\"><span style=\"white-space: pre-wrap;\">Meta's Llama series (e.g., Llama 4 and 3.2)</span></li><li value=\"2\"><span style=\"white-space: pre-wrap;\">Mistral AI's models (e.g., Mistral 7B)</span></li><li value=\"3\"><span style=\"white-space: pre-wrap;\">Alibaba's Qwen series (e.g., Qwen 3)</span></li><li value=\"4\"><span style=\"white-space: pre-wrap;\">DeepSeek AI's models (e.g., DeepSeek-R1)</span></li></ul><p><span style=\"white-space: pre-wrap;\">Beyond these, many open-source models are trained to excel in specific areas. Here are some examples:</span></p><ul><li value=\"1\"><span style=\"white-space: pre-wrap;\">Multilingual: Microsoftâ€™s phi4-mini</span></li><li value=\"2\"><span style=\"white-space: pre-wrap;\">Coding: athene-v2, codegemma, deepseek-coder</span></li><li value=\"3\"><span style=\"white-space: pre-wrap;\">Vision (Image Understanding): mistral-small3.1, gemma3, granite3.2-vision</span></li><li value=\"4\"><span style=\"white-space: pre-wrap;\">Reasoning: DeepSeek-R1, QWQ, marco-o1</span></li><li value=\"5\"><span style=\"white-space: pre-wrap;\">Mathematics: mathstral, athene-v2</span></li></ul></div>\n        </div><h2 id=\"wrap-up\">Wrap up</h2><p>Running LLMs locally is not only doable but also practical for those who prioritize privacy, cost savings, or want a deeper understanding of AI.</p><p>Thanks to tools like Ollama, which make it easier to run LLMs on consumer hardware, and platforms like n8n, which help you build AI-powered applications, using LLMs on your own computer is now simpler than ever!</p><h2 id=\"what%E2%80%99s-next\">Whatâ€™s next?</h2><p>Now that you've explored how to run LLMs locally, why not dive deeper into practical applications? Check out these YouTube videos:</p><ul><li><strong>Get started with local AI agents:</strong> Learn how to <a href=\"https://www.youtube.com/watch?v=qqjzohCle48&amp;ref=blog.n8n.io\" rel=\"noopener\" target=\"_blank\">Build a Local AI Agent with N8N, Postgres, and Ollama (Free)</a> or explore another comprehensive tutorial on <a href=\"https://www.youtube.com/watch?v=y9m3i12qkms&amp;ref=blog.n8n.io\" rel=\"noopener\" target=\"_blank\">Setting Up Local AI Agents Without Code</a> using similar tools.</li><li><strong>Explore vector databases with local LLMs:</strong> Discover how to <a href=\"https://www.youtube.com/watch?v=XQ7wNqbB1x8&amp;ref=blog.n8n.io\" rel=\"noopener\" target=\"_blank\">Build a Local AI Agent with Qdrant and Ollama to Interact with Your Documents</a>.</li></ul><p>And if you're interested in exploring a broader range of AI-powered automations beyond just local LLMs, be sure to check out this selection of workflow templates:</p>\n<!--kg-card-begin: html-->\n<script>\n  workflowBanner([3879, 2753, 2741, 1934, 3535], document.currentScript);\n</script><div class=\"workflows\">\n    \n    <h3>Most popular workflows with these integrations</h3>\n  <div class=\"workflow\">\n      <div class=\"workflow-content\">\n        <div class=\"workflow-nodes\">\n          <img src=\"data:image/svg+xml;base64,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\" alt=\"Pinecone Vector Store\" title=\"Pinecone Vector Store\"><img src=\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiB2aWV3Qm94PSIwIDAgNDggNDgiPjxkZWZzPjxwYXRoIGlkPSJhIiBkPSJNNDQuNSAyMEgyNHY4LjVoMTEuOEMzNC43IDMzLjkgMzAuMSAzNyAyNCAzN2MtNy4yIDAtMTMtNS44LTEzLTEzczUuOC0xMyAxMy0xM2MzLjEgMCA1LjkgMS4xIDguMSAyLjlsNi40LTYuNEMzNC42IDQuMSAyOS42IDIgMjQgMiAxMS44IDIgMiAxMS44IDIgMjRzOS44IDIyIDIyIDIyYzExIDAgMjEtOCAyMS0yMiAwLTEuMy0uMi0yLjctLjUtNCIvPjwvZGVmcz48Y2xpcFBhdGggaWQ9ImIiPjx1c2UgeGxpbms6aHJlZj0iI2EiIG92ZXJmbG93PSJ2aXNpYmxlIi8+PC9jbGlwUGF0aD48cGF0aCBmaWxsPSIjRkJCQzA1IiBkPSJNMCAzN1YxMWwxNyAxM3oiIGNsaXAtcGF0aD0idXJsKCNiKSIvPjxwYXRoIGZpbGw9IiNFQTQzMzUiIGQ9Im0wIDExIDE3IDEzIDctNi4xTDQ4IDE0VjBIMHoiIGNsaXAtcGF0aD0idXJsKCNiKSIvPjxwYXRoIGZpbGw9IiMzNEE4NTMiIGQ9Im0wIDM3IDMwLTIzIDcuOSAxTDQ4IDB2NDhIMHoiIGNsaXAtcGF0aD0idXJsKCNiKSIvPjxwYXRoIGZpbGw9IiM0Mjg1RjQiIGQ9Ik00OCA0OCAxNyAyNGwtNC0zIDM1LTEweiIgY2xpcC1wYXRoPSJ1cmwoI2IpIi8+PC9zdmc+\" alt=\"Embeddings Google Gemini\" title=\"Embeddings Google Gemini\"><img src=\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSI3NjgiIGhlaWdodD0iMTAyNCI+PHBhdGggZmlsbD0iIzdEN0Q4NyIgZD0iTTAgOTYwVjY0aDU3NmwxOTIgMTkydjcwNHptNzA0LTY0MEw1MTIgMTI4SDY0djc2OGg2NDB6TTMyMCA1MTJIMTI4VjI1NmgxOTJ6bS02NC0xOTJoLTY0djEyOGg2NHptMCA0NDhoNjR2NjRIMTI4di02NGg2NFY2NDBoLTY0di02NGgxMjh6bTI1Ni0zMjBoNjR2NjRIMzg0di02NGg2NFYzMjBoLTY0di02NGgxMjh6bTY0IDM4NEgzODRWNTc2aDE5MnptLTY0LTE5MmgtNjR2MTI4aDY0eiIvPjwvc3ZnPg==\" alt=\"Default Data Loader\" title=\"Default Data Loader\">\n          <i class=\"fa fa-grip-lines-vertical\" aria-hidden=\"true\"></i>\n        \n          <i class=\"fa fa-robot\" aria-hidden=\"true\" style=\"color:#404040\"></i>\n        \n          <span>+5</span>\n        </div>\n        <div class=\"workflow-details\">\n          <p class=\"workflow-details-name\">\n            <a href=\"https://n8n.io/workflows/2753-rag-chatbot-for-company-documents-using-google-drive-and-gemini/\" class=\"blog-banner-workflow\">RAG Chatbot for Company Documents using Google Drive and Gemini</a>\n          </p>\n          <p class=\"workflow-details-stats\">\n          <svg xmlns=\"http://www.w3.org/2000/svg\" width=\"12\" height=\"10\" fill=\"none\" viewBox=\"0 0 12 10\"><path fill=\"#707183\" d=\"M4.94 6.06a1.5 1.5 0 1 1 2.121-2.12 1.5 1.5 0 0 1-2.12 2.12Z\"></path><path fill=\"#707183\" fill-rule=\"evenodd\" d=\"M.462 6.143C1.38 7.135 3.294 9.2 6 9.2s4.62-2.065 5.539-3.057a1.703 1.703 0 0 0 0-2.332l-.001-.002C10.703 2.907 8.749.8 6 .8 3.256.8 1.304 2.903.466 3.806l-.004.005a1.703 1.703 0 0 0 0 2.332ZM3.77 3.305c.689-.38 1.447-.62 2.23-.705a5.88 5.88 0 0 1 3.972 2.17.301.301 0 0 1 0 .414A5.88 5.88 0 0 1 6 7.4 6.216 6.216 0 0 1 1.996 5.24a.3.3 0 0 1-.01-.423A5.937 5.937 0 0 1 3.77 3.305Z\" clip-rule=\"evenodd\"></path></svg>\n          74518 <span>â€¢</span> <strong>by mihailtd</strong> <span>â€¢</span> 4 months\n        </p>\n        </div>\n      </div>\n      <a href=\"https://n8n.io/workflows/2753-rag-chatbot-for-company-documents-using-google-drive-and-gemini/\" class=\"global-button blog-banner-workflow\">\n        Use this workflow\n      </a>\n    </div><div class=\"workflow\">\n      <div class=\"workflow-content\">\n        <div class=\"workflow-nodes\">\n          \n          <i class=\"fa fa-comments\" aria-hidden=\"true\"></i>\n        \n          <i class=\"fa fa-robot\" aria-hidden=\"true\" style=\"color:#404040\"></i>\n        \n          <i class=\"fa fa-database\" aria-hidden=\"true\"></i>\n        <img src=\"data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTgwIiBoZWlnaHQ9IjE4MCIgdmlld0JveD0iMCAwIDE5NSAxOTUiIGZpbGw9Im5vbmUiIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyI+Cgk8ZyBzdHJva2U9IiMwMDAiIHN0cm9rZS13aWR0aD0iMTIiIHN0cm9rZS1saW5lY2FwPSJyb3VuZCI+CgkJPHBhdGggZD0iTTI1IDk3Ljg1MjhMOTIuODgyMyAyOS45NzA2QzEwMi4yNTUgMjAuNTk4IDExNy40NTEgMjAuNTk4IDEyNi44MjMgMjkuOTcwNlYyOS45NzA2QzEzNi4xOTYgMzkuMzQzMSAxMzYuMTk2IDU0LjUzOTEgMTI2LjgyMyA2My45MTE3TDc1LjU1ODEgMTE1LjE3NyIvPgoJCTxwYXRoIGQ9Ik03Ni4yNjUzIDExNC40N0wxMjYuODIzIDYzLjkxMTdDMTM2LjE5NiA1NC41MzkxIDE1MS4zOTIgNTQuNTM5MSAxNjAuNzY1IDYzLjkxMTdMMTYxLjExOCA2NC4yNjUyQzE3MC40OTEgNzMuNjM3OCAxNzAuNDkxIDg4LjgzMzggMTYxLjExOCA5OC4yMDYzTDk5LjcyNDggMTU5LjZDOTYuNjAwNiAxNjIuNzI0IDk2LjYwMDYgMTY3Ljc4OSA5OS43MjQ4IDE3MC45MTNMMTEyLjMzMSAxODMuNTIiLz4KCQk8cGF0aCBkPSJNMTA5Ljg1MyA0Ni45NDExTDU5LjY0ODIgOTcuMTQ1N0M1MC4yNzU3IDEwNi41MTggNTAuMjc1NyAxMjEuNzE0IDU5LjY0ODIgMTMxLjA4N1YxMzEuMDg3QzY5LjAyMDggMTQwLjQ1OSA4NC4yMTY4IDE0MC40NTkgOTMuNTg5NCAxMzEuMDg3TDE0My43OTQgODAuODgyMiIvPgoJPC9nPgo8L3N2Zz4K\" alt=\"MCP Client Tool\" title=\"MCP Client Tool\"><img src=\"data:image/svg+xml;base64,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\" alt=\"OpenAI Chat Model\" title=\"OpenAI Chat Model\">\n          <span>+2</span>\n        </div>\n        <div class=\"workflow-details\">\n          <p class=\"workflow-details-name\">\n            <a href=\"https://n8n.io/workflows/3879-build-an-mcp-server-with-airtable/\" class=\"blog-banner-workflow\">Build an MCP Server with Airtable</a>\n          </p>\n          <p class=\"workflow-details-stats\">\n          <svg xmlns=\"http://www.w3.org/2000/svg\" width=\"12\" height=\"10\" fill=\"none\" viewBox=\"0 0 12 10\"><path fill=\"#707183\" d=\"M4.94 6.06a1.5 1.5 0 1 1 2.121-2.12 1.5 1.5 0 0 1-2.12 2.12Z\"></path><path fill=\"#707183\" fill-rule=\"evenodd\" d=\"M.462 6.143C1.38 7.135 3.294 9.2 6 9.2s4.62-2.065 5.539-3.057a1.703 1.703 0 0 0 0-2.332l-.001-.002C10.703 2.907 8.749.8 6 .8 3.256.8 1.304 2.903.466 3.806l-.004.005a1.703 1.703 0 0 0 0 2.332ZM3.77 3.305c.689-.38 1.447-.62 2.23-.705a5.88 5.88 0 0 1 3.972 2.17.301.301 0 0 1 0 .414A5.88 5.88 0 0 1 6 7.4 6.216 6.216 0 0 1 1.996 5.24a.3.3 0 0 1-.01-.423A5.937 5.937 0 0 1 3.77 3.305Z\" clip-rule=\"evenodd\"></path></svg>\n          4323 <span>â€¢</span> <strong>by aitoralonso</strong> <span>â€¢</span> 22 days\n        </p>\n        </div>\n      </div>\n      <a href=\"https://n8n.io/workflows/3879-build-an-mcp-server-with-airtable/\" class=\"global-button blog-banner-workflow\">\n        Use this workflow\n      </a>\n    </div><div class=\"workflow\">\n      <div class=\"workflow-content\">\n        <div class=\"workflow-nodes\">\n          <img src=\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiB2aWV3Qm94PSIwIDAgNDggNDgiPjxkZWZzPjxwYXRoIGlkPSJhIiBkPSJNNDQuNSAyMEgyNHY4LjVoMTEuOEMzNC43IDMzLjkgMzAuMSAzNyAyNCAzN2MtNy4yIDAtMTMtNS44LTEzLTEzczUuOC0xMyAxMy0xM2MzLjEgMCA1LjkgMS4xIDguMSAyLjlsNi40LTYuNEMzNC42IDQuMSAyOS42IDIgMjQgMiAxMS44IDIgMiAxMS44IDIgMjRzOS44IDIyIDIyIDIyYzExIDAgMjEtOCAyMS0yMiAwLTEuMy0uMi0yLjctLjUtNCIvPjwvZGVmcz48Y2xpcFBhdGggaWQ9ImIiPjx1c2UgeGxpbms6aHJlZj0iI2EiIG92ZXJmbG93PSJ2aXNpYmxlIi8+PC9jbGlwUGF0aD48cGF0aCBmaWxsPSIjRkJCQzA1IiBkPSJNMCAzN1YxMWwxNyAxM3oiIGNsaXAtcGF0aD0idXJsKCNiKSIvPjxwYXRoIGZpbGw9IiNFQTQzMzUiIGQ9Im0wIDExIDE3IDEzIDctNi4xTDQ4IDE0VjBIMHoiIGNsaXAtcGF0aD0idXJsKCNiKSIvPjxwYXRoIGZpbGw9IiMzNEE4NTMiIGQ9Im0wIDM3IDMwLTIzIDcuOSAxTDQ4IDB2NDhIMHoiIGNsaXAtcGF0aD0idXJsKCNiKSIvPjxwYXRoIGZpbGw9IiM0Mjg1RjQiIGQ9Ik00OCA0OCAxNyAyNGwtNC0zIDM1LTEweiIgY2xpcC1wYXRoPSJ1cmwoI2IpIi8+PC9zdmc+\" alt=\"Google Gemini Chat Model\" title=\"Google Gemini Chat Model\"><img src=\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0MCA0MCI+PHBhdGggZmlsbD0iIzAwMDRGNSIgZmlsbC1ydWxlPSJldmVub2RkIiBkPSJNNDAgMjBDNDAgOC45NTMgMzEuMDQ3IDAgMjAgMFMwIDguOTUzIDAgMjBzOC45NTMgMjAgMjAgMjAgMjAtOC45NTMgMjAtMjBNMjAgMzYuOTQ2Yy0xLjExNSAwLTIuODYyLS45NzktNC41LTQuMjQ3LS43MDQtMS40MDctMS4zMDQtMy4xNTYtMS43NDctNS4wMTRIMjYuMTljLS4zODYgMS44NTUtLjk4NiAzLjYwNS0xLjY5IDUuMDE0LTEuNjM4IDMuMjY4LTMuMzg1IDQuMjQ3LTQuNSA0LjI0N00xMi45MDYgMjBjMCAxLjYxLjEwMyAzLjE2NC4yOTQgNC42M2gxMy42YTM2IDM2IDAgMCAwIC4yOTQtNC42M2MwLTEuNjEtLjEwMy0zLjE2NC0uMjk0LTQuNjNIMTMuMmEzNiAzNiAwIDAgMC0uMjk0IDQuNjNNMjAgMy4wNTRjMS4xMTUgMCAyLjg2Mi45NzcgNC41IDQuMjQ2LjcwNyAxLjQxNCAxLjMwNyAzLjEwNyAxLjY5MiA1LjAxNUgxMy43NWMuNDQzLTEuOTEgMS4wNDQtMy42MDIgMS43NS01LjAxNCAxLjYzOC0zLjI3IDMuMzg1LTQuMjQ3IDQuNS00LjI0N00zMC4xNDggMjBjMC0xLjU5LS4wOTQtMy4xMzgtLjMyNS00LjYzaDYuNDgxYy40MjEgMS40NzIuNjQyIDMuMDI2LjY0MiA0LjYzcy0uMjIgMy4xNTgtLjY0MiA0LjYzaC02LjQ4MWMuMjMxLTEuNDkyLjMyNS0zLjA0LjMyNS00LjYzTTI2LjI3NyA0LjI1NWMxLjM2IDIuMTA1IDIuNDM0IDQuODc3IDMuMSA4LjA2aDUuNzI4YTE2Ljk4IDE2Ljk4IDAgMCAwLTguODI4LTguMDZtLTE1LjY1NCA4LjA2aC01LjczYzEuODU4LTMuNjQ3IDUtNi41MzIgOC44My04LjA2LTEuMzYgMi4xMDUtMi40MzQgNC44NzctMy4xIDguMDZNMy4wNTQgMjBjMCAxLjYwMy4yMjMgMy4xNTcuNjQgNC42M2g2LjQyOGE0MCA0MCAwIDAgMS0uMjctNC42M2MwLTEuNTk0LjA5NC0zLjE0Mi4yNy00LjYzSDMuNjk1YTE3IDE3IDAgMCAwLS42NCA0LjYzbTIzLjIyMyAxNS43NDNjMS4zNi0yLjEwNCAyLjQzNC00Ljg3NSAzLjEtOC4wNThoNS43MjhhMTYuOTYgMTYuOTYgMCAwIDEtOC44MjggOC4wNThtLTEyLjU1NCAwYTE3IDE3IDAgMCAxLTguODMtOC4wNThoNS43M2MuNjY2IDMuMTgzIDEuNzQgNS45NTQgMy4xIDguMDU4IiBjbGlwLXJ1bGU9ImV2ZW5vZGQiLz48L3N2Zz4=\" alt=\"HTTP Request Tool\" title=\"HTTP Request Tool\">\n          <i class=\"fa fa-robot\" aria-hidden=\"true\" style=\"color:#404040\"></i>\n        \n          <i class=\"fa fa-comments\" aria-hidden=\"true\"></i>\n        \n          <i class=\"fa fa-sticky-note\" aria-hidden=\"true\" style=\"color:#FFD233\"></i>\n        \n          \n        </div>\n        <div class=\"workflow-details\">\n          <p class=\"workflow-details-name\">\n            <a href=\"https://n8n.io/workflows/3535-ai-agent-scrape-summarize-and-save-articles-to-notion-gemini-browserless/\" class=\"blog-banner-workflow\">AI Agent: Scrape, Summarize &amp; Save Articles to Notion (Gemini, Browserless)</a>\n          </p>\n          <p class=\"workflow-details-stats\">\n          <svg xmlns=\"http://www.w3.org/2000/svg\" width=\"12\" height=\"10\" fill=\"none\" viewBox=\"0 0 12 10\"><path fill=\"#707183\" d=\"M4.94 6.06a1.5 1.5 0 1 1 2.121-2.12 1.5 1.5 0 0 1-2.12 2.12Z\"></path><path fill=\"#707183\" fill-rule=\"evenodd\" d=\"M.462 6.143C1.38 7.135 3.294 9.2 6 9.2s4.62-2.065 5.539-3.057a1.703 1.703 0 0 0 0-2.332l-.001-.002C10.703 2.907 8.749.8 6 .8 3.256.8 1.304 2.903.466 3.806l-.004.005a1.703 1.703 0 0 0 0 2.332ZM3.77 3.305c.689-.38 1.447-.62 2.23-.705a5.88 5.88 0 0 1 3.972 2.17.301.301 0 0 1 0 .414A5.88 5.88 0 0 1 6 7.4 6.216 6.216 0 0 1 1.996 5.24a.3.3 0 0 1-.01-.423A5.937 5.937 0 0 1 3.77 3.305Z\" clip-rule=\"evenodd\"></path></svg>\n          4818 <span>â€¢</span> <strong>by mihailtd</strong> <span>â€¢</span> 1 month\n        </p>\n        </div>\n      </div>\n      <a href=\"https://n8n.io/workflows/3535-ai-agent-scrape-summarize-and-save-articles-to-notion-gemini-browserless/\" class=\"global-button blog-banner-workflow\">\n        Use this workflow\n      </a>\n    </div><div class=\"workflow\">\n      <div class=\"workflow-content\">\n        <div class=\"workflow-nodes\">\n          <img src=\"data:image/svg+xml;base64,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\" alt=\"Pinecone Vector Store\" title=\"Pinecone Vector Store\"><img src=\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiB2aWV3Qm94PSIwIDAgNDggNDgiPjxkZWZzPjxwYXRoIGlkPSJhIiBkPSJNNDQuNSAyMEgyNHY4LjVoMTEuOEMzNC43IDMzLjkgMzAuMSAzNyAyNCAzN2MtNy4yIDAtMTMtNS44LTEzLTEzczUuOC0xMyAxMy0xM2MzLjEgMCA1LjkgMS4xIDguMSAyLjlsNi40LTYuNEMzNC42IDQuMSAyOS42IDIgMjQgMiAxMS44IDIgMiAxMS44IDIgMjRzOS44IDIyIDIyIDIyYzExIDAgMjEtOCAyMS0yMiAwLTEuMy0uMi0yLjctLjUtNCIvPjwvZGVmcz48Y2xpcFBhdGggaWQ9ImIiPjx1c2UgeGxpbms6aHJlZj0iI2EiIG92ZXJmbG93PSJ2aXNpYmxlIi8+PC9jbGlwUGF0aD48cGF0aCBmaWxsPSIjRkJCQzA1IiBkPSJNMCAzN1YxMWwxNyAxM3oiIGNsaXAtcGF0aD0idXJsKCNiKSIvPjxwYXRoIGZpbGw9IiNFQTQzMzUiIGQ9Im0wIDExIDE3IDEzIDctNi4xTDQ4IDE0VjBIMHoiIGNsaXAtcGF0aD0idXJsKCNiKSIvPjxwYXRoIGZpbGw9IiMzNEE4NTMiIGQ9Im0wIDM3IDMwLTIzIDcuOSAxTDQ4IDB2NDhIMHoiIGNsaXAtcGF0aD0idXJsKCNiKSIvPjxwYXRoIGZpbGw9IiM0Mjg1RjQiIGQ9Ik00OCA0OCAxNyAyNGwtNC0zIDM1LTEweiIgY2xpcC1wYXRoPSJ1cmwoI2IpIi8+PC9zdmc+\" alt=\"Embeddings Google Gemini\" title=\"Embeddings Google Gemini\"><img src=\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSI3NjgiIGhlaWdodD0iMTAyNCI+PHBhdGggZmlsbD0iIzdEN0Q4NyIgZD0iTTAgOTYwVjY0aDU3NmwxOTIgMTkydjcwNHptNzA0LTY0MEw1MTIgMTI4SDY0djc2OGg2NDB6TTMyMCA1MTJIMTI4VjI1NmgxOTJ6bS02NC0xOTJoLTY0djEyOGg2NHptMCA0NDhoNjR2NjRIMTI4di02NGg2NFY2NDBoLTY0di02NGgxMjh6bTI1Ni0zMjBoNjR2NjRIMzg0di02NGg2NFYzMjBoLTY0di02NGgxMjh6bTY0IDM4NEgzODRWNTc2aDE5MnptLTY0LTE5MmgtNjR2MTI4aDY0eiIvPjwvc3ZnPg==\" alt=\"Default Data Loader\" title=\"Default Data Loader\">\n          <i class=\"fa fa-grip-lines-vertical\" aria-hidden=\"true\"></i>\n        \n          <i class=\"fa fa-sync\" aria-hidden=\"true\" style=\"color:#007755\"></i>\n        \n          <span>+5</span>\n        </div>\n        <div class=\"workflow-details\">\n          <p class=\"workflow-details-name\">\n            <a href=\"https://n8n.io/workflows/2741-ai-powered-rag-workflow-for-stock-earnings-report-analysis/\" class=\"blog-banner-workflow\">AI-Powered RAG Workflow For Stock Earnings Report Analysis</a>\n          </p>\n          <p class=\"workflow-details-stats\">\n          <svg xmlns=\"http://www.w3.org/2000/svg\" width=\"12\" height=\"10\" fill=\"none\" viewBox=\"0 0 12 10\"><path fill=\"#707183\" d=\"M4.94 6.06a1.5 1.5 0 1 1 2.121-2.12 1.5 1.5 0 0 1-2.12 2.12Z\"></path><path fill=\"#707183\" fill-rule=\"evenodd\" d=\"M.462 6.143C1.38 7.135 3.294 9.2 6 9.2s4.62-2.065 5.539-3.057a1.703 1.703 0 0 0 0-2.332l-.001-.002C10.703 2.907 8.749.8 6 .8 3.256.8 1.304 2.903.466 3.806l-.004.005a1.703 1.703 0 0 0 0 2.332ZM3.77 3.305c.689-.38 1.447-.62 2.23-.705a5.88 5.88 0 0 1 3.972 2.17.301.301 0 0 1 0 .414A5.88 5.88 0 0 1 6 7.4 6.216 6.216 0 0 1 1.996 5.24a.3.3 0 0 1-.01-.423A5.937 5.937 0 0 1 3.77 3.305Z\" clip-rule=\"evenodd\"></path></svg>\n          13127 <span>â€¢</span> <strong>by mihailtd</strong> <span>â€¢</span> 4 months\n        </p>\n        </div>\n      </div>\n      <a href=\"https://n8n.io/workflows/2741-ai-powered-rag-workflow-for-stock-earnings-report-analysis/\" class=\"global-button blog-banner-workflow\">\n        Use this workflow\n      </a>\n    </div><div class=\"workflow\">\n      <div class=\"workflow-content\">\n        <div class=\"workflow-nodes\">\n          <img src=\"data:image/svg+xml;base64,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\" alt=\"Merge\" title=\"Merge\">\n          <i class=\"fa fa-pen\" aria-hidden=\"true\"></i>\n        <img src=\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiBmaWxsPSIjZmZmIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiIHN0cm9rZT0iIzAwMCIgc3Ryb2tlLWxpbmVjYXA9InJvdW5kIiBzdHJva2UtbGluZWpvaW49InJvdW5kIiB2aWV3Qm94PSIwIDAgNjYgNjYiPjx1c2UgeGxpbms6aHJlZj0iI2EiIHg9Ii41IiB5PSIuNSIvPjxzeW1ib2wgaWQ9ImEiIG92ZXJmbG93PSJ2aXNpYmxlIj48ZyBmaWxsLXJ1bGU9Im5vbnplcm8iIHN0cm9rZT0ibm9uZSI+PHBhdGggZmlsbD0iIzM3YWVlMiIgZD0iTTAgMzJjMCAxNy42NzMgMTQuMzI3IDMyIDMyIDMyczMyLTE0LjMyNyAzMi0zMlM0OS42NzMgMCAzMiAwIDAgMTQuMzI3IDAgMzIiLz48cGF0aCBmaWxsPSIjYzhkYWVhIiBkPSJtMjEuNjYxIDM0LjMzOCAzLjc5NyAxMC41MDhzLjQ3NS45ODMuOTgzLjk4MyA4LjA2OC03Ljg2NCA4LjA2OC03Ljg2NGw4LjQwNy0xNi4yMzctMjEuMTE5IDkuODk4eiIvPjxwYXRoIGZpbGw9IiNhOWM2ZDgiIGQ9Im0yNi42OTUgMzcuMDM0LS43MjkgNy43NDZzLS4zMDUgMi4zNzMgMi4wNjggMGw0LjY0NC00LjIwMyIvPjxwYXRoIGQ9Im0yMS43MyAzNC43MTItNy44MDktMi41NDVzLS45MzItLjM3OC0uNjMzLTEuMjM3Yy4wNjItLjE3Ny4xODYtLjMyOC41NTktLjU4OCAxLjczMS0xLjIwNiAzMi4wMjgtMTIuMDk2IDMyLjAyOC0xMi4wOTZzLjg1Ni0uMjg4IDEuMzYxLS4wOTdjLjIzMS4wODguMzc4LjE4Ny41MDMuNTQ4LjA0NS4xMzIuMDcxLjQxMS4wNjguNjg5LS4wMDMuMjAxLS4wMjcuMzg2LS4wNDUuNjc4LS4xODQgMi45NzgtNS43MDYgMjUuMTk4LTUuNzA2IDI1LjE5OHMtLjMzIDEuMy0xLjUxNCAxLjM0NWMtLjQzMi4wMTYtLjk1Ni0uMDcxLTEuNTgyLS42MS0yLjMyMy0xLjk5OC0xMC4zNTItNy4zOTQtMTIuMTI2LTguNThhLjM0LjM0IDAgMCAxLS4xNDYtLjIzOWMtLjAyNS0uMTI1LjEwOC0uMjguMTA4LS4yOHMxMy45OC0xMi40MjcgMTQuMzUyLTEzLjczMWMuMDI5LS4xMDEtLjA3OS0uMTUxLS4yMjYtLjEwNy0uOTI5LjM0Mi0xNy4wMjUgMTAuNTA2LTE4LjgwMSAxMS42MjktLjEwNC4wNjYtLjM5NS4wMjMtLjM5NS4wMjMiLz48L2c+PC9zeW1ib2w+PC9zdmc+\" alt=\"Telegram\" title=\"Telegram\"><img src=\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiBmaWxsPSIjZmZmIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiIHN0cm9rZT0iIzAwMCIgc3Ryb2tlLWxpbmVjYXA9InJvdW5kIiBzdHJva2UtbGluZWpvaW49InJvdW5kIiB2aWV3Qm94PSIwIDAgNjYgNjYiPjx1c2UgeGxpbms6aHJlZj0iI2EiIHg9Ii41IiB5PSIuNSIvPjxzeW1ib2wgaWQ9ImEiIG92ZXJmbG93PSJ2aXNpYmxlIj48ZyBmaWxsLXJ1bGU9Im5vbnplcm8iIHN0cm9rZT0ibm9uZSI+PHBhdGggZmlsbD0iIzM3YWVlMiIgZD0iTTAgMzJjMCAxNy42NzMgMTQuMzI3IDMyIDMyIDMyczMyLTE0LjMyNyAzMi0zMlM0OS42NzMgMCAzMiAwIDAgMTQuMzI3IDAgMzIiLz48cGF0aCBmaWxsPSIjYzhkYWVhIiBkPSJtMjEuNjYxIDM0LjMzOCAzLjc5NyAxMC41MDhzLjQ3NS45ODMuOTgzLjk4MyA4LjA2OC03Ljg2NCA4LjA2OC03Ljg2NGw4LjQwNy0xNi4yMzctMjEuMTE5IDkuODk4eiIvPjxwYXRoIGZpbGw9IiNhOWM2ZDgiIGQ9Im0yNi42OTUgMzcuMDM0LS43MjkgNy43NDZzLS4zMDUgMi4zNzMgMi4wNjggMGw0LjY0NC00LjIwMyIvPjxwYXRoIGQ9Im0yMS43MyAzNC43MTItNy44MDktMi41NDVzLS45MzItLjM3OC0uNjMzLTEuMjM3Yy4wNjItLjE3Ny4xODYtLjMyOC41NTktLjU4OCAxLjczMS0xLjIwNiAzMi4wMjgtMTIuMDk2IDMyLjAyOC0xMi4wOTZzLjg1Ni0uMjg4IDEuMzYxLS4wOTdjLjIzMS4wODguMzc4LjE4Ny41MDMuNTQ4LjA0NS4xMzIuMDcxLjQxMS4wNjguNjg5LS4wMDMuMjAxLS4wMjcuMzg2LS4wNDUuNjc4LS4xODQgMi45NzgtNS43MDYgMjUuMTk4LTUuNzA2IDI1LjE5OHMtLjMzIDEuMy0xLjUxNCAxLjM0NWMtLjQzMi4wMTYtLjk1Ni0uMDcxLTEuNTgyLS42MS0yLjMyMy0xLjk5OC0xMC4zNTItNy4zOTQtMTIuMTI2LTguNThhLjM0LjM0IDAgMCAxLS4xNDYtLjIzOWMtLjAyNS0uMTI1LjEwOC0uMjguMTA4LS4yOHMxMy45OC0xMi40MjcgMTQuMzUyLTEzLjczMWMuMDI5LS4xMDEtLjA3OS0uMTUxLS4yMjYtLjEwNy0uOTI5LjM0Mi0xNy4wMjUgMTAuNTA2LTE4LjgwMSAxMS42MjktLjEwNC4wNjYtLjM5NS4wMjMtLjM5NS4wMjMiLz48L2c+PC9zeW1ib2w+PC9zdmc+\" alt=\"Telegram Trigger\" title=\"Telegram Trigger\">\n          <i class=\"fa fa-map-signs\" aria-hidden=\"true\" style=\"color:#506000\"></i>\n        \n          <span>+2</span>\n        </div>\n        <div class=\"workflow-details\">\n          <p class=\"workflow-details-name\">\n            <a href=\"https://n8n.io/workflows/1934-telegram-ai-chatbot/\" class=\"blog-banner-workflow\">Telegram AI Chatbot</a>\n          </p>\n          <p class=\"workflow-details-stats\">\n          <svg xmlns=\"http://www.w3.org/2000/svg\" width=\"12\" height=\"10\" fill=\"none\" viewBox=\"0 0 12 10\"><path fill=\"#707183\" d=\"M4.94 6.06a1.5 1.5 0 1 1 2.121-2.12 1.5 1.5 0 0 1-2.12 2.12Z\"></path><path fill=\"#707183\" fill-rule=\"evenodd\" d=\"M.462 6.143C1.38 7.135 3.294 9.2 6 9.2s4.62-2.065 5.539-3.057a1.703 1.703 0 0 0 0-2.332l-.001-.002C10.703 2.907 8.749.8 6 .8 3.256.8 1.304 2.903.466 3.806l-.004.005a1.703 1.703 0 0 0 0 2.332ZM3.77 3.305c.689-.38 1.447-.62 2.23-.705a5.88 5.88 0 0 1 3.972 2.17.301.301 0 0 1 0 .414A5.88 5.88 0 0 1 6 7.4 6.216 6.216 0 0 1 1.996 5.24a.3.3 0 0 1-.01-.423A5.937 5.937 0 0 1 3.77 3.305Z\" clip-rule=\"evenodd\"></path></svg>\n          138080 <span>â€¢</span> <strong>by eduard</strong> <span>â€¢</span> 1 year\n        </p>\n        </div>\n      </div>\n      <a href=\"https://n8n.io/workflows/1934-telegram-ai-chatbot/\" class=\"global-button blog-banner-workflow\">\n        Use this workflow\n      </a>\n    </div>\n    <div class=\"workflows-button\">\n      <a href=\"https://app.n8n.cloud/register\" class=\"global-button blog-banner-signup\">\n        Get started\n      </a>\n    </div>\n  </div>\n<!--kg-card-end: html-->\n\n\t\t<div class=\"newsletter-banner\">\n\t    <div class=\"newsletter-banner-content\">\n\t      <div class=\"section-header\">\n\t        <h2>Subscribe to <span>n8n newsletter</span></h2>\n\t        <div class=\"section-subheader--bottom\">\n\t          Get the best, coolest, and latest in automation and low-code delivered to your inbox each week.\n\t        </div>\n\t      </div>\n\t      <div class=\"newsletter-banner-form\">\n\t        <form autocomplete=\"off\" class=\"contact-form\" onsubmit=\"subscribeNewsletter(event)\">\n\t        \t<div id=\"recaptcha\" class=\"g-recaptcha\" data-sitekey=\"6LeAQeopAAAAAKlLsRb1weWm6T_vijoQBkGkbHzB\" data-callback=\"submitSubscription\" data-size=\"invisible\"><div class=\"grecaptcha-badge\" data-style=\"bottomright\" style=\"width: 256px; height: 60px; display: block; transition: right 0.3s ease 0s; position: fixed; bottom: 14px; right: -186px; box-shadow: gray 0px 0px 5px; border-radius: 2px; overflow: hidden;\"><div class=\"grecaptcha-logo\"><iframe title=\"reCAPTCHA\" width=\"256\" height=\"60\" role=\"presentation\" name=\"a-fk9583x2o7qq\" frameborder=\"0\" scrolling=\"no\" sandbox=\"allow-forms allow-popups allow-same-origin allow-scripts allow-top-navigation allow-modals allow-popups-to-escape-sandbox allow-storage-access-by-user-activation\" src=\"https://www.google.com/recaptcha/api2/anchor?ar=1&amp;k=6LeAQeopAAAAAKlLsRb1weWm6T_vijoQBkGkbHzB&amp;co=aHR0cHM6Ly9ibG9nLm44bi5pbzo0NDM.&amp;hl=en&amp;v=jt8Oh2-Ue1u7nEbJQUIdocyd&amp;size=invisible&amp;cb=nia9ql2l3cx8\"></iframe></div><div class=\"grecaptcha-error\"></div><textarea id=\"g-recaptcha-response\" name=\"g-recaptcha-response\" class=\"g-recaptcha-response\" style=\"width: 250px; height: 40px; border: 1px solid rgb(193, 193, 193); margin: 10px 25px; padding: 0px; resize: none; display: none;\"></textarea></div><iframe style=\"display: none;\"></iframe></div>\n\t          <div class=\"input-wrapper\">\n\t            <input placeholder=\"Email\" name=\"email\" type=\"email\" required=\"required\" class=\"\">\n\t            <div class=\"messages\">\n\t              <div class=\"message message--error\">Something went wrong. Please try again later.</div>\n\t              <div class=\"message message--success\">Subscribed!</div>\n\t            </div>\n\t          </div>\n\t          <button type=\"submit\" class=\"submit-btn\">Subscribe</button>\n\t        </form>\n\t      </div>\n\t    </div>\n    </div>\n\t\t<div class=\"post-share-section\">\n\t<div class=\"post-share-wrap\">\n\t\t<a href=\"https://twitter.com/intent/tweet?text=How%20to%20Run%20a%20Local%20LLM%3A%20Complete%20Guide%20to%20Setup%20%26%20Best%20Models%20(2025)&amp;url=https://blog.n8n.io/local-llm/\" target=\"_blank\" rel=\"noopener\" aria-label=\"Twitter share icon\"><svg role=\"img\" viewBox=\"0 0 24 24\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M23.954 4.569c-.885.389-1.83.654-2.825.775 1.014-.611 1.794-1.574 2.163-2.723-.951.555-2.005.959-3.127 1.184-.896-.959-2.173-1.559-3.591-1.559-2.717 0-4.92 2.203-4.92 4.917 0 .39.045.765.127 1.124C7.691 8.094 4.066 6.13 1.64 3.161c-.427.722-.666 1.561-.666 2.475 0 1.71.87 3.213 2.188 4.096-.807-.026-1.566-.248-2.228-.616v.061c0 2.385 1.693 4.374 3.946 4.827-.413.111-.849.171-1.296.171-.314 0-.615-.03-.916-.086.631 1.953 2.445 3.377 4.604 3.417-1.68 1.319-3.809 2.105-6.102 2.105-.39 0-.779-.023-1.17-.067 2.189 1.394 4.768 2.209 7.557 2.209 9.054 0 13.999-7.496 13.999-13.986 0-.209 0-.42-.015-.63.961-.689 1.8-1.56 2.46-2.548l-.047-.02z\"></path></svg></a>\n\t\t<a href=\"https://www.facebook.com/sharer/sharer.php?u=https://blog.n8n.io/local-llm/\" target=\"_blank\" rel=\"noopener\" aria-label=\"Facebook share icon\"><svg role=\"img\" viewBox=\"0 0 24 24\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M23.9981 11.9991C23.9981 5.37216 18.626 0 11.9991 0C5.37216 0 0 5.37216 0 11.9991C0 17.9882 4.38789 22.9522 10.1242 23.8524V15.4676H7.07758V11.9991H10.1242V9.35553C10.1242 6.34826 11.9156 4.68714 14.6564 4.68714C15.9692 4.68714 17.3424 4.92149 17.3424 4.92149V7.87439H15.8294C14.3388 7.87439 13.8739 8.79933 13.8739 9.74824V11.9991H17.2018L16.6698 15.4676H13.8739V23.8524C19.6103 22.9522 23.9981 17.9882 23.9981 11.9991Z\"></path></svg></a>\n\t\t<!-- <a href=\"javascript:\" class=\"post-share-link\" id=\"copy\" data-clipboard-target=\"#copy-link\" aria-label=\"Copy link icon\"><svg role=\"img\" viewBox=\"0 0 33 24\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M27.3999996,13.4004128 L21.7999996,13.4004128 L21.7999996,19 L18.9999996,19 L18.9999996,13.4004128 L13.3999996,13.4004128 L13.3999996,10.6006192 L18.9999996,10.6006192 L18.9999996,5 L21.7999996,5 L21.7999996,10.6006192 L27.3999996,10.6006192 L27.3999996,13.4004128 Z M12,20.87 C7.101,20.87 3.13,16.898 3.13,12 C3.13,7.102 7.101,3.13 12,3.13 C12.091,3.13 12.181,3.139 12.272,3.142 C9.866,5.336 8.347,8.487 8.347,12 C8.347,15.512 9.866,18.662 12.271,20.857 C12.18,20.859 12.091,20.87 12,20.87 Z M20.347,0 C18.882,0 17.484,0.276 16.186,0.756 C14.882,0.271 13.473,0 12,0 C5.372,0 0,5.373 0,12 C0,18.628 5.372,24 12,24 C13.471,24 14.878,23.726 16.181,23.242 C17.481,23.724 18.88,24 20.347,24 C26.975,24 32.347,18.628 32.347,12 C32.347,5.373 26.975,0 20.347,0 Z\"/></svg></a>\n\t\t<small class=\"share-link-info\">The link has been copied!</small> -->\n\t</div>\n\t<input type=\"text\" value=\"https://blog.n8n.io/local-llm/\" id=\"copy-link\" aria-label=\"Copy link input\">\n</div>",
  "readme": "Have you ever worried about the costs of using ChatGPT for your projects? Or perhaps you work in a field with strict data governance rules, making it difficult to use cloud-based AI solutions?\n\nIf so, running Large Language Models (LLMs) locally could be the answer you've been looking for.\n\nLocal LLMs offer a cost-effective and secure alternative to cloud-based options. By running models on your own hardware, you can avoid the recurring costs of API calls and keep your sensitive data within your own infrastructure. This is particularly beneficial in industries like healthcare, finance, and legal, where data privacy is paramount.\n\nExperimenting and tinkering with LLMs on your local machine can also be a fantastic learning opportunity, deepening your understanding of AI and its applications.\n\n### Local LLM workflows to experiment with:\n\n__![HTTP Request](data:image/svg+xml;base64,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)![Code](data:image/svg+xml;base64,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)![HTML](data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iNDAiIGhlaWdodD0iNDAiIHZpZXdCb3g9IjAgMCA0MCA0MCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggZD0iTTguNjQwNjIgMEgxMC40Mzc1VjEuNzgxMjVIMTIuMDkzN1YwSDEzLjg5MDZWNS4zOTA2MkgxMi4wOTM3VjMuNTkzNzVIMTAuNDUzMVY1LjM5MDYySDguNjQwNjJNMTYuMjY1NiAxLjc5Njg3SDE0LjY3OTdWMEgxOS42NTYyVjEuNzk2ODdIMTguMDYyNVY1LjM5MDYySDE2LjI2NTZNMjAuNDQ1MyAwSDIyLjMyODFMMjMuNDg0NCAxLjg5ODQ0TDI0LjY0MDYgMEgyNi41MjM0VjUuMzkwNjJIMjQuNzI2NlYyLjcxODc1TDIzLjQ2ODcgNC42NTYyNUwyMi4yMTA5IDIuNzE4NzVWNS4zOTA2MkgyMC40NDUzTTI3LjQxNDEgMEgyOS4yMTA5VjMuNjA5MzdIMzEuNzU3OFY1LjM5MDYySDI3LjQxNDEiIGZpbGw9ImJsYWNrIi8+CjxwYXRoIGQ9Ik04LjU3ODEyIDM2Ljc5NjlMNiA3Ljg1OTM4SDM0LjM0MzdMMzEuNzY1NiAzNi43ODEyTDIwLjE0ODQgNDAiIGZpbGw9IiNFNDREMjYiLz4KPHBhdGggZD0iTTIwLjE3MTkgMzcuNTM5MVYxMC4yMzQ0SDMxLjc1NzhMMjkuNTQ2OSAzNC45MjE5IiBmaWxsPSIjRjE2NTI5Ii8+CjxwYXRoIGQ9Ik0xMS4yNjU2IDEzLjc3MzRIMjAuMTcxOVYxNy4zMjAzSDE1LjE1NjJMMTUuNDg0NCAyMC45NTMxSDIwLjE3MTlWMjQuNDkyMkgxMi4yMzQ0TTEyLjM5MDYgMjYuMjczNEgxNS45NTMxTDE2LjIwMzEgMjkuMTA5NEwyMC4xNzE5IDMwLjE3MTlWMzMuODc1TDEyLjg5MDYgMzEuODQzNyIgZmlsbD0iI0VCRUJFQiIvPgo8cGF0aCBkPSJNMjkuMDQ2OSAxMy43NzM0SDIwLjE1NjJWMTcuMzIwM0gyOC43MTg3TTI4LjM5ODQgMjAuOTUzMUgyMC4xNTYyVjI0LjVIMjQuNTMxMkwyNC4xMTcyIDI5LjEwOTRMMjAuMTU2MiAzMC4xNzE5VjMzLjg1OTRMMjcuNDIxOSAzMS44NDM3IiBmaWxsPSJ3aGl0ZSIvPgo8L3N2Zz4K) __ +5\n\n[Recipe Recommendations with Qdrant and Mistral](https://n8n.io/workflows/2333-recipe-recommendations-with-qdrant-and-mistral/)\n\n5571 â€¢ **by jimleuk** â€¢ 10 months \n\n[ Use this workflow ](https://n8n.io/workflows/2333-recipe-recommendations-with-qdrant-and-mistral/)\n\n__![Embeddings Mistral Cloud](data:image/svg+xml;base64,<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<svg
   width="216"
   height="216"
   version="1.1"
   id="svg41"
   sodipodi:docname="mistral.svg"
   inkscape:version="1.3.2 (091e20ef0f, 2023-11-25, custom)"
   xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"
   xmlns:sodipodi="http://sodipodi.sourceforge.net/DTD/sodipodi-0.dtd"
   xmlns:xlink="http://www.w3.org/1999/xlink"
   xmlns="http://www.w3.org/2000/svg"
   xmlns:svg="http://www.w3.org/2000/svg">
  <sodipodi:namedview
     id="namedview41"
     pagecolor="#ffffff"
     bordercolor="#000000"
     borderopacity="0.25"
     inkscape:showpageshadow="2"
     inkscape:pageopacity="0.0"
     inkscape:pagecheckerboard="0"
     inkscape:deskcolor="#d1d1d1"
     inkscape:zoom="1.936488"
     inkscape:cx="197.78072"
     inkscape:cy="79.00901"
     inkscape:window-width="1920"
     inkscape:window-height="1017"
     inkscape:window-x="0"
     inkscape:window-y="0"
     inkscape:window-maximized="1"
     inkscape:current-layer="svg41" />
  <style
     id="style1"><![CDATA[.I{fill:#ff7000}.J{fill:#ff4900}.K{fill:#ffa300}.L{fill:#1c1c1b icc-color(adobe-rgb-1998, 0.13299561, 0.13299561, 0.1289978)}]]></style>
  <defs
     id="defs10">
    <clipPath
       id="A">
      <path
         d="M 0,184.252 H 481.89 V 0 H 0 Z"
         transform="translate(-206.251,-140.139)"
         id="path1" />
    </clipPath>
    <clipPath
       id="B">
      <path
         d="M 0,184.252 H 481.89 V 0 H 0 Z"
         transform="translate(-247.436,-104.865)"
         id="path2" />
    </clipPath>
    <clipPath
       id="C">
      <path
         d="M 0,184.252 H 481.89 V 0 H 0 Z"
         transform="translate(-285.938,-102.089)"
         id="path3" />
    </clipPath>
    <clipPath
       id="D">
      <path
         d="M 0,184.252 H 481.89 V 0 H 0 Z"
         transform="translate(-337.769,-131.877)"
         id="path4" />
    </clipPath>
    <clipPath
       id="E">
      <path
         d="M 0,184.252 H 481.89 V 0 H 0 Z"
         transform="translate(-377.247,-132.319)"
         id="path5" />
    </clipPath>
    <clipPath
       id="F">
      <path
         d="M 0,184.252 H 481.89 V 0 H 0 Z"
         transform="translate(-418.107,-114.634)"
         id="path6" />
    </clipPath>
    <clipPath
       id="G">
      <path
         d="M 0,184.252 H 481.89 V 0 H 0 Z"
         transform="translate(-450.023,-140.139)"
         id="path7" />
    </clipPath>
    <clipPath
       id="H">
      <path
         d="M 0,184.252 H 481.89 V 0 H 0 Z"
         transform="translate(-217.694,-44.794)"
         id="path8" />
    </clipPath>
    <clipPath
       id="I">
      <path
         d="M 0,184.252 H 481.89 V 0 H 0 Z"
         transform="translate(-247.436,-35.025)"
         id="path9" />
    </clipPath>
    <clipPath
       id="J">
      <path
         d="M 0,184.252 H 481.89 V 0 H 0 Z"
         id="path10" />
    </clipPath>
    <path
       id="K"
       d="m 173.987,134.362 h -37.795 l 9.633,-37.776 h 37.796 z" />
  </defs>
  <g
     transform="matrix(1,0,0.254535,1,-51.362792,-7.4725007)"
     id="g32">
    <g
       class="L"
       id="g22">
      <path
         d="M 98.397,134.362 H 60.602 l 9.633,-37.776 h 37.796 z"
         id="path11" />
      <path
         d="M 126.558,172.138 H 88.763 l 9.633,-37.776 h 37.796 z"
         id="path12" />
      <path
         d="M 136.192,134.362 H 98.397 l 9.633,-37.776 h 37.796 z"
         id="path13" />
      <use
         xlink:href="#K"
         id="use13" />
      <path
         d="M 108.031,96.585 H 70.236 l 9.633,-37.776 h 37.796 z"
         id="path14" />
      <use
         xlink:href="#K"
         x="9.6339998"
         y="-37.777"
         id="use14" />
      <path
         d="M 60.602,134.362 H 22.807 L 32.44,96.586 h 37.796 z"
         id="path15" />
      <path
         d="M 70.236,96.585 H 32.441 L 42.074,58.809 H 79.87 Z"
         id="path16" />
      <path
         d="M 79.87,58.809 H 42.075 l 9.633,-37.776 h 37.796 z"
         id="path17" />
      <use
         xlink:href="#K"
         x="57.063"
         y="-75.553001"
         id="use17" />
      <path
         d="M 50.968,172.138 H 13.173 l 9.633,-37.776 h 37.796 z"
         id="path18" />
      <path
         d="M 41.334,209.915 H 3.539 l 9.633,-37.776 h 37.796 z"
         id="path19" />
      <use
         xlink:href="#K"
         x="37.794998"
         id="use19" />
      <use
         xlink:href="#K"
         x="47.429001"
         y="-37.777"
         id="use20" />
      <use
         xlink:href="#K"
         x="28.160999"
         y="37.776001"
         id="use21" />
      <use
         xlink:href="#K"
         x="18.527"
         y="75.553001"
         id="use22" />
    </g>
    <path
       d="M 114.115,134.359 H 76.321 l 9.633,-37.776 h 37.796 z"
       class="I"
       id="path22" />
    <use
       xlink:href="#K"
       x="-31.709999"
       y="37.772999"
       class="J"
       id="use23" />
    <g
       class="I"
       id="g25">
      <use
         xlink:href="#K"
         x="-22.076"
         y="-0.003"
         id="use24" />
      <use
         xlink:href="#K"
         x="15.719"
         y="-0.003"
         id="use25" />
    </g>
    <g
       class="K"
       id="g26">
      <path
         d="M 123.749,96.582 H 85.955 l 9.633,-37.776 h 37.796 z"
         id="path25" />
      <use
         xlink:href="#K"
         x="25.353001"
         y="-37.779999"
         id="use26" />
    </g>
    <path
       d="M 76.32,134.359 H 38.526 l 9.633,-37.776 h 37.796 z"
       class="I"
       id="path26" />
    <path
       d="M 85.954,96.582 H 48.16 l 9.633,-37.776 h 37.796 z"
       class="K"
       id="path27" />
    <g
       fill="#ffce00"
       id="g28">
      <path
         d="M 95.588,58.806 H 57.794 L 67.427,21.03 h 37.796 z"
         id="path28" />
      <use
         xlink:href="#K"
         x="72.781998"
         y="-75.556"
         id="use28" />
    </g>
    <path
       d="M 66.686,172.135 H 28.892 l 9.633,-37.776 h 37.796 z"
       class="J"
       id="path29" />
    <path
       d="M 57.052,209.912 H 19.258 l 9.633,-37.776 h 37.796 z"
       fill="#ff0107"
       id="path30" />
    <use
       xlink:href="#K"
       x="53.514"
       y="-0.003"
       class="I"
       id="use30" />
    <path
       d="M 237.135,96.582 H 199.34 l 9.633,-37.776 h 37.796 z"
       class="K"
       id="path31" />
    <use
       xlink:href="#K"
       x="43.880001"
       y="37.772999"
       class="J"
       id="use31" />
    <use
       xlink:href="#K"
       x="34.245998"
       y="75.550003"
       fill="#ff0107"
       id="use32" />
  </g>
</svg>
)![Default Data Loader](data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSI3NjgiIGhlaWdodD0iMTAyNCI+PHBhdGggZmlsbD0iIzdEN0Q4NyIgZD0iTTAgOTYwVjY0aDU3NmwxOTIgMTkydjcwNHptNzA0LTY0MEw1MTIgMTI4SDY0djc2OGg2NDB6TTMyMCA1MTJIMTI4VjI1NmgxOTJ6bS02NC0xOTJoLTY0djEyOGg2NHptMCA0NDhoNjR2NjRIMTI4di02NGg2NFY2NDBoLTY0di02NGgxMjh6bTI1Ni0zMjBoNjR2NjRIMzg0di02NGg2NFYzMjBoLTY0di02NGgxMjh6bTY0IDM4NEgzODRWNTc2aDE5MnptLTY0LTE5MmgtNjR2MTI4aDY0eiIvPjwvc3ZnPg==) __![HTTP Request](data:image/svg+xml;base64,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) +5\n\n[Build a Tax Code Assistant with Qdrant, Mistral.ai and OpenAI](https://n8n.io/workflows/2341-build-a-tax-code-assistant-with-qdrant-mistralai-and-openai/)\n\n8215 â€¢ **by jimleuk** â€¢ 10 months \n\n[ Use this workflow ](https://n8n.io/workflows/2341-build-a-tax-code-assistant-with-qdrant-mistralai-and-openai/)\n\n________![Read/Write Files from Disk](data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iNTEyIiBoZWlnaHQ9IjUxMiIgdmlld0JveD0iMCAwIDUxMiA1MTIiIGZpbGw9Im5vbmUiIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyI+CjxnIGNsaXAtcGF0aD0idXJsKCNjbGlwMF8xMTQxXzE1NDcpIj4KPHBhdGggZD0iTTAgMTJDMCA1LjM3MjU4IDUuMzcyNTggMCAxMiAwSDE1OVYxNTRDMTU5IDE2MC42MjcgMTY0LjM3MyAxNjYgMTcxIDE2NkgzMjVWMjQySDIyOC41NjJDMjEwLjg5NSAyNDIgMTk0LjY1NiAyNTEuNzA1IDE4Ni4yODggMjY3LjI2NEwxMjkuMjAzIDM3My40MDdDMTI1LjEzMSAzODAuOTc4IDEyMyAzODkuNDQgMTIzIDM5OC4wMzdWNDM0SDEyQzUuMzcyNTcgNDM0IDAgNDI4LjYyNyAwIDQyMlYxMloiIGZpbGw9IiM0NEFBNDQiLz4KPHBhdGggZD0iTTMyNSAxMzRWMTI3LjQwMUMzMjUgMTI0LjIyMyAzMjMuNzQgMTIxLjE3NSAzMjEuNDk1IDExOC45MjVMMjA2LjM2OSAzLjUyNDgxQzIwNC4xMTggMS4yNjgyIDIwMS4wNjEgMCAxOTcuODczIDBIMTkxVjEzNEgzMjVaIiBmaWxsPSIjNDRBQTQ0Ii8+CjxwYXRoIGZpbGwtcnVsZT0iZXZlbm9kZCIgY2xpcC1ydWxlPSJldmVub2RkIiBkPSJNMjI4LjU2MyAyNzRDMjIyLjY3NCAyNzQgMjE3LjI2MSAyNzcuMjM1IDIxNC40NzIgMjgyLjQyMUwxNzIuMjExIDM2MUg0OTIuNjRMNDQ0LjY3IDI4MS43MTdDNDQxLjc3MiAyNzYuOTI3IDQzNi41OCAyNzQgNDMwLjk4MSAyNzRIMjI4LjU2M1oiIGZpbGw9IiM0NEFBNDQiLz4KPHBhdGggZmlsbC1ydWxlPSJldmVub2RkIiBjbGlwLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik0xNTUgNDA5QzE1NSA0MDAuMTYzIDE2Mi4xNjMgMzkzIDE3MSAzOTNINDk2QzUwNC44MzcgMzkzIDUxMiA0MDAuMTYzIDUxMiA0MDlWNDk2QzUxMiA1MDQuODM3IDUwNC44MzcgNTEyIDQ5NiA1MTJIMTcxQzE2Mi4xNjMgNTEyIDE1NSA1MDQuODM3IDE1NSA0OTZWNDA5Wk0zOTcgNDUzQzM5NyA0NjYuMjU1IDM4Ni4yNTUgNDc3IDM3MyA0NzdDMzU5Ljc0NSA0NzcgMzQ5IDQ2Ni4yNTUgMzQ5IDQ1M0MzNDkgNDM5Ljc0NSAzNTkuNzQ1IDQyOSAzNzMgNDI5QzM4Ni4yNTUgNDI5IDM5NyA0MzkuNzQ1IDM5NyA0NTNaTTQ0NSA0NzdDNDU4LjI1NSA0NzcgNDY5IDQ2Ni4yNTUgNDY5IDQ1M0M0NjkgNDM5Ljc0NSA0NTguMjU1IDQyOSA0NDUgNDI5QzQzMS43NDUgNDI5IDQyMSA0MzkuNzQ1IDQyMSA0NTNDNDIxIDQ2Ni4yNTUgNDMxLjc0NSA0NzcgNDQ1IDQ3N1oiIGZpbGw9IiM0NEFBNDQiLz4KPC9nPgo8ZGVmcz4KPGNsaXBQYXRoIGlkPSJjbGlwMF8xMTQxXzE1NDciPgo8cmVjdCB3aWR0aD0iNTEyIiBoZWlnaHQ9IjUxMiIgZmlsbD0id2hpdGUiLz4KPC9jbGlwUGF0aD4KPC9kZWZzPgo8L3N2Zz4K) +5\n\n[Build a Financial Documents Assistant using Qdrant and Mistral.ai](https://n8n.io/workflows/2335-build-a-financial-documents-assistant-using-qdrant-and-mistralai/)\n\n15287 â€¢ **by jimleuk** â€¢ 10 months \n\n[ Use this workflow ](https://n8n.io/workflows/2335-build-a-financial-documents-assistant-using-qdrant-and-mistralai/)\n\n__![Default Data Loader](data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSI3NjgiIGhlaWdodD0iMTAyNCI+PHBhdGggZmlsbD0iIzdEN0Q4NyIgZD0iTTAgOTYwVjY0aDU3NmwxOTIgMTkydjcwNHptNzA0LTY0MEw1MTIgMTI4SDY0djc2OGg2NDB6TTMyMCA1MTJIMTI4VjI1NmgxOTJ6bS02NC0xOTJoLTY0djEyOGg2NHptMCA0NDhoNjR2NjRIMTI4di02NGg2NFY2NDBoLTY0di02NGgxMjh6bTI1Ni0zMjBoNjR2NjRIMzg0di02NGg2NFYzMjBoLTY0di02NGgxMjh6bTY0IDM4NEgzODRWNTc2aDE5MnptLTY0LTE5MmgtNjR2MTI4aDY0eiIvPjwvc3ZnPg==) __![Embeddings Mistral Cloud](data:image/svg+xml;base64,<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<svg
   width="216"
   height="216"
   version="1.1"
   id="svg41"
   sodipodi:docname="mistral.svg"
   inkscape:version="1.3.2 (091e20ef0f, 2023-11-25, custom)"
   xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"
   xmlns:sodipodi="http://sodipodi.sourceforge.net/DTD/sodipodi-0.dtd"
   xmlns:xlink="http://www.w3.org/1999/xlink"
   xmlns="http://www.w3.org/2000/svg"
   xmlns:svg="http://www.w3.org/2000/svg">
  <sodipodi:namedview
     id="namedview41"
     pagecolor="#ffffff"
     bordercolor="#000000"
     borderopacity="0.25"
     inkscape:showpageshadow="2"
     inkscape:pageopacity="0.0"
     inkscape:pagecheckerboard="0"
     inkscape:deskcolor="#d1d1d1"
     inkscape:zoom="1.936488"
     inkscape:cx="197.78072"
     inkscape:cy="79.00901"
     inkscape:window-width="1920"
     inkscape:window-height="1017"
     inkscape:window-x="0"
     inkscape:window-y="0"
     inkscape:window-maximized="1"
     inkscape:current-layer="svg41" />
  <style
     id="style1"><![CDATA[.I{fill:#ff7000}.J{fill:#ff4900}.K{fill:#ffa300}.L{fill:#1c1c1b icc-color(adobe-rgb-1998, 0.13299561, 0.13299561, 0.1289978)}]]></style>
  <defs
     id="defs10">
    <clipPath
       id="A">
      <path
         d="M 0,184.252 H 481.89 V 0 H 0 Z"
         transform="translate(-206.251,-140.139)"
         id="path1" />
    </clipPath>
    <clipPath
       id="B">
      <path
         d="M 0,184.252 H 481.89 V 0 H 0 Z"
         transform="translate(-247.436,-104.865)"
         id="path2" />
    </clipPath>
    <clipPath
       id="C">
      <path
         d="M 0,184.252 H 481.89 V 0 H 0 Z"
         transform="translate(-285.938,-102.089)"
         id="path3" />
    </clipPath>
    <clipPath
       id="D">
      <path
         d="M 0,184.252 H 481.89 V 0 H 0 Z"
         transform="translate(-337.769,-131.877)"
         id="path4" />
    </clipPath>
    <clipPath
       id="E">
      <path
         d="M 0,184.252 H 481.89 V 0 H 0 Z"
         transform="translate(-377.247,-132.319)"
         id="path5" />
    </clipPath>
    <clipPath
       id="F">
      <path
         d="M 0,184.252 H 481.89 V 0 H 0 Z"
         transform="translate(-418.107,-114.634)"
         id="path6" />
    </clipPath>
    <clipPath
       id="G">
      <path
         d="M 0,184.252 H 481.89 V 0 H 0 Z"
         transform="translate(-450.023,-140.139)"
         id="path7" />
    </clipPath>
    <clipPath
       id="H">
      <path
         d="M 0,184.252 H 481.89 V 0 H 0 Z"
         transform="translate(-217.694,-44.794)"
         id="path8" />
    </clipPath>
    <clipPath
       id="I">
      <path
         d="M 0,184.252 H 481.89 V 0 H 0 Z"
         transform="translate(-247.436,-35.025)"
         id="path9" />
    </clipPath>
    <clipPath
       id="J">
      <path
         d="M 0,184.252 H 481.89 V 0 H 0 Z"
         id="path10" />
    </clipPath>
    <path
       id="K"
       d="m 173.987,134.362 h -37.795 l 9.633,-37.776 h 37.796 z" />
  </defs>
  <g
     transform="matrix(1,0,0.254535,1,-51.362792,-7.4725007)"
     id="g32">
    <g
       class="L"
       id="g22">
      <path
         d="M 98.397,134.362 H 60.602 l 9.633,-37.776 h 37.796 z"
         id="path11" />
      <path
         d="M 126.558,172.138 H 88.763 l 9.633,-37.776 h 37.796 z"
         id="path12" />
      <path
         d="M 136.192,134.362 H 98.397 l 9.633,-37.776 h 37.796 z"
         id="path13" />
      <use
         xlink:href="#K"
         id="use13" />
      <path
         d="M 108.031,96.585 H 70.236 l 9.633,-37.776 h 37.796 z"
         id="path14" />
      <use
         xlink:href="#K"
         x="9.6339998"
         y="-37.777"
         id="use14" />
      <path
         d="M 60.602,134.362 H 22.807 L 32.44,96.586 h 37.796 z"
         id="path15" />
      <path
         d="M 70.236,96.585 H 32.441 L 42.074,58.809 H 79.87 Z"
         id="path16" />
      <path
         d="M 79.87,58.809 H 42.075 l 9.633,-37.776 h 37.796 z"
         id="path17" />
      <use
         xlink:href="#K"
         x="57.063"
         y="-75.553001"
         id="use17" />
      <path
         d="M 50.968,172.138 H 13.173 l 9.633,-37.776 h 37.796 z"
         id="path18" />
      <path
         d="M 41.334,209.915 H 3.539 l 9.633,-37.776 h 37.796 z"
         id="path19" />
      <use
         xlink:href="#K"
         x="37.794998"
         id="use19" />
      <use
         xlink:href="#K"
         x="47.429001"
         y="-37.777"
         id="use20" />
      <use
         xlink:href="#K"
         x="28.160999"
         y="37.776001"
         id="use21" />
      <use
         xlink:href="#K"
         x="18.527"
         y="75.553001"
         id="use22" />
    </g>
    <path
       d="M 114.115,134.359 H 76.321 l 9.633,-37.776 h 37.796 z"
       class="I"
       id="path22" />
    <use
       xlink:href="#K"
       x="-31.709999"
       y="37.772999"
       class="J"
       id="use23" />
    <g
       class="I"
       id="g25">
      <use
         xlink:href="#K"
         x="-22.076"
         y="-0.003"
         id="use24" />
      <use
         xlink:href="#K"
         x="15.719"
         y="-0.003"
         id="use25" />
    </g>
    <g
       class="K"
       id="g26">
      <path
         d="M 123.749,96.582 H 85.955 l 9.633,-37.776 h 37.796 z"
         id="path25" />
      <use
         xlink:href="#K"
         x="25.353001"
         y="-37.779999"
         id="use26" />
    </g>
    <path
       d="M 76.32,134.359 H 38.526 l 9.633,-37.776 h 37.796 z"
       class="I"
       id="path26" />
    <path
       d="M 85.954,96.582 H 48.16 l 9.633,-37.776 h 37.796 z"
       class="K"
       id="path27" />
    <g
       fill="#ffce00"
       id="g28">
      <path
         d="M 95.588,58.806 H 57.794 L 67.427,21.03 h 37.796 z"
         id="path28" />
      <use
         xlink:href="#K"
         x="72.781998"
         y="-75.556"
         id="use28" />
    </g>
    <path
       d="M 66.686,172.135 H 28.892 l 9.633,-37.776 h 37.796 z"
       class="J"
       id="path29" />
    <path
       d="M 57.052,209.912 H 19.258 l 9.633,-37.776 h 37.796 z"
       fill="#ff0107"
       id="path30" />
    <use
       xlink:href="#K"
       x="53.514"
       y="-0.003"
       class="I"
       id="use30" />
    <path
       d="M 237.135,96.582 H 199.34 l 9.633,-37.776 h 37.796 z"
       class="K"
       id="path31" />
    <use
       xlink:href="#K"
       x="43.880001"
       y="37.772999"
       class="J"
       id="use31" />
    <use
       xlink:href="#K"
       x="34.245998"
       y="75.550003"
       fill="#ff0107"
       id="use32" />
  </g>
</svg>
)![Mistral Cloud Chat Model](data:image/svg+xml;base64,<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<svg
   width="216"
   height="216"
   version="1.1"
   id="svg41"
   sodipodi:docname="mistral.svg"
   inkscape:version="1.3.2 (091e20ef0f, 2023-11-25, custom)"
   xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"
   xmlns:sodipodi="http://sodipodi.sourceforge.net/DTD/sodipodi-0.dtd"
   xmlns:xlink="http://www.w3.org/1999/xlink"
   xmlns="http://www.w3.org/2000/svg"
   xmlns:svg="http://www.w3.org/2000/svg">
  <sodipodi:namedview
     id="namedview41"
     pagecolor="#ffffff"
     bordercolor="#000000"
     borderopacity="0.25"
     inkscape:showpageshadow="2"
     inkscape:pageopacity="0.0"
     inkscape:pagecheckerboard="0"
     inkscape:deskcolor="#d1d1d1"
     inkscape:zoom="1.936488"
     inkscape:cx="197.78072"
     inkscape:cy="79.00901"
     inkscape:window-width="1920"
     inkscape:window-height="1017"
     inkscape:window-x="0"
     inkscape:window-y="0"
     inkscape:window-maximized="1"
     inkscape:current-layer="svg41" />
  <style
     id="style1"><![CDATA[.I{fill:#ff7000}.J{fill:#ff4900}.K{fill:#ffa300}.L{fill:#1c1c1b icc-color(adobe-rgb-1998, 0.13299561, 0.13299561, 0.1289978)}]]></style>
  <defs
     id="defs10">
    <clipPath
       id="A">
      <path
         d="M 0,184.252 H 481.89 V 0 H 0 Z"
         transform="translate(-206.251,-140.139)"
         id="path1" />
    </clipPath>
    <clipPath
       id="B">
      <path
         d="M 0,184.252 H 481.89 V 0 H 0 Z"
         transform="translate(-247.436,-104.865)"
         id="path2" />
    </clipPath>
    <clipPath
       id="C">
      <path
         d="M 0,184.252 H 481.89 V 0 H 0 Z"
         transform="translate(-285.938,-102.089)"
         id="path3" />
    </clipPath>
    <clipPath
       id="D">
      <path
         d="M 0,184.252 H 481.89 V 0 H 0 Z"
         transform="translate(-337.769,-131.877)"
         id="path4" />
    </clipPath>
    <clipPath
       id="E">
      <path
         d="M 0,184.252 H 481.89 V 0 H 0 Z"
         transform="translate(-377.247,-132.319)"
         id="path5" />
    </clipPath>
    <clipPath
       id="F">
      <path
         d="M 0,184.252 H 481.89 V 0 H 0 Z"
         transform="translate(-418.107,-114.634)"
         id="path6" />
    </clipPath>
    <clipPath
       id="G">
      <path
         d="M 0,184.252 H 481.89 V 0 H 0 Z"
         transform="translate(-450.023,-140.139)"
         id="path7" />
    </clipPath>
    <clipPath
       id="H">
      <path
         d="M 0,184.252 H 481.89 V 0 H 0 Z"
         transform="translate(-217.694,-44.794)"
         id="path8" />
    </clipPath>
    <clipPath
       id="I">
      <path
         d="M 0,184.252 H 481.89 V 0 H 0 Z"
         transform="translate(-247.436,-35.025)"
         id="path9" />
    </clipPath>
    <clipPath
       id="J">
      <path
         d="M 0,184.252 H 481.89 V 0 H 0 Z"
         id="path10" />
    </clipPath>
    <path
       id="K"
       d="m 173.987,134.362 h -37.795 l 9.633,-37.776 h 37.796 z" />
  </defs>
  <g
     transform="matrix(1,0,0.254535,1,-51.362792,-7.4725007)"
     id="g32">
    <g
       class="L"
       id="g22">
      <path
         d="M 98.397,134.362 H 60.602 l 9.633,-37.776 h 37.796 z"
         id="path11" />
      <path
         d="M 126.558,172.138 H 88.763 l 9.633,-37.776 h 37.796 z"
         id="path12" />
      <path
         d="M 136.192,134.362 H 98.397 l 9.633,-37.776 h 37.796 z"
         id="path13" />
      <use
         xlink:href="#K"
         id="use13" />
      <path
         d="M 108.031,96.585 H 70.236 l 9.633,-37.776 h 37.796 z"
         id="path14" />
      <use
         xlink:href="#K"
         x="9.6339998"
         y="-37.777"
         id="use14" />
      <path
         d="M 60.602,134.362 H 22.807 L 32.44,96.586 h 37.796 z"
         id="path15" />
      <path
         d="M 70.236,96.585 H 32.441 L 42.074,58.809 H 79.87 Z"
         id="path16" />
      <path
         d="M 79.87,58.809 H 42.075 l 9.633,-37.776 h 37.796 z"
         id="path17" />
      <use
         xlink:href="#K"
         x="57.063"
         y="-75.553001"
         id="use17" />
      <path
         d="M 50.968,172.138 H 13.173 l 9.633,-37.776 h 37.796 z"
         id="path18" />
      <path
         d="M 41.334,209.915 H 3.539 l 9.633,-37.776 h 37.796 z"
         id="path19" />
      <use
         xlink:href="#K"
         x="37.794998"
         id="use19" />
      <use
         xlink:href="#K"
         x="47.429001"
         y="-37.777"
         id="use20" />
      <use
         xlink:href="#K"
         x="28.160999"
         y="37.776001"
         id="use21" />
      <use
         xlink:href="#K"
         x="18.527"
         y="75.553001"
         id="use22" />
    </g>
    <path
       d="M 114.115,134.359 H 76.321 l 9.633,-37.776 h 37.796 z"
       class="I"
       id="path22" />
    <use
       xlink:href="#K"
       x="-31.709999"
       y="37.772999"
       class="J"
       id="use23" />
    <g
       class="I"
       id="g25">
      <use
         xlink:href="#K"
         x="-22.076"
         y="-0.003"
         id="use24" />
      <use
         xlink:href="#K"
         x="15.719"
         y="-0.003"
         id="use25" />
    </g>
    <g
       class="K"
       id="g26">
      <path
         d="M 123.749,96.582 H 85.955 l 9.633,-37.776 h 37.796 z"
         id="path25" />
      <use
         xlink:href="#K"
         x="25.353001"
         y="-37.779999"
         id="use26" />
    </g>
    <path
       d="M 76.32,134.359 H 38.526 l 9.633,-37.776 h 37.796 z"
       class="I"
       id="path26" />
    <path
       d="M 85.954,96.582 H 48.16 l 9.633,-37.776 h 37.796 z"
       class="K"
       id="path27" />
    <g
       fill="#ffce00"
       id="g28">
      <path
         d="M 95.588,58.806 H 57.794 L 67.427,21.03 h 37.796 z"
         id="path28" />
      <use
         xlink:href="#K"
         x="72.781998"
         y="-75.556"
         id="use28" />
    </g>
    <path
       d="M 66.686,172.135 H 28.892 l 9.633,-37.776 h 37.796 z"
       class="J"
       id="path29" />
    <path
       d="M 57.052,209.912 H 19.258 l 9.633,-37.776 h 37.796 z"
       fill="#ff0107"
       id="path30" />
    <use
       xlink:href="#K"
       x="53.514"
       y="-0.003"
       class="I"
       id="use30" />
    <path
       d="M 237.135,96.582 H 199.34 l 9.633,-37.776 h 37.796 z"
       class="K"
       id="path31" />
    <use
       xlink:href="#K"
       x="43.880001"
       y="37.772999"
       class="J"
       id="use31" />
    <use
       xlink:href="#K"
       x="34.245998"
       y="75.550003"
       fill="#ff0107"
       id="use32" />
  </g>
</svg>
) +5\n\n[Breakdown Documents into Study Notes using Templating MistralAI and Qdrant](https://n8n.io/workflows/2339-breakdown-documents-into-study-notes-using-templating-mistralai-and-qdrant/)\n\n19670 â€¢ **by jimleuk** â€¢ 10 months \n\n[ Use this workflow ](https://n8n.io/workflows/2339-breakdown-documents-into-study-notes-using-templating-mistralai-and-qdrant/)\n\n[ Get started ](https://app.n8n.cloud/register)\n\n## What is a local LLM?\n\nA local LLM is simply a large language model that runs locally, on your computer, eliminating the need to send your data to a cloud provider. This means you can harness the power of an LLM while maintaining full control over your sensitive information, ensuring privacy and security.\n\nBy running an LLM locally, you have the freedom to experiment, customize, and fine-tune the model to your specific needs without external dependencies. You can choose from a wide range of open-source models, tailor them to your specific tasks, and even experiment with different configurations to optimize performance.\n\nWhile there might be upfront costs for suitable hardware, you can avoid the recurring expenses associated with API calls, potentially leading to significant savings in the long run. This makes local LLMs a more cost-effective solution, especially for high-volume usage.\n\nðŸ’¡\n\nLooking for the fastest way to build your own self-hosted AI workflows? Use [this self-hosted AI kit](https://blog.n8n.io/self-hosted-ai/), an easy-to-deploy docker compose template that includes n8n and a selection of best-in-class local AI tools. \n\n## Can I run LLM locally?\n\nSo, you're probably wondering, \"Can I actually run an LLM on my local workstation?\". The good news is that you likely can do so if you have a relatively modern laptop or desktop! However, some hardware considerations can significantly impact the speed of prompt answering and overall performance.\n\nLetâ€™s look at 3 components youâ€™ll need to experiment with local LLMs.\n\n### Hardware requirements\n\nWhile not strictly necessary, having a PC or laptop with a dedicated graphics card is highly recommended. This will significantly improve the performance of LLMs, as they can leverage the GPU for faster computations. Without a dedicated GPU, LLMs might run quite slowly, making them impractical for real-world use.\n\nThe GPU's video RAM (vRAM) plays a pivotal role here: it determines the maximum size and complexity of the LLM that can be loaded and processed efficiently. More vRAM allows larger models to fit entirely on the GPU, leading to significantly faster speeds, as accessing model parameters from vRAM is orders of magnitude quicker than from standard system RAM.\n\nLLMs can be quite resource-intensive, so it's essential to have enough RAM and storage space to accommodate them. The exact requirements will vary depending on the specific LLM you choose, but having at least 16GB of RAM and a decent amount of free disk space is a good starting point.\n\n### Software requirements\n\nBesides the hardware, you also need the right software to effectively run and manage LLMs locally. This software generally falls into three categories:\n\n  * Servers: these run and manage LLMs in the background, handling tasks like loading models, processing requests, and generating responses. They provide the essential infrastructure for your LLMs. Some examples are [Ollama](https://ollama.com/?ref=blog.n8n.io) and [Lalamafile](https://github.com/Mozilla-Ocho/llamafile?ref=blog.n8n.io).\n  * User interfaces: these provide a visual way to interact with your LLMs. They allow you to input prompts, view generated text, and potentially customize the model's behavior. User interfaces make it easier to experiment with LLMs. Some examples are [OpenWebUI](https://openwebui.com/?ref=blog.n8n.io) and [LobeChat](https://github.com/lobehub/lobe-chat?ref=blog.n8n.io).\n  * Full-stack solutions: these are all-in-one tools that combine the server and the user interface components. They handle everything from model management to processing and provide a built-in visual interface for interacting with the LLMs. They are particularly suitable for users who prefer a simplified setup. Some examples are [GPT4All](https://www.nomic.ai/gpt4all?ref=blog.n8n.io) and [Jan](https://jan.ai/?ref=blog.n8n.io).\n\n\n\n### Open source LLMs\n\nLast, but not least, you need the LLMs themselves. These are the large language models that will process your prompts and generate text. There are many different LLMs available, each with its own strengths and weaknesses. Some are better at generating creative text formats, while others are suited for writing code.\n\nWhere can you download the LLMs from? One popular source for open-source LLMs is Hugging Face. They have a large repository of models that you can download and use for free.\n\nNext, let's look at what are some of the most popular LLMs to get started with.\n\n## Which LLMs to run locally?\n\nThe landscape of LLMs you can run on your own hardware is rapidly expanding, with newer, more capable, or more specialized models being released every day!\n\nMany powerful open-source models are available, catering to a wide range of tasks and computational resources. Let's explore some popular options, categorized by their general capabilities and specializations!\n\n### General-purpose model families\n\nSeveral families of models have gained significant popularity in the open-source community due to their strong performance across various benchmarks and tasks.\n\n  * **Llama (Meta AI):** The Llama series, particularly Llama 3 and its variants, are highly capable models known for their strong reasoning and general text generation abilities. They come in various sizes, making them adaptable to different hardware setups. The newest iteration, Llama 4, has been released, however, its size exceeds the capabilities of standard hardware for now.\n  * **Qwen (Alibaba Cloud):** The Qwen family offers a range of models, including multilingual capabilities and versions optimized for coding. They are recognized for their performance, and tool calling abilities. Qwen 2.5 has extremely good performance, especially compared to its size. The recently launched Qwen 3 is even better across benchmarks!\n  * **DeepSeek:** DeepSeek models, including the DeepSeek-R1 series, are often highlighted for their reasoning and coding proficiency. They provide strong open-source alternatives with competitive performance.\n  * **Phi (Microsoft):** Microsoft's Phi models focus on achieving high performance with smaller parameter counts, making them excellent candidates for resource-constrained local setups while still offering surprising capabilities, particularly in reasoning and coding.\n  * **Gemma (Google):** Gemma models represent a family of lightweight, state-of-the-art open models built from the same research and technology used to create Gemini models. They are designed to run on a single GPU making them ideal for local deployment! The latest iteration, Gemma 3, offers various sizes (e.g., 1B, 4B, 12B and 27B parameters) and is known for strong general performance, especially considering model size.\n  * **Mistral (Mistral AI)** : Mistral AI, a French company, offers a popular family of powerful and efficient open-source models (many under Apache 2.0 license), including the influential Mistral 7B and various Mixtral (Mixture of Experts) versions. These models are known for strong performance in reasoning and coding, come in diverse sizes suitable for local setups, and are praised for their efficiency.\n  * **Granite (IBM):** IBM's Granite models are another family available for open use. The Granite 3.3 iteration, for example, offers variants with 2B and 8B parameters, providing options suitable for different local hardware configurations.\n\n\n\n### Models with advanced capabilities\n\nBeyond general text generation, many open-source models excel in specific advanced capabilities:\n\n  * **Reasoning models:** Models like DeepSeek-R1 and specific fine-tunes of Llama or Mistral are often optimized for complex reasoning, problem-solving, and logical deduction tasks. Microsoftâ€™s Phi family of models also offer reasoning variants, in the form of `phi4-reasoning` and `phi4-mini-reasoning`.\n  * **Mixture-of-experts (MoE):** This architecture allows models to scale efficiently by activating only relevant \"expert\" parts of the network for a given input. Qwen 3 is a MoE model, and Granite also has a MoE variant in the form of `granite3.1-moe`.\n  * **Tool calling models:** The ability for an LLM to use external tools (like APIs or functions) is fundamental to building agentic AI systems. Models are increasingly being trained or fine-tuned with tool-calling capabilities, allowing them to interact with external systems to gather information or perform actions. Frameworks like LangChain or LlamaIndex often facilitate this when running models locally. Examples include `qwen3`, `granite3.3`, `mistral-small3.1` and `phi4-mini`.\n  * **Vision models:** sometimes also called **multimodal** models, are models that can understand and interpret images alongside text. They are becoming more common in the open-source space. Examples include Granite3.2-vision, `llama3.2-vision`, `llava-phi3`, and `BakLLaVA` (which is derived from Mistral 7B).\n\n\n\n### Models that excel at specific tasks\n\nSometimes, you need a model fine-tuned for a particular domain or task for optimal performance.\n\n  1. Coding assistants:\n\n\n  * **DeepCoder:** A fully open-source family (1.5B and 14B parameters) aimed at high-performance code generation.\n  * **OpenCoder** : An open and reproducible code LLM family (1.5B and 8B models) supporting chat in English and Chinese.\n  * **Qwen2.5-Coder** : Part of the Qwen family, specifically optimized for code-related tasks.\n\n\n  2. Math and research\n\n\n  * **Starling-LM-11B-alpha** : Mistral-based model for research and instruction-following.\n  * **Mathstral** : Specialized Mistral AI model for advanced mathematical reasoning.\n  * **Qwen2-math:** Part of the Qwen family, specifically optimized for complex mathematical problem-solving.\n\n\n  3. Creative writing\n\n\n  * **Mistral-7B-OpenOrca** : A fine-tuned version of Mistral AI's base Mistral-7B model, specifically enhanced by training on a curated selection of the OpenOrca dataset.\n\n\n\nChoosing the right open-source model depends heavily on your specific needs, the tasks you want to perform, and the hardware you have available. Experimenting with different models is often the best way to find the perfect fit for your local LLM setup.\n\n## How to run LLMs locally?\n\nTo run LLMs locally, the first step is choosing which model best fits your needs. Once you've selected a model, the next decision is how to run itâ€”most commonly using software like Ollama. However, Ollama isnâ€™t your only option. There are several other powerful and user-friendly tools available for running local LLMs, each with its own strengths.\n\nLetâ€™s explore some of the most popular choices below!\n\n### Ollama (+ OpenWebUI)\n\n![Ollama homepage](https://blog.n8n.io/content/images/2025/05/ollama.webp)Ollama homepage\n\n[Ollama ](https://ollama.com/?ref=blog.n8n.io)is a command-line tool that simplifies the process of downloading and running LLMs locally. It has a simple set of commands for managing models, making it easy to get started.\n\nOllama is ideal for quickly trying out different open-source LLMs, especially for users comfortable with the command line. Itâ€™s also the go-to tool for homelab and self-hosting enthusiasts who can use Ollama as an AI backend for various applications.\n\nWhile Ollama itself is primarily a command-line tool, you can enhance its usability by pairing it with [OpenWebUI](https://github.com/open-webui/open-webui?ref=blog.n8n.io), which provides a graphical interface for interacting with your LLMs.\n\nðŸ’¡\n\nConnect your local Ollama setup to n8n and start using your downloaded LLMs in any of your automation workflows! Check out this YouTube video to see [_how to create a local AI agent for free with n8n and Ollama_](https://www.youtube.com/watch?v=y9m3i12qkms&ref=blog.n8n.io).\n\n#### Pros\n\n  * Simple and easy to use\n  * Supports a wide range of open-source models\n  * Runs on most hardware and major operating systems\n\n\n\n#### Cons\n\n  * Primarily command-line based (without OpenWebUI), which may not be suitable for all users.\n\n\n\n### LM Studio\n\n![](https://blog.n8n.io/content/images/2025/05/lmstudio.webp)LM Studio homepage\n\n[LM Studio](https://lmstudio.ai/?ref=blog.n8n.io) is a platform designed to make it easy to run and experiment with LLMs locally. It offers a range of tools for customizing and fine-tuning your LLMs, allowing you to optimize their performance for specific tasks.\n\nIt is excellent for customizing and fine-tuning LLMs for specific tasks, making it a favorite among researchers and developers seeking granular control over their AI solutions.\n\n#### Pros\n\n  * Model customization options\n  * Ability to fine-tune LLMs\n  * Track and compare the performance of different models and configurations to identify the best approach for your use case.\n  * Runs on most hardware and major operating systems\n\n\n\n#### Cons\n\n  * Steeper learning curve compared to other tools\n  * Fine-tuning and experimenting with LLMs can demand significant computational resources.\n\n\n\n### Jan\n\n![Jan chat interface](https://blog.n8n.io/content/images/2025/05/jan.webp)Jan chat interface\n\n[Jan](https://jan.ai/?ref=blog.n8n.io) is another noteworthy option for running LLMs locally. It places a strong emphasis on privacy and security. It can be used to interact with both local and remote (cloud-based) LLMs.\n\nOne of Jan's unique features is its flexibility in terms of server options. While it offers its own local server, Jan can also integrate with Ollama and LM Studio, utilizing them as remote servers. This is particularly useful when you want to use Jan as a client and have LLMs running on a more powerful server.\n\n#### Pros\n\n  * Strong focus on privacy and security\n  * Flexible server options, including integration with Ollama and LM Studio\n  * Jan offers a user-friendly experience, even for those new to running LLMs locally\n\n\n\n#### Cons\n\n  * While compatible with most hardware, support for AMD GPUs is still in development.\n\n\n\n### GPT4All\n\n![GPT4All chat interface](https://blog.n8n.io/content/images/2025/05/gpt4all.webp)GPT4All chat interface\n\n[GPT4All ](https://www.nomic.ai/gpt4all?ref=blog.n8n.io)is designed to be user-friendly, offering a chat-based interface that makes it easy to interact with the LLMs. It has out-of-the-box support for â€œLocalDocsâ€, a feature allowing you to chat privately and locally with your documents.\n\n#### Pros\n\n  * Intuitive chat-based interface\n  * Runs on most hardware and major operating systems\n  * Open-source and community-driven\n  * Enterprise edition available\n\n\n\n#### Cons\n\n  * May not be as feature-rich as some other options, lacking in areas such as model customization and fine-tuning.\n\n\n\n### NextChat\n\n![nextchat homepage](https://blog.n8n.io/content/images/2025/05/nextchat.dev_.webp)nextchat homepage\n\n[NextChat](https://nextchat.dev/?ref=blog.n8n.io) is a versatile platform designed for building and deploying conversational AI experiences. Unlike the other options on this list, which primarily focus on running open-source LLMs locally, NextChat excels at integrating with closed-source models like ChatGPT and Google Gemini.\n\n#### Pros\n\n  * Compatibility with a wide range of LLMs, including closed-source models\n  * Robust tools for building and deploying conversational AI experiences\n  * Enterprise-focused features and integrations\n\n\n\n#### Cons\n\n  * May be overkill for simple local LLM experimentation\n  * Geared towards more complex conversational AI applications.\n\n\n\n## How to run a local LLM with n8n?\n\nNow that youâ€™re familiar with what local LLMs are, the hardware and software they require, and the most popular tools for running them on your machine, the next step is putting that power to work.\n\nIf you're looking to automate tasks, build intelligent workflows, or integrate LLMs into broader systems, **n8n** offers a flexible way to do just that.\n\nIn the following section, weâ€™ll walk through how to run a local LLM with n8nâ€”connecting your model, setting up a workflow, and chatting with it seamlessly using tools like Ollama.\n\nðŸ’¡\n\nTo run a local LLM with n8n, use [the ****Self-Hosted AI Starter Kit****](https://blog.n8n.io/self-hosted-ai/)â€”a Docker Compose setup that bundles n8n with tools like Ollama and Qdrant. It offers easy installation, workflow templates, and flexible configurations, giving you full control over your local AI workflows and data.\n\nn8n uses [LangChain](https://www.langchain.com/?ref=blog.n8n.io) to simplify the development of complex interactions with LLMs such as chaining multiple prompts together, implementing decision making and interacting with external data sources. The low-code approach that n8n uses, fits perfectly with the modular nature of LangChain, allowing users to assemble and customize LLM workflows without extensive coding.\n\nNow, let's also explore a quick local LLM workflow!\n\nWith this n8n workflow, you can easily chat with your self-hosted Large Language Models (LLMs) through a simple, user-friendly interface. By hooking up to Ollama, a handy tool for managing local LLMs, you can send prompts and get AI-generated responses right within n8n:\n\n__![Ollama Chat Model](data:image/svg+xml;base64,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) ____\n\n[Chat with local LLMs using n8n and Ollama](https://n8n.io/workflows/2384-chat-with-local-llms-using-n8n-and-ollama/)\n\nby mihailtd\n\n[ Use this workflow ](https://n8n.io/workflows/2384-chat-with-local-llms-using-n8n-and-ollama/)\n\n### Step 1: Install Ollama and run a model\n\nInstalling Ollama is straightforward, just [download the Ollama installer](https://ollama.com/download?ref=blog.n8n.io) for your operating system. You can install Ollama on Windows, Mac or Linux.\n\nAfter youâ€™ve installed Ollama, you can pull a model such as Llama3, with the `ollama pull llama3` command:\n\n![terminal command for running Ollama](https://blog.n8n.io/content/images/2025/05/ollama_cli.webp)terminal command for running Ollama\n\nDepending on the model, the download can take some time. This version of Llama3, for example, is 4.7 Gb.After the download is complete, run `ollama run llama3` and you can start chatting with the model right from the command line!\n\n### Step 2: Set up a chat workflow\n\nLetâ€™s now set up a simple n8n workflow that uses your local LLM running with Ollama. Here is a sneak peek of the workflow we will build:\n\n![n8n workflow with local LLM using Ollama](https://blog.n8n.io/content/images/2025/05/n8n_ollama_integration.webp)n8n workflow with local LLM using Ollama\n\nStart by adding a [Chat trigger node](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-langchain.chattrigger/?ref=blog.n8n.io&_gl=1*15sckhc*_gcl_aw*R0NMLjE3NDIyMDExMjAuQ2owS0NRandrTi0tQmhEa0FSSXNBRF9tbklxd1dsSnNMTWRFUjRHdzdHd01ERUo4VXlZa055WDZTSFdUMlc3MHVCODJCR3lxZ3F4NjM0SWFBcF9ORUFMd193Y0I.*_gcl_au*MTQ3NjA3MzYzMi4xNzM5ODI5NDY5*_ga*MjEzOTMyNzI5OC4xNzQ3MTcyNDg5*_ga_0SC4FF2FH9*czE3NDcyNDc0NDQkbzYkZzEkdDE3NDcyNDg5MTIkajYwJGwwJGgw), which is the workflow starting point for building chat interfaces with n8n. Then we need to connect the chat trigger to a [Basic LLM Chain](https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.chainllm/?ref=blog.n8n.io) where we will set the prompt and configure the LLM to use.\n\n### Step 3: Connect n8n with Ollama\n\nConnecting Ollama with n8n couldnâ€™t be easier thanks to the [Ollama Model sub-node](https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmollama/?ref=blog.n8n.io)! Ollama is a background process running on your computer and exposes an API on port 11434. You can check if the Ollama API is running by opening a browser window and accessing `http://localhost :11434`, and you should see a message saying â€œOllama is runningâ€.\n\nFor n8n to be able to communicate with Ollamaâ€™s API via localhost, both applications need to be on the same network. If you are running n8n in Docker, you would need to start the Docker container with the `--network=host` parameter. That way the n8n container can access any port on the hostâ€™s machine.\n\nTo set a connection between n8n and Ollama, we simply leave everything as default in the Ollama connection window:\n\n![n8n Ollama connection setup](https://blog.n8n.io/content/images/2025/05/n8n_ollama_connection.webp)n8n Ollama connection setup\n\nAfter the connection to the Ollama API is successful, in the **Model**  dropdown you should not see all the models youâ€™ve downloaded. Just pick the `llama3:latest` model weâ€™ve downloaded earlier.\n\n![choosing a local model to use with n8n](https://blog.n8n.io/content/images/2025/05/n8n_ollama_configuration.webp)choosing a local model to use with n8n\n\n### Step 4: Chat with Llama3\n\nNext, let's chat with our local LLM! Click the **Chat**  button on the bottom of the workflow page to test it out. Type any message and your local LLM should respond. Itâ€™s that easy!\n\n![chatting with local LLMs in n8n](https://blog.n8n.io/content/images/2025/05/n8n_chat_interface.webp)chatting with local LLMs in n8n\n\n## FAQ\n\n#### Are local LLMs as good as ChatGPT?\n\nLocal LLMs are getting incredibly good, very quickly! Many of them, like some versions of Llama, Qwen, or Gemma, can be amazing for specific jobs you want them to do. If you want an AI that's private because all your data stays with you, a local LLM can be just as good, or even better for that particular need!\n\nPlus, running an LLM locally means you can often use it even without an internet connection, customize it to your heart's content, and you don't have to worry about ongoing subscription fees.\n\nWhile ChatGPT is an extremely good LLM, local LLMs can be just as good if not better in specific scenarios.\n\n#### What is the difference between local LLM and online LLM?\n\nThe core difference is where the computation happens and who controls the data\n\n****Local LLMs:****\n\n  * Run directly on your own computer or server.\n  * You control the hardware and software setup.\n  * Your data (prompts, documents, etc.) remains entirely within your infrastructure.\n  * Costs are primarily related to hardware; no per-request fees.\n\n\n\n****Online (Cloud-based) LLMs:****\n\n  * Run on powerful servers managed by a third-party provider (e.g., OpenAI, Google).\n  * You access the model usually through an API or web interface.\n  * Your prompts and potentially other data are sent to the provider's servers for processing.\n  * Costs are typically based on usage (per token, subscription fees).\n  * The provider manages the complex infrastructure.\n\n\n\n#### How to run LLM locally for free?\n\nFor those looking for a straightforward way to get started with running LLMs locally, Ollama offers a user-friendly experience. After installing Ollama (available for macOS, Windows, and Linux), you can easily download and run a wide variety of open-source models directly from the command line. For instance, to use a model like Deepseek R1, you would typically open your terminal and use a simple command such as `ollama pull deepseek-r1:14b` to download the 14b parameter varian. Once downloaded, another straightforward command like `ollama run deepseek-r1` allows you to start interacting with the model immediately from the command line.\n\nOllama manages the model files and provides a simple API, abstracting away much of the underlying complexity. You can find a list of available models on the [_Ollama library page_](https://ollama.com/library?ref=blog.n8n.io).\n\n#### What is the cheapest LLM?\n\nWhile many open-source LLMs are free to download, the real cost of running LLMs locally lies in the hardware needed to run them effectively and the electricity costs. \"Cheaper\" models in this context are those with lower hardware requirements, which often correlates with the number of parameters they have.\n\nThe model itself (or at least significant parts of it) needs to fit into the Video RAM (VRAM) of your graphics card (GPU) for optimal performance. Larger models require more VRAM. For example, running a model that's around 20GB in size efficiently would typically require a graphics card with at least 24GB of VRAM, such as an NVIDIA GeForce RTX 4090 or RTX 3090.\n\nModels with fewer parameters (e.g., 1 billion to 8 billion) are generally \"cheaper\" to run because they require less VRAM and processing power. They can perform well and quickly on mid-tier consumer hardware. Here are some examples of liter models:\n\n  * Llama 3.2 with either 1B or 3B parameters\n  * Qwen 3 has 0.6B, 1.7B, 4B and 8B parameter versions available\n  * DeepSeek-R1 (distilled): 1.5B, 7B or 8B parameter models\n\n\n\nModels with significantly more parameters (e.g., 14 billion+) offer potentially higher capability but demand more substantial hardware. High-end consumer graphics cards like the NVIDIA GeForce RTX 4090 (24GB), RTX 5090 (32GB) or AMD Radeon RX 7900 XTX (24GB) are often needed. For the very largest models, you might require professional GPUs (like NVIDIA A100/H100) or even multiple GPUs working together, significantly increasing the cost of running local LLMs.\n\nGPUs like NVIDIA GeForce RTX 3060 (12GB), RTX 4060 Ti (16GB), or RTX 4070 (12GB) can often handle these models well. Even some modern integrated graphics or Apple Silicon chips (M-series) can run smaller models, albeit slower than dedicated GPUs.\n\nCloud-based LLMs follow a similar pattern regarding cost and capability. Providers often offer different tiers:\n\n  * Cheaper/Faster Models: Usually smaller or optimized versions (e.g., OpenAI's gpt-4o-mini, Google's gemini-2.0-flash). They are less expensive per token/request but may be less capable for complex reasoning or nuanced tasks.\n  * More Expensive/Capable Models: State-of-the-art, larger models (e.g., OpenAI's gpt-4o, Google's gemini-2.5-pro). They offer higher performance but come at a higher usage cost.\n\n\n\n#### Is there any open-source LLM?\n\nYes, absolutely! The open-source LLM landscape is vast and growing rapidly. Many leading AI companies and research institutions release models under open-source licenses.\n\nPopular examples include:\n\n  * Meta's Llama series (e.g., Llama 4 and 3.2)\n  * Mistral AI's models (e.g., Mistral 7B)\n  * Alibaba's Qwen series (e.g., Qwen 3)\n  * DeepSeek AI's models (e.g., DeepSeek-R1)\n\n\n\nBeyond these, many open-source models are trained to excel in specific areas. Here are some examples:\n\n  * Multilingual: Microsoftâ€™s phi4-mini\n  * Coding: athene-v2, codegemma, deepseek-coder\n  * Vision (Image Understanding): mistral-small3.1, gemma3, granite3.2-vision\n  * Reasoning: DeepSeek-R1, QWQ, marco-o1\n  * Mathematics: mathstral, athene-v2\n\n\n\n## Wrap up\n\nRunning LLMs locally is not only doable but also practical for those who prioritize privacy, cost savings, or want a deeper understanding of AI.\n\nThanks to tools like Ollama, which make it easier to run LLMs on consumer hardware, and platforms like n8n, which help you build AI-powered applications, using LLMs on your own computer is now simpler than ever!\n\n## Whatâ€™s next?\n\nNow that you've explored how to run LLMs locally, why not dive deeper into practical applications? Check out these YouTube videos:\n\n  * **Get started with local AI agents:** Learn how to [Build a Local AI Agent with N8N, Postgres, and Ollama (Free)](https://www.youtube.com/watch?v=qqjzohCle48&ref=blog.n8n.io) or explore another comprehensive tutorial on [Setting Up Local AI Agents Without Code](https://www.youtube.com/watch?v=y9m3i12qkms&ref=blog.n8n.io) using similar tools.\n  * **Explore vector databases with local LLMs:** Discover how to [Build a Local AI Agent with Qdrant and Ollama to Interact with Your Documents](https://www.youtube.com/watch?v=XQ7wNqbB1x8&ref=blog.n8n.io).\n\n\n\nAnd if you're interested in exploring a broader range of AI-powered automations beyond just local LLMs, be sure to check out this selection of workflow templates:\n\n### Most popular workflows with these integrations\n\n![Pinecone Vector Store](data:image/svg+xml;base64,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)![Embeddings Google Gemini](data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiB2aWV3Qm94PSIwIDAgNDggNDgiPjxkZWZzPjxwYXRoIGlkPSJhIiBkPSJNNDQuNSAyMEgyNHY4LjVoMTEuOEMzNC43IDMzLjkgMzAuMSAzNyAyNCAzN2MtNy4yIDAtMTMtNS44LTEzLTEzczUuOC0xMyAxMy0xM2MzLjEgMCA1LjkgMS4xIDguMSAyLjlsNi40LTYuNEMzNC42IDQuMSAyOS42IDIgMjQgMiAxMS44IDIgMiAxMS44IDIgMjRzOS44IDIyIDIyIDIyYzExIDAgMjEtOCAyMS0yMiAwLTEuMy0uMi0yLjctLjUtNCIvPjwvZGVmcz48Y2xpcFBhdGggaWQ9ImIiPjx1c2UgeGxpbms6aHJlZj0iI2EiIG92ZXJmbG93PSJ2aXNpYmxlIi8+PC9jbGlwUGF0aD48cGF0aCBmaWxsPSIjRkJCQzA1IiBkPSJNMCAzN1YxMWwxNyAxM3oiIGNsaXAtcGF0aD0idXJsKCNiKSIvPjxwYXRoIGZpbGw9IiNFQTQzMzUiIGQ9Im0wIDExIDE3IDEzIDctNi4xTDQ4IDE0VjBIMHoiIGNsaXAtcGF0aD0idXJsKCNiKSIvPjxwYXRoIGZpbGw9IiMzNEE4NTMiIGQ9Im0wIDM3IDMwLTIzIDcuOSAxTDQ4IDB2NDhIMHoiIGNsaXAtcGF0aD0idXJsKCNiKSIvPjxwYXRoIGZpbGw9IiM0Mjg1RjQiIGQ9Ik00OCA0OCAxNyAyNGwtNC0zIDM1LTEweiIgY2xpcC1wYXRoPSJ1cmwoI2IpIi8+PC9zdmc+)![Default Data Loader](data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSI3NjgiIGhlaWdodD0iMTAyNCI+PHBhdGggZmlsbD0iIzdEN0Q4NyIgZD0iTTAgOTYwVjY0aDU3NmwxOTIgMTkydjcwNHptNzA0LTY0MEw1MTIgMTI4SDY0djc2OGg2NDB6TTMyMCA1MTJIMTI4VjI1NmgxOTJ6bS02NC0xOTJoLTY0djEyOGg2NHptMCA0NDhoNjR2NjRIMTI4di02NGg2NFY2NDBoLTY0di02NGgxMjh6bTI1Ni0zMjBoNjR2NjRIMzg0di02NGg2NFYzMjBoLTY0di02NGgxMjh6bTY0IDM4NEgzODRWNTc2aDE5MnptLTY0LTE5MmgtNjR2MTI4aDY0eiIvPjwvc3ZnPg==) ____ +5\n\n[RAG Chatbot for Company Documents using Google Drive and Gemini](https://n8n.io/workflows/2753-rag-chatbot-for-company-documents-using-google-drive-and-gemini/)\n\n74518 â€¢ **by mihailtd** â€¢ 4 months \n\n[ Use this workflow ](https://n8n.io/workflows/2753-rag-chatbot-for-company-documents-using-google-drive-and-gemini/)\n\n______![MCP Client Tool](data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTgwIiBoZWlnaHQ9IjE4MCIgdmlld0JveD0iMCAwIDE5NSAxOTUiIGZpbGw9Im5vbmUiIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyI+Cgk8ZyBzdHJva2U9IiMwMDAiIHN0cm9rZS13aWR0aD0iMTIiIHN0cm9rZS1saW5lY2FwPSJyb3VuZCI+CgkJPHBhdGggZD0iTTI1IDk3Ljg1MjhMOTIuODgyMyAyOS45NzA2QzEwMi4yNTUgMjAuNTk4IDExNy40NTEgMjAuNTk4IDEyNi44MjMgMjkuOTcwNlYyOS45NzA2QzEzNi4xOTYgMzkuMzQzMSAxMzYuMTk2IDU0LjUzOTEgMTI2LjgyMyA2My45MTE3TDc1LjU1ODEgMTE1LjE3NyIvPgoJCTxwYXRoIGQ9Ik03Ni4yNjUzIDExNC40N0wxMjYuODIzIDYzLjkxMTdDMTM2LjE5NiA1NC41MzkxIDE1MS4zOTIgNTQuNTM5MSAxNjAuNzY1IDYzLjkxMTdMMTYxLjExOCA2NC4yNjUyQzE3MC40OTEgNzMuNjM3OCAxNzAuNDkxIDg4LjgzMzggMTYxLjExOCA5OC4yMDYzTDk5LjcyNDggMTU5LjZDOTYuNjAwNiAxNjIuNzI0IDk2LjYwMDYgMTY3Ljc4OSA5OS43MjQ4IDE3MC45MTNMMTEyLjMzMSAxODMuNTIiLz4KCQk8cGF0aCBkPSJNMTA5Ljg1MyA0Ni45NDExTDU5LjY0ODIgOTcuMTQ1N0M1MC4yNzU3IDEwNi41MTggNTAuMjc1NyAxMjEuNzE0IDU5LjY0ODIgMTMxLjA4N1YxMzEuMDg3QzY5LjAyMDggMTQwLjQ1OSA4NC4yMTY4IDE0MC40NTkgOTMuNTg5NCAxMzEuMDg3TDE0My43OTQgODAuODgyMiIvPgoJPC9nPgo8L3N2Zz4K)![OpenAI Chat Model](data:image/svg+xml;base64,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) +2\n\n[Build an MCP Server with Airtable](https://n8n.io/workflows/3879-build-an-mcp-server-with-airtable/)\n\n4323 â€¢ **by aitoralonso** â€¢ 22 days \n\n[ Use this workflow ](https://n8n.io/workflows/3879-build-an-mcp-server-with-airtable/)\n\n![Google Gemini Chat Model](data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiB2aWV3Qm94PSIwIDAgNDggNDgiPjxkZWZzPjxwYXRoIGlkPSJhIiBkPSJNNDQuNSAyMEgyNHY4LjVoMTEuOEMzNC43IDMzLjkgMzAuMSAzNyAyNCAzN2MtNy4yIDAtMTMtNS44LTEzLTEzczUuOC0xMyAxMy0xM2MzLjEgMCA1LjkgMS4xIDguMSAyLjlsNi40LTYuNEMzNC42IDQuMSAyOS42IDIgMjQgMiAxMS44IDIgMiAxMS44IDIgMjRzOS44IDIyIDIyIDIyYzExIDAgMjEtOCAyMS0yMiAwLTEuMy0uMi0yLjctLjUtNCIvPjwvZGVmcz48Y2xpcFBhdGggaWQ9ImIiPjx1c2UgeGxpbms6aHJlZj0iI2EiIG92ZXJmbG93PSJ2aXNpYmxlIi8+PC9jbGlwUGF0aD48cGF0aCBmaWxsPSIjRkJCQzA1IiBkPSJNMCAzN1YxMWwxNyAxM3oiIGNsaXAtcGF0aD0idXJsKCNiKSIvPjxwYXRoIGZpbGw9IiNFQTQzMzUiIGQ9Im0wIDExIDE3IDEzIDctNi4xTDQ4IDE0VjBIMHoiIGNsaXAtcGF0aD0idXJsKCNiKSIvPjxwYXRoIGZpbGw9IiMzNEE4NTMiIGQ9Im0wIDM3IDMwLTIzIDcuOSAxTDQ4IDB2NDhIMHoiIGNsaXAtcGF0aD0idXJsKCNiKSIvPjxwYXRoIGZpbGw9IiM0Mjg1RjQiIGQ9Ik00OCA0OCAxNyAyNGwtNC0zIDM1LTEweiIgY2xpcC1wYXRoPSJ1cmwoI2IpIi8+PC9zdmc+)![HTTP Request Tool](data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0MCA0MCI+PHBhdGggZmlsbD0iIzAwMDRGNSIgZmlsbC1ydWxlPSJldmVub2RkIiBkPSJNNDAgMjBDNDAgOC45NTMgMzEuMDQ3IDAgMjAgMFMwIDguOTUzIDAgMjBzOC45NTMgMjAgMjAgMjAgMjAtOC45NTMgMjAtMjBNMjAgMzYuOTQ2Yy0xLjExNSAwLTIuODYyLS45NzktNC41LTQuMjQ3LS43MDQtMS40MDctMS4zMDQtMy4xNTYtMS43NDctNS4wMTRIMjYuMTljLS4zODYgMS44NTUtLjk4NiAzLjYwNS0xLjY5IDUuMDE0LTEuNjM4IDMuMjY4LTMuMzg1IDQuMjQ3LTQuNSA0LjI0N00xMi45MDYgMjBjMCAxLjYxLjEwMyAzLjE2NC4yOTQgNC42M2gxMy42YTM2IDM2IDAgMCAwIC4yOTQtNC42M2MwLTEuNjEtLjEwMy0zLjE2NC0uMjk0LTQuNjNIMTMuMmEzNiAzNiAwIDAgMC0uMjk0IDQuNjNNMjAgMy4wNTRjMS4xMTUgMCAyLjg2Mi45NzcgNC41IDQuMjQ2LjcwNyAxLjQxNCAxLjMwNyAzLjEwNyAxLjY5MiA1LjAxNUgxMy43NWMuNDQzLTEuOTEgMS4wNDQtMy42MDIgMS43NS01LjAxNCAxLjYzOC0zLjI3IDMuMzg1LTQuMjQ3IDQuNS00LjI0N00zMC4xNDggMjBjMC0xLjU5LS4wOTQtMy4xMzgtLjMyNS00LjYzaDYuNDgxYy40MjEgMS40NzIuNjQyIDMuMDI2LjY0MiA0LjYzcy0uMjIgMy4xNTgtLjY0MiA0LjYzaC02LjQ4MWMuMjMxLTEuNDkyLjMyNS0zLjA0LjMyNS00LjYzTTI2LjI3NyA0LjI1NWMxLjM2IDIuMTA1IDIuNDM0IDQuODc3IDMuMSA4LjA2aDUuNzI4YTE2Ljk4IDE2Ljk4IDAgMCAwLTguODI4LTguMDZtLTE1LjY1NCA4LjA2aC01LjczYzEuODU4LTMuNjQ3IDUtNi41MzIgOC44My04LjA2LTEuMzYgMi4xMDUtMi40MzQgNC44NzctMy4xIDguMDZNMy4wNTQgMjBjMCAxLjYwMy4yMjMgMy4xNTcuNjQgNC42M2g2LjQyOGE0MCA0MCAwIDAgMS0uMjctNC42M2MwLTEuNTk0LjA5NC0zLjE0Mi4yNy00LjYzSDMuNjk1YTE3IDE3IDAgMCAwLS42NCA0LjYzbTIzLjIyMyAxNS43NDNjMS4zNi0yLjEwNCAyLjQzNC00Ljg3NSAzLjEtOC4wNThoNS43MjhhMTYuOTYgMTYuOTYgMCAwIDEtOC44MjggOC4wNThtLTEyLjU1NCAwYTE3IDE3IDAgMCAxLTguODMtOC4wNThoNS43M2MuNjY2IDMuMTgzIDEuNzQgNS45NTQgMy4xIDguMDU4IiBjbGlwLXJ1bGU9ImV2ZW5vZGQiLz48L3N2Zz4=) ______\n\n[AI Agent: Scrape, Summarize & Save Articles to Notion (Gemini, Browserless)](https://n8n.io/workflows/3535-ai-agent-scrape-summarize-and-save-articles-to-notion-gemini-browserless/)\n\n4818 â€¢ **by mihailtd** â€¢ 1 month \n\n[ Use this workflow ](https://n8n.io/workflows/3535-ai-agent-scrape-summarize-and-save-articles-to-notion-gemini-browserless/)\n\n![Pinecone Vector Store](data:image/svg+xml;base64,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)![Embeddings Google Gemini](data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiB2aWV3Qm94PSIwIDAgNDggNDgiPjxkZWZzPjxwYXRoIGlkPSJhIiBkPSJNNDQuNSAyMEgyNHY4LjVoMTEuOEMzNC43IDMzLjkgMzAuMSAzNyAyNCAzN2MtNy4yIDAtMTMtNS44LTEzLTEzczUuOC0xMyAxMy0xM2MzLjEgMCA1LjkgMS4xIDguMSAyLjlsNi40LTYuNEMzNC42IDQuMSAyOS42IDIgMjQgMiAxMS44IDIgMiAxMS44IDIgMjRzOS44IDIyIDIyIDIyYzExIDAgMjEtOCAyMS0yMiAwLTEuMy0uMi0yLjctLjUtNCIvPjwvZGVmcz48Y2xpcFBhdGggaWQ9ImIiPjx1c2UgeGxpbms6aHJlZj0iI2EiIG92ZXJmbG93PSJ2aXNpYmxlIi8+PC9jbGlwUGF0aD48cGF0aCBmaWxsPSIjRkJCQzA1IiBkPSJNMCAzN1YxMWwxNyAxM3oiIGNsaXAtcGF0aD0idXJsKCNiKSIvPjxwYXRoIGZpbGw9IiNFQTQzMzUiIGQ9Im0wIDExIDE3IDEzIDctNi4xTDQ4IDE0VjBIMHoiIGNsaXAtcGF0aD0idXJsKCNiKSIvPjxwYXRoIGZpbGw9IiMzNEE4NTMiIGQ9Im0wIDM3IDMwLTIzIDcuOSAxTDQ4IDB2NDhIMHoiIGNsaXAtcGF0aD0idXJsKCNiKSIvPjxwYXRoIGZpbGw9IiM0Mjg1RjQiIGQ9Ik00OCA0OCAxNyAyNGwtNC0zIDM1LTEweiIgY2xpcC1wYXRoPSJ1cmwoI2IpIi8+PC9zdmc+)![Default Data Loader](data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSI3NjgiIGhlaWdodD0iMTAyNCI+PHBhdGggZmlsbD0iIzdEN0Q4NyIgZD0iTTAgOTYwVjY0aDU3NmwxOTIgMTkydjcwNHptNzA0LTY0MEw1MTIgMTI4SDY0djc2OGg2NDB6TTMyMCA1MTJIMTI4VjI1NmgxOTJ6bS02NC0xOTJoLTY0djEyOGg2NHptMCA0NDhoNjR2NjRIMTI4di02NGg2NFY2NDBoLTY0di02NGgxMjh6bTI1Ni0zMjBoNjR2NjRIMzg0di02NGg2NFYzMjBoLTY0di02NGgxMjh6bTY0IDM4NEgzODRWNTc2aDE5MnptLTY0LTE5MmgtNjR2MTI4aDY0eiIvPjwvc3ZnPg==) ____ +5\n\n[AI-Powered RAG Workflow For Stock Earnings Report Analysis](https://n8n.io/workflows/2741-ai-powered-rag-workflow-for-stock-earnings-report-analysis/)\n\n13127 â€¢ **by mihailtd** â€¢ 4 months \n\n[ Use this workflow ](https://n8n.io/workflows/2741-ai-powered-rag-workflow-for-stock-earnings-report-analysis/)\n\n![Merge](data:image/svg+xml;base64,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) __![Telegram](data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiBmaWxsPSIjZmZmIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiIHN0cm9rZT0iIzAwMCIgc3Ryb2tlLWxpbmVjYXA9InJvdW5kIiBzdHJva2UtbGluZWpvaW49InJvdW5kIiB2aWV3Qm94PSIwIDAgNjYgNjYiPjx1c2UgeGxpbms6aHJlZj0iI2EiIHg9Ii41IiB5PSIuNSIvPjxzeW1ib2wgaWQ9ImEiIG92ZXJmbG93PSJ2aXNpYmxlIj48ZyBmaWxsLXJ1bGU9Im5vbnplcm8iIHN0cm9rZT0ibm9uZSI+PHBhdGggZmlsbD0iIzM3YWVlMiIgZD0iTTAgMzJjMCAxNy42NzMgMTQuMzI3IDMyIDMyIDMyczMyLTE0LjMyNyAzMi0zMlM0OS42NzMgMCAzMiAwIDAgMTQuMzI3IDAgMzIiLz48cGF0aCBmaWxsPSIjYzhkYWVhIiBkPSJtMjEuNjYxIDM0LjMzOCAzLjc5NyAxMC41MDhzLjQ3NS45ODMuOTgzLjk4MyA4LjA2OC03Ljg2NCA4LjA2OC03Ljg2NGw4LjQwNy0xNi4yMzctMjEuMTE5IDkuODk4eiIvPjxwYXRoIGZpbGw9IiNhOWM2ZDgiIGQ9Im0yNi42OTUgMzcuMDM0LS43MjkgNy43NDZzLS4zMDUgMi4zNzMgMi4wNjggMGw0LjY0NC00LjIwMyIvPjxwYXRoIGQ9Im0yMS43MyAzNC43MTItNy44MDktMi41NDVzLS45MzItLjM3OC0uNjMzLTEuMjM3Yy4wNjItLjE3Ny4xODYtLjMyOC41NTktLjU4OCAxLjczMS0xLjIwNiAzMi4wMjgtMTIuMDk2IDMyLjAyOC0xMi4wOTZzLjg1Ni0uMjg4IDEuMzYxLS4wOTdjLjIzMS4wODguMzc4LjE4Ny41MDMuNTQ4LjA0NS4xMzIuMDcxLjQxMS4wNjguNjg5LS4wMDMuMjAxLS4wMjcuMzg2LS4wNDUuNjc4LS4xODQgMi45NzgtNS43MDYgMjUuMTk4LTUuNzA2IDI1LjE5OHMtLjMzIDEuMy0xLjUxNCAxLjM0NWMtLjQzMi4wMTYtLjk1Ni0uMDcxLTEuNTgyLS42MS0yLjMyMy0xLjk5OC0xMC4zNTItNy4zOTQtMTIuMTI2LTguNThhLjM0LjM0IDAgMCAxLS4xNDYtLjIzOWMtLjAyNS0uMTI1LjEwOC0uMjguMTA4LS4yOHMxMy45OC0xMi40MjcgMTQuMzUyLTEzLjczMWMuMDI5LS4xMDEtLjA3OS0uMTUxLS4yMjYtLjEwNy0uOTI5LjM0Mi0xNy4wMjUgMTAuNTA2LTE4LjgwMSAxMS42MjktLjEwNC4wNjYtLjM5NS4wMjMtLjM5NS4wMjMiLz48L2c+PC9zeW1ib2w+PC9zdmc+)![Telegram Trigger](data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiBmaWxsPSIjZmZmIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiIHN0cm9rZT0iIzAwMCIgc3Ryb2tlLWxpbmVjYXA9InJvdW5kIiBzdHJva2UtbGluZWpvaW49InJvdW5kIiB2aWV3Qm94PSIwIDAgNjYgNjYiPjx1c2UgeGxpbms6aHJlZj0iI2EiIHg9Ii41IiB5PSIuNSIvPjxzeW1ib2wgaWQ9ImEiIG92ZXJmbG93PSJ2aXNpYmxlIj48ZyBmaWxsLXJ1bGU9Im5vbnplcm8iIHN0cm9rZT0ibm9uZSI+PHBhdGggZmlsbD0iIzM3YWVlMiIgZD0iTTAgMzJjMCAxNy42NzMgMTQuMzI3IDMyIDMyIDMyczMyLTE0LjMyNyAzMi0zMlM0OS42NzMgMCAzMiAwIDAgMTQuMzI3IDAgMzIiLz48cGF0aCBmaWxsPSIjYzhkYWVhIiBkPSJtMjEuNjYxIDM0LjMzOCAzLjc5NyAxMC41MDhzLjQ3NS45ODMuOTgzLjk4MyA4LjA2OC03Ljg2NCA4LjA2OC03Ljg2NGw4LjQwNy0xNi4yMzctMjEuMTE5IDkuODk4eiIvPjxwYXRoIGZpbGw9IiNhOWM2ZDgiIGQ9Im0yNi42OTUgMzcuMDM0LS43MjkgNy43NDZzLS4zMDUgMi4zNzMgMi4wNjggMGw0LjY0NC00LjIwMyIvPjxwYXRoIGQ9Im0yMS43MyAzNC43MTItNy44MDktMi41NDVzLS45MzItLjM3OC0uNjMzLTEuMjM3Yy4wNjItLjE3Ny4xODYtLjMyOC41NTktLjU4OCAxLjczMS0xLjIwNiAzMi4wMjgtMTIuMDk2IDMyLjAyOC0xMi4wOTZzLjg1Ni0uMjg4IDEuMzYxLS4wOTdjLjIzMS4wODguMzc4LjE4Ny41MDMuNTQ4LjA0NS4xMzIuMDcxLjQxMS4wNjguNjg5LS4wMDMuMjAxLS4wMjcuMzg2LS4wNDUuNjc4LS4xODQgMi45NzgtNS43MDYgMjUuMTk4LTUuNzA2IDI1LjE5OHMtLjMzIDEuMy0xLjUxNCAxLjM0NWMtLjQzMi4wMTYtLjk1Ni0uMDcxLTEuNTgyLS42MS0yLjMyMy0xLjk5OC0xMC4zNTItNy4zOTQtMTIuMTI2LTguNThhLjM0LjM0IDAgMCAxLS4xNDYtLjIzOWMtLjAyNS0uMTI1LjEwOC0uMjguMTA4LS4yOHMxMy45OC0xMi40MjcgMTQuMzUyLTEzLjczMWMuMDI5LS4xMDEtLjA3OS0uMTUxLS4yMjYtLjEwNy0uOTI5LjM0Mi0xNy4wMjUgMTAuNTA2LTE4LjgwMSAxMS42MjktLjEwNC4wNjYtLjM5NS4wMjMtLjM5NS4wMjMiLz48L2c+PC9zeW1ib2w+PC9zdmc+) __ +2\n\n[Telegram AI Chatbot](https://n8n.io/workflows/1934-telegram-ai-chatbot/)\n\n138080 â€¢ **by eduard** â€¢ 1 year \n\n[ Use this workflow ](https://n8n.io/workflows/1934-telegram-ai-chatbot/)\n\n[ Get started ](https://app.n8n.cloud/register)\n\n## Subscribe to n8n newsletter\n\nGet the best, coolest, and latest in automation and low-code delivered to your inbox each week. \n\nSomething went wrong. Please try again later.\n\nSubscribed!\n\nSubscribe\n\n[](https://twitter.com/intent/tweet?text=How%20to%20Run%20a%20Local%20LLM%3A%20Complete%20Guide%20to%20Setup%20%26%20Best%20Models%20\\(2025\\)&url=https://blog.n8n.io/local-llm/) [](https://www.facebook.com/sharer/sharer.php?u=https://blog.n8n.io/local-llm/)\n",
  "crawled_at": "2025-05-28T10:44:01.931684"
}