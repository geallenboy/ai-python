{
  "url": "https://blog.n8n.io/create-a-toxic-language-detector-for-telegram/",
  "title": "Create a toxic language detector for Telegram in 4 steps",
  "excerpt": "Leverage the power of automation and machine learning to enable kinder online discussions.",
  "thumbnail": "https://blog.n8n.io/content/images/size/w1200/2021/09/Perspective-blogpost-cover-1.svg",
  "tags": [
    "Tutorial"
  ],
  "html": "<p>When was the last time you talked to someone online, be it friends, coworkers, or even strangers? Nowadays, you most likely do it every day. </p><h2 id=\"toxic-language-online\">Toxic language online</h2><p>Online communication platforms like Telegram, Reddit, or Discord have made it possible for people from all over the world to connect and share their thoughts on pretty much any topic, instantly. </p><p>This can be an enriching experience for users, but these platforms can also foster toxicity like cyberbullying, threats, and insults, forcing some users offline and silencing their voices.</p><h2 id=\"managing-toxic-language-with-perspective-api\">Managing toxic language with Perspective API</h2><p>One solution to this problem comes from <a href=\"https://jigsaw.google.com/?ref=blog.n8n.io\" target=\"_blank\" rel=\"noopener\">Jigsaw</a> and Google's Counter Abuse Technology team, who developed <a href=\"https://www.perspectiveapi.com/?ref=blog.n8n.io\" target=\"_blank\" rel=\"noopener\"><em>Perspective API</em></a>: a free API that uses machine learning to identify toxic language in English, Spanish, French, German, Portuguese, Italian, and Russian. Toxic language is defined here as<em> </em>“a rude, disrespectful, or unreasonable comment that is likely to make someone leave a discussion”.</p><p>In practice, Perspective scores a phrase based on the perceived impact the text may have in a conversation. The phrase can be analyzed on different attributes: flirtation, identity attack, insult, profanity, sexually explicit, threat, and (severe) toxicity. Keep in mind though that machine learning models can only be as good as the data they’re trained on. This means that they may misclassify as toxic some innocent comments (and vice versa), so the flagged comments should be reviewed by a human eye.</p><p>Perspective API has been implemented by <a href=\"https://www.perspectiveapi.com/case-studies/?ref=blog.n8n.io\" target=\"_blank\" rel=\"noopener\">several major publishers and platforms</a> like Reddit, The New York Times, and DISQUS, helping them moderate online comments. At n8n, we communicate with our 16,000+ community members in the <a href=\"https://community.n8n.io/?ref=blog.n8n.io\" target=\"_blank\" rel=\"noopener\">Discourse forum</a>, on <a href=\"https://discord.gg/vWwMVThRta?ref=blog.n8n.io\" target=\"_blank\" rel=\"noopener\">Discord</a>, <a href=\"https://twitter.com/n8n_io?ref=blog.n8n.io\" target=\"_blank\" rel=\"noopener\">Twitter</a>, and even via <a href=\"https://t.me/comunidadn8n?ref=blog.n8n.io\" target=\"_blank\" rel=\"noopener\">Telegram for Spanish speakers</a>. We value open, <a href=\"https://n8n.io/workflows/982?ref=blog.n8n.io\" target=\"_blank\" rel=\"noopener\">inclusive</a>, and respectful communication and want to ensure that everyone has a positive experience in the n8n community – and beyond.</p><p>To this end, we used the Perspective API to build the <a href=\"https://docs.n8n.io/nodes/n8n-nodes-base.googlePerspective/?ref=blog.n8n.io\" target=\"_blank\" rel=\"noopener\"><em><strong>Google Perspective node</strong></em></a><em>, </em>which allows you to integrate toxic language detection in your workflows.</p><h2 id=\"workflow-for-detecting-toxic-language-in-telegram-messages\">Workflow for detecting toxic language in Telegram messages</h2><p>To give you an idea of how you can use the <em>Google Perspective node</em>, we created <a href=\"https://n8n.io/workflows/1216?ref=blog.n8n.io\" target=\"_blank\" rel=\"noopener\">a workflow</a> that detects toxic language in messages sent in a Telegram chat and replies with a warning message.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://blog.n8n.io/content/images/2022/09/Screenshot-2022-09-01-at-15.49.44.png\" class=\"kg-image lightense-target\" alt=\"Workflow for toxic language detection in Telegram\" loading=\"lazy\" width=\"1194\" height=\"558\" srcset=\"https://blog.n8n.io/content/images/size/w600/2022/09/Screenshot-2022-09-01-at-15.49.44.png 600w, https://blog.n8n.io/content/images/size/w1000/2022/09/Screenshot-2022-09-01-at-15.49.44.png 1000w, https://blog.n8n.io/content/images/2022/09/Screenshot-2022-09-01-at-15.49.44.png 1194w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Workflow for toxic language detection in Telegram</figcaption></figure><ul><li><em><strong>Telegram Trigger node</strong></em> starts the workflow when a new message is sent in a Telegram chat.</li><li><em><strong>Google Perspective node</strong></em> analyzes the text of the message and returns a probability value between 0 and 1 of how likely it is that the content is toxic.</li><li><em><strong>IF node</strong></em> filters messages with a toxic probability value above 0.7.</li><li><em><strong>Telegram node</strong></em> sends a message in the chat with the text “I don’t tolerate toxic language” if the probability value is above 0.7.</li><li><em><strong>NoOp node</strong></em> takes no action if the probability value is below 0.7. This node is optional and serves only to show that the workflow can be extended in this direction.</li></ul><h3 id=\"prerequisites-for-building-the-workflow\">Prerequisites for building the workflow</h3><ul><li><strong>n8n </strong>to connect the services. The easiest way to get started with n8n is to download the <a href=\"https://docs.n8n.io/getting-started/installation/?ref=blog.n8n.io#desktop-app\" target=\"_blank\" rel=\"noopener\">desktop app</a>, but you can also sign up for a <a href=\"https://n8n.io/cloud?ref=blog.n8n.io\" target=\"_blank\" rel=\"noopener\">free n8n cloud trial</a> or <a href=\"https://docs.n8n.io/getting-started/installation/?ref=blog.n8n.io#self-hosting-n8n\" target=\"_blank\" rel=\"noopener\">self-host n8n</a>.</li><li><strong>Telegram account </strong>to create the chatbot.</li><li><strong>Google account</strong> to <a href=\"https://docs.n8n.io/credentials/google/?ref=blog.n8n.io#using-oauth\" target=\"_blank\" rel=\"noopener\">get credentials</a> and <a href=\"https://docs.google.com/forms/d/e/1FAIpQLSdhBBnVVVbXSElby-jhNnEj-Zwpt5toQSCFsJerGfpXW66CuQ/viewform?ref=blog.n8n.io\" target=\"_blank\" rel=\"noopener\">request access to the Perspective API</a>.</li></ul><p>Now let’s see how to configure each node step by step.</p><h3 id=\"1-get-new-messages-from-telegram\">1. Get new messages from Telegram</h3><p>First of all, you need to create a Telegram bot and get credentials. Start a chat with <a href=\"https://telegram.me/BotFather?ref=blog.n8n.io\" target=\"_blank\" rel=\"noopener\">Botfather</a> in your Telegram account and follow the instructions to create your bot and get credentials. Make sure you add your newly created bot to the channel you want to monitor.</p><p>Then, open the <em>Telegram Trigger node</em> and add your <em>Credentials Name</em> and <em>Access Token</em> in <em>Telegram API</em>.</p><p>In the <em>Updates </em>field select: <em>message, edited_message, channel_post, </em>and<em> edited_channel_post</em>. These update options will trigger the workflow when a text message is posted.</p><p>To test if the bot works well so far, execute the <em>Trigger node</em> and send a message to the Telegram channel. We tested this workflow with the message “You’re a stupid bot! I hate you!” (we swear it’s just for testing purposes, we actually think bots are pretty cool and smart). The <em>Telegram Trigger node</em> should output the following result:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://blog.n8n.io/content/images/2022/09/Screenshot-2022-09-01-at-15.50.09.png\" class=\"kg-image lightense-target\" alt=\"Configuration of the Telegram Trigger node\" loading=\"lazy\" width=\"1244\" height=\"608\" srcset=\"https://blog.n8n.io/content/images/size/w600/2022/09/Screenshot-2022-09-01-at-15.50.09.png 600w, https://blog.n8n.io/content/images/size/w1000/2022/09/Screenshot-2022-09-01-at-15.50.09.png 1000w, https://blog.n8n.io/content/images/2022/09/Screenshot-2022-09-01-at-15.50.09.png 1244w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Configuration of the Telegram Trigger node</figcaption></figure><h3 id=\"2-analyze-the-toxicity-of-the-message\">2. Analyze the toxicity of the message</h3><p>In the second step, the incoming message from Telegram has to be analyzed with Perspective. In the <em>Google Perspective node</em> configure the following parameters:</p><ul><li><em>Operation</em>: Analyze Content<br>This operation analyzes the incoming text message.</li><li><em>Text</em>: {{$json[\"message\"][\"text\"]}}<br>This expression selects the incoming Telegram message to be analyzed.</li></ul><p>In the section <em>Attributes to Analyze </em>you can add one or more attributes supported by Perspective that you want to be detected in the incoming message. If you don’t add any attribute, all will be returned by default. For this example, the node is configured to detect profanities and identity attacks in the text, so two attributes are added with the properties:</p><ul><li><em>Attribute Name:</em> Profanity</li><li><em>Score Threshold</em>: 0.00<br>This value sets the score above which to return results. The score is a value between 0 and 1 representing the probability that the text is toxic; it doesn’t reflect the intensity (how toxic the text is). For example, if you set the <em>Score Threshold</em> at 0.5, then only messages that are 50% likely to be toxic are returned. If no value is set, at zero all scores are returned. You can read more <a href=\"https://medium.com/jigsaw/what-do-perspectives-scores-mean-113b37788a5d?ref=blog.n8n.io\" target=\"_blank\" rel=\"noopener\">in this article</a> about what the scores mean.</li></ul><p>In the section <em>Options</em>, you can select the <em>Language</em> of the text input. This option is useful if you want to monitor only a specific language. If unspecified, the node will auto-detect the language. In our example, we select the <em>Language </em>English.</p><p>Now if you execute the <em>Google Perspective node</em>, the output should look like this:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://blog.n8n.io/content/images/2022/09/Screenshot-2022-09-01-at-15.50.17.png\" class=\"kg-image lightense-target\" alt=\"Configuration of the Google Perspective node\" loading=\"lazy\" width=\"1244\" height=\"864\" srcset=\"https://blog.n8n.io/content/images/size/w600/2022/09/Screenshot-2022-09-01-at-15.50.17.png 600w, https://blog.n8n.io/content/images/size/w1000/2022/09/Screenshot-2022-09-01-at-15.50.17.png 1000w, https://blog.n8n.io/content/images/2022/09/Screenshot-2022-09-01-at-15.50.17.png 1244w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Configuration of the Google Perspective node</figcaption></figure><h3 id=\"3-filter-toxic-messages\">3. Filter toxic messages</h3><p>In the third step, the toxic messages with a probability higher that 0.7 have to be filtered out. For this, you need to set up an <em>IF node </em>with the following parameters:</p><ul><li><em>Value 1: </em>{{$json[\"attributeScores\"][\"PROFANITY\"][\"summaryScore\"][\"value\"]}}<br>This expression selects the score value of the respective attribute.</li><li><em><em><em>Operation: </em>Larger</em></em></li><li><em>Value 2</em>: 0.7<br>This is the value we want to compare the score with.</li></ul><p>If you execute the IF node now, it outputs the following results:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://blog.n8n.io/content/images/2022/09/Screenshot-2022-09-01-at-15.50.27.png\" class=\"kg-image lightense-target\" alt=\"Configuration of the IF node\" loading=\"lazy\" width=\"1246\" height=\"862\" srcset=\"https://blog.n8n.io/content/images/size/w600/2022/09/Screenshot-2022-09-01-at-15.50.27.png 600w, https://blog.n8n.io/content/images/size/w1000/2022/09/Screenshot-2022-09-01-at-15.50.27.png 1000w, https://blog.n8n.io/content/images/2022/09/Screenshot-2022-09-01-at-15.50.27.png 1246w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Configuration of the IF node</figcaption></figure><p>The message “You’re a stupid bot! I hate you!” scored 0.92 for profanity and 0.62 for identity attack, which means it has downright strong toxic language on these attributes.</p><h3 id=\"4-send-a-warning-message-to-telegram\">4. Send a warning message to Telegram</h3><p>The final step is taking action against the toxic message. A mild action would be to just reply to the message in the Telegram channel warning the user that “We don’t tolerate toxic language here!”. To do this, configure the <em>Telegram node </em>with the following parameters:</p><ul><li><em>Resource</em>: Message</li><li><em>Operation</em>: Send Message</li><li><em>Chat ID</em>: {{$node[\"Telegram Trigger\"].json[\"message\"][\"chat\"][\"id\"]}}</li><li><em>Text</em>: I don’t tolerate toxic language!</li><li><em>Add Field &gt; Reply to Message ID</em>: {{$node[\"Telegram Trigger\"].json[\"message\"][\"message_id\"]}}</li></ul><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://blog.n8n.io/content/images/2022/09/Screenshot-2022-09-01-at-15.50.36.png\" class=\"kg-image lightense-target\" alt=\"Configuration of the Telegram node\" loading=\"lazy\" width=\"1242\" height=\"600\" srcset=\"https://blog.n8n.io/content/images/size/w600/2022/09/Screenshot-2022-09-01-at-15.50.36.png 600w, https://blog.n8n.io/content/images/size/w1000/2022/09/Screenshot-2022-09-01-at-15.50.36.png 1000w, https://blog.n8n.io/content/images/2022/09/Screenshot-2022-09-01-at-15.50.36.png 1242w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Configuration of the Telegram node</figcaption></figure><p>Now the bully will be publicly admonished in Telegram (once again, sorry, bot, you’re really cool):</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://blog.n8n.io/content/images/2022/09/Screenshot-2022-09-01-at-15.50.46.png\" class=\"kg-image lightense-target\" alt=\"Bot response to a toxic message in Telegram\" loading=\"lazy\" width=\"922\" height=\"446\" srcset=\"https://blog.n8n.io/content/images/size/w600/2022/09/Screenshot-2022-09-01-at-15.50.46.png 600w, https://blog.n8n.io/content/images/2022/09/Screenshot-2022-09-01-at-15.50.46.png 922w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Bot response to a toxic message in Telegram</figcaption></figure><h2 id=\"what%E2%80%99s-next\">What’s next?</h2><p>In this post, you've learned about the challenge and importance of monitoring toxic language in online communities and how you can build a no-code Telegram bot for this purpose. The use case in this tutorial is fairly simplistic, but this kind of toxic language detector can be implemented in various platforms at scale.</p><p>For example, you could tweak this workflow and connect the <em>Google Perspective node</em> to Discord, Discourse, or DISQUS to detect toxic language in online communities and forums, or even to Gmail to filter out toxic emails. You can take different actions to toxic messages, for example forwarding them to a moderator, storing them in a database, flagging or banning the user depending on their message scores.</p><p>Here’s what you can do next:</p><ul><li>Try this workflow yourself:<a href=\"https://n8n.io/?ref=blog.n8n.io\" target=\"_blank\" rel=\"noopener\"> install n8n</a> or sign up for a <a href=\"https://n8n.io/cloud?ref=blog.n8n.io\" target=\"_blank\" rel=\"noopener\">free n8n cloud trial</a> ☁️</li><li>Discover <a href=\"https://n8n.io/workflows?ref=blog.n8n.io\" target=\"_blank\" rel=\"noopener\">more workflows</a> using the <em>Telegram (Trigger) node</em> ⚙️</li><li>Join the discussion in the<a href=\"https://community.n8n.io/c/docs-and-tutorials/6?ref=blog.n8n.io\" target=\"_blank\" rel=\"noopener\"> n8n community forum</a> 🗣️</li><li>Read more <a href=\"https://blog.n8n.io/tag/tutorial/\">workflow tutorials</a> 💡</li></ul>\n\t\t<div class=\"newsletter-banner\">\n\t    <div class=\"newsletter-banner-content\">\n\t      <div class=\"section-header\">\n\t        <h2>Subscribe to <span>n8n newsletter</span></h2>\n\t        <div class=\"section-subheader--bottom\">\n\t          Get the best, coolest, and latest in automation and low-code delivered to your inbox each week.\n\t        </div>\n\t      </div>\n\t      <div class=\"newsletter-banner-form\">\n\t        <form autocomplete=\"off\" class=\"contact-form\" onsubmit=\"subscribeNewsletter(event)\">\n\t        \t<div id=\"recaptcha\" class=\"g-recaptcha\" data-sitekey=\"6LeAQeopAAAAAKlLsRb1weWm6T_vijoQBkGkbHzB\" data-callback=\"submitSubscription\" data-size=\"invisible\"><div class=\"grecaptcha-badge\" data-style=\"bottomright\" style=\"width: 256px; height: 60px; display: block; transition: right 0.3s ease 0s; position: fixed; bottom: 14px; right: -186px; box-shadow: gray 0px 0px 5px; border-radius: 2px; overflow: hidden;\"><div class=\"grecaptcha-logo\"><iframe title=\"reCAPTCHA\" width=\"256\" height=\"60\" role=\"presentation\" name=\"a-147sc3c5j89k\" frameborder=\"0\" scrolling=\"no\" sandbox=\"allow-forms allow-popups allow-same-origin allow-scripts allow-top-navigation allow-modals allow-popups-to-escape-sandbox allow-storage-access-by-user-activation\" src=\"https://www.google.com/recaptcha/api2/anchor?ar=1&amp;k=6LeAQeopAAAAAKlLsRb1weWm6T_vijoQBkGkbHzB&amp;co=aHR0cHM6Ly9ibG9nLm44bi5pbzo0NDM.&amp;hl=en&amp;v=jt8Oh2-Ue1u7nEbJQUIdocyd&amp;size=invisible&amp;cb=5gdp2ebsy4m5\"></iframe></div><div class=\"grecaptcha-error\"></div><textarea id=\"g-recaptcha-response\" name=\"g-recaptcha-response\" class=\"g-recaptcha-response\" style=\"width: 250px; height: 40px; border: 1px solid rgb(193, 193, 193); margin: 10px 25px; padding: 0px; resize: none; display: none;\"></textarea></div><iframe style=\"display: none;\"></iframe></div>\n\t          <div class=\"input-wrapper\">\n\t            <input placeholder=\"Email\" name=\"email\" type=\"email\" required=\"required\" class=\"\">\n\t            <div class=\"messages\">\n\t              <div class=\"message message--error\">Something went wrong. Please try again later.</div>\n\t              <div class=\"message message--success\">Subscribed!</div>\n\t            </div>\n\t          </div>\n\t          <button type=\"submit\" class=\"submit-btn\">Subscribe</button>\n\t        </form>\n\t      </div>\n\t    </div>\n    </div>\n\t\t<div class=\"post-share-section\">\n\t<div class=\"post-share-wrap\">\n\t\t<a href=\"https://twitter.com/intent/tweet?text=Create%20a%20toxic%20language%20detector%20for%20Telegram%20in%204%20steps&amp;url=https://blog.n8n.io/create-a-toxic-language-detector-for-telegram/\" target=\"_blank\" rel=\"noopener\" aria-label=\"Twitter share icon\"><svg role=\"img\" viewBox=\"0 0 24 24\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M23.954 4.569c-.885.389-1.83.654-2.825.775 1.014-.611 1.794-1.574 2.163-2.723-.951.555-2.005.959-3.127 1.184-.896-.959-2.173-1.559-3.591-1.559-2.717 0-4.92 2.203-4.92 4.917 0 .39.045.765.127 1.124C7.691 8.094 4.066 6.13 1.64 3.161c-.427.722-.666 1.561-.666 2.475 0 1.71.87 3.213 2.188 4.096-.807-.026-1.566-.248-2.228-.616v.061c0 2.385 1.693 4.374 3.946 4.827-.413.111-.849.171-1.296.171-.314 0-.615-.03-.916-.086.631 1.953 2.445 3.377 4.604 3.417-1.68 1.319-3.809 2.105-6.102 2.105-.39 0-.779-.023-1.17-.067 2.189 1.394 4.768 2.209 7.557 2.209 9.054 0 13.999-7.496 13.999-13.986 0-.209 0-.42-.015-.63.961-.689 1.8-1.56 2.46-2.548l-.047-.02z\"></path></svg></a>\n\t\t<a href=\"https://www.facebook.com/sharer/sharer.php?u=https://blog.n8n.io/create-a-toxic-language-detector-for-telegram/\" target=\"_blank\" rel=\"noopener\" aria-label=\"Facebook share icon\"><svg role=\"img\" viewBox=\"0 0 24 24\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M23.9981 11.9991C23.9981 5.37216 18.626 0 11.9991 0C5.37216 0 0 5.37216 0 11.9991C0 17.9882 4.38789 22.9522 10.1242 23.8524V15.4676H7.07758V11.9991H10.1242V9.35553C10.1242 6.34826 11.9156 4.68714 14.6564 4.68714C15.9692 4.68714 17.3424 4.92149 17.3424 4.92149V7.87439H15.8294C14.3388 7.87439 13.8739 8.79933 13.8739 9.74824V11.9991H17.2018L16.6698 15.4676H13.8739V23.8524C19.6103 22.9522 23.9981 17.9882 23.9981 11.9991Z\"></path></svg></a>\n\t\t<!-- <a href=\"javascript:\" class=\"post-share-link\" id=\"copy\" data-clipboard-target=\"#copy-link\" aria-label=\"Copy link icon\"><svg role=\"img\" viewBox=\"0 0 33 24\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M27.3999996,13.4004128 L21.7999996,13.4004128 L21.7999996,19 L18.9999996,19 L18.9999996,13.4004128 L13.3999996,13.4004128 L13.3999996,10.6006192 L18.9999996,10.6006192 L18.9999996,5 L21.7999996,5 L21.7999996,10.6006192 L27.3999996,10.6006192 L27.3999996,13.4004128 Z M12,20.87 C7.101,20.87 3.13,16.898 3.13,12 C3.13,7.102 7.101,3.13 12,3.13 C12.091,3.13 12.181,3.139 12.272,3.142 C9.866,5.336 8.347,8.487 8.347,12 C8.347,15.512 9.866,18.662 12.271,20.857 C12.18,20.859 12.091,20.87 12,20.87 Z M20.347,0 C18.882,0 17.484,0.276 16.186,0.756 C14.882,0.271 13.473,0 12,0 C5.372,0 0,5.373 0,12 C0,18.628 5.372,24 12,24 C13.471,24 14.878,23.726 16.181,23.242 C17.481,23.724 18.88,24 20.347,24 C26.975,24 32.347,18.628 32.347,12 C32.347,5.373 26.975,0 20.347,0 Z\"/></svg></a>\n\t\t<small class=\"share-link-info\">The link has been copied!</small> -->\n\t</div>\n\t<input type=\"text\" value=\"https://blog.n8n.io/create-a-toxic-language-detector-for-telegram/\" id=\"copy-link\" aria-label=\"Copy link input\">\n</div>",
  "readme": "When was the last time you talked to someone online, be it friends, coworkers, or even strangers? Nowadays, you most likely do it every day. \n\n## Toxic language online\n\nOnline communication platforms like Telegram, Reddit, or Discord have made it possible for people from all over the world to connect and share their thoughts on pretty much any topic, instantly. \n\nThis can be an enriching experience for users, but these platforms can also foster toxicity like cyberbullying, threats, and insults, forcing some users offline and silencing their voices.\n\n## Managing toxic language with Perspective API\n\nOne solution to this problem comes from [Jigsaw](https://jigsaw.google.com/?ref=blog.n8n.io) and Google's Counter Abuse Technology team, who developed [_Perspective API_](https://www.perspectiveapi.com/?ref=blog.n8n.io): a free API that uses machine learning to identify toxic language in English, Spanish, French, German, Portuguese, Italian, and Russian. Toxic language is defined here as __ “a rude, disrespectful, or unreasonable comment that is likely to make someone leave a discussion”.\n\nIn practice, Perspective scores a phrase based on the perceived impact the text may have in a conversation. The phrase can be analyzed on different attributes: flirtation, identity attack, insult, profanity, sexually explicit, threat, and (severe) toxicity. Keep in mind though that machine learning models can only be as good as the data they’re trained on. This means that they may misclassify as toxic some innocent comments (and vice versa), so the flagged comments should be reviewed by a human eye.\n\nPerspective API has been implemented by [several major publishers and platforms](https://www.perspectiveapi.com/case-studies/?ref=blog.n8n.io) like Reddit, The New York Times, and DISQUS, helping them moderate online comments. At n8n, we communicate with our 16,000+ community members in the [Discourse forum](https://community.n8n.io/?ref=blog.n8n.io), on [Discord](https://discord.gg/vWwMVThRta?ref=blog.n8n.io), [Twitter](https://twitter.com/n8n_io?ref=blog.n8n.io), and even via [Telegram for Spanish speakers](https://t.me/comunidadn8n?ref=blog.n8n.io). We value open, [inclusive](https://n8n.io/workflows/982?ref=blog.n8n.io), and respectful communication and want to ensure that everyone has a positive experience in the n8n community – and beyond.\n\nTo this end, we used the Perspective API to build the [_**Google Perspective node**_](https://docs.n8n.io/nodes/n8n-nodes-base.googlePerspective/?ref=blog.n8n.io) _,_ which allows you to integrate toxic language detection in your workflows.\n\n## Workflow for detecting toxic language in Telegram messages\n\nTo give you an idea of how you can use the _Google Perspective node_ , we created [a workflow](https://n8n.io/workflows/1216?ref=blog.n8n.io) that detects toxic language in messages sent in a Telegram chat and replies with a warning message.\n\n![Workflow for toxic language detection in Telegram](https://blog.n8n.io/content/images/2022/09/Screenshot-2022-09-01-at-15.49.44.png)Workflow for toxic language detection in Telegram\n\n  *  _**Telegram Trigger node**_ starts the workflow when a new message is sent in a Telegram chat.\n  * _**Google Perspective node**_ analyzes the text of the message and returns a probability value between 0 and 1 of how likely it is that the content is toxic.\n  * _**IF node**_ filters messages with a toxic probability value above 0.7.\n  * _**Telegram node**_ sends a message in the chat with the text “I don’t tolerate toxic language” if the probability value is above 0.7.\n  * _**NoOp node**_ takes no action if the probability value is below 0.7. This node is optional and serves only to show that the workflow can be extended in this direction.\n\n\n\n### Prerequisites for building the workflow\n\n  * **n8n** to connect the services. The easiest way to get started with n8n is to download the [desktop app](https://docs.n8n.io/getting-started/installation/?ref=blog.n8n.io#desktop-app), but you can also sign up for a [free n8n cloud trial](https://n8n.io/cloud?ref=blog.n8n.io) or [self-host n8n](https://docs.n8n.io/getting-started/installation/?ref=blog.n8n.io#self-hosting-n8n).\n  * **Telegram account** to create the chatbot.\n  * **Google account** to [get credentials](https://docs.n8n.io/credentials/google/?ref=blog.n8n.io#using-oauth) and [request access to the Perspective API](https://docs.google.com/forms/d/e/1FAIpQLSdhBBnVVVbXSElby-jhNnEj-Zwpt5toQSCFsJerGfpXW66CuQ/viewform?ref=blog.n8n.io).\n\n\n\nNow let’s see how to configure each node step by step.\n\n### 1\\. Get new messages from Telegram\n\nFirst of all, you need to create a Telegram bot and get credentials. Start a chat with [Botfather](https://telegram.me/BotFather?ref=blog.n8n.io) in your Telegram account and follow the instructions to create your bot and get credentials. Make sure you add your newly created bot to the channel you want to monitor.\n\nThen, open the _Telegram Trigger node_ and add your _Credentials Name_ and _Access Token_ in _Telegram API_.\n\nIn the _Updates_ field select: _message, edited_message, channel_post,_ and _edited_channel_post_. These update options will trigger the workflow when a text message is posted.\n\nTo test if the bot works well so far, execute the _Trigger node_ and send a message to the Telegram channel. We tested this workflow with the message “You’re a stupid bot! I hate you!” (we swear it’s just for testing purposes, we actually think bots are pretty cool and smart). The _Telegram Trigger node_ should output the following result:\n\n![Configuration of the Telegram Trigger node](https://blog.n8n.io/content/images/2022/09/Screenshot-2022-09-01-at-15.50.09.png)Configuration of the Telegram Trigger node\n\n### 2\\. Analyze the toxicity of the message\n\nIn the second step, the incoming message from Telegram has to be analyzed with Perspective. In the _Google Perspective node_ configure the following parameters:\n\n  * _Operation_ : Analyze Content  \nThis operation analyzes the incoming text message.\n  * _Text_ : {{$json[\"message\"][\"text\"]}}  \nThis expression selects the incoming Telegram message to be analyzed.\n\n\n\nIn the section _Attributes to Analyze_ you can add one or more attributes supported by Perspective that you want to be detected in the incoming message. If you don’t add any attribute, all will be returned by default. For this example, the node is configured to detect profanities and identity attacks in the text, so two attributes are added with the properties:\n\n  * _Attribute Name:_ Profanity\n  *  _Score Threshold_ : 0.00  \nThis value sets the score above which to return results. The score is a value between 0 and 1 representing the probability that the text is toxic; it doesn’t reflect the intensity (how toxic the text is). For example, if you set the _Score Threshold_ at 0.5, then only messages that are 50% likely to be toxic are returned. If no value is set, at zero all scores are returned. You can read more [in this article](https://medium.com/jigsaw/what-do-perspectives-scores-mean-113b37788a5d?ref=blog.n8n.io) about what the scores mean.\n\n\n\nIn the section _Options_ , you can select the _Language_ of the text input. This option is useful if you want to monitor only a specific language. If unspecified, the node will auto-detect the language. In our example, we select the _Language_ English.\n\nNow if you execute the _Google Perspective node_ , the output should look like this:\n\n![Configuration of the Google Perspective node](https://blog.n8n.io/content/images/2022/09/Screenshot-2022-09-01-at-15.50.17.png)Configuration of the Google Perspective node\n\n### 3\\. Filter toxic messages\n\nIn the third step, the toxic messages with a probability higher that 0.7 have to be filtered out. For this, you need to set up an _IF node_ with the following parameters:\n\n  * _Value 1:_{{$json[\"attributeScores\"][\"PROFANITY\"][\"summaryScore\"][\"value\"]}}  \nThis expression selects the score value of the respective attribute.\n  * ___Operation:_ Larger__\n  *  _Value 2_ : 0.7  \nThis is the value we want to compare the score with.\n\n\n\nIf you execute the IF node now, it outputs the following results:\n\n![Configuration of the IF node](https://blog.n8n.io/content/images/2022/09/Screenshot-2022-09-01-at-15.50.27.png)Configuration of the IF node\n\nThe message “You’re a stupid bot! I hate you!” scored 0.92 for profanity and 0.62 for identity attack, which means it has downright strong toxic language on these attributes.\n\n### 4\\. Send a warning message to Telegram\n\nThe final step is taking action against the toxic message. A mild action would be to just reply to the message in the Telegram channel warning the user that “We don’t tolerate toxic language here!”. To do this, configure the _Telegram node_ with the following parameters:\n\n  * _Resource_ : Message\n  *  _Operation_ : Send Message\n  *  _Chat ID_ : {{$node[\"Telegram Trigger\"].json[\"message\"][\"chat\"][\"id\"]}}\n  * _Text_ : I don’t tolerate toxic language!\n  * _Add Field > Reply to Message ID_: {{$node[\"Telegram Trigger\"].json[\"message\"][\"message_id\"]}}\n\n![Configuration of the Telegram node](https://blog.n8n.io/content/images/2022/09/Screenshot-2022-09-01-at-15.50.36.png)Configuration of the Telegram node\n\nNow the bully will be publicly admonished in Telegram (once again, sorry, bot, you’re really cool):\n\n![Bot response to a toxic message in Telegram](https://blog.n8n.io/content/images/2022/09/Screenshot-2022-09-01-at-15.50.46.png)Bot response to a toxic message in Telegram\n\n## What’s next?\n\nIn this post, you've learned about the challenge and importance of monitoring toxic language in online communities and how you can build a no-code Telegram bot for this purpose. The use case in this tutorial is fairly simplistic, but this kind of toxic language detector can be implemented in various platforms at scale.\n\nFor example, you could tweak this workflow and connect the _Google Perspective node_ to Discord, Discourse, or DISQUS to detect toxic language in online communities and forums, or even to Gmail to filter out toxic emails. You can take different actions to toxic messages, for example forwarding them to a moderator, storing them in a database, flagging or banning the user depending on their message scores.\n\nHere’s what you can do next:\n\n  * Try this workflow yourself:[ install n8n](https://n8n.io/?ref=blog.n8n.io) or sign up for a [free n8n cloud trial](https://n8n.io/cloud?ref=blog.n8n.io) ☁️\n  * Discover [more workflows](https://n8n.io/workflows?ref=blog.n8n.io) using the _Telegram (Trigger) node_ ⚙️\n  * Join the discussion in the[ n8n community forum](https://community.n8n.io/c/docs-and-tutorials/6?ref=blog.n8n.io) 🗣️\n  * Read more [workflow tutorials](https://blog.n8n.io/tag/tutorial/) 💡\n\n\n\n## Subscribe to n8n newsletter\n\nGet the best, coolest, and latest in automation and low-code delivered to your inbox each week. \n\nSomething went wrong. Please try again later.\n\nSubscribed!\n\nSubscribe\n\n[](https://twitter.com/intent/tweet?text=Create%20a%20toxic%20language%20detector%20for%20Telegram%20in%204%20steps&url=https://blog.n8n.io/create-a-toxic-language-detector-for-telegram/) [](https://www.facebook.com/sharer/sharer.php?u=https://blog.n8n.io/create-a-toxic-language-detector-for-telegram/)\n",
  "crawled_at": "2025-05-28T11:01:15.919471"
}