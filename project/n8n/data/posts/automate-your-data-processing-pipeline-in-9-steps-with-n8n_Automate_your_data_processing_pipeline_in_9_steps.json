{
  "url": "https://blog.n8n.io/automate-your-data-processing-pipeline-in-9-steps-with-n8n/",
  "title": "Automate your data processing pipeline in 9 steps",
  "excerpt": "Learn how to build an n8n workflow that processes text, stores data in two databases, and sends messages to Slack.",
  "thumbnail": "https://blog.n8n.io/content/images/size/w1200/2021/11/data_pipeline_cover.svg",
  "tags": [
    "Tutorial"
  ],
  "html": "<p>If you’ve ever struggled with setting up pipelines for extracting, transforming, and loading data (so-called ETL jobs), managing different databases, and scheduling workflows – know that there’s an easier way to automate these data engineering tasks. </p><p>In this tutorial, you’ll learn how to build a no-code n8n workflow that processes text, stores data in two databases, and sends messages to Slack.</p><!--kg-card-begin: markdown--><h4 id=\"table-of-contents\">Table of contents</h4>\n<p><a href=\"#the-data-pipeline\">The data pipeline</a><br>\n<a href=\"#the-workflow-with-python\">The workflow with Python</a><br>\n<a href=\"#the-workflow-with-no-code\">The workflow with no code</a><br>\n&nbsp; &nbsp; <a href=\"#1-starting-the-workflow\">1. Starting the workflow</a><br>\n&nbsp; &nbsp; <a href=\"#2-collecting-tweets\">2. Collecting tweets</a><br>\n&nbsp; &nbsp; <a href=\"#3-inserting-tweets-into-mongodb\">3. Inserting tweets into MongoDB</a><br>\n&nbsp; &nbsp; <a href=\"#4-analysing-the-sentiment-of-tweets\">4. Analysing the sentiment of tweets</a><br>\n&nbsp; &nbsp; <a href=\"#5-processing-sentiment-analysis\">5. Processing sentiment analysis</a><br>\n&nbsp; &nbsp; <a href=\"#6-inserting-tweets-values-into-postgres\">6. Inserting tweets values into Postgres</a><br>\n&nbsp; &nbsp; <a href=\"#7-filtering-positive-and-negative-tweets\">7. Filtering positive and negative tweets</a><br>\n&nbsp; &nbsp; <a href=\"#8-sending-positive-tweets-to-slack\">8. Sending positive tweets to Slack</a><br>\n&nbsp; &nbsp; <a href=\"#9-ignoring-negative-tweets\">9. Ignoring negative tweets</a><br>\n<a href=\"#whats-next\">What's next?</a></p>\n<!--kg-card-end: markdown--><h2 id=\"the-data-pipeline\">The data pipeline </h2><p>A few months ago, I completed a Data Science bootcamp, where one week was all about data engineering, ETL pipelines, and workflow automation. The project for that week was to create a database of tweets that use the hashtag #OnThisDay, along with their sentiment score, and post tweets in a Slack channel to inform members about historical events that happened on that day. This pipeline had to be done with <a href=\"https://docs.docker.com/compose/?ref=blog.n8n.io\" target=\"_blank\" rel=\"noopener\">Docker Compose</a> and included six steps:</p><ol><li>Collect tweets with the hashtag #OnThisDay</li><li>Store the collected tweets in a <a href=\"https://www.mongodb.com/?ref=blog.n8n.io\" target=\"_blank\" rel=\"noopener\">MongoDB</a> database</li><li>Extract tweets from the database</li><li>Process the tweets (clean the text, analyse sentiment)</li><li>Load the cleaned tweets and their sentiment score in a <a href=\"https://www.postgresql.org/?ref=blog.n8n.io\" target=\"_blank\" rel=\"noopener\">Postgres</a> database</li><li>Extract and post tweets with positive sentiment in a <a href=\"https://slack.com/intl/en-de/?ref=blog.n8n.io\" target=\"_blank\" rel=\"noopener\">Slack</a> channel</li></ol><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://blog.n8n.io/content/images/2021/04/ETL_pipeline_simple2-1.png\" class=\"kg-image lightense-target\" alt=\"\" loading=\"lazy\" width=\"960\" height=\"268\" srcset=\"https://blog.n8n.io/content/images/size/w600/2021/04/ETL_pipeline_simple2-1.png 600w, https://blog.n8n.io/content/images/2021/04/ETL_pipeline_simple2-1.png 960w\" sizes=\"(min-width: 720px) 720px\"><figcaption>ETL pipeline</figcaption></figure><h2 id=\"the-workflow-with-python\">The workflow with Python</h2><p>This is a fun project that offers lots of learning opportunities about different topics: APIs, text processing with Natural Language Processing libraries, both relational and non-relational databases, social media and communication apps, as well as workflow orchestration. </p><p>If you're wondering, like I did, why we had to use two different databases, the answer is simple: for the sake of learning more. Postgres and MongoDB represent not only different database providers, but different kinds of database structures – <a href=\"https://www.mongodb.com/nosql-explained/nosql-vs-sql?ref=blog.n8n.io\" target=\"_blank\" rel=\"noopener\">relational (SQL) vs non-relational (NoSQL)</a> – and it’s useful to be familiar with both.</p><p>Though our use case is just for fun, this pipeline can support most common data engineering tasks (e.g. aggregating data from multiple sources, setting up and managing the data flow across databases, developing and maintaining data pipelines). </p><p>I was really excited, though also a bit overwhelmed by all the things I had to set up for this project. In total, I spent five days learning the tools, debugging, and building this pipeline with Python (including libraries like <a href=\"https://www.tweepy.org/?ref=blog.n8n.io\" target=\"_blank\" rel=\"noopener\">Tweepy</a>, <a href=\"https://textblob.readthedocs.io/en/dev/?ref=blog.n8n.io\" target=\"_blank\" rel=\"noopener\">TextBlob</a>, <a href=\"https://github.com/cjhutto/vaderSentiment?ref=blog.n8n.io\" target=\"_blank\" rel=\"noopener\">VADER</a>, and <a href=\"https://www.sqlalchemy.org/?ref=blog.n8n.io\" target=\"_blank\" rel=\"noopener\">SQLAlchemy</a>), Postgres, MongoDB, <a href=\"https://www.docker.com/?ref=blog.n8n.io\" target=\"_blank\" rel=\"noopener\">Docker</a>, and <a href=\"https://airflow.apache.org/?ref=blog.n8n.io\" target=\"_blank\" rel=\"noopener\">Airflow</a> (most frustrating part...). If you’re interested to see how I did this, you can check out the project on <a href=\"https://github.com/lorenanda/tweets-docker-pipeline?ref=blog.n8n.io\" target=\"_blank\" rel=\"noopener\">GitHub</a> and read <a href=\"https://lorenaciutacu.com/2020-11-14-bootcamp7/?ref=blog.n8n.io\" target=\"_blank\" rel=\"noopener\">this blog post</a>. </p><p>But in this article, I’ll show you an easier way to achieve the same result in as much as an hour – with a <strong>no-code workflow </strong>in n8n!</p><h2 id=\"the-workflow-with-no-code\">The workflow with no code</h2><p>Since I started using n8n, I’ve been looking for use cases for various data science tasks, starting with my existing projects. When I realised that all the apps and services that I used in my tweets pipeline are available as n8n nodes, I decided to replicate the project as an n8n workflow with nine nodes:</p><ol><li><a href=\"https://docs.n8n.io/nodes/n8n-nodes-base.cron/?ref=blog.n8n.io\" target=\"_blank\" rel=\"noopener\">Cron node</a> to schedule the workflow</li><li><a href=\"https://docs.n8n.io/nodes/n8n-nodes-base.twitter/?ref=blog.n8n.io\" target=\"_blank\" rel=\"noopener\">Twitter node</a> to collect the tweets</li><li><a href=\"https://docs.n8n.io/nodes/n8n-nodes-base.mongoDb/?ref=blog.n8n.io\" target=\"_blank\" rel=\"noopener\">MongoDB</a> to store the tweets</li><li><a href=\"https://docs.n8n.io/nodes/n8n-nodes-base.googleCloudNaturalLanguage/?ref=blog.n8n.io\" target=\"_blank\" rel=\"noopener\">Google Cloud Natural Language</a> to analyse the sentiment of the tweets</li><li><a href=\"https://docs.n8n.io/nodes/n8n-nodes-base.set/?ref=blog.n8n.io\" target=\"_blank\" rel=\"noopener\">Set</a> to extract the sentiment values</li><li><a href=\"https://docs.n8n.io/nodes/n8n-nodes-base.postgres/?ref=blog.n8n.io\" target=\"_blank\" rel=\"noopener\">Postgres</a> to store the tweets and their sentiment</li><li><a href=\"https://docs.n8n.io/nodes/n8n-nodes-base.if/?ref=blog.n8n.io\" target=\"_blank\" rel=\"noopener\">IF</a> to filter positive and negative tweets</li><li><a href=\"https://docs.n8n.io/nodes/n8n-nodes-base.slack/?ref=blog.n8n.io\" target=\"_blank\" rel=\"noopener\">Slack</a> to post tweets into a channel</li><li><a href=\"https://docs.n8n.io/nodes/n8n-nodes-base.noOp/?ref=blog.n8n.io\" target=\"_blank\" rel=\"noopener\">NoOp</a> to ignore negative tweets</li></ol><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://blog.n8n.io/content/images/2022/09/Screenshot-2022-09-13-at-18.43.51.png\" class=\"kg-image lightense-target\" alt=\"n8n workflow Twitter MongoDB Postgres Slack\" loading=\"lazy\" width=\"1216\" height=\"586\" srcset=\"https://blog.n8n.io/content/images/size/w600/2022/09/Screenshot-2022-09-13-at-18.43.51.png 600w, https://blog.n8n.io/content/images/size/w1000/2022/09/Screenshot-2022-09-13-at-18.43.51.png 1000w, https://blog.n8n.io/content/images/2022/09/Screenshot-2022-09-13-at-18.43.51.png 1216w\" sizes=\"(min-width: 720px) 720px\"><figcaption>n8n workflow</figcaption></figure><p>In this article, I’ll show you how to set up this workflow node by node. If this is your first n8n workflow, have a look at our<a href=\"https://docs.n8n.io/try-it-out/quickstart/?ref=blog.n8n.io\" target=\"_blank\" rel=\"noopener\"> quickstart guide</a> to learn how to set up n8n and how to navigate the Editor UI. It’s also helpful to have at least basic knowledge of databases and SQL. </p><p>Once you have your n8n Editor UI open, there are two ways to follow this tutorial: either copy the workflow from <a href=\"https://n8n.io/workflows/1045?ref=blog.n8n.io\" target=\"_blank\" rel=\"noopener\">here</a> into your Editor UI and deactivate the nodes, so that you can execute and test each node separately, or add the nodes one at a time.</p><h3 id=\"1-starting-the-workflow\">1. Starting the workflow</h3><p>We will begin with the end in mind: We know that we want this whole workflow to run every day, so first we need to set up the <strong>Cron node</strong> to trigger our workflow every day at 06:00.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://blog.n8n.io/content/images/2022/09/Screenshot-2022-09-13-at-18.44.08.png\" class=\"kg-image lightense-target\" alt=\"Cron node\" loading=\"lazy\" width=\"1358\" height=\"684\" srcset=\"https://blog.n8n.io/content/images/size/w600/2022/09/Screenshot-2022-09-13-at-18.44.08.png 600w, https://blog.n8n.io/content/images/size/w1000/2022/09/Screenshot-2022-09-13-at-18.44.08.png 1000w, https://blog.n8n.io/content/images/2022/09/Screenshot-2022-09-13-at-18.44.08.png 1358w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Cron node</figcaption></figure><p>The Cron node makes it very easy to schedule and trigger workflows, compared to setting up <a href=\"https://airflow.apache.org/docs/apache-airflow/1.10.1/scheduler.html?ref=blog.n8n.io\" target=\"_blank\" rel=\"noopener\">scheduling and triggers in Airflow</a>, and this saved me so much time and nerves!</p><h3 id=\"2-collecting-tweets\">2. Collecting tweets</h3><p>Next, we are going to collect tweets with the hashtag #OnThisDay. To do this, first you need to create a <a href=\"https://developer.twitter.com/?ref=blog.n8n.io\" target=\"_blank\" rel=\"noopener\">Twitter Developer</a> account and register an app. Follow the instructions <a href=\"https://docs.n8n.io/credentials/twitter/?ref=blog.n8n.io\" target=\"_blank\" rel=\"noopener\">in our reference docs</a> to learn how to set up your Twitter app and get the necessary credentials (Consumer Key and Consumer Secret). Once you have your credentials, copy and paste them in the <em><strong>Credentials</strong></em> field of the <strong>Twitter node</strong>. Next, set the parameters:</p><ul><li><em>Operation</em>: Search</li><li><em>Search Text</em>: #OnThisDay</li><li><em>Limit</em>: 3. This last step is not mandatory, but I recommend limiting the number of collected tweets at least for testing the workflow, to ensure that you don’t reach the query rate limit of the Twitter API and Google Cloud Natural Language.</li></ul><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://blog.n8n.io/content/images/2022/09/Screenshot-2022-09-13-at-18.44.19.png\" class=\"kg-image lightense-target\" alt=\"Twitter node\" loading=\"lazy\" width=\"1378\" height=\"688\" srcset=\"https://blog.n8n.io/content/images/size/w600/2022/09/Screenshot-2022-09-13-at-18.44.19.png 600w, https://blog.n8n.io/content/images/size/w1000/2022/09/Screenshot-2022-09-13-at-18.44.19.png 1000w, https://blog.n8n.io/content/images/2022/09/Screenshot-2022-09-13-at-18.44.19.png 1378w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Twitter node</figcaption></figure><h3 id=\"3-inserting-tweets-into-mongodb\">3. Inserting tweets into MongoDB</h3><p>Now that we collected some tweets, we need to store them into a database. MongoDB is a non-relational database (NoSQL) that stores data in JSON-like documents. Since our tweets are returned in JSON format, MongoDB is the ideal database to store them in and the <strong>MongoDB node</strong> allows us to connect to the database. Before configuring the node, you need to create a MongoDB instance, set up a cluster, create a database and a collection within it.</p><ol><li><a href=\"https://account.mongodb.com/account/register?ref=blog.n8n.io\" target=\"_blank\" rel=\"noopener\">Create a MongoDB account</a></li><li>Set up a cluster: <em>cloud.mongodb.com &gt; Clusters &gt; Create New Cluster</em></li><li>Create a database: <em>Cluster &gt; Collections &gt; Create Database</em></li><li>Create a collection: <em>Cluster &gt; Collections &gt; Database &gt; Create Collection</em></li><li>Create a field:<em><em><em> Collection &gt; Insert document &gt; Type the field “text” below “_id”</em></em></em></li><li>Allow access to the database:<em> Project &gt; Security &gt; Network Access &gt; IP Access List &gt; Add your IP address.</em></li><li>Connect to the database from your terminal:<br><em>mongo \"mongodb+srv://&lt;YourClusterName&gt;.mongodb.net/&lt;YourDatabaseName&gt;\" --username &lt;YourUsername&gt;</em></li></ol><p>If you need more detailed information or other set up options, refer to the <a href=\"https://docs.atlas.mongodb.com/connect-to-cluster/?ref=blog.n8n.io\" target=\"_blank\" rel=\"noopener\">MongoDB documentation</a>. Now that we have a MongoDB collection up and running, we can set up the MongoDB node<strong> </strong>for our workflow. Set up:</p><ul><li><em>Connection String</em>: mongodb+srv://&lt;YourClusterName&gt;.mongodb.net/&lt;YourDatabaseName&gt; </li><li><em>Database</em>: &lt;YourDatabaseName&gt;</li></ul><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://blog.n8n.io/content/images/2022/09/Screenshot-2022-09-13-at-18.45.42.png\" class=\"kg-image lightense-target\" alt=\"MongoDB node credentials\" loading=\"lazy\" width=\"1366\" height=\"688\" srcset=\"https://blog.n8n.io/content/images/size/w600/2022/09/Screenshot-2022-09-13-at-18.45.42.png 600w, https://blog.n8n.io/content/images/size/w1000/2022/09/Screenshot-2022-09-13-at-18.45.42.png 1000w, https://blog.n8n.io/content/images/2022/09/Screenshot-2022-09-13-at-18.45.42.png 1366w\" sizes=\"(min-width: 720px) 720px\"><figcaption>MongoDB node credentials</figcaption></figure><p>Next, configure the node parameters to insert the collected tweets into the collection:</p><ul><li><em>Operation</em>: Insert</li><li><em>Collection</em>: &lt;YourCollectionName&gt;</li><li><em>Fields</em>: text</li></ul><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://blog.n8n.io/content/images/2022/09/Screenshot-2022-09-13-at-18.45.57.png\" class=\"kg-image lightense-target\" alt=\"MongoDB node\" loading=\"lazy\" width=\"1376\" height=\"688\" srcset=\"https://blog.n8n.io/content/images/size/w600/2022/09/Screenshot-2022-09-13-at-18.45.57.png 600w, https://blog.n8n.io/content/images/size/w1000/2022/09/Screenshot-2022-09-13-at-18.45.57.png 1000w, https://blog.n8n.io/content/images/2022/09/Screenshot-2022-09-13-at-18.45.57.png 1376w\" sizes=\"(min-width: 720px) 720px\"><figcaption>MongoDB node</figcaption></figure><h3 id=\"4-analysing-the-sentiment-of-tweets\">4. Analysing the sentiment of tweets</h3><p>Here comes my personal favourite part of this workflow: analysing the sentiment of tweets, i.e. the feeling associated with the entire text or entities in the text. For this, we use the <strong>Google Cloud Natural Language node</strong>, which analyses a text and returns two numerical values:</p><ul><li><strong>score</strong>: Sentiment score between -1.0 (negative sentiment) and 1.0 (positive sentiment).</li><li><strong>magnitude</strong>: A non-negative number in the [0, +inf) range, which represents the absolute magnitude of sentiment regardless of score (positive or negative).</li></ul><p>Both results are returned as documentSentiment in JSON format:</p><!--kg-card-begin: markdown--><pre><code class=\"language-json\">{\n\"magnitude\": number,\n\"score\": number\n}</code></pre>\n<!--kg-card-end: markdown--><p>Before configuring the node, you have to sign up on the <a href=\"https://cloud.google.com/?ref=blog.n8n.io\" target=\"_blank\" rel=\"noopener\">Google Cloud Platform</a> to enable the API and get the necessary credentials (Client ID and Client Secret). Follow the instructions in <a href=\"https://docs.n8n.io/credentials/google/?ref=blog.n8n.io#prerequisites\" target=\"_blank\" rel=\"noopener\">our reference docs</a> to set up your account and the node credentials. </p><p>Once that’s done, add an expression to the parameter <em>Content</em> by clicking on the gear icon and selecting <em>Current Node &gt; Input Data &gt; text</em>.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://blog.n8n.io/content/images/2022/09/Screenshot-2022-09-13-at-18.46.09.png\" class=\"kg-image lightense-target\" alt=\"Google Cloud Natural Language node\" loading=\"lazy\" width=\"1390\" height=\"690\" srcset=\"https://blog.n8n.io/content/images/size/w600/2022/09/Screenshot-2022-09-13-at-18.46.09.png 600w, https://blog.n8n.io/content/images/size/w1000/2022/09/Screenshot-2022-09-13-at-18.46.09.png 1000w, https://blog.n8n.io/content/images/2022/09/Screenshot-2022-09-13-at-18.46.09.png 1390w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Google Cloud Natural Language node</figcaption></figure><p>As a side note, here it was interesting to see how differently Google Cloud Natural Language and the VADER and TextBlob libraries evaluated the sentiment of text:</p><!--kg-card-begin: html--><table style=\"border:none;border-collapse:collapse;\"><colgroup><col width=\"348\"><col width=\"98\"><col width=\"87\"><col width=\"91\"></colgroup><tbody><tr style=\"height:0pt\"><td style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;background-color:#ffffff;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"><p dir=\"ltr\" style=\"line-height:1.2;text-align: center;margin-top:0pt;margin-bottom:0pt;\"><span style=\"font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:700;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\">Tweet</span></p></td><td style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;background-color:#ffffff;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"><p dir=\"ltr\" style=\"line-height:1.2;text-align: center;margin-top:0pt;margin-bottom:0pt;\"><span style=\"font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:700;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\">GCNL</span></p></td><td style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;background-color:#ffffff;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"><p dir=\"ltr\" style=\"line-height:1.2;text-align: center;margin-top:0pt;margin-bottom:0pt;\"><span style=\"font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:700;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\">VADER</span></p></td><td style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;background-color:#ffffff;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"><p dir=\"ltr\" style=\"line-height:1.2;text-align: center;margin-top:0pt;margin-bottom:0pt;\"><span style=\"font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:700;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\">TextBlob</span></p></td></tr><tr style=\"height:0pt\"><td style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;background-color:#ffffff;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"><p dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"><span style=\"font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\">#OnThisDay in 2018!Champions League,quarter-final,1st legLiverpool-Manchester City 3-01-0 Salah(12),2-0 Oxlade-Chamber…</span></p></td><td style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;background-color:#ffffff;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"><p dir=\"ltr\" style=\"line-height:1.2;text-align: right;margin-top:0pt;margin-bottom:0pt;\"><span style=\"font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\">0.3</span></p></td><td style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;background-color:#ffffff;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"><p dir=\"ltr\" style=\"line-height:1.2;text-align: right;margin-top:0pt;margin-bottom:0pt;\"><span style=\"font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\">0</span></p></td><td style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;background-color:#ffffff;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"><p dir=\"ltr\" style=\"line-height:1.2;text-align: right;margin-top:0pt;margin-bottom:0pt;\"><span style=\"font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\">0</span></p></td></tr><tr style=\"height:0pt\"><td style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;background-color:#ffffff;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"><p dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"><span style=\"font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\">Champions 🏆🏆#OnThisDay in 2016 🎉</span></p></td><td style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;background-color:#ffffff;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"><p dir=\"ltr\" style=\"line-height:1.2;text-align: right;margin-top:0pt;margin-bottom:0pt;\"><span style=\"font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\">0.1</span></p></td><td style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;background-color:#ffffff;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"><p dir=\"ltr\" style=\"line-height:1.2;text-align: right;margin-top:0pt;margin-bottom:0pt;\"><span style=\"font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\">0.7269</span></p></td><td style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;background-color:#ffffff;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"><p dir=\"ltr\" style=\"line-height:1.2;text-align: right;margin-top:0pt;margin-bottom:0pt;\"><span style=\"font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\">0</span></p></td></tr><tr style=\"height:0pt\"><td style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;background-color:#ffffff;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"><p dir=\"ltr\" style=\"line-height:1.2;margin-top:0pt;margin-bottom:0pt;\"><span style=\"font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\">#OnThisDay - 4th Apr 2018 former player, assistant manager &amp;amp; caretaker manager passed away aged 61.3 years #GBNFRa…</span></p></td><td style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;background-color:#ffffff;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"><p dir=\"ltr\" style=\"line-height:1.2;text-align: right;margin-top:0pt;margin-bottom:0pt;\"><span style=\"font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\">0</span></p></td><td style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;background-color:#ffffff;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"><p dir=\"ltr\" style=\"line-height:1.2;text-align: right;margin-top:0pt;margin-bottom:0pt;\"><span style=\"font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\">0</span></p></td><td style=\"border-left:solid #000000 1pt;border-right:solid #000000 1pt;border-bottom:solid #000000 1pt;border-top:solid #000000 1pt;vertical-align:top;background-color:#ffffff;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;\"><p dir=\"ltr\" style=\"line-height:1.2;text-align: right;margin-top:0pt;margin-bottom:0pt;\"><span style=\"font-size:11pt;font-family:Arial;color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\">-0.05</span></p></td></tr></tbody></table><!--kg-card-end: html--><h3 id=\"5-processing-sentiment-analysis\">5. Processing sentiment analysis</h3><p>Now that we have sentiment scores for each tweet, we want to insert the text, sentiment score, and magnitude of the tweets into a new Postgres database. Since the magnitude sentiment score and the magnitude are included in the documentSentiment, we need to extract them in order to insert the values in two separate columns in Postgres. </p><p>For this, we use the <strong>Set node</strong>, which allows us to set new values based on the data we already have. In the node parameters, set three values:</p><ul><li><strong>Score</strong> (number): <em>Current Node &gt; Input Data &gt; JSON &gt; documentSentiment &gt; score</em></li><li><strong>Magnitude</strong> (number): <em>Current Node &gt; Input Data &gt; JSON &gt; documentSentiment &gt; score</em></li><li><strong>Text</strong> (string):<em><em> <em>Current Node &gt; Input Data &gt; JSON &gt; sentences &gt; [Item: 0] &gt; text &gt; content</em></em></em></li></ul><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://blog.n8n.io/content/images/2022/09/Screenshot-2022-09-13-at-18.46.20.png\" class=\"kg-image lightense-target\" alt=\"Set node\" loading=\"lazy\" width=\"1366\" height=\"684\" srcset=\"https://blog.n8n.io/content/images/size/w600/2022/09/Screenshot-2022-09-13-at-18.46.20.png 600w, https://blog.n8n.io/content/images/size/w1000/2022/09/Screenshot-2022-09-13-at-18.46.20.png 1000w, https://blog.n8n.io/content/images/2022/09/Screenshot-2022-09-13-at-18.46.20.png 1366w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Set node</figcaption></figure><h3 id=\"6-inserting-tweets-values-into-postgres\">6. Inserting tweets values into Postgres</h3><p>Next, we want to insert the newly set data values into a Postgres database. First, you need to <a href=\"https://www.postgresql.org/download/?ref=blog.n8n.io\" target=\"_blank\" rel=\"noopener\">install Postgres</a>, then create a database and a table for tweets. The process is quite similar to the MongoDB setup and you can do this from your terminal:</p><!--kg-card-begin: markdown--><ol>\n<li>Connect to Postgres:</li>\n</ol>\n<pre><code class=\"language-postgres\">psql\n</code></pre>\n<ol start=\"2\">\n<li>Create a database:</li>\n</ol>\n<pre><code class=\"language-postgres\">createdb twitter\n</code></pre>\n<ol start=\"3\">\n<li>Go into the created database:</li>\n</ol>\n<pre><code class=\"language-postgres\">psql twitter\n</code></pre>\n<ol start=\"4\">\n<li>Create columns in the database. The columns have to be named like the values defined in the Set node, in order to be matched.</li>\n</ol>\n<pre><code class=\"language-postgres\">CREATE TABLE tweets (text varchar(280), score numeric(4,3), magnitude numeric(4,3));\n</code></pre>\n<!--kg-card-end: markdown--><p>Now we can go ahead and configure the <strong>Postgres node</strong>. Fill in the name of your database, username, and password in the <em>Credential Data</em> fields, then configure the node parameters:</p><ul><li><em>Operation</em>: Insert</li><li><em>Table</em>: tweets</li><li><em>Columns</em>: text, score, magnitude</li><li><em>Return Fields</em>: *</li></ul><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://blog.n8n.io/content/images/2022/09/Screenshot-2022-09-13-at-18.46.36.png\" class=\"kg-image lightense-target\" alt=\"Postgres node\" loading=\"lazy\" width=\"1370\" height=\"698\" srcset=\"https://blog.n8n.io/content/images/size/w600/2022/09/Screenshot-2022-09-13-at-18.46.36.png 600w, https://blog.n8n.io/content/images/size/w1000/2022/09/Screenshot-2022-09-13-at-18.46.36.png 1000w, https://blog.n8n.io/content/images/2022/09/Screenshot-2022-09-13-at-18.46.36.png 1370w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Postgres node</figcaption></figure><p>After executing the node, you can check if the tweets have been inserted in the table by running <em>SELECT * FROM tweets; </em>in the terminal. </p><h3 id=\"7-filtering-positive-and-negative-tweets\">7. Filtering positive and negative tweets</h3><p>Here comes another fun part related to sentiment analysis: filtering negative tweets. For this, we use the <strong>IF node</strong>, which allows us to split the workflow conditionally based on comparison operations. We define positive tweets as those with a sentiment score above 0. To configure the IF node with this condition, configure the parameters:</p><ul><li><em>Value 1</em>: Current Node &gt; Input Data &gt; JSON &gt; score</li><li><em>Operation:</em> Larger</li><li><em>Value 2:</em> 0</li></ul><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://blog.n8n.io/content/images/2022/09/Screenshot-2022-09-13-at-18.46.45.png\" class=\"kg-image lightense-target\" alt=\"IF node\" loading=\"lazy\" width=\"1374\" height=\"690\" srcset=\"https://blog.n8n.io/content/images/size/w600/2022/09/Screenshot-2022-09-13-at-18.46.45.png 600w, https://blog.n8n.io/content/images/size/w1000/2022/09/Screenshot-2022-09-13-at-18.46.45.png 1000w, https://blog.n8n.io/content/images/2022/09/Screenshot-2022-09-13-at-18.46.45.png 1374w\" sizes=\"(min-width: 720px) 720px\"><figcaption>IF node</figcaption></figure><p>This condition determines the data flow to the following connection: if the sentiment score is greater than 0, the tweet will be sent to Slack, otherwise it will just be kept stored in the database.</p><h3 id=\"8-sending-positive-tweets-to-slack\">8. Sending positive tweets to Slack</h3><p>The way to send tweets from a database to a Slack channel is via a Slackbot, which you have to create from your Slack account. Follow the instructions <a href=\"https://api.slack.com/bot-users?ref=blog.n8n.io\" target=\"_blank\" rel=\"noopener\">on Slack</a> and in <a href=\"https://docs.n8n.io/credentials/slack/?ref=blog.n8n.io\" target=\"_blank\" rel=\"noopener\">our reference docs</a> to learn how to create your Slackbot and get the necessary credentials (Access Token). </p><p>Once you have the Slack node credentials set up, configure the parameters:</p><ul><li><em>Resource</em>: Message</li><li><em>Operation</em>: Post</li><li><em>Channel</em>: &lt;YourSlackChannelName&gt;</li><li><em>Text</em>: 🐦 NEW TWEET with sentiment score {{$json[\"score\"]}} and magnitude {{$json[\"magnitude\"]}} ⬇️<br>{{$json[\"text\"]}}</li></ul><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://blog.n8n.io/content/images/2022/09/Screenshot-2022-09-13-at-18.46.57.png\" class=\"kg-image lightense-target\" alt=\"Slack node\" loading=\"lazy\" width=\"1370\" height=\"698\" srcset=\"https://blog.n8n.io/content/images/size/w600/2022/09/Screenshot-2022-09-13-at-18.46.57.png 600w, https://blog.n8n.io/content/images/size/w1000/2022/09/Screenshot-2022-09-13-at-18.46.57.png 1000w, https://blog.n8n.io/content/images/2022/09/Screenshot-2022-09-13-at-18.46.57.png 1370w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Slack node</figcaption></figure><p>After executing the node, check your Slack channel for a new tweet:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://blog.n8n.io/content/images/2021/04/Screenshot-from-2021-04-08-09-23-39.png\" class=\"kg-image lightense-target\" alt=\"\" loading=\"lazy\" width=\"1081\" height=\"594\" srcset=\"https://blog.n8n.io/content/images/size/w600/2021/04/Screenshot-from-2021-04-08-09-23-39.png 600w, https://blog.n8n.io/content/images/size/w1000/2021/04/Screenshot-from-2021-04-08-09-23-39.png 1000w, https://blog.n8n.io/content/images/2021/04/Screenshot-from-2021-04-08-09-23-39.png 1081w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Slack channel message</figcaption></figure><h3 id=\"9-ignoring-negative-tweets\">9. Ignoring negative tweets</h3><p>The last node in this workflow is the <strong>NoOp node</strong>, which is used when we don't want to perform any operations. The purpose of this node is to make the workflow easier to read and understand where the data flow stops. Though this node is not necessary for our workflow, I included it to mark visually the false condition and make it clear that the workflow can be extended in this direction.</p><p>Finally, execute the whole workflow and activate it, so that it runs as scheduled. Also, check your MongoDB collection and Postgres database to make sure that the tweets have been inserted properly.</p><h2 id=\"whats-next\">What's next?</h2><p>Congrats – you now have an automated workflow that informs you every day about positive historical events that happened on that day! As usual, you can tweak and extend this workflow, for example by keeping track of whether a tweet has been processed already, adding an action for the condition when the IF node is false, or cleaning the text of the collected tweets to check whether it influences the sentiment score. </p><p>Of course, you can also build other ETL pipelines for various business use cases, such as product feedback at scale, Jira ticket automation based on customer sentiment, or regular database querying for reporting.</p><p><em>Start automating!</em></p><p><em>The best part is, you can start automating for free with n8n. The easiest way to get started is to sign up for a <a href=\"https://n8n.io/cloud?ref=blog.n8n.io\" target=\"_blank\" rel=\"noopener\">free n8n cloud trial</a>. Thanks to n8n’s fair-code license, you can also </em><a href=\"https://docs.n8n.io/hosting/?ref=blog.n8n.io\" target=\"_blank\" rel=\"noopener\"><em>self-host n8n for free</em></a><em>.</em></p><p><em>Did you find this tutorial helpful? Feel free to <a href=\"https://twitter.com/intent/tweet?text=ETL+automation+with+%40n8n_io++n8n.io%2Fblog%2Fautomate-your-data-processing-pipeline-in-9-steps-with-n8n%2F&amp;ref=blog.n8n.io\" target=\"_blank\" rel=\"noopener\">share it on Twitter</a> 🐦 and discuss it in the <a href=\"https://community.n8n.io/?ref=blog.n8n.io\" target=\"_blank\" rel=\"noopener\">community forum</a> 🧡 To get our latest content about automation, subscribe to our blog by adding your email address in the form below!</em></p>\n\t\t<div class=\"newsletter-banner\">\n\t    <div class=\"newsletter-banner-content\">\n\t      <div class=\"section-header\">\n\t        <h2>Subscribe to <span>n8n newsletter</span></h2>\n\t        <div class=\"section-subheader--bottom\">\n\t          Get the best, coolest, and latest in automation and low-code delivered to your inbox each week.\n\t        </div>\n\t      </div>\n\t      <div class=\"newsletter-banner-form\">\n\t        <form autocomplete=\"off\" class=\"contact-form\" onsubmit=\"subscribeNewsletter(event)\">\n\t        \t<div id=\"recaptcha\" class=\"g-recaptcha\" data-sitekey=\"6LeAQeopAAAAAKlLsRb1weWm6T_vijoQBkGkbHzB\" data-callback=\"submitSubscription\" data-size=\"invisible\"><div class=\"grecaptcha-badge\" data-style=\"bottomright\" style=\"width: 256px; height: 60px; display: block; transition: right 0.3s ease 0s; position: fixed; bottom: 14px; right: -186px; box-shadow: gray 0px 0px 5px; border-radius: 2px; overflow: hidden;\"><div class=\"grecaptcha-logo\"><iframe title=\"reCAPTCHA\" width=\"256\" height=\"60\" role=\"presentation\" name=\"a-ebkoh94ltsgu\" frameborder=\"0\" scrolling=\"no\" sandbox=\"allow-forms allow-popups allow-same-origin allow-scripts allow-top-navigation allow-modals allow-popups-to-escape-sandbox allow-storage-access-by-user-activation\" src=\"https://www.google.com/recaptcha/api2/anchor?ar=1&amp;k=6LeAQeopAAAAAKlLsRb1weWm6T_vijoQBkGkbHzB&amp;co=aHR0cHM6Ly9ibG9nLm44bi5pbzo0NDM.&amp;hl=en&amp;v=jt8Oh2-Ue1u7nEbJQUIdocyd&amp;size=invisible&amp;cb=t31rewe3eod6\"></iframe></div><div class=\"grecaptcha-error\"></div><textarea id=\"g-recaptcha-response\" name=\"g-recaptcha-response\" class=\"g-recaptcha-response\" style=\"width: 250px; height: 40px; border: 1px solid rgb(193, 193, 193); margin: 10px 25px; padding: 0px; resize: none; display: none;\"></textarea></div><iframe style=\"display: none;\"></iframe></div>\n\t          <div class=\"input-wrapper\">\n\t            <input placeholder=\"Email\" name=\"email\" type=\"email\" required=\"required\" class=\"\">\n\t            <div class=\"messages\">\n\t              <div class=\"message message--error\">Something went wrong. Please try again later.</div>\n\t              <div class=\"message message--success\">Subscribed!</div>\n\t            </div>\n\t          </div>\n\t          <button type=\"submit\" class=\"submit-btn\">Subscribe</button>\n\t        </form>\n\t      </div>\n\t    </div>\n    </div>\n\t\t<div class=\"post-share-section\">\n\t<div class=\"post-share-wrap\">\n\t\t<a href=\"https://twitter.com/intent/tweet?text=Automate%20your%20data%20processing%20pipeline%20in%209%20steps&amp;url=https://blog.n8n.io/automate-your-data-processing-pipeline-in-9-steps-with-n8n/\" target=\"_blank\" rel=\"noopener\" aria-label=\"Twitter share icon\"><svg role=\"img\" viewBox=\"0 0 24 24\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M23.954 4.569c-.885.389-1.83.654-2.825.775 1.014-.611 1.794-1.574 2.163-2.723-.951.555-2.005.959-3.127 1.184-.896-.959-2.173-1.559-3.591-1.559-2.717 0-4.92 2.203-4.92 4.917 0 .39.045.765.127 1.124C7.691 8.094 4.066 6.13 1.64 3.161c-.427.722-.666 1.561-.666 2.475 0 1.71.87 3.213 2.188 4.096-.807-.026-1.566-.248-2.228-.616v.061c0 2.385 1.693 4.374 3.946 4.827-.413.111-.849.171-1.296.171-.314 0-.615-.03-.916-.086.631 1.953 2.445 3.377 4.604 3.417-1.68 1.319-3.809 2.105-6.102 2.105-.39 0-.779-.023-1.17-.067 2.189 1.394 4.768 2.209 7.557 2.209 9.054 0 13.999-7.496 13.999-13.986 0-.209 0-.42-.015-.63.961-.689 1.8-1.56 2.46-2.548l-.047-.02z\"></path></svg></a>\n\t\t<a href=\"https://www.facebook.com/sharer/sharer.php?u=https://blog.n8n.io/automate-your-data-processing-pipeline-in-9-steps-with-n8n/\" target=\"_blank\" rel=\"noopener\" aria-label=\"Facebook share icon\"><svg role=\"img\" viewBox=\"0 0 24 24\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M23.9981 11.9991C23.9981 5.37216 18.626 0 11.9991 0C5.37216 0 0 5.37216 0 11.9991C0 17.9882 4.38789 22.9522 10.1242 23.8524V15.4676H7.07758V11.9991H10.1242V9.35553C10.1242 6.34826 11.9156 4.68714 14.6564 4.68714C15.9692 4.68714 17.3424 4.92149 17.3424 4.92149V7.87439H15.8294C14.3388 7.87439 13.8739 8.79933 13.8739 9.74824V11.9991H17.2018L16.6698 15.4676H13.8739V23.8524C19.6103 22.9522 23.9981 17.9882 23.9981 11.9991Z\"></path></svg></a>\n\t\t<!-- <a href=\"javascript:\" class=\"post-share-link\" id=\"copy\" data-clipboard-target=\"#copy-link\" aria-label=\"Copy link icon\"><svg role=\"img\" viewBox=\"0 0 33 24\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M27.3999996,13.4004128 L21.7999996,13.4004128 L21.7999996,19 L18.9999996,19 L18.9999996,13.4004128 L13.3999996,13.4004128 L13.3999996,10.6006192 L18.9999996,10.6006192 L18.9999996,5 L21.7999996,5 L21.7999996,10.6006192 L27.3999996,10.6006192 L27.3999996,13.4004128 Z M12,20.87 C7.101,20.87 3.13,16.898 3.13,12 C3.13,7.102 7.101,3.13 12,3.13 C12.091,3.13 12.181,3.139 12.272,3.142 C9.866,5.336 8.347,8.487 8.347,12 C8.347,15.512 9.866,18.662 12.271,20.857 C12.18,20.859 12.091,20.87 12,20.87 Z M20.347,0 C18.882,0 17.484,0.276 16.186,0.756 C14.882,0.271 13.473,0 12,0 C5.372,0 0,5.373 0,12 C0,18.628 5.372,24 12,24 C13.471,24 14.878,23.726 16.181,23.242 C17.481,23.724 18.88,24 20.347,24 C26.975,24 32.347,18.628 32.347,12 C32.347,5.373 26.975,0 20.347,0 Z\"/></svg></a>\n\t\t<small class=\"share-link-info\">The link has been copied!</small> -->\n\t</div>\n\t<input type=\"text\" value=\"https://blog.n8n.io/automate-your-data-processing-pipeline-in-9-steps-with-n8n/\" id=\"copy-link\" aria-label=\"Copy link input\">\n</div>",
  "readme": "If you’ve ever struggled with setting up pipelines for extracting, transforming, and loading data (so-called ETL jobs), managing different databases, and scheduling workflows – know that there’s an easier way to automate these data engineering tasks. \n\nIn this tutorial, you’ll learn how to build a no-code n8n workflow that processes text, stores data in two databases, and sends messages to Slack.\n\n#### Table of contents\n\nThe data pipeline  \nThe workflow with Python  \nThe workflow with no code  \n    1\\. Starting the workflow  \n    2\\. Collecting tweets  \n    3\\. Inserting tweets into MongoDB  \n    4\\. Analysing the sentiment of tweets  \n    5\\. Processing sentiment analysis  \n    6\\. Inserting tweets values into Postgres  \n    7\\. Filtering positive and negative tweets  \n    8\\. Sending positive tweets to Slack  \n    9\\. Ignoring negative tweets  \nWhat's next?\n\n## The data pipeline \n\nA few months ago, I completed a Data Science bootcamp, where one week was all about data engineering, ETL pipelines, and workflow automation. The project for that week was to create a database of tweets that use the hashtag #OnThisDay, along with their sentiment score, and post tweets in a Slack channel to inform members about historical events that happened on that day. This pipeline had to be done with [Docker Compose](https://docs.docker.com/compose/?ref=blog.n8n.io) and included six steps:\n\n  1. Collect tweets with the hashtag #OnThisDay\n  2. Store the collected tweets in a [MongoDB](https://www.mongodb.com/?ref=blog.n8n.io) database\n  3. Extract tweets from the database\n  4. Process the tweets (clean the text, analyse sentiment)\n  5. Load the cleaned tweets and their sentiment score in a [Postgres](https://www.postgresql.org/?ref=blog.n8n.io) database\n  6. Extract and post tweets with positive sentiment in a [Slack](https://slack.com/intl/en-de/?ref=blog.n8n.io) channel\n\n![](https://blog.n8n.io/content/images/2021/04/ETL_pipeline_simple2-1.png)ETL pipeline\n\n## The workflow with Python\n\nThis is a fun project that offers lots of learning opportunities about different topics: APIs, text processing with Natural Language Processing libraries, both relational and non-relational databases, social media and communication apps, as well as workflow orchestration. \n\nIf you're wondering, like I did, why we had to use two different databases, the answer is simple: for the sake of learning more. Postgres and MongoDB represent not only different database providers, but different kinds of database structures – [relational (SQL) vs non-relational (NoSQL)](https://www.mongodb.com/nosql-explained/nosql-vs-sql?ref=blog.n8n.io) – and it’s useful to be familiar with both.\n\nThough our use case is just for fun, this pipeline can support most common data engineering tasks (e.g. aggregating data from multiple sources, setting up and managing the data flow across databases, developing and maintaining data pipelines). \n\nI was really excited, though also a bit overwhelmed by all the things I had to set up for this project. In total, I spent five days learning the tools, debugging, and building this pipeline with Python (including libraries like [Tweepy](https://www.tweepy.org/?ref=blog.n8n.io), [TextBlob](https://textblob.readthedocs.io/en/dev/?ref=blog.n8n.io), [VADER](https://github.com/cjhutto/vaderSentiment?ref=blog.n8n.io), and [SQLAlchemy](https://www.sqlalchemy.org/?ref=blog.n8n.io)), Postgres, MongoDB, [Docker](https://www.docker.com/?ref=blog.n8n.io), and [Airflow](https://airflow.apache.org/?ref=blog.n8n.io) (most frustrating part...). If you’re interested to see how I did this, you can check out the project on [GitHub](https://github.com/lorenanda/tweets-docker-pipeline?ref=blog.n8n.io) and read [this blog post](https://lorenaciutacu.com/2020-11-14-bootcamp7/?ref=blog.n8n.io). \n\nBut in this article, I’ll show you an easier way to achieve the same result in as much as an hour – with a **no-code workflow** in n8n!\n\n## The workflow with no code\n\nSince I started using n8n, I’ve been looking for use cases for various data science tasks, starting with my existing projects. When I realised that all the apps and services that I used in my tweets pipeline are available as n8n nodes, I decided to replicate the project as an n8n workflow with nine nodes:\n\n  1. [Cron node](https://docs.n8n.io/nodes/n8n-nodes-base.cron/?ref=blog.n8n.io) to schedule the workflow\n  2. [Twitter node](https://docs.n8n.io/nodes/n8n-nodes-base.twitter/?ref=blog.n8n.io) to collect the tweets\n  3. [MongoDB](https://docs.n8n.io/nodes/n8n-nodes-base.mongoDb/?ref=blog.n8n.io) to store the tweets\n  4. [Google Cloud Natural Language](https://docs.n8n.io/nodes/n8n-nodes-base.googleCloudNaturalLanguage/?ref=blog.n8n.io) to analyse the sentiment of the tweets\n  5. [Set](https://docs.n8n.io/nodes/n8n-nodes-base.set/?ref=blog.n8n.io) to extract the sentiment values\n  6. [Postgres](https://docs.n8n.io/nodes/n8n-nodes-base.postgres/?ref=blog.n8n.io) to store the tweets and their sentiment\n  7. [IF](https://docs.n8n.io/nodes/n8n-nodes-base.if/?ref=blog.n8n.io) to filter positive and negative tweets\n  8. [Slack](https://docs.n8n.io/nodes/n8n-nodes-base.slack/?ref=blog.n8n.io) to post tweets into a channel\n  9. [NoOp](https://docs.n8n.io/nodes/n8n-nodes-base.noOp/?ref=blog.n8n.io) to ignore negative tweets\n\n![n8n workflow Twitter MongoDB Postgres Slack](https://blog.n8n.io/content/images/2022/09/Screenshot-2022-09-13-at-18.43.51.png)n8n workflow\n\nIn this article, I’ll show you how to set up this workflow node by node. If this is your first n8n workflow, have a look at our[ quickstart guide](https://docs.n8n.io/try-it-out/quickstart/?ref=blog.n8n.io) to learn how to set up n8n and how to navigate the Editor UI. It’s also helpful to have at least basic knowledge of databases and SQL. \n\nOnce you have your n8n Editor UI open, there are two ways to follow this tutorial: either copy the workflow from [here](https://n8n.io/workflows/1045?ref=blog.n8n.io) into your Editor UI and deactivate the nodes, so that you can execute and test each node separately, or add the nodes one at a time.\n\n### 1\\. Starting the workflow\n\nWe will begin with the end in mind: We know that we want this whole workflow to run every day, so first we need to set up the **Cron node** to trigger our workflow every day at 06:00.\n\n![Cron node](https://blog.n8n.io/content/images/2022/09/Screenshot-2022-09-13-at-18.44.08.png)Cron node\n\nThe Cron node makes it very easy to schedule and trigger workflows, compared to setting up [scheduling and triggers in Airflow](https://airflow.apache.org/docs/apache-airflow/1.10.1/scheduler.html?ref=blog.n8n.io), and this saved me so much time and nerves!\n\n### 2\\. Collecting tweets\n\nNext, we are going to collect tweets with the hashtag #OnThisDay. To do this, first you need to create a [Twitter Developer](https://developer.twitter.com/?ref=blog.n8n.io) account and register an app. Follow the instructions [in our reference docs](https://docs.n8n.io/credentials/twitter/?ref=blog.n8n.io) to learn how to set up your Twitter app and get the necessary credentials (Consumer Key and Consumer Secret). Once you have your credentials, copy and paste them in the _**Credentials**_ field of the **Twitter node**. Next, set the parameters:\n\n  * _Operation_ : Search\n  *  _Search Text_ : #OnThisDay\n  *  _Limit_ : 3. This last step is not mandatory, but I recommend limiting the number of collected tweets at least for testing the workflow, to ensure that you don’t reach the query rate limit of the Twitter API and Google Cloud Natural Language.\n\n![Twitter node](https://blog.n8n.io/content/images/2022/09/Screenshot-2022-09-13-at-18.44.19.png)Twitter node\n\n### 3\\. Inserting tweets into MongoDB\n\nNow that we collected some tweets, we need to store them into a database. MongoDB is a non-relational database (NoSQL) that stores data in JSON-like documents. Since our tweets are returned in JSON format, MongoDB is the ideal database to store them in and the **MongoDB node** allows us to connect to the database. Before configuring the node, you need to create a MongoDB instance, set up a cluster, create a database and a collection within it.\n\n  1. [Create a MongoDB account](https://account.mongodb.com/account/register?ref=blog.n8n.io)\n  2. Set up a cluster: _cloud.mongodb.com > Clusters > Create New Cluster_\n  3. Create a database: _Cluster > Collections > Create Database_\n  4. Create a collection: _Cluster > Collections > Database > Create Collection_\n  5. Create a field:___Collection > Insert document > Type the field “text” below “_id”___\n  6. Allow access to the database:_Project > Security > Network Access > IP Access List > Add your IP address._\n  7. Connect to the database from your terminal:  \n_mongo \"mongodb+srv:// <YourClusterName>.mongodb.net/<YourDatabaseName>\" --username <YourUsername>_\n\n\n\nIf you need more detailed information or other set up options, refer to the [MongoDB documentation](https://docs.atlas.mongodb.com/connect-to-cluster/?ref=blog.n8n.io). Now that we have a MongoDB collection up and running, we can set up the MongoDB node**** for our workflow. Set up:\n\n  * _Connection String_ : mongodb+srv://<YourClusterName>.mongodb.net/<YourDatabaseName>\n  * _Database_ : <YourDatabaseName>\n\n![MongoDB node credentials](https://blog.n8n.io/content/images/2022/09/Screenshot-2022-09-13-at-18.45.42.png)MongoDB node credentials\n\nNext, configure the node parameters to insert the collected tweets into the collection:\n\n  * _Operation_ : Insert\n  *  _Collection_ : <YourCollectionName>\n  * _Fields_ : text\n\n![MongoDB node](https://blog.n8n.io/content/images/2022/09/Screenshot-2022-09-13-at-18.45.57.png)MongoDB node\n\n### 4\\. Analysing the sentiment of tweets\n\nHere comes my personal favourite part of this workflow: analysing the sentiment of tweets, i.e. the feeling associated with the entire text or entities in the text. For this, we use the **Google Cloud Natural Language node** , which analyses a text and returns two numerical values:\n\n  * **score** : Sentiment score between -1.0 (negative sentiment) and 1.0 (positive sentiment).\n  * **magnitude** : A non-negative number in the [0, +inf) range, which represents the absolute magnitude of sentiment regardless of score (positive or negative).\n\n\n\nBoth results are returned as documentSentiment in JSON format:\n    \n    \n    {\n    \"magnitude\": number,\n    \"score\": number\n    }\n\nBefore configuring the node, you have to sign up on the [Google Cloud Platform](https://cloud.google.com/?ref=blog.n8n.io) to enable the API and get the necessary credentials (Client ID and Client Secret). Follow the instructions in [our reference docs](https://docs.n8n.io/credentials/google/?ref=blog.n8n.io#prerequisites) to set up your account and the node credentials. \n\nOnce that’s done, add an expression to the parameter _Content_ by clicking on the gear icon and selecting _Current Node > Input Data > text_.\n\n![Google Cloud Natural Language node](https://blog.n8n.io/content/images/2022/09/Screenshot-2022-09-13-at-18.46.09.png)Google Cloud Natural Language node\n\nAs a side note, here it was interesting to see how differently Google Cloud Natural Language and the VADER and TextBlob libraries evaluated the sentiment of text:\n\nTweet| GCNL| VADER| TextBlob  \n---|---|---|---  \n#OnThisDay in 2018!Champions League,quarter-final,1st legLiverpool-Manchester City 3-01-0 Salah(12),2-0 Oxlade-Chamber…| 0.3| 0| 0  \nChampions 🏆🏆#OnThisDay in 2016 🎉| 0.1| 0.7269| 0  \n#OnThisDay - 4th Apr 2018 former player, assistant manager &amp; caretaker manager passed away aged 61.3 years #GBNFRa…| 0| 0| -0.05  \n  \n### 5\\. Processing sentiment analysis\n\nNow that we have sentiment scores for each tweet, we want to insert the text, sentiment score, and magnitude of the tweets into a new Postgres database. Since the magnitude sentiment score and the magnitude are included in the documentSentiment, we need to extract them in order to insert the values in two separate columns in Postgres. \n\nFor this, we use the **Set node** , which allows us to set new values based on the data we already have. In the node parameters, set three values:\n\n  * **Score** (number): _Current Node > Input Data > JSON > documentSentiment > score_\n  * **Magnitude** (number): _Current Node > Input Data > JSON > documentSentiment > score_\n  * **Text** (string):___Current Node > Input Data > JSON > sentences > [Item: 0] > text > content___\n\n![Set node](https://blog.n8n.io/content/images/2022/09/Screenshot-2022-09-13-at-18.46.20.png)Set node\n\n### 6\\. Inserting tweets values into Postgres\n\nNext, we want to insert the newly set data values into a Postgres database. First, you need to [install Postgres](https://www.postgresql.org/download/?ref=blog.n8n.io), then create a database and a table for tweets. The process is quite similar to the MongoDB setup and you can do this from your terminal:\n\n  1. Connect to Postgres:\n\n\n    \n    \n    psql\n    \n\n  2. Create a database:\n\n\n    \n    \n    createdb twitter\n    \n\n  3. Go into the created database:\n\n\n    \n    \n    psql twitter\n    \n\n  4. Create columns in the database. The columns have to be named like the values defined in the Set node, in order to be matched.\n\n\n    \n    \n    CREATE TABLE tweets (text varchar(280), score numeric(4,3), magnitude numeric(4,3));\n    \n\nNow we can go ahead and configure the **Postgres node**. Fill in the name of your database, username, and password in the _Credential Data_ fields, then configure the node parameters:\n\n  * _Operation_ : Insert\n  *  _Table_ : tweets\n  *  _Columns_ : text, score, magnitude\n  *  _Return Fields_ : *\n\n![Postgres node](https://blog.n8n.io/content/images/2022/09/Screenshot-2022-09-13-at-18.46.36.png)Postgres node\n\nAfter executing the node, you can check if the tweets have been inserted in the table by running _SELECT * FROM tweets;_ in the terminal. \n\n### 7\\. Filtering positive and negative tweets\n\nHere comes another fun part related to sentiment analysis: filtering negative tweets. For this, we use the **IF node** , which allows us to split the workflow conditionally based on comparison operations. We define positive tweets as those with a sentiment score above 0. To configure the IF node with this condition, configure the parameters:\n\n  * _Value 1_ : Current Node > Input Data > JSON > score\n  *  _Operation:_ Larger\n  *  _Value 2:_ 0\n\n![IF node](https://blog.n8n.io/content/images/2022/09/Screenshot-2022-09-13-at-18.46.45.png)IF node\n\nThis condition determines the data flow to the following connection: if the sentiment score is greater than 0, the tweet will be sent to Slack, otherwise it will just be kept stored in the database.\n\n### 8\\. Sending positive tweets to Slack\n\nThe way to send tweets from a database to a Slack channel is via a Slackbot, which you have to create from your Slack account. Follow the instructions [on Slack](https://api.slack.com/bot-users?ref=blog.n8n.io) and in [our reference docs](https://docs.n8n.io/credentials/slack/?ref=blog.n8n.io) to learn how to create your Slackbot and get the necessary credentials (Access Token). \n\nOnce you have the Slack node credentials set up, configure the parameters:\n\n  * _Resource_ : Message\n  *  _Operation_ : Post\n  *  _Channel_ : <YourSlackChannelName>\n  * _Text_ : 🐦 NEW TWEET with sentiment score {{$json[\"score\"]}} and magnitude {{$json[\"magnitude\"]}} ⬇️  \n{{$json[\"text\"]}}\n\n![Slack node](https://blog.n8n.io/content/images/2022/09/Screenshot-2022-09-13-at-18.46.57.png)Slack node\n\nAfter executing the node, check your Slack channel for a new tweet:\n\n![](https://blog.n8n.io/content/images/2021/04/Screenshot-from-2021-04-08-09-23-39.png)Slack channel message\n\n### 9\\. Ignoring negative tweets\n\nThe last node in this workflow is the **NoOp node** , which is used when we don't want to perform any operations. The purpose of this node is to make the workflow easier to read and understand where the data flow stops. Though this node is not necessary for our workflow, I included it to mark visually the false condition and make it clear that the workflow can be extended in this direction.\n\nFinally, execute the whole workflow and activate it, so that it runs as scheduled. Also, check your MongoDB collection and Postgres database to make sure that the tweets have been inserted properly.\n\n## What's next?\n\nCongrats – you now have an automated workflow that informs you every day about positive historical events that happened on that day! As usual, you can tweak and extend this workflow, for example by keeping track of whether a tweet has been processed already, adding an action for the condition when the IF node is false, or cleaning the text of the collected tweets to check whether it influences the sentiment score. \n\nOf course, you can also build other ETL pipelines for various business use cases, such as product feedback at scale, Jira ticket automation based on customer sentiment, or regular database querying for reporting.\n\n_Start automating!_\n\n_The best part is, you can start automating for free with n8n. The easiest way to get started is to sign up for a[free n8n cloud trial](https://n8n.io/cloud?ref=blog.n8n.io). Thanks to n8n’s fair-code license, you can also _[_self-host n8n for free_](https://docs.n8n.io/hosting/?ref=blog.n8n.io) _._\n\n_Did you find this tutorial helpful? Feel free to[share it on Twitter](https://twitter.com/intent/tweet?text=ETL+automation+with+%40n8n_io++n8n.io%2Fblog%2Fautomate-your-data-processing-pipeline-in-9-steps-with-n8n%2F&ref=blog.n8n.io) 🐦 and discuss it in the [community forum](https://community.n8n.io/?ref=blog.n8n.io) 🧡 To get our latest content about automation, subscribe to our blog by adding your email address in the form below!_\n\n## Subscribe to n8n newsletter\n\nGet the best, coolest, and latest in automation and low-code delivered to your inbox each week. \n\nSomething went wrong. Please try again later.\n\nSubscribed!\n\nSubscribe\n\n[](https://twitter.com/intent/tweet?text=Automate%20your%20data%20processing%20pipeline%20in%209%20steps&url=https://blog.n8n.io/automate-your-data-processing-pipeline-in-9-steps-with-n8n/) [](https://www.facebook.com/sharer/sharer.php?u=https://blog.n8n.io/automate-your-data-processing-pipeline-in-9-steps-with-n8n/)\n",
  "crawled_at": "2025-05-28T10:55:34.635216"
}