{
  "url": "https://blog.n8n.io/rag-chatbot/",
  "title": "Build a custom knowledge RAG chatbot using n8n",
  "excerpt": "Learn how to build powerful RAG chatbots with n8n's visual workflow automation. This step-by-step guide demonstrates how to connect to any knowledge source, index it in a vector database, and create an AI-powered chatbot that provides accurate, context-aware answers.",
  "thumbnail": "https://blog.n8n.io/content/images/size/w1200/2025/01/Slide-16_9---86--1-.png",
  "tags": [
    "AI",
    "Tutorial"
  ],
  "html": "<p>Ever wished for a chatbot that could answer specific questions about your data or documentation, instead of just hallucinating generic responses? Build one that actually knows your data with Retrieval Augmented Generation (RAG)!</p><p>In this blog post, we'll examine how Retrieval Augmented Generation (RAG) allows you to build specialized chatbots that go beyond the limitations of typical chatbot interactions. Instead of relying on generic responses, RAG chatbots utilize external knowledge sources to deliver precise and informative answers to complex queries.</p><p>We'll break down the core concepts of RAG and look at some practical RAG workflow examples. Plus, this isn't just theory - we'll demonstrate how to implement RAG using <a href=\"https://n8n.io/ai/?ref=blog.n8n.io\" target=\"_blank\" rel=\"noopener\"><u>n8n, a workflow automation tool</u></a>.</p><p>By the end of this article, you'll have the knowledge and tools to construct your own RAG chatbots!</p><h2 id=\"how-is-rag-used-in-chatbots\">How is RAG used in chatbots?</h2><p>Retrieval Augmented Generation (RAG) in chatbots is a powerful technique that combines the strengths of large language models (LLMs) with external knowledge sources to generate more relevant, and most importantly, accurate responses.</p><h3 id=\"what-is-the-rag-in-the-chatbot\">What is the RAG in the chatbot?</h3><p>RAG is particularly useful in scenarios where LLMs need to access and utilize information that was not included in their initial training data, such as when answering questions about specific domains, internal documents, or data that is not publicly available.</p><p><a href=\"https://blog.n8n.io/best-ai-chatbot/\"><u>AI chatbots</u></a> can use RAG to access and process information from a variety of sources, including unstructured data like text documents, web pages, and social media posts, as well as structured data like databases and knowledge graphs. This allows them to:</p><ul><li>provide more comprehensive and informative responses;</li><li>personalize the user experience;</li><li>stay up-to-date with the latest information;</li><li>provide responses based on internal documents.</li></ul><h3 id=\"what-is-the-difference-between-semantic-search-and-rag\">What is the difference between semantic search and RAG?</h3><p>While both semantic search and RAG aim to improve information retrieval, they differ in their approach and capabilities.</p><p>Semantic search focuses on understanding the intent and context of a user's query to retrieve relevant information. It uses techniques like natural language processing (NLP) to analyze the meaning behind the words and identify related concepts. Think of it as a smarter search engine that goes beyond keyword matching.</p><p>RAG builds upon semantic search by incorporating a generative component. It not only retrieves relevant information but also uses an LLM to synthesize and generate a comprehensive answer based on the retrieved information. This allows RAG to provide more concise and human-like responses, compared to simply presenting a list of search results.</p><p>Imagine you need to find information about a specific error code in a large technical manual. Semantic search would help you locate the relevant sections in the manual. RAG would then take those sections, synthesize the information, and provide you with a concise explanation of the error and potential solutions.</p><h2 id=\"rag-chatbot-examples\">RAG chatbot examples</h2><p>Now that we’ve explored the fundamentals of RAG, let’s dive into some examples to inspire your creativity.</p><p>We’ll demonstrate how to bring these ideas to life with <strong>n8n</strong>, a powerful workflow automation tool that streamlines the integration of external knowledge sources into RAG workflows. Plus, we’ll highlight why n8n is the ideal platform for building efficient, scalable, and customizable RAG chatbots.</p><p>The following scenarios are just a glimpse of what's possible when you combine the retrieval power of semantic search with the generative capabilities of LLMs.</p><h3 id=\"internal-knowledge-base-chatbot\">Internal knowledge base chatbot</h3><p>A workflow that connects to internal company resources, with a focus on documents stored in Google Drive. It leverages a mechanism to automatically update a Pinecone vector database whenever new documents are added or existing ones are modified in designated Google Drive folders. When a user asks a question, the workflow uses a combination of nodes (including semantic search with Pinecone and an LLM) to retrieve relevant information from the indexed documents and generate a response.</p><p>An employee asks the chatbot, \"What is the company's policy on remote work?\". The chatbot accesses the vector store, retrieves relevant documents and generates a summary of the policy.</p>\n<!--kg-card-begin: html-->\n<script>\n  workflowBanner(2753, document.currentScript);\n</script><div class=\"workflow\">\n      <div class=\"workflow-content\">\n        <div class=\"workflow-nodes\">\n          <img src=\"data:image/svg+xml;base64,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\" alt=\"Pinecone Vector Store\" title=\"Pinecone Vector Store\"><img src=\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiB2aWV3Qm94PSIwIDAgNDggNDgiPjxkZWZzPjxwYXRoIGlkPSJhIiBkPSJNNDQuNSAyMEgyNHY4LjVoMTEuOEMzNC43IDMzLjkgMzAuMSAzNyAyNCAzN2MtNy4yIDAtMTMtNS44LTEzLTEzczUuOC0xMyAxMy0xM2MzLjEgMCA1LjkgMS4xIDguMSAyLjlsNi40LTYuNEMzNC42IDQuMSAyOS42IDIgMjQgMiAxMS44IDIgMiAxMS44IDIgMjRzOS44IDIyIDIyIDIyYzExIDAgMjEtOCAyMS0yMiAwLTEuMy0uMi0yLjctLjUtNCIvPjwvZGVmcz48Y2xpcFBhdGggaWQ9ImIiPjx1c2UgeGxpbms6aHJlZj0iI2EiIG92ZXJmbG93PSJ2aXNpYmxlIi8+PC9jbGlwUGF0aD48cGF0aCBmaWxsPSIjRkJCQzA1IiBkPSJNMCAzN1YxMWwxNyAxM3oiIGNsaXAtcGF0aD0idXJsKCNiKSIvPjxwYXRoIGZpbGw9IiNFQTQzMzUiIGQ9Im0wIDExIDE3IDEzIDctNi4xTDQ4IDE0VjBIMHoiIGNsaXAtcGF0aD0idXJsKCNiKSIvPjxwYXRoIGZpbGw9IiMzNEE4NTMiIGQ9Im0wIDM3IDMwLTIzIDcuOSAxTDQ4IDB2NDhIMHoiIGNsaXAtcGF0aD0idXJsKCNiKSIvPjxwYXRoIGZpbGw9IiM0Mjg1RjQiIGQ9Ik00OCA0OCAxNyAyNGwtNC0zIDM1LTEweiIgY2xpcC1wYXRoPSJ1cmwoI2IpIi8+PC9zdmc+\" alt=\"Embeddings Google Gemini\" title=\"Embeddings Google Gemini\"><img src=\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSI3NjgiIGhlaWdodD0iMTAyNCI+PHBhdGggZmlsbD0iIzdEN0Q4NyIgZD0iTTAgOTYwVjY0aDU3NmwxOTIgMTkydjcwNHptNzA0LTY0MEw1MTIgMTI4SDY0djc2OGg2NDB6TTMyMCA1MTJIMTI4VjI1NmgxOTJ6bS02NC0xOTJoLTY0djEyOGg2NHptMCA0NDhoNjR2NjRIMTI4di02NGg2NFY2NDBoLTY0di02NGgxMjh6bTI1Ni0zMjBoNjR2NjRIMzg0di02NGg2NFYzMjBoLTY0di02NGgxMjh6bTY0IDM4NEgzODRWNTc2aDE5MnptLTY0LTE5MmgtNjR2MTI4aDY0eiIvPjwvc3ZnPg==\" alt=\"Default Data Loader\" title=\"Default Data Loader\">\n          <i class=\"fa fa-grip-lines-vertical\" aria-hidden=\"true\"></i>\n        \n          <i class=\"fa fa-robot\" aria-hidden=\"true\" style=\"color:#404040\"></i>\n        \n          <span>+5</span>\n        </div>\n        <div class=\"workflow-details\">\n          <p class=\"workflow-details-name\">\n            <a href=\"https://n8n.io/workflows/2753-rag-chatbot-for-company-documents-using-google-drive-and-gemini/\" class=\"blog-banner-workflow\">RAG Chatbot for Company Documents using Google Drive and Gemini</a>\n          </p>\n          <p class=\"workflow-details-stats\">by mihailtd</p>\n        </div>\n      </div>\n      <a href=\"https://n8n.io/workflows/2753-rag-chatbot-for-company-documents-using-google-drive-and-gemini/\" class=\"global-button blog-banner-workflow\">\n        Use this workflow\n      </a>\n    </div>\n<!--kg-card-end: html-->\n<h3 id=\"api-documentation-chatbot\">API documentation chatbot</h3><p>This workflow connects to API documentation, code examples, and developer documentation. It uses a \"Function node\" to parse API specifications and extract relevant information. When a developer asks a question about the API, the workflow retrieves relevant documentation and code examples. An LLM is used to generate concise explanations, provide usage examples tailored to the developer's programming language, and even generate code snippets for common API calls.</p><p>A developer asks the chatbot, \"How do I authenticate a user with the OAuth 2.0 protocol in my Node.js application?\" The chatbot retrieves the relevant API documentation and code examples, then generates a Node.js code snippet demonstrating the authentication process, along with explanations and security considerations.</p><p>Later in this article, we will walk through the steps of creating this API Documentation Chatbot workflow in detail, demonstrating how to connect to a real-world API specification, integrate with a vector database, and build a chat interface using n8n's powerful features!</p>\n<!--kg-card-begin: html-->\n<script>\n  workflowBanner(2705, document.currentScript);\n</script><div class=\"workflow\">\n      <div class=\"workflow-content\">\n        <div class=\"workflow-nodes\">\n          \n          <i class=\"fa fa-mouse-pointer\" aria-hidden=\"true\" style=\"color:#909298\"></i>\n        <img src=\"data:image/svg+xml;base64,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\" alt=\"HTTP Request\" title=\"HTTP Request\"><img src=\"data:image/svg+xml;base64,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\" alt=\"Pinecone Vector Store\" title=\"Pinecone Vector Store\"><img src=\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSI3NjgiIGhlaWdodD0iMTAyNCI+PHBhdGggZmlsbD0iIzdEN0Q4NyIgZD0iTTAgOTYwVjY0aDU3NmwxOTIgMTkydjcwNHptNzA0LTY0MEw1MTIgMTI4SDY0djc2OGg2NDB6TTMyMCA1MTJIMTI4VjI1NmgxOTJ6bS02NC0xOTJoLTY0djEyOGg2NHptMCA0NDhoNjR2NjRIMTI4di02NGg2NFY2NDBoLTY0di02NGgxMjh6bTI1Ni0zMjBoNjR2NjRIMzg0di02NGg2NFYzMjBoLTY0di02NGgxMjh6bTY0IDM4NEgzODRWNTc2aDE5MnptLTY0LTE5MmgtNjR2MTI4aDY0eiIvPjwvc3ZnPg==\" alt=\"Default Data Loader\" title=\"Default Data Loader\">\n          <i class=\"fa fa-grip-lines-vertical\" aria-hidden=\"true\"></i>\n        \n          <span>+5</span>\n        </div>\n        <div class=\"workflow-details\">\n          <p class=\"workflow-details-name\">\n            <a href=\"https://n8n.io/workflows/2705-chat-with-github-api-documentation-rag-powered-chatbot-with-pinecone-and-openai/\" class=\"blog-banner-workflow\">Chat with GitHub API Documentation: RAG-Powered Chatbot with Pinecone &amp; OpenAI</a>\n          </p>\n          <p class=\"workflow-details-stats\">by mihailtd</p>\n        </div>\n      </div>\n      <a href=\"https://n8n.io/workflows/2705-chat-with-github-api-documentation-rag-powered-chatbot-with-pinecone-and-openai/\" class=\"global-button blog-banner-workflow\">\n        Use this workflow\n      </a>\n    </div>\n<!--kg-card-end: html-->\n<h3 id=\"financial-analyst-chatbot\">Financial analyst chatbot</h3><p>This workflow integrates with financial data providers (e.g., Bloomberg, Refinitiv). It uses \"HTTP Request\" nodes to fetch real-time market data, historical stock prices, and company financial reports. When a user asks a financial question, the workflow retrieves relevant data and uses an LLM to generate insightful analyses, risk assessments, or investment recommendations.</p><p>An analyst asks the chatbot, \"What is the current market sentiment towards renewable energy companies, and how does it compare to the previous quarter?\" The chatbot analyzes news articles, social media sentiment, and market data to provide a comprehensive answer, potentially including charts and graphs generated with other n8n nodes.</p>\n<!--kg-card-begin: html-->\n<script>\n  workflowBanner(2741, document.currentScript);\n</script><div class=\"workflow\">\n      <div class=\"workflow-content\">\n        <div class=\"workflow-nodes\">\n          <img src=\"data:image/svg+xml;base64,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\" alt=\"Pinecone Vector Store\" title=\"Pinecone Vector Store\"><img src=\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiB2aWV3Qm94PSIwIDAgNDggNDgiPjxkZWZzPjxwYXRoIGlkPSJhIiBkPSJNNDQuNSAyMEgyNHY4LjVoMTEuOEMzNC43IDMzLjkgMzAuMSAzNyAyNCAzN2MtNy4yIDAtMTMtNS44LTEzLTEzczUuOC0xMyAxMy0xM2MzLjEgMCA1LjkgMS4xIDguMSAyLjlsNi40LTYuNEMzNC42IDQuMSAyOS42IDIgMjQgMiAxMS44IDIgMiAxMS44IDIgMjRzOS44IDIyIDIyIDIyYzExIDAgMjEtOCAyMS0yMiAwLTEuMy0uMi0yLjctLjUtNCIvPjwvZGVmcz48Y2xpcFBhdGggaWQ9ImIiPjx1c2UgeGxpbms6aHJlZj0iI2EiIG92ZXJmbG93PSJ2aXNpYmxlIi8+PC9jbGlwUGF0aD48cGF0aCBmaWxsPSIjRkJCQzA1IiBkPSJNMCAzN1YxMWwxNyAxM3oiIGNsaXAtcGF0aD0idXJsKCNiKSIvPjxwYXRoIGZpbGw9IiNFQTQzMzUiIGQ9Im0wIDExIDE3IDEzIDctNi4xTDQ4IDE0VjBIMHoiIGNsaXAtcGF0aD0idXJsKCNiKSIvPjxwYXRoIGZpbGw9IiMzNEE4NTMiIGQ9Im0wIDM3IDMwLTIzIDcuOSAxTDQ4IDB2NDhIMHoiIGNsaXAtcGF0aD0idXJsKCNiKSIvPjxwYXRoIGZpbGw9IiM0Mjg1RjQiIGQ9Ik00OCA0OCAxNyAyNGwtNC0zIDM1LTEweiIgY2xpcC1wYXRoPSJ1cmwoI2IpIi8+PC9zdmc+\" alt=\"Embeddings Google Gemini\" title=\"Embeddings Google Gemini\"><img src=\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSI3NjgiIGhlaWdodD0iMTAyNCI+PHBhdGggZmlsbD0iIzdEN0Q4NyIgZD0iTTAgOTYwVjY0aDU3NmwxOTIgMTkydjcwNHptNzA0LTY0MEw1MTIgMTI4SDY0djc2OGg2NDB6TTMyMCA1MTJIMTI4VjI1NmgxOTJ6bS02NC0xOTJoLTY0djEyOGg2NHptMCA0NDhoNjR2NjRIMTI4di02NGg2NFY2NDBoLTY0di02NGgxMjh6bTI1Ni0zMjBoNjR2NjRIMzg0di02NGg2NFYzMjBoLTY0di02NGgxMjh6bTY0IDM4NEgzODRWNTc2aDE5MnptLTY0LTE5MmgtNjR2MTI4aDY0eiIvPjwvc3ZnPg==\" alt=\"Default Data Loader\" title=\"Default Data Loader\">\n          <i class=\"fa fa-grip-lines-vertical\" aria-hidden=\"true\"></i>\n        \n          <i class=\"fa fa-sync\" aria-hidden=\"true\" style=\"color:#007755\"></i>\n        \n          <span>+5</span>\n        </div>\n        <div class=\"workflow-details\">\n          <p class=\"workflow-details-name\">\n            <a href=\"https://n8n.io/workflows/2741-ai-powered-rag-workflow-for-stock-earnings-report-analysis/\" class=\"blog-banner-workflow\">AI-Powered RAG Workflow For Stock Earnings Report Analysis</a>\n          </p>\n          <p class=\"workflow-details-stats\">by mihailtd</p>\n        </div>\n      </div>\n      <a href=\"https://n8n.io/workflows/2741-ai-powered-rag-workflow-for-stock-earnings-report-analysis/\" class=\"global-button blog-banner-workflow\">\n        Use this workflow\n      </a>\n    </div>\n<!--kg-card-end: html-->\n<h2 id=\"how-to-build-a-rag-chatbot-with-n8n\">How to build a RAG chatbot with n8n?</h2><p>Let's turn theory into practice by building an RAG chatbot with n8n's powerful visual workflow automation. We'll be creating an API documentation chatbot for the GitHub API, demonstrating how n8n simplifies the process of connecting to data sources, vector databases, and LLMs. This hands-on example will guide you through each step, from data extraction and indexing to creating a user-friendly chat interface.</p><h3 id=\"prerequisites\">Prerequisites</h3><p>Before we start building, make sure you have the following set up:</p><ol><li><strong>n8n account:</strong> You'll need an n8n account to create and run workflows. If you don't have one already, you can <a href=\"https://app.n8n.cloud/register?ref=blog.n8n.io\" target=\"_blank\" rel=\"noopener\"><u>sign up for an n8n cloud account</u></a> or<a href=\"https://docs.n8n.io/hosting/?ref=blog.n8n.io\" target=\"_blank\" rel=\"noopener\"> <u>self-host n8n</u></a>.</li><li><strong>OpenAI account and API key:</strong> We'll be using OpenAI's models for generating embeddings and responses. You'll need an OpenAI account and an API key. You can find this documentation page about <a href=\"https://docs.n8n.io/integrations/builtin/credentials/openai/?ref=blog.n8n.io\" target=\"_blank\" rel=\"noopener\"><u>setting up OpenAI credentials in n8n</u></a>.</li><li><strong>Pinecone account and API key:</strong> We'll use Pinecone as our vector database to store and retrieve API documentation embeddings. You can create a free account on the Pinecone website and check out the documentation page on <a href=\"https://docs.n8n.io/integrations/builtin/credentials/pinecone/?ref=blog.n8n.io\" target=\"_blank\" rel=\"noopener\"><u>how to set up Pinecone credentials in n8n</u></a>.</li></ol><p><strong>Basic familiarity with vector databases:</strong> While not strictly required, understanding the basic concepts of vector databases will be helpful. You can check out this n8n documentation for a primer:<a href=\"https://docs.n8n.io/advanced-ai/examples/understand-vector-databases/?ref=blog.n8n.io\" target=\"_blank\" rel=\"noopener\"> u<u>sing Vector Databases in n8n</u></a>.</p><p>Once you have these prerequisites in place, you're ready to start building your RAG chatbot! You can follow along by importing the workflow:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-08-100219.webp\" class=\"kg-image lightense-target\" alt=\"RAG chatbot n8n workflow\" loading=\"lazy\" width=\"966\" height=\"752\" srcset=\"https://blog.n8n.io/content/images/size/w600/2025/01/Screenshot-2025-01-08-100219.webp 600w, https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-08-100219.webp 966w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">RAG chatbot n8n workflow</span></figcaption></figure>\n<!--kg-card-begin: html-->\n<script>\n  workflowBanner(2705, document.currentScript);\n</script><div class=\"workflow\">\n      <div class=\"workflow-content\">\n        <div class=\"workflow-nodes\">\n          \n          <i class=\"fa fa-mouse-pointer\" aria-hidden=\"true\" style=\"color:#909298\"></i>\n        <img src=\"data:image/svg+xml;base64,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\" alt=\"HTTP Request\" title=\"HTTP Request\"><img src=\"data:image/svg+xml;base64,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\" alt=\"Pinecone Vector Store\" title=\"Pinecone Vector Store\"><img src=\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSI3NjgiIGhlaWdodD0iMTAyNCI+PHBhdGggZmlsbD0iIzdEN0Q4NyIgZD0iTTAgOTYwVjY0aDU3NmwxOTIgMTkydjcwNHptNzA0LTY0MEw1MTIgMTI4SDY0djc2OGg2NDB6TTMyMCA1MTJIMTI4VjI1NmgxOTJ6bS02NC0xOTJoLTY0djEyOGg2NHptMCA0NDhoNjR2NjRIMTI4di02NGg2NFY2NDBoLTY0di02NGgxMjh6bTI1Ni0zMjBoNjR2NjRIMzg0di02NGg2NFYzMjBoLTY0di02NGgxMjh6bTY0IDM4NEgzODRWNTc2aDE5MnptLTY0LTE5MmgtNjR2MTI4aDY0eiIvPjwvc3ZnPg==\" alt=\"Default Data Loader\" title=\"Default Data Loader\">\n          <i class=\"fa fa-grip-lines-vertical\" aria-hidden=\"true\"></i>\n        \n          <span>+5</span>\n        </div>\n        <div class=\"workflow-details\">\n          <p class=\"workflow-details-name\">\n            <a href=\"https://n8n.io/workflows/2705-chat-with-github-api-documentation-rag-powered-chatbot-with-pinecone-and-openai/\" class=\"blog-banner-workflow\">Chat with GitHub API Documentation: RAG-Powered Chatbot with Pinecone &amp; OpenAI</a>\n          </p>\n          <p class=\"workflow-details-stats\">by mihailtd</p>\n        </div>\n      </div>\n      <a href=\"https://n8n.io/workflows/2705-chat-with-github-api-documentation-rag-powered-chatbot-with-pinecone-and-openai/\" class=\"global-button blog-banner-workflow\">\n        Use this workflow\n      </a>\n    </div>\n<!--kg-card-end: html-->\n<h3 id=\"step-1-set-up-data-source-and-content-extraction\">Step 1: Set up data source and content extraction</h3><p>This workflow consists of two parts. The first part handles grabbing the data and indexing it into Pinecone vector DB and the second part will handle the AI chatbot.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-08-100035.webp\" class=\"kg-image lightense-target\" alt=\"Loading data into the vector store\" loading=\"lazy\" width=\"922\" height=\"506\" srcset=\"https://blog.n8n.io/content/images/size/w600/2025/01/Screenshot-2025-01-08-100035.webp 600w, https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-08-100035.webp 922w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">Loading data into the vector store</span></figcaption></figure><p>Using the <a href=\"https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.httprequest/?utm_source=n8n_app&amp;utm_medium=node_settings_modal-credential_link&amp;utm_campaign=n8n-nodes-base.httpRequest\" target=\"_blank\" rel=\"noopener\"><strong><u>HTTP Request node</u></strong></a> we are fetching the OpenAPI 3.0 specification from GitHub. We simply use this <a href=\"https://raw.githubusercontent.com/github/rest-api-description/refs/heads/main/descriptions/api.github.com/api.github.com.json?ref=blog.n8n.io\" target=\"_blank\" rel=\"noopener\"><u>GitHub raw URL</u></a> to get the JSON file for the repository. Leave all other options at their default settings.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-07-220725.webp\" class=\"kg-image lightense-target\" alt=\"Retrieve the GitHub OpenAPI spec\" loading=\"lazy\" width=\"886\" height=\"1121\" srcset=\"https://blog.n8n.io/content/images/size/w600/2025/01/Screenshot-2025-01-07-220725.webp 600w, https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-07-220725.webp 886w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">Retrieve the GitHub OpenAPI spec</span></figcaption></figure><p>This node makes a GET request to the specified URL, which points to the raw JSON representation of the GitHub API specification. The response is the entire OpenAPI specification file. The file will be used in the next step.</p><h3 id=\"step-2-generate-embeddings\">Step 2: Generate embeddings</h3><p>In this important step, we transform the text chunks from the API documentation into numerical vector representations known as embeddings. These embeddings capture the semantic meaning of each text chunk, allowing us to perform similarity searches later on. We can do this using the <a href=\"https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.vectorstorepinecone/?utm_source=n8n_app&amp;utm_medium=node_settings_modal-credential_link&amp;utm_campaign=%40n8n%2Fn8n-nodes-langchain.vectorStorePinecone\" target=\"_blank\" rel=\"noopener\"><strong><u>Pinecone Vector Store node</u></strong></a>.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-07-220732.webp\" class=\"kg-image lightense-target\" alt=\"Set up saving document chunks in Pinecone vector store\" loading=\"lazy\" width=\"896\" height=\"697\" srcset=\"https://blog.n8n.io/content/images/size/w600/2025/01/Screenshot-2025-01-07-220732.webp 600w, https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-07-220732.webp 896w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">Set up saving document chunks in Pinecone vector store</span></figcaption></figure><p>Then we need to connect an <a href=\"https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.embeddingsopenai/?utm_source=n8n_app&amp;utm_medium=node_settings_modal-credential_link&amp;utm_campaign=%40n8n%2Fn8n-nodes-langchain.embeddingsOpenAi\" target=\"_blank\" rel=\"noopener\"><u>Embeddings OpenAI node</u></a> to the Pinecone Vector Store node.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-07-220741.webp\" class=\"kg-image lightense-target\" alt=\"Generate document embeddings\" loading=\"lazy\" width=\"891\" height=\"523\" srcset=\"https://blog.n8n.io/content/images/size/w600/2025/01/Screenshot-2025-01-07-220741.webp 600w, https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-07-220741.webp 891w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">Generate document embeddings</span></figcaption></figure><p>This node takes the text chunks and generates their corresponding vector embeddings using OpenAI's embedding model. Use your OpenAI credentials and choose <em>text-embedding-3-small</em> as the <strong>Model</strong>.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-07-220748.webp\" class=\"kg-image lightense-target\" alt=\"Set up default data loader for RAG\" loading=\"lazy\" width=\"891\" height=\"608\" srcset=\"https://blog.n8n.io/content/images/size/w600/2025/01/Screenshot-2025-01-07-220748.webp 600w, https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-07-220748.webp 891w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">Set up default data loader for RAG</span></figcaption></figure><p>We also need to connect the <a href=\"https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.documentdefaultdataloader/?utm_source=n8n_app&amp;utm_medium=node_settings_modal-credential_link&amp;utm_campaign=%40n8n%2Fn8n-nodes-langchain.documentDefaultDataLoader\" target=\"_blank\" rel=\"noopener\"><u>Default Data Loader node</u></a> and connect the <a href=\"https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.textsplitterrecursivecharactertextsplitter/?utm_source=n8n_app&amp;utm_medium=node_settings_modal-credential_link&amp;utm_campaign=%40n8n%2Fn8n-nodes-langchain.textSplitterRecursiveCharacterTextSplitter\" target=\"_blank\" rel=\"noopener\"><u>Recursive Character Text Splitter node</u></a> to that. You can leave everything as default.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-07-220756.webp\" class=\"kg-image lightense-target\" alt=\"Set up recursive character splitter\" loading=\"lazy\" width=\"888\" height=\"533\" srcset=\"https://blog.n8n.io/content/images/size/w600/2025/01/Screenshot-2025-01-07-220756.webp 600w, https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-07-220756.webp 888w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">Set up recursive character splitter</span></figcaption></figure><h3 id=\"step-3-save-documents-and-embeddings-to-the-pinecone-vector-store\">Step 3: Save documents and embeddings to the Pinecone vector store</h3><p>You can now run this part of the workflow. It might take a while to generate all the embeddings and save them to Pinecone, especially if the API specification file is large. After that is done, your Pinecone dashboard should show some data in that vector store:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-07-221159.webp\" class=\"kg-image lightense-target\" alt=\"Pinecone vector store index\" loading=\"lazy\" width=\"2000\" height=\"662\" srcset=\"https://blog.n8n.io/content/images/size/w600/2025/01/Screenshot-2025-01-07-221159.webp 600w, https://blog.n8n.io/content/images/size/w1000/2025/01/Screenshot-2025-01-07-221159.webp 1000w, https://blog.n8n.io/content/images/size/w1600/2025/01/Screenshot-2025-01-07-221159.webp 1600w, https://blog.n8n.io/content/images/size/w2400/2025/01/Screenshot-2025-01-07-221159.webp 2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">Pinecone vector store index</span></figcaption></figure><h3 id=\"step-4-build-the-core-chatbot-logic\">Step 4: Build the core chatbot logic</h3><p>With our API specification indexed in the vector database, we can now set up the querying and response generation part of the workflow. This involves receiving the user's query, finding relevant documents in the vector store, and crafting a response using an LLM.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-08-100219-1.webp\" class=\"kg-image lightense-target\" alt=\"RAG chatbot n8n workflow\" loading=\"lazy\" width=\"966\" height=\"752\" srcset=\"https://blog.n8n.io/content/images/size/w600/2025/01/Screenshot-2025-01-08-100219-1.webp 600w, https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-08-100219-1.webp 966w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">RAG chatbot n8n workflow</span></figcaption></figure><p>Use the <a href=\"https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-langchain.chattrigger/?utm_source=n8n_app&amp;utm_medium=node_settings_modal-credential_link&amp;utm_campaign=%40n8n%2Fn8n-nodes-langchain.chatTrigger\" target=\"_blank\" rel=\"noopener\"><strong><u>Chat Trigger</u></strong></a> node to receive user input. This node acts as the entry point for user interaction, triggering the workflow when a new chat message is received. Leave all settings as default for now.</p><p>We then connect the Chat Trigger node to an <a href=\"https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.agent/?utm_source=n8n_app&amp;utm_medium=node_settings_modal-credential_link&amp;utm_campaign=%40n8n%2Fn8n-nodes-langchain.agent\" target=\"_blank\" rel=\"noopener\"><u>AI Agent node</u></a>. This node orchestrates the retrieval and generation steps. It receives the user’s question and the relevant documents, and calls upon the LLM to produce an answer.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-07-220811.webp\" class=\"kg-image lightense-target\" alt=\"Set up n8n AI agent node\" loading=\"lazy\" width=\"904\" height=\"978\" srcset=\"https://blog.n8n.io/content/images/size/w600/2025/01/Screenshot-2025-01-07-220811.webp 600w, https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-07-220811.webp 904w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">Set up n8n AI agent node</span></figcaption></figure><p>We can select the <strong>Agent </strong>type as <em>Tools Agent</em>. We can also set a <em>System Message</em>,which will be combined with the user's input to create a prompt for the LLM. Here's a simple example of a system message prompt:</p><pre><code>You are a helpful assistant providing information about the GitHub API and how to use it based on the OpenAPI V3 specifications.\n</code></pre>\n<p>Next, connect the AI Agent node to the <a href=\"https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmchatopenai/?utm_source=n8n_app&amp;utm_medium=node_settings_modal-credential_link&amp;utm_campaign=%40n8n%2Fn8n-nodes-langchain.lmChatOpenAi\" target=\"_blank\" rel=\"noopener\"><u>OpenAI Chat Model node</u></a>. This node is responsible for taking the user's query, along with the retrieved text chunks, and using an OpenAI LLM to generate a final, comprehensive answer.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-07-220820.webp\" class=\"kg-image lightense-target\" alt=\"Set up OpenAI GPT-4o-mini as the main chat model\" loading=\"lazy\" width=\"891\" height=\"525\" srcset=\"https://blog.n8n.io/content/images/size/w600/2025/01/Screenshot-2025-01-07-220820.webp 600w, https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-07-220820.webp 891w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">Set up OpenAI GPT-4o-mini as the main chat model</span></figcaption></figure><p>Select your OpenAI credentials, and from the Model dropdown, choose the efficient gpt-4o-mini model.</p><p>Connect the <a href=\"https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.memorybufferwindow/?utm_source=n8n_app&amp;utm_medium=node_settings_modal-credential_link&amp;utm_campaign=%40n8n%2Fn8n-nodes-langchain.memoryBufferWindow\" target=\"_blank\" rel=\"noopener\"><u>Window Buffer Memory node</u></a> to the AI Agent node. This node provides short-term memory for the conversation, enabling the LLM to answer follow-up questions and use previous prompts and answers to improve its responses. You can leave all settings as default here.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-07-220826.webp\" class=\"kg-image lightense-target\" alt=\"Implement chat memory using window buffer memory\" loading=\"lazy\" width=\"885\" height=\"546\" srcset=\"https://blog.n8n.io/content/images/size/w600/2025/01/Screenshot-2025-01-07-220826.webp 600w, https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-07-220826.webp 885w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">Implement chat memory using window buffer memory</span></figcaption></figure><h3 id=\"step-5-retrieve-information-using-the-vector-store-tool\">Step 5: Retrieve information using the vector store tool</h3><p>Now comes the crucial part that transforms this into a RAG chatbot instead of a regular AI chatbot!</p><p>Connect a <a href=\"https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.toolvectorstore/?utm_source=n8n_app&amp;utm_medium=node_settings_modal-credential_link&amp;utm_campaign=%40n8n%2Fn8n-nodes-langchain.toolVectorStore\" target=\"_blank\" rel=\"noopener\"><u>Vector Store Tool node</u></a> to the <strong>AI Agent</strong> node. The node uses the embedding of the user’s query to perform a similarity search against embeddings of the indexed API specification chunks.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-07-220832.webp\" class=\"kg-image lightense-target\" alt=\"Vector store tool set up\" loading=\"lazy\" width=\"890\" height=\"599\" srcset=\"https://blog.n8n.io/content/images/size/w600/2025/01/Screenshot-2025-01-07-220832.webp 600w, https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-07-220832.webp 890w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">Vector store tool set up</span></figcaption></figure><p>Give this tool a descriptive name and a description so the LLM understands when to use it. For this example, you can use the following description:</p><pre><code>Use this tool to get information about the GitHub API. This database contains OpenAPI v3 specifications.\n</code></pre>\n<p>We can also limit the number of results that we retrieve from the vector store to the 4 most relevant for the user’s query.</p><p>Then, connect the <a href=\"https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.vectorstorepinecone/?utm_source=n8n_app&amp;utm_medium=node_settings_modal-credential_link&amp;utm_campaign=%40n8n%2Fn8n-nodes-langchain.vectorStorePinecone\" target=\"_blank\" rel=\"noopener\"><u>Pinecone Vector Store node</u></a>, this time set the <strong>Operation Mode </strong>as <em>Retrieve Documents (For Agent/Chain)</em> and connect the same <a href=\"https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.embeddingsopenai/?utm_source=n8n_app&amp;utm_medium=node_settings_modal-credential_link&amp;utm_campaign=%40n8n%2Fn8n-nodes-langchain.embeddingsOpenAi\" target=\"_blank\" rel=\"noopener\"><u>Embeddings OpenAI node</u></a><strong> </strong>that we used earlier, ensuring the same text-embedding-3-large model is selected. This setup will generate embeddings for the user's query, allowing for a comparison against all the embeddings in your vector store.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-07-220843.webp\" class=\"kg-image lightense-target\" alt=\"Retrieve documents from Pinecone vector store\" loading=\"lazy\" width=\"893\" height=\"673\" srcset=\"https://blog.n8n.io/content/images/size/w600/2025/01/Screenshot-2025-01-07-220843.webp 600w, https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-07-220843.webp 893w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">Retrieve documents from Pinecone vector store</span></figcaption></figure><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-07-220850.webp\" class=\"kg-image lightense-target\" alt=\"Generate user query embeddings\" loading=\"lazy\" width=\"886\" height=\"609\" srcset=\"https://blog.n8n.io/content/images/size/w600/2025/01/Screenshot-2025-01-07-220850.webp 600w, https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-07-220850.webp 886w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">Generate user query embeddings</span></figcaption></figure><p>Finally, connect another <a href=\"https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmchatopenai/?utm_source=n8n_app&amp;utm_medium=node_settings_modal-credential_link&amp;utm_campaign=%40n8n%2Fn8n-nodes-langchain.lmChatOpenAi\" target=\"_blank\" rel=\"noopener\"><u>OpenAI Chat Model node</u></a>. This node will summarize the retrieved chunks from the database, providing context for the final response.</p><p>You can use the same gpt-4o-mini model here as well.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-07-220900.webp\" class=\"kg-image lightense-target\" alt=\"Set up OpenAI gpt-4o-mini chat model\" loading=\"lazy\" width=\"888\" height=\"547\" srcset=\"https://blog.n8n.io/content/images/size/w600/2025/01/Screenshot-2025-01-07-220900.webp 600w, https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-07-220900.webp 888w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">Set up OpenAI gpt-4o-mini chat model</span></figcaption></figure><h3 id=\"step-6-test-your-rag-chatbot\">Step 6: Test your RAG chatbot</h3><p>And there you have it!</p><p>You've now configured the core components of your RAG-powered GitHub API chatbot.</p><p>To test it out, simply click the Chat button located at the bottom of the n8n editor. This will open the chat interface where you can start interacting with your bot. As a test question, try asking: \"How do I create a GitHub App from a manifest?\". You'll be amazed to see how the chatbot retrieves relevant information from the GitHub API specification and provides you with a detailed, step-by-step solution using the API. This demonstrates the power of RAG and how n8n makes it easy to build sophisticated AI-powered applications.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-08-111319.webp\" class=\"kg-image lightense-target\" alt=\"\" loading=\"lazy\" width=\"1211\" height=\"919\" srcset=\"https://blog.n8n.io/content/images/size/w600/2025/01/Screenshot-2025-01-08-111319.webp 600w, https://blog.n8n.io/content/images/size/w1000/2025/01/Screenshot-2025-01-08-111319.webp 1000w, https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-08-111319.webp 1211w\" sizes=\"(min-width: 720px) 720px\"></figure><h2 id=\"wrap-up\">Wrap up</h2><p>In this article, we covered Retrieval Augmented Generation (RAG) and how it enables you to build specialized chatbots that can tap into specific knowledge sources, providing more accurate and relevant answers than traditional chatbots.</p><p>You've seen how n8n’s intuitive, visual interface and <a href=\"https://n8n.io/integrations/?ref=blog.n8n.io\" target=\"_blank\" rel=\"noopener\"><u>pre-built integrations</u></a> with various LLMs and databases make it an ideal platform for building and deploying RAG workflows. You can easily connect all the necessary components, experiment with different configurations, and scale your chatbot as your needs grow.</p>\n<!--kg-card-begin: html-->\n<div class=\"content-banner\">\n  <div>\n    <h3>Ready to create your own custom RAG chatbot?</h3>\n    <p>Integrate AI &amp; Automation to your business data, APIs, and entire stack</p>\n  </div>\n  <a href=\"https://app.n8n.cloud/register?ref=blog.n8n.io\" class=\"global-button blog-banner-signup\" target=\"_blank\" rel=\"noopener\">Explore n8n with a free trial</a>\n</div>\n<!--kg-card-end: html-->\n<h2 id=\"what%E2%80%99s-next\">What’s next?</h2><p>Okay, so you understand RAG and you've seen how n8n can put it all together. Now it's time to get practical. Here's what you should focus on next:</p><ul><li>Once you have the basic chatbot working, start experimenting. Try different embedding models, fine-tune your prompts, or test different retrieval strategies to improve performance.</li><li>n8n isn't tied to a single LLM. You can use nodes for OpenAI, Ollama, or integrate with LangChain. Each LLM has its strengths and weaknesses, so test them out to find the best fit. Check out this article to <a href=\"https://blog.n8n.io/local-llm/\"><u>learn more about integrating local Ollama models into your workflows</u></a>.</li><li>Check out YouTube tutorials from the community to deepen your understanding and see n8n in action:<ul><li><a href=\"https://www.youtube.com/watch?v=iT9xpiUwVbI&amp;ref=blog.n8n.io\" rel=\"noopener\" target=\"_blank\">Step-by-step RAG Agent with Pinecone and n8n</a></li><li><a href=\"https://www.youtube.com/watch?v=PEI_ePNNfJQ&amp;ref=blog.n8n.io\" rel=\"noopener\" target=\"_blank\">RAG agent with n8n and Supabase</a></li></ul></li><li>Get inspired by other <a href=\"https://n8n.io/workflows/categories/ai/?ref=blog.n8n.io\" target=\"_blank\" rel=\"noopener\"><u>AI workflows created by the n8n community</u></a>.</li></ul>\n\t\t<div class=\"newsletter-banner\">\n\t    <div class=\"newsletter-banner-content\">\n\t      <div class=\"section-header\">\n\t        <h2>Subscribe to <span>n8n newsletter</span></h2>\n\t        <div class=\"section-subheader--bottom\">\n\t          Get the best, coolest, and latest in automation and low-code delivered to your inbox each week.\n\t        </div>\n\t      </div>\n\t      <div class=\"newsletter-banner-form\">\n\t        <form autocomplete=\"off\" class=\"contact-form\" onsubmit=\"subscribeNewsletter(event)\">\n\t        \t<div id=\"recaptcha\" class=\"g-recaptcha\" data-sitekey=\"6LeAQeopAAAAAKlLsRb1weWm6T_vijoQBkGkbHzB\" data-callback=\"submitSubscription\" data-size=\"invisible\"><div class=\"grecaptcha-badge\" data-style=\"bottomright\" style=\"width: 256px; height: 60px; display: block; transition: right 0.3s ease 0s; position: fixed; bottom: 14px; right: -186px; box-shadow: gray 0px 0px 5px; border-radius: 2px; overflow: hidden;\"><div class=\"grecaptcha-logo\"><iframe title=\"reCAPTCHA\" width=\"256\" height=\"60\" role=\"presentation\" name=\"a-d8xce1g24wu3\" frameborder=\"0\" scrolling=\"no\" sandbox=\"allow-forms allow-popups allow-same-origin allow-scripts allow-top-navigation allow-modals allow-popups-to-escape-sandbox allow-storage-access-by-user-activation\" src=\"https://www.google.com/recaptcha/api2/anchor?ar=1&amp;k=6LeAQeopAAAAAKlLsRb1weWm6T_vijoQBkGkbHzB&amp;co=aHR0cHM6Ly9ibG9nLm44bi5pbzo0NDM.&amp;hl=en&amp;v=jt8Oh2-Ue1u7nEbJQUIdocyd&amp;size=invisible&amp;cb=z46stzdgk6r5\"></iframe></div><div class=\"grecaptcha-error\"></div><textarea id=\"g-recaptcha-response\" name=\"g-recaptcha-response\" class=\"g-recaptcha-response\" style=\"width: 250px; height: 40px; border: 1px solid rgb(193, 193, 193); margin: 10px 25px; padding: 0px; resize: none; display: none;\"></textarea></div><iframe style=\"display: none;\"></iframe></div>\n\t          <div class=\"input-wrapper\">\n\t            <input placeholder=\"Email\" name=\"email\" type=\"email\" required=\"required\" class=\"\">\n\t            <div class=\"messages\">\n\t              <div class=\"message message--error\">Something went wrong. Please try again later.</div>\n\t              <div class=\"message message--success\">Subscribed!</div>\n\t            </div>\n\t          </div>\n\t          <button type=\"submit\" class=\"submit-btn\">Subscribe</button>\n\t        </form>\n\t      </div>\n\t    </div>\n    </div>\n\t\t<div class=\"post-share-section\">\n\t<div class=\"post-share-wrap\">\n\t\t<a href=\"https://twitter.com/intent/tweet?text=Build%20a%20custom%20knowledge%20RAG%20chatbot%20using%20n8n&amp;url=https://blog.n8n.io/rag-chatbot/\" target=\"_blank\" rel=\"noopener\" aria-label=\"Twitter share icon\"><svg role=\"img\" viewBox=\"0 0 24 24\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M23.954 4.569c-.885.389-1.83.654-2.825.775 1.014-.611 1.794-1.574 2.163-2.723-.951.555-2.005.959-3.127 1.184-.896-.959-2.173-1.559-3.591-1.559-2.717 0-4.92 2.203-4.92 4.917 0 .39.045.765.127 1.124C7.691 8.094 4.066 6.13 1.64 3.161c-.427.722-.666 1.561-.666 2.475 0 1.71.87 3.213 2.188 4.096-.807-.026-1.566-.248-2.228-.616v.061c0 2.385 1.693 4.374 3.946 4.827-.413.111-.849.171-1.296.171-.314 0-.615-.03-.916-.086.631 1.953 2.445 3.377 4.604 3.417-1.68 1.319-3.809 2.105-6.102 2.105-.39 0-.779-.023-1.17-.067 2.189 1.394 4.768 2.209 7.557 2.209 9.054 0 13.999-7.496 13.999-13.986 0-.209 0-.42-.015-.63.961-.689 1.8-1.56 2.46-2.548l-.047-.02z\"></path></svg></a>\n\t\t<a href=\"https://www.facebook.com/sharer/sharer.php?u=https://blog.n8n.io/rag-chatbot/\" target=\"_blank\" rel=\"noopener\" aria-label=\"Facebook share icon\"><svg role=\"img\" viewBox=\"0 0 24 24\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M23.9981 11.9991C23.9981 5.37216 18.626 0 11.9991 0C5.37216 0 0 5.37216 0 11.9991C0 17.9882 4.38789 22.9522 10.1242 23.8524V15.4676H7.07758V11.9991H10.1242V9.35553C10.1242 6.34826 11.9156 4.68714 14.6564 4.68714C15.9692 4.68714 17.3424 4.92149 17.3424 4.92149V7.87439H15.8294C14.3388 7.87439 13.8739 8.79933 13.8739 9.74824V11.9991H17.2018L16.6698 15.4676H13.8739V23.8524C19.6103 22.9522 23.9981 17.9882 23.9981 11.9991Z\"></path></svg></a>\n\t\t<!-- <a href=\"javascript:\" class=\"post-share-link\" id=\"copy\" data-clipboard-target=\"#copy-link\" aria-label=\"Copy link icon\"><svg role=\"img\" viewBox=\"0 0 33 24\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M27.3999996,13.4004128 L21.7999996,13.4004128 L21.7999996,19 L18.9999996,19 L18.9999996,13.4004128 L13.3999996,13.4004128 L13.3999996,10.6006192 L18.9999996,10.6006192 L18.9999996,5 L21.7999996,5 L21.7999996,10.6006192 L27.3999996,10.6006192 L27.3999996,13.4004128 Z M12,20.87 C7.101,20.87 3.13,16.898 3.13,12 C3.13,7.102 7.101,3.13 12,3.13 C12.091,3.13 12.181,3.139 12.272,3.142 C9.866,5.336 8.347,8.487 8.347,12 C8.347,15.512 9.866,18.662 12.271,20.857 C12.18,20.859 12.091,20.87 12,20.87 Z M20.347,0 C18.882,0 17.484,0.276 16.186,0.756 C14.882,0.271 13.473,0 12,0 C5.372,0 0,5.373 0,12 C0,18.628 5.372,24 12,24 C13.471,24 14.878,23.726 16.181,23.242 C17.481,23.724 18.88,24 20.347,24 C26.975,24 32.347,18.628 32.347,12 C32.347,5.373 26.975,0 20.347,0 Z\"/></svg></a>\n\t\t<small class=\"share-link-info\">The link has been copied!</small> -->\n\t</div>\n\t<input type=\"text\" value=\"https://blog.n8n.io/rag-chatbot/\" id=\"copy-link\" aria-label=\"Copy link input\">\n</div>",
  "readme": "Ever wished for a chatbot that could answer specific questions about your data or documentation, instead of just hallucinating generic responses? Build one that actually knows your data with Retrieval Augmented Generation (RAG)!\n\nIn this blog post, we'll examine how Retrieval Augmented Generation (RAG) allows you to build specialized chatbots that go beyond the limitations of typical chatbot interactions. Instead of relying on generic responses, RAG chatbots utilize external knowledge sources to deliver precise and informative answers to complex queries.\n\nWe'll break down the core concepts of RAG and look at some practical RAG workflow examples. Plus, this isn't just theory - we'll demonstrate how to implement RAG using [_n8n, a workflow automation tool_](https://n8n.io/ai/?ref=blog.n8n.io).\n\nBy the end of this article, you'll have the knowledge and tools to construct your own RAG chatbots!\n\n## How is RAG used in chatbots?\n\nRetrieval Augmented Generation (RAG) in chatbots is a powerful technique that combines the strengths of large language models (LLMs) with external knowledge sources to generate more relevant, and most importantly, accurate responses.\n\n### What is the RAG in the chatbot?\n\nRAG is particularly useful in scenarios where LLMs need to access and utilize information that was not included in their initial training data, such as when answering questions about specific domains, internal documents, or data that is not publicly available.\n\n[_AI chatbots_](https://blog.n8n.io/best-ai-chatbot/) can use RAG to access and process information from a variety of sources, including unstructured data like text documents, web pages, and social media posts, as well as structured data like databases and knowledge graphs. This allows them to:\n\n  * provide more comprehensive and informative responses;\n  * personalize the user experience;\n  * stay up-to-date with the latest information;\n  * provide responses based on internal documents.\n\n\n\n### What is the difference between semantic search and RAG?\n\nWhile both semantic search and RAG aim to improve information retrieval, they differ in their approach and capabilities.\n\nSemantic search focuses on understanding the intent and context of a user's query to retrieve relevant information. It uses techniques like natural language processing (NLP) to analyze the meaning behind the words and identify related concepts. Think of it as a smarter search engine that goes beyond keyword matching.\n\nRAG builds upon semantic search by incorporating a generative component. It not only retrieves relevant information but also uses an LLM to synthesize and generate a comprehensive answer based on the retrieved information. This allows RAG to provide more concise and human-like responses, compared to simply presenting a list of search results.\n\nImagine you need to find information about a specific error code in a large technical manual. Semantic search would help you locate the relevant sections in the manual. RAG would then take those sections, synthesize the information, and provide you with a concise explanation of the error and potential solutions.\n\n## RAG chatbot examples\n\nNow that we’ve explored the fundamentals of RAG, let’s dive into some examples to inspire your creativity.\n\nWe’ll demonstrate how to bring these ideas to life with **n8n** , a powerful workflow automation tool that streamlines the integration of external knowledge sources into RAG workflows. Plus, we’ll highlight why n8n is the ideal platform for building efficient, scalable, and customizable RAG chatbots.\n\nThe following scenarios are just a glimpse of what's possible when you combine the retrieval power of semantic search with the generative capabilities of LLMs.\n\n### Internal knowledge base chatbot\n\nA workflow that connects to internal company resources, with a focus on documents stored in Google Drive. It leverages a mechanism to automatically update a Pinecone vector database whenever new documents are added or existing ones are modified in designated Google Drive folders. When a user asks a question, the workflow uses a combination of nodes (including semantic search with Pinecone and an LLM) to retrieve relevant information from the indexed documents and generate a response.\n\nAn employee asks the chatbot, \"What is the company's policy on remote work?\". The chatbot accesses the vector store, retrieves relevant documents and generates a summary of the policy.\n\n![Pinecone Vector Store](data:image/svg+xml;base64,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)![Embeddings Google Gemini](data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiB2aWV3Qm94PSIwIDAgNDggNDgiPjxkZWZzPjxwYXRoIGlkPSJhIiBkPSJNNDQuNSAyMEgyNHY4LjVoMTEuOEMzNC43IDMzLjkgMzAuMSAzNyAyNCAzN2MtNy4yIDAtMTMtNS44LTEzLTEzczUuOC0xMyAxMy0xM2MzLjEgMCA1LjkgMS4xIDguMSAyLjlsNi40LTYuNEMzNC42IDQuMSAyOS42IDIgMjQgMiAxMS44IDIgMiAxMS44IDIgMjRzOS44IDIyIDIyIDIyYzExIDAgMjEtOCAyMS0yMiAwLTEuMy0uMi0yLjctLjUtNCIvPjwvZGVmcz48Y2xpcFBhdGggaWQ9ImIiPjx1c2UgeGxpbms6aHJlZj0iI2EiIG92ZXJmbG93PSJ2aXNpYmxlIi8+PC9jbGlwUGF0aD48cGF0aCBmaWxsPSIjRkJCQzA1IiBkPSJNMCAzN1YxMWwxNyAxM3oiIGNsaXAtcGF0aD0idXJsKCNiKSIvPjxwYXRoIGZpbGw9IiNFQTQzMzUiIGQ9Im0wIDExIDE3IDEzIDctNi4xTDQ4IDE0VjBIMHoiIGNsaXAtcGF0aD0idXJsKCNiKSIvPjxwYXRoIGZpbGw9IiMzNEE4NTMiIGQ9Im0wIDM3IDMwLTIzIDcuOSAxTDQ4IDB2NDhIMHoiIGNsaXAtcGF0aD0idXJsKCNiKSIvPjxwYXRoIGZpbGw9IiM0Mjg1RjQiIGQ9Ik00OCA0OCAxNyAyNGwtNC0zIDM1LTEweiIgY2xpcC1wYXRoPSJ1cmwoI2IpIi8+PC9zdmc+)![Default Data Loader](data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSI3NjgiIGhlaWdodD0iMTAyNCI+PHBhdGggZmlsbD0iIzdEN0Q4NyIgZD0iTTAgOTYwVjY0aDU3NmwxOTIgMTkydjcwNHptNzA0LTY0MEw1MTIgMTI4SDY0djc2OGg2NDB6TTMyMCA1MTJIMTI4VjI1NmgxOTJ6bS02NC0xOTJoLTY0djEyOGg2NHptMCA0NDhoNjR2NjRIMTI4di02NGg2NFY2NDBoLTY0di02NGgxMjh6bTI1Ni0zMjBoNjR2NjRIMzg0di02NGg2NFYzMjBoLTY0di02NGgxMjh6bTY0IDM4NEgzODRWNTc2aDE5MnptLTY0LTE5MmgtNjR2MTI4aDY0eiIvPjwvc3ZnPg==) ____ +5\n\n[RAG Chatbot for Company Documents using Google Drive and Gemini](https://n8n.io/workflows/2753-rag-chatbot-for-company-documents-using-google-drive-and-gemini/)\n\nby mihailtd\n\n[ Use this workflow ](https://n8n.io/workflows/2753-rag-chatbot-for-company-documents-using-google-drive-and-gemini/)\n\n### API documentation chatbot\n\nThis workflow connects to API documentation, code examples, and developer documentation. It uses a \"Function node\" to parse API specifications and extract relevant information. When a developer asks a question about the API, the workflow retrieves relevant documentation and code examples. An LLM is used to generate concise explanations, provide usage examples tailored to the developer's programming language, and even generate code snippets for common API calls.\n\nA developer asks the chatbot, \"How do I authenticate a user with the OAuth 2.0 protocol in my Node.js application?\" The chatbot retrieves the relevant API documentation and code examples, then generates a Node.js code snippet demonstrating the authentication process, along with explanations and security considerations.\n\nLater in this article, we will walk through the steps of creating this API Documentation Chatbot workflow in detail, demonstrating how to connect to a real-world API specification, integrate with a vector database, and build a chat interface using n8n's powerful features!\n\n__![HTTP Request](data:image/svg+xml;base64,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)![Pinecone Vector Store](data:image/svg+xml;base64,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)![Default Data Loader](data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSI3NjgiIGhlaWdodD0iMTAyNCI+PHBhdGggZmlsbD0iIzdEN0Q4NyIgZD0iTTAgOTYwVjY0aDU3NmwxOTIgMTkydjcwNHptNzA0LTY0MEw1MTIgMTI4SDY0djc2OGg2NDB6TTMyMCA1MTJIMTI4VjI1NmgxOTJ6bS02NC0xOTJoLTY0djEyOGg2NHptMCA0NDhoNjR2NjRIMTI4di02NGg2NFY2NDBoLTY0di02NGgxMjh6bTI1Ni0zMjBoNjR2NjRIMzg0di02NGg2NFYzMjBoLTY0di02NGgxMjh6bTY0IDM4NEgzODRWNTc2aDE5MnptLTY0LTE5MmgtNjR2MTI4aDY0eiIvPjwvc3ZnPg==) __ +5\n\n[Chat with GitHub API Documentation: RAG-Powered Chatbot with Pinecone & OpenAI](https://n8n.io/workflows/2705-chat-with-github-api-documentation-rag-powered-chatbot-with-pinecone-and-openai/)\n\nby mihailtd\n\n[ Use this workflow ](https://n8n.io/workflows/2705-chat-with-github-api-documentation-rag-powered-chatbot-with-pinecone-and-openai/)\n\n### Financial analyst chatbot\n\nThis workflow integrates with financial data providers (e.g., Bloomberg, Refinitiv). It uses \"HTTP Request\" nodes to fetch real-time market data, historical stock prices, and company financial reports. When a user asks a financial question, the workflow retrieves relevant data and uses an LLM to generate insightful analyses, risk assessments, or investment recommendations.\n\nAn analyst asks the chatbot, \"What is the current market sentiment towards renewable energy companies, and how does it compare to the previous quarter?\" The chatbot analyzes news articles, social media sentiment, and market data to provide a comprehensive answer, potentially including charts and graphs generated with other n8n nodes.\n\n![Pinecone Vector Store](data:image/svg+xml;base64,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)![Embeddings Google Gemini](data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiB2aWV3Qm94PSIwIDAgNDggNDgiPjxkZWZzPjxwYXRoIGlkPSJhIiBkPSJNNDQuNSAyMEgyNHY4LjVoMTEuOEMzNC43IDMzLjkgMzAuMSAzNyAyNCAzN2MtNy4yIDAtMTMtNS44LTEzLTEzczUuOC0xMyAxMy0xM2MzLjEgMCA1LjkgMS4xIDguMSAyLjlsNi40LTYuNEMzNC42IDQuMSAyOS42IDIgMjQgMiAxMS44IDIgMiAxMS44IDIgMjRzOS44IDIyIDIyIDIyYzExIDAgMjEtOCAyMS0yMiAwLTEuMy0uMi0yLjctLjUtNCIvPjwvZGVmcz48Y2xpcFBhdGggaWQ9ImIiPjx1c2UgeGxpbms6aHJlZj0iI2EiIG92ZXJmbG93PSJ2aXNpYmxlIi8+PC9jbGlwUGF0aD48cGF0aCBmaWxsPSIjRkJCQzA1IiBkPSJNMCAzN1YxMWwxNyAxM3oiIGNsaXAtcGF0aD0idXJsKCNiKSIvPjxwYXRoIGZpbGw9IiNFQTQzMzUiIGQ9Im0wIDExIDE3IDEzIDctNi4xTDQ4IDE0VjBIMHoiIGNsaXAtcGF0aD0idXJsKCNiKSIvPjxwYXRoIGZpbGw9IiMzNEE4NTMiIGQ9Im0wIDM3IDMwLTIzIDcuOSAxTDQ4IDB2NDhIMHoiIGNsaXAtcGF0aD0idXJsKCNiKSIvPjxwYXRoIGZpbGw9IiM0Mjg1RjQiIGQ9Ik00OCA0OCAxNyAyNGwtNC0zIDM1LTEweiIgY2xpcC1wYXRoPSJ1cmwoI2IpIi8+PC9zdmc+)![Default Data Loader](data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSI3NjgiIGhlaWdodD0iMTAyNCI+PHBhdGggZmlsbD0iIzdEN0Q4NyIgZD0iTTAgOTYwVjY0aDU3NmwxOTIgMTkydjcwNHptNzA0LTY0MEw1MTIgMTI4SDY0djc2OGg2NDB6TTMyMCA1MTJIMTI4VjI1NmgxOTJ6bS02NC0xOTJoLTY0djEyOGg2NHptMCA0NDhoNjR2NjRIMTI4di02NGg2NFY2NDBoLTY0di02NGgxMjh6bTI1Ni0zMjBoNjR2NjRIMzg0di02NGg2NFYzMjBoLTY0di02NGgxMjh6bTY0IDM4NEgzODRWNTc2aDE5MnptLTY0LTE5MmgtNjR2MTI4aDY0eiIvPjwvc3ZnPg==) ____ +5\n\n[AI-Powered RAG Workflow For Stock Earnings Report Analysis](https://n8n.io/workflows/2741-ai-powered-rag-workflow-for-stock-earnings-report-analysis/)\n\nby mihailtd\n\n[ Use this workflow ](https://n8n.io/workflows/2741-ai-powered-rag-workflow-for-stock-earnings-report-analysis/)\n\n## How to build a RAG chatbot with n8n?\n\nLet's turn theory into practice by building an RAG chatbot with n8n's powerful visual workflow automation. We'll be creating an API documentation chatbot for the GitHub API, demonstrating how n8n simplifies the process of connecting to data sources, vector databases, and LLMs. This hands-on example will guide you through each step, from data extraction and indexing to creating a user-friendly chat interface.\n\n### Prerequisites\n\nBefore we start building, make sure you have the following set up:\n\n  1. **n8n account:** You'll need an n8n account to create and run workflows. If you don't have one already, you can [_sign up for an n8n cloud account_](https://app.n8n.cloud/register?ref=blog.n8n.io) or[ _self-host n8n_](https://docs.n8n.io/hosting/?ref=blog.n8n.io).\n  2. **OpenAI account and API key:** We'll be using OpenAI's models for generating embeddings and responses. You'll need an OpenAI account and an API key. You can find this documentation page about [_setting up OpenAI credentials in n8n_](https://docs.n8n.io/integrations/builtin/credentials/openai/?ref=blog.n8n.io).\n  3. **Pinecone account and API key:** We'll use Pinecone as our vector database to store and retrieve API documentation embeddings. You can create a free account on the Pinecone website and check out the documentation page on [_how to set up Pinecone credentials in n8n_](https://docs.n8n.io/integrations/builtin/credentials/pinecone/?ref=blog.n8n.io).\n\n\n\n**Basic familiarity with vector databases:** While not strictly required, understanding the basic concepts of vector databases will be helpful. You can check out this n8n documentation for a primer:[ u _sing Vector Databases in n8n_](https://docs.n8n.io/advanced-ai/examples/understand-vector-databases/?ref=blog.n8n.io).\n\nOnce you have these prerequisites in place, you're ready to start building your RAG chatbot! You can follow along by importing the workflow:\n\n![RAG chatbot n8n workflow](https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-08-100219.webp)RAG chatbot n8n workflow\n\n__![HTTP Request](data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iNDAiIGhlaWdodD0iNDAiIHZpZXdCb3g9IjAgMCA0MCA0MCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggZmlsbC1ydWxlPSJldmVub2RkIiBjbGlwLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik00MCAyMEM0MCA4Ljk1MzE0IDMxLjA0NjkgMCAyMCAwQzguOTUzMTQgMCAwIDguOTUzMTQgMCAyMEMwIDMxLjA0NjkgOC45NTMxNCA0MCAyMCA0MEMzMS4wNDY5IDQwIDQwIDMxLjA0NjkgNDAgMjBaTTIwIDM2Ljk0NThDMTguODg1MiAzNi45NDU4IDE3LjEzNzggMzUuOTY3IDE1LjQ5OTggMzIuNjk4NUMxNC43OTY0IDMxLjI5MTggMTQuMTk2MSAyOS41NDMxIDEzLjc1MjYgMjcuNjg0N0gyNi4xODk4QzI1LjgwNDUgMjkuNTQwMyAyNS4yMDQ0IDMxLjI5MDEgMjQuNTAwMiAzMi42OTg1QzIyLjg2MjIgMzUuOTY3IDIxLjExNDggMzYuOTQ1OCAyMCAzNi45NDU4Wk0xMi45MDY0IDIwQzEyLjkwNjQgMjEuNjA5NyAxMy4wMDg3IDIzLjE2NCAxMy4yMDAzIDI0LjYzMDVIMjYuNzk5N0MyNi45OTEzIDIzLjE2NCAyNy4wOTM2IDIxLjYwOTcgMjcuMDkzNiAyMEMyNy4wOTM2IDE4LjM5MDMgMjYuOTkxMyAxNi44MzYgMjYuNzk5NyAxNS4zNjk1SDEzLjIwMDNDMTMuMDA4NyAxNi44MzYgMTIuOTA2NCAxOC4zOTAzIDEyLjkwNjQgMjBaTTIwIDMuMDU0MTlDMjEuMTE0OSAzLjA1NDE5IDIyLjg2MjIgNC4wMzA3OCAyNC41MDAxIDcuMzAwMzlDMjUuMjA2NiA4LjcxNDA4IDI1LjgwNzIgMTAuNDA2NyAyNi4xOTIgMTIuMzE1M0gxMy43NTAxQzE0LjE5MzMgMTAuNDA0NyAxNC43OTQyIDguNzEyNTQgMTUuNDk5OCA3LjMwMDY0QzE3LjEzNzcgNC4wMzA4MyAxOC44ODUxIDMuMDU0MTkgMjAgMy4wNTQxOVpNMzAuMTQ3OCAyMEMzMC4xNDc4IDE4LjQwOTkgMzAuMDU0MyAxNi44NjE3IDI5LjgyMjcgMTUuMzY5NUgzNi4zMDQyQzM2LjcyNTIgMTYuODQyIDM2Ljk0NTggMTguMzk2NCAzNi45NDU4IDIwQzM2Ljk0NTggMjEuNjAzNiAzNi43MjUyIDIzLjE1OCAzNi4zMDQyIDI0LjYzMDVIMjkuODIyN0MzMC4wNTQzIDIzLjEzODMgMzAuMTQ3OCAyMS41OTAxIDMwLjE0NzggMjBaTTI2LjI3NjcgNC4yNTUxMkMyNy42MzY1IDYuMzYwMTkgMjguNzExIDkuMTMyIDI5LjM3NzQgMTIuMzE1M0gzNS4xMDQ2QzMzLjI1MTEgOC42NjggMzAuMTA3IDUuNzgzNDYgMjYuMjc2NyA0LjI1NTEyWk0xMC42MjI2IDEyLjMxNTNINC44OTI5M0M2Ljc1MTQ3IDguNjY3ODQgOS44OTM1MSA1Ljc4MzQxIDEzLjcyMzIgNC4yNTUxM0MxMi4zNjM1IDYuMzYwMjEgMTEuMjg5IDkuMTMyMDEgMTAuNjIyNiAxMi4zMTUzWk0zLjA1NDE5IDIwQzMuMDU0MTkgMjEuNjAzIDMuMjc3NDMgMjMuMTU3NSAzLjY5NDg0IDI0LjYzMDVIMTAuMTIxN0M5Ljk0NjE5IDIzLjE0MiA5Ljg1MjIyIDIxLjU5NDMgOS44NTIyMiAyMEM5Ljg1MjIyIDE4LjQwNTcgOS45NDYxOSAxNi44NTggMTAuMTIxNyAxNS4zNjk1SDMuNjk0ODRDMy4yNzc0MyAxNi44NDI1IDMuMDU0MTkgMTguMzk3IDMuMDU0MTkgMjBaTTI2LjI3NjYgMzUuNzQyN0MyNy42MzY1IDMzLjYzOTMgMjguNzExIDMwLjg2OCAyOS4zNzc0IDI3LjY4NDdIMzUuMTA0NkMzMy4yNTEgMzEuMzMyMiAzMC4xMDY4IDM0LjIxNzkgMjYuMjc2NiAzNS43NDI3Wk0xMy43MjM0IDM1Ljc0MjdDOS44OTM2OSAzNC4yMTc5IDYuNzUxNTUgMzEuMzMyNCA0Ljg5MjkzIDI3LjY4NDdIMTAuNjIyNkMxMS4yODkgMzAuODY4IDEyLjM2MzUgMzMuNjM5MyAxMy43MjM0IDM1Ljc0MjdaIiBmaWxsPSIjM0E0MkU5Ii8+Cjwvc3ZnPgo=)![Pinecone Vector Store](data:image/svg+xml;base64,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)![Default Data Loader](data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSI3NjgiIGhlaWdodD0iMTAyNCI+PHBhdGggZmlsbD0iIzdEN0Q4NyIgZD0iTTAgOTYwVjY0aDU3NmwxOTIgMTkydjcwNHptNzA0LTY0MEw1MTIgMTI4SDY0djc2OGg2NDB6TTMyMCA1MTJIMTI4VjI1NmgxOTJ6bS02NC0xOTJoLTY0djEyOGg2NHptMCA0NDhoNjR2NjRIMTI4di02NGg2NFY2NDBoLTY0di02NGgxMjh6bTI1Ni0zMjBoNjR2NjRIMzg0di02NGg2NFYzMjBoLTY0di02NGgxMjh6bTY0IDM4NEgzODRWNTc2aDE5MnptLTY0LTE5MmgtNjR2MTI4aDY0eiIvPjwvc3ZnPg==) __ +5\n\n[Chat with GitHub API Documentation: RAG-Powered Chatbot with Pinecone & OpenAI](https://n8n.io/workflows/2705-chat-with-github-api-documentation-rag-powered-chatbot-with-pinecone-and-openai/)\n\nby mihailtd\n\n[ Use this workflow ](https://n8n.io/workflows/2705-chat-with-github-api-documentation-rag-powered-chatbot-with-pinecone-and-openai/)\n\n### Step 1: Set up data source and content extraction\n\nThis workflow consists of two parts. The first part handles grabbing the data and indexing it into Pinecone vector DB and the second part will handle the AI chatbot.\n\n![Loading data into the vector store](https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-08-100035.webp)Loading data into the vector store\n\nUsing the [**_HTTP Request node_**](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.httprequest/?utm_source=n8n_app&utm_medium=node_settings_modal-credential_link&utm_campaign=n8n-nodes-base.httpRequest) we are fetching the OpenAPI 3.0 specification from GitHub. We simply use this [_GitHub raw URL_](https://raw.githubusercontent.com/github/rest-api-description/refs/heads/main/descriptions/api.github.com/api.github.com.json?ref=blog.n8n.io) to get the JSON file for the repository. Leave all other options at their default settings.\n\n![Retrieve the GitHub OpenAPI spec](https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-07-220725.webp)Retrieve the GitHub OpenAPI spec\n\nThis node makes a GET request to the specified URL, which points to the raw JSON representation of the GitHub API specification. The response is the entire OpenAPI specification file. The file will be used in the next step.\n\n### Step 2: Generate embeddings\n\nIn this important step, we transform the text chunks from the API documentation into numerical vector representations known as embeddings. These embeddings capture the semantic meaning of each text chunk, allowing us to perform similarity searches later on. We can do this using the [**_Pinecone Vector Store node_**](https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.vectorstorepinecone/?utm_source=n8n_app&utm_medium=node_settings_modal-credential_link&utm_campaign=%40n8n%2Fn8n-nodes-langchain.vectorStorePinecone).\n\n![Set up saving document chunks in Pinecone vector store](https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-07-220732.webp)Set up saving document chunks in Pinecone vector store\n\nThen we need to connect an [_Embeddings OpenAI node_](https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.embeddingsopenai/?utm_source=n8n_app&utm_medium=node_settings_modal-credential_link&utm_campaign=%40n8n%2Fn8n-nodes-langchain.embeddingsOpenAi) to the Pinecone Vector Store node.\n\n![Generate document embeddings](https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-07-220741.webp)Generate document embeddings\n\nThis node takes the text chunks and generates their corresponding vector embeddings using OpenAI's embedding model. Use your OpenAI credentials and choose _text-embedding-3-small_ as the **Model**.\n\n![Set up default data loader for RAG](https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-07-220748.webp)Set up default data loader for RAG\n\nWe also need to connect the [_Default Data Loader node_](https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.documentdefaultdataloader/?utm_source=n8n_app&utm_medium=node_settings_modal-credential_link&utm_campaign=%40n8n%2Fn8n-nodes-langchain.documentDefaultDataLoader) and connect the [_Recursive Character Text Splitter node_](https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.textsplitterrecursivecharactertextsplitter/?utm_source=n8n_app&utm_medium=node_settings_modal-credential_link&utm_campaign=%40n8n%2Fn8n-nodes-langchain.textSplitterRecursiveCharacterTextSplitter) to that. You can leave everything as default.\n\n![Set up recursive character splitter](https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-07-220756.webp)Set up recursive character splitter\n\n### Step 3: Save documents and embeddings to the Pinecone vector store\n\nYou can now run this part of the workflow. It might take a while to generate all the embeddings and save them to Pinecone, especially if the API specification file is large. After that is done, your Pinecone dashboard should show some data in that vector store:\n\n![Pinecone vector store index](https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-07-221159.webp)Pinecone vector store index\n\n### Step 4: Build the core chatbot logic\n\nWith our API specification indexed in the vector database, we can now set up the querying and response generation part of the workflow. This involves receiving the user's query, finding relevant documents in the vector store, and crafting a response using an LLM.\n\n![RAG chatbot n8n workflow](https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-08-100219-1.webp)RAG chatbot n8n workflow\n\nUse the [**_Chat Trigger_**](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-langchain.chattrigger/?utm_source=n8n_app&utm_medium=node_settings_modal-credential_link&utm_campaign=%40n8n%2Fn8n-nodes-langchain.chatTrigger) node to receive user input. This node acts as the entry point for user interaction, triggering the workflow when a new chat message is received. Leave all settings as default for now.\n\nWe then connect the Chat Trigger node to an [_AI Agent node_](https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.agent/?utm_source=n8n_app&utm_medium=node_settings_modal-credential_link&utm_campaign=%40n8n%2Fn8n-nodes-langchain.agent). This node orchestrates the retrieval and generation steps. It receives the user’s question and the relevant documents, and calls upon the LLM to produce an answer.\n\n![Set up n8n AI agent node](https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-07-220811.webp)Set up n8n AI agent node\n\nWe can select the **Agent** type as _Tools Agent_. We can also set a _System Message_ ,which will be combined with the user's input to create a prompt for the LLM. Here's a simple example of a system message prompt:\n    \n    \n    You are a helpful assistant providing information about the GitHub API and how to use it based on the OpenAPI V3 specifications.\n    \n\nNext, connect the AI Agent node to the [_OpenAI Chat Model node_](https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmchatopenai/?utm_source=n8n_app&utm_medium=node_settings_modal-credential_link&utm_campaign=%40n8n%2Fn8n-nodes-langchain.lmChatOpenAi). This node is responsible for taking the user's query, along with the retrieved text chunks, and using an OpenAI LLM to generate a final, comprehensive answer.\n\n![Set up OpenAI GPT-4o-mini as the main chat model](https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-07-220820.webp)Set up OpenAI GPT-4o-mini as the main chat model\n\nSelect your OpenAI credentials, and from the Model dropdown, choose the efficient gpt-4o-mini model.\n\nConnect the [_Window Buffer Memory node_](https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.memorybufferwindow/?utm_source=n8n_app&utm_medium=node_settings_modal-credential_link&utm_campaign=%40n8n%2Fn8n-nodes-langchain.memoryBufferWindow) to the AI Agent node. This node provides short-term memory for the conversation, enabling the LLM to answer follow-up questions and use previous prompts and answers to improve its responses. You can leave all settings as default here.\n\n![Implement chat memory using window buffer memory](https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-07-220826.webp)Implement chat memory using window buffer memory\n\n### Step 5: Retrieve information using the vector store tool\n\nNow comes the crucial part that transforms this into a RAG chatbot instead of a regular AI chatbot!\n\nConnect a [_Vector Store Tool node_](https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.toolvectorstore/?utm_source=n8n_app&utm_medium=node_settings_modal-credential_link&utm_campaign=%40n8n%2Fn8n-nodes-langchain.toolVectorStore) to the **AI Agent** node. The node uses the embedding of the user’s query to perform a similarity search against embeddings of the indexed API specification chunks.\n\n![Vector store tool set up](https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-07-220832.webp)Vector store tool set up\n\nGive this tool a descriptive name and a description so the LLM understands when to use it. For this example, you can use the following description:\n    \n    \n    Use this tool to get information about the GitHub API. This database contains OpenAPI v3 specifications.\n    \n\nWe can also limit the number of results that we retrieve from the vector store to the 4 most relevant for the user’s query.\n\nThen, connect the [_Pinecone Vector Store node_](https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.vectorstorepinecone/?utm_source=n8n_app&utm_medium=node_settings_modal-credential_link&utm_campaign=%40n8n%2Fn8n-nodes-langchain.vectorStorePinecone), this time set the **Operation Mode** as _Retrieve Documents (For Agent/Chain)_ and connect the same [_Embeddings OpenAI node_](https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.embeddingsopenai/?utm_source=n8n_app&utm_medium=node_settings_modal-credential_link&utm_campaign=%40n8n%2Fn8n-nodes-langchain.embeddingsOpenAi)**** that we used earlier, ensuring the same text-embedding-3-large model is selected. This setup will generate embeddings for the user's query, allowing for a comparison against all the embeddings in your vector store.\n\n![Retrieve documents from Pinecone vector store](https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-07-220843.webp)Retrieve documents from Pinecone vector store![Generate user query embeddings](https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-07-220850.webp)Generate user query embeddings\n\nFinally, connect another [_OpenAI Chat Model node_](https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmchatopenai/?utm_source=n8n_app&utm_medium=node_settings_modal-credential_link&utm_campaign=%40n8n%2Fn8n-nodes-langchain.lmChatOpenAi). This node will summarize the retrieved chunks from the database, providing context for the final response.\n\nYou can use the same gpt-4o-mini model here as well.\n\n![Set up OpenAI gpt-4o-mini chat model](https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-07-220900.webp)Set up OpenAI gpt-4o-mini chat model\n\n### Step 6: Test your RAG chatbot\n\nAnd there you have it!\n\nYou've now configured the core components of your RAG-powered GitHub API chatbot.\n\nTo test it out, simply click the Chat button located at the bottom of the n8n editor. This will open the chat interface where you can start interacting with your bot. As a test question, try asking: \"How do I create a GitHub App from a manifest?\". You'll be amazed to see how the chatbot retrieves relevant information from the GitHub API specification and provides you with a detailed, step-by-step solution using the API. This demonstrates the power of RAG and how n8n makes it easy to build sophisticated AI-powered applications.\n\n![](https://blog.n8n.io/content/images/2025/01/Screenshot-2025-01-08-111319.webp)\n\n## Wrap up\n\nIn this article, we covered Retrieval Augmented Generation (RAG) and how it enables you to build specialized chatbots that can tap into specific knowledge sources, providing more accurate and relevant answers than traditional chatbots.\n\nYou've seen how n8n’s intuitive, visual interface and [_pre-built integrations_](https://n8n.io/integrations/?ref=blog.n8n.io) with various LLMs and databases make it an ideal platform for building and deploying RAG workflows. You can easily connect all the necessary components, experiment with different configurations, and scale your chatbot as your needs grow.\n\n### Ready to create your own custom RAG chatbot?\n\nIntegrate AI & Automation to your business data, APIs, and entire stack\n\n[Explore n8n with a free trial](https://app.n8n.cloud/register?ref=blog.n8n.io)\n\n## What’s next?\n\nOkay, so you understand RAG and you've seen how n8n can put it all together. Now it's time to get practical. Here's what you should focus on next:\n\n  * Once you have the basic chatbot working, start experimenting. Try different embedding models, fine-tune your prompts, or test different retrieval strategies to improve performance.\n  * n8n isn't tied to a single LLM. You can use nodes for OpenAI, Ollama, or integrate with LangChain. Each LLM has its strengths and weaknesses, so test them out to find the best fit. Check out this article to [_learn more about integrating local Ollama models into your workflows_](https://blog.n8n.io/local-llm/).\n  * Check out YouTube tutorials from the community to deepen your understanding and see n8n in action:\n    * [Step-by-step RAG Agent with Pinecone and n8n](https://www.youtube.com/watch?v=iT9xpiUwVbI&ref=blog.n8n.io)\n    * [RAG agent with n8n and Supabase](https://www.youtube.com/watch?v=PEI_ePNNfJQ&ref=blog.n8n.io)\n  * Get inspired by other [_AI workflows created by the n8n community_](https://n8n.io/workflows/categories/ai/?ref=blog.n8n.io).\n\n\n\n## Subscribe to n8n newsletter\n\nGet the best, coolest, and latest in automation and low-code delivered to your inbox each week. \n\nSomething went wrong. Please try again later.\n\nSubscribed!\n\nSubscribe\n\n[](https://twitter.com/intent/tweet?text=Build%20a%20custom%20knowledge%20RAG%20chatbot%20using%20n8n&url=https://blog.n8n.io/rag-chatbot/) [](https://www.facebook.com/sharer/sharer.php?u=https://blog.n8n.io/rag-chatbot/)\n",
  "crawled_at": "2025-05-28T10:47:20.417704"
}