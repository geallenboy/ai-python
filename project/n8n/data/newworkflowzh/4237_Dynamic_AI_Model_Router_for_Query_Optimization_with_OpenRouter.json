{
  "url": "https://n8n.io/workflows/4237-dynamic-ai-model-router-for-query-optimization-with-openrouter/",
  "title": "Dynamic AI Model Router for Query Optimization with OpenRouter",
  "author": "Davide",
  "publish_date": "Last update 6 days ago",
  "publish_date_absolute": "",
  "categories": [
    {
      "name": "Engineering"
    },
    {
      "name": "Building Blocks"
    },
    {
      "name": "AI"
    },
    {
      "name": "IT Ops"
    }
  ],
  "workflow_json": "",
  "readme": "The **Agent Decisioner** is a dynamic, AI-powered routing system that automatically selects the most appropriate large language model (LLM) to respond to a user's query based on the query‚Äôs content and purpose.\n\nThis workflow ensures **dynamic, optimized AI responses** by intelligently routing queries to the best-suited model.\n\n* * *\n\n### **Advantages**\n\n  * **üîÅ Automatic Model Routing:**  \nAutomatically selects the best model for the job, improving efficiency and relevance of responses.\n\n  * **üéØ Optimized Use of Resources:**  \nAvoids overuse of expensive models like GPT-4 by routing simpler queries to lightweight models.\n\n  * **üìö Model-Aware Reasoning:**  \nUses detailed metadata about model capabilities (e.g., reasoning, coding, web search) for intelligent selection.\n\n  * **üì• Modular and Extendable:**  \nEasy to integrate with other tools or expand by adding more models or custom decision logic.\n\n  * **üë®‚Äçüíª Ideal for RAG and Multi-Agent Systems:**  \nCan serve as the brain behind more complex agent frameworks or Retrieval-Augmented Generation pipelines.\n\n\n\n\n* * *\n\n### **How It Works**\n\n  1. **Chat Trigger** : The workflow starts when a user sends a message, triggering the **Routing Agent**.\n  2. **Model Selection** : The **AI Agent** analyzes the query and selects the best-suited model from the available options (e.g., Claude 3.7 Sonnet for coding, Perplexity/Sonar for web searches, GPT-4o Mini for reasoning).\n  3. **Structured Output** : The agent returns a **JSON response** with the user‚Äôs prompt and the chosen model.\n  4. **Execution** : The selected model processes the query and generates a response, ensuring optimal performance for the task.\n\n\n\n### **Set Up Steps**\n\n  1. **Configure Nodes** :\n\n     * **Chat Trigger** : Set up the webhook to receive user messages.\n     * **Routing Agent (AI Agent)** : Define the system message with model strengths and JSON output rules.\n     * **OpenRouter Chat Model** : Connect to OpenRouter for model access.\n     * **Structured Output Parser** : Ensure it validates the JSON response format (`prompt` \\+ `model`).\n     * **Execution Agent (AI Agent1)** : Configure it to forward the prompt to the selected model.\n  2. **Connect Nodes** :\n\n     * Link the **Chat Trigger** to the **Routing Agent**.\n     * Connect the **OpenRouter Chat Model** and **Output Parser** to the **Routing Agent**.\n     * Route the parsed JSON to the **Execution Agent** , which uses the chosen model via **OpenRouter Chat Model1**.\n  3. **Credentials** :\n\n     * Ensure **OpenRouter API credentials** are correctly set for both chat model nodes.\n  4. **Test & Deploy**:\n\n     * Activate the workflow and test with sample queries to verify model selection logic.\n     * Adjust the routing rules if needed for better accuracy.\n\n\n\n* * *\n\n### **Need help customizing?**\n\n[Contact me](mailto:info@n3w.it) for consulting and support or add me on [Linkedin](https://www.linkedin.com/in/davideboizza/).\n",
  "crawled_at": "2025-05-26T07:23:42.728766"
}