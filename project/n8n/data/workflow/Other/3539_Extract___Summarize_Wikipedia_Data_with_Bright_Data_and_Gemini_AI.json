{
  "title": "Extract & Summarize Wikipedia Data with Bright Data and Gemini AI",
  "url": "https://n8n.io/workflows/3539-extract-and-summarize-wikipedia-data-with-bright-data-and-gemini-ai/",
  "category": "Other",
  "category_url": "https://n8n.io/workflows/categories/other/?sort=createdAt:desc",
  "author": "Ranjan Dailata",
  "publish_date": "Last update 20 days ago",
  "publish_date_absolute": "2025-05-02",
  "content": "",
  "workflow_json": "{\"id\":\"sczRNO4u1HYc5YV7\",\"meta\":{\"instanceId\":\"885b4fb4a6a9c2cb5621429a7b972df0d05bb724c20ac7dac7171b62f1c7ef40\",\"templateCredsSetupCompleted\":true},\"name\":\"Extract & Summarize Wikipedia Data with Bright Data and Gemini AI\",\"tags\":[{\"id\":\"Kujft2FOjmOVQAmJ\",\"name\":\"Engineering\",\"createdAt\":\"2025-04-09T01:31:00.558Z\",\"updatedAt\":\"2025-04-09T01:31:00.558Z\"},{\"id\":\"ddPkw7Hg5dZhQu2w\",\"name\":\"AI\",\"createdAt\":\"2025-04-13T05:38:08.053Z\",\"updatedAt\":\"2025-04-13T05:38:08.053Z\"}],\"nodes\":[{\"id\":\"0f4b4939-6356-4672-ae61-8d1daf66a168\",\"name\":\"When clicking ‘Test workflow’\",\"type\":\"n8n-nodes-base.manualTrigger\",\"position\":[340,-440],\"parameters\":{},\"typeVersion\":1},{\"id\":\"167e060a-c36c-462a-826c-81ef379c824b\",\"name\":\"Google Gemini Chat Model For Summarization\",\"type\":\"@n8n/n8n-nodes-langchain.lmChatGoogleGemini\",\"position\":[1520,-60],\"parameters\":{\"options\":{},\"modelName\":\"models/gemini-2.0-flash-exp\"},\"credentials\":{\"googlePalmApi\":{\"id\":\"YeO7dHZnuGBVQKVZ\",\"name\":\"Google Gemini(PaLM) Api account\"}},\"typeVersion\":1},{\"id\":\"a51f2634-8b59-4feb-be39-674e8f198714\",\"name\":\"Google Gemini Chat Model2\",\"type\":\"@n8n/n8n-nodes-langchain.lmChatGoogleGemini\",\"position\":[1000,-240],\"parameters\":{\"options\":{},\"modelName\":\"models/gemini-2.0-pro-exp\"},\"credentials\":{\"googlePalmApi\":{\"id\":\"YeO7dHZnuGBVQKVZ\",\"name\":\"Google Gemini(PaLM) Api account\"}},\"typeVersion\":1},{\"id\":\"a1ec001f-6e97-4efb-91d9-9a037fbf472c\",\"name\":\"Summary Webhook Notifier\",\"type\":\"n8n-nodes-base.httpRequest\",\"position\":[1860,-280],\"parameters\":{\"url\":\"https://webhook.site/ce41e056-c097-48c8-a096-9b876d3abbf7\",\"options\":{},\"sendBody\":true,\"bodyParameters\":{\"parameters\":[{\"name\":\"summary\",\"value\":\"={{ $json.response.text }}\"}]}},\"typeVersion\":4.2},{\"id\":\"f4dd93b5-2a33-4ac7-a0c9-9e0956bea363\",\"name\":\"Sticky Note\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[340,-820],\"parameters\":{\"width\":400,\"height\":300,\"content\":\"## Note\\n\\nThis template deals with the Wikipedia data extraction and summarization of content with the Bright Data. \\n\\nThe LLM Data Extractor is responsible for producing a human readable content.\\n\\nThe Concise Summary Generator node is responsible for generating the concise summary of the Wikipedia extracted info.\\n\\n**Please make sure to update the Wikipedia URL with Bright Data Zone. Also make sure to set the Webhook Notification URL.**\"},\"typeVersion\":1},{\"id\":\"9bd6f913-c526-4e54-81f8-8885a0fe974f\",\"name\":\"Sticky Note1\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[780,-820],\"parameters\":{\"width\":500,\"height\":300,\"content\":\"## LLM Usages\\n\\nGoogle Gemini Flash Exp model is being used to demonstrate the data extraction and summarization aspects.\\n\\nBasic LLM Chain is being used for extracting the html to text\\n\\nSummarization Chain is being used for summarization of the Wikipedia data.\\n\\n**Note - Replace Google Gemini with the Open AI or suitable LLM providers of your choice.**\"},\"typeVersion\":1},{\"id\":\"30008ce4-4de2-43c5-bb03-94db58262f86\",\"name\":\"Wikipedia Web Request\",\"type\":\"n8n-nodes-base.httpRequest\",\"position\":[780,-440],\"parameters\":{\"url\":\"https://api.brightdata.com/request\",\"method\":\"POST\",\"options\":{},\"sendBody\":true,\"sendHeaders\":true,\"authentication\":\"genericCredentialType\",\"bodyParameters\":{\"parameters\":[{\"name\":\"zone\",\"value\":\"={{ $json.zone }}\"},{\"name\":\"url\",\"value\":\"={{ $json.url }}\"},{\"name\":\"format\",\"value\":\"raw\"}]},\"genericAuthType\":\"httpHeaderAuth\",\"headerParameters\":{\"parameters\":[{}]}},\"credentials\":{\"httpHeaderAuth\":{\"id\":\"kdbqXuxIR8qIxF7y\",\"name\":\"Header Auth account\"}},\"typeVersion\":4.2},{\"id\":\"28656a7d-4bd8-41c8-8471-50d19d88e7f2\",\"name\":\"LLM Data Extractor\",\"type\":\"@n8n/n8n-nodes-langchain.chainLlm\",\"position\":[1000,-440],\"parameters\":{\"text\":\"={{ $json.data }}\",\"messages\":{\"messageValues\":[{\"message\":\"You are an expert Data Formatter. Make sure to format the data in a human readable manner. Please output the human readable content without your own thoughts\"}]},\"promptType\":\"define\",\"hasOutputParser\":true},\"typeVersion\":1.6},{\"id\":\"7045af3b-9e74-42ef-92f0-f8d3266f2890\",\"name\":\"Concise Summary Generator\",\"type\":\"@n8n/n8n-nodes-langchain.chainSummarization\",\"position\":[1440,-280],\"parameters\":{\"options\":{\"summarizationMethodAndPrompts\":{\"values\":{\"prompt\":\"Write a concise summary of the following:\\n\\n\\n\\\"{text}\\\"\\n\"}}},\"chunkingMode\":\"advanced\"},\"typeVersion\":2},{\"id\":\"0cc843c1-252a-4c18-9856-5c7dfc732072\",\"name\":\"Set Wikipedia URL with Bright Data Zone\",\"type\":\"n8n-nodes-base.set\",\"notes\":\"Set the URL which you are interested to scrap the data\",\"position\":[560,-440],\"parameters\":{\"options\":{},\"assignments\":{\"assignments\":[{\"id\":\"1c132dd6-31e4-453b-a8cf-cad9845fe55b\",\"name\":\"url\",\"type\":\"string\",\"value\":\"https://en.wikipedia.org/wiki/Cloud_computing?product=unlocker&method=api\"},{\"id\":\"0fa387df-2511-4228-b6aa-237cceb3e9c7\",\"name\":\"zone\",\"type\":\"string\",\"value\":\"web_unlocker1\"}]}},\"notesInFlow\":true,\"typeVersion\":3.4},{\"id\":\"6cb9930f-1924-4762-8150-f5cd0e063348\",\"name\":\"Sticky Note2\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[940,-500],\"parameters\":{\"color\":4,\"width\":380,\"height\":420,\"content\":\"## Basic LLM Chain Data Extractor\\n\"},\"typeVersion\":1},{\"id\":\"47811535-bce5-4946-aaa6-baef87db1100\",\"name\":\"Sticky Note3\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[1400,-340],\"parameters\":{\"color\":5,\"width\":340,\"height\":420,\"content\":\"## Summarization Chain\\n\"},\"typeVersion\":1}],\"active\":false,\"pinData\":{},\"settings\":{\"executionOrder\":\"v1\"},\"versionId\":\"5b5e78fb-6e5a-4b92-838c-6c4060618e9c\",\"connections\":{\"LLM Data Extractor\":{\"main\":[[{\"node\":\"Concise Summary Generator\",\"type\":\"main\",\"index\":0}]]},\"Wikipedia Web Request\":{\"main\":[[{\"node\":\"LLM Data Extractor\",\"type\":\"main\",\"index\":0}]]},\"Concise Summary Generator\":{\"main\":[[{\"node\":\"Summary Webhook Notifier\",\"type\":\"main\",\"index\":0}]]},\"Google Gemini Chat Model2\":{\"ai_languageModel\":[[{\"node\":\"LLM Data Extractor\",\"type\":\"ai_languageModel\",\"index\":0}]]},\"When clicking ‘Test workflow’\":{\"main\":[[{\"node\":\"Set Wikipedia URL with Bright Data Zone\",\"type\":\"main\",\"index\":0}]]},\"Set Wikipedia URL with Bright Data Zone\":{\"main\":[[{\"node\":\"Wikipedia Web Request\",\"type\":\"main\",\"index\":0}]]},\"Google Gemini Chat Model For Summarization\":{\"ai_languageModel\":[[{\"node\":\"Concise Summary Generator\",\"type\":\"ai_languageModel\",\"index\":0}]]}}}",
  "readme": "### Who this is for?\n\nThis workflow automates the process of Wikipedia data extraction using the Bright Data Web Unlocker, parsing and cleaning the data, and then sending the results to a specified webhook URL for downstream processing, reporting, or integration.\n\n### What problem is this workflow solving?\n\n  * Researchers who need structured information from Wikipedia pages regularly.\n\n  * Data Engineers building knowledge bases or enriching datasets with factual data.\n\n  * Digital Marketers or Content Writers automating fact-checking or content sourcing.\n\n  * Automation Enthusiasts who want to trigger external systems with rich context from Wikipedia.\n\n\n\n\n### What this workflow does\n\nThis workflow addresses the challenges of manually retrieving, structuring, and using data from Wikipedia at scale.\n\n#### Workflow Breakdown\n\n**Trigger**\n\n  * Type: Scheduled or Manual\n  * Purpose: Starts the workflow either on a fixed schedule (e.g., daily) or on-demand via a manual trigger or incoming webhook.\n\n\n\n**Bright Data Wikipedia Scraping**\n\n  * Tool Used: Bright Data Web Unlocker\n  * Action: Scrape the HTML content of one or multiple Wikipedia article URLs.\n\n\n\n**Parse & Extract Structured Data**\n\n  * The Basic LLM Chain node is responsible for producing a human readable content.\n\n\n\n**Summarization**\n\n  * Summarize the Wikipedia content by utilizing the Summarization Chain node.\n\n\n\n**Send to Webhook**\n\n  * Initiates a Webhook notification to the specified URL as part of the \"**Summary Webhook Notifier** \" node.\n\n\n\n### Setup\n\n  * Sign up at [Bright Data](https://brightdata.com/).\n  * Navigate to Proxies & Scraping and create a new Web Unlocker zone by selecting Web Unlocker API under Scraping Solutions.\n  * In n8n, configure the Header Auth account under Credentials (Generic Auth Type: Header Authentication).\n  * A Google Gemini API key (or access through Vertex AI or proxy).\n  * Update the **Set Wikipedia URL with Bright Data Zone** node with the Wikipedia URL and Bright Data Zone.\n  * Update the **Summary Webhook Notifier** node with the Webhook endpoint of your choice.\n\n\n\n### How to customize this workflow to your needs\n\n  1. **Update Wikipedia URL**\n\n\n  * Replace with your own Wikipedia URL of your interest.\n  * Make sure to set the Wikipedia URL as part of the \"**Set Wikipedia URL with Bright Data Zone** \" node.\n\n\n  1. **Modify Data Extraction Logic**\n\n\n  * Extract entire article content or just specific sections by extending the \"**LLM Data Extractor** \" node prompt.\n\n\n  1. **Extend AI Summarization**\n\n\n  * Extract key bullet points or entities.\n  * Create short-form summaries by extending the \"**Concise Summary Generator** \" node.\n\n\n  1. **Extend Summary Webhook Notifier**\n\n\n  * Send to Slack, Discord, Telegram, MS Teams via the Webhook notification mechanism.\n  * Connect to your internal database/API via the Webhook notification mechanism.\n\n\n",
  "readme_html": "<!--[--><div data-v-50766329=\"\"><h3>Who this is for?</h3>\n<p>This workflow automates the process of Wikipedia data extraction using the Bright Data Web Unlocker, parsing and cleaning the data, and then sending the results to a specified webhook URL for downstream processing, reporting, or integration.</p>\n<h3>What problem is this workflow solving?</h3>\n<ul>\n<li>\n<p>Researchers who need structured information from Wikipedia pages regularly.</p>\n</li>\n<li>\n<p>Data Engineers building knowledge bases or enriching datasets with factual data.</p>\n</li>\n<li>\n<p>Digital Marketers or Content Writers automating fact-checking or content sourcing.</p>\n</li>\n<li>\n<p>Automation Enthusiasts who want to trigger external systems with rich context from Wikipedia.</p>\n</li>\n</ul>\n<h3>What this workflow does</h3>\n<p>This workflow addresses the challenges of manually retrieving, structuring, and using data from Wikipedia at scale.</p>\n<h4>Workflow Breakdown</h4>\n<p><strong>Trigger</strong></p>\n<ul>\n<li>Type: Scheduled or Manual</li>\n<li>Purpose: Starts the workflow either on a fixed schedule (e.g., daily) or on-demand via a manual trigger or incoming webhook.</li>\n</ul>\n<p><strong>Bright Data Wikipedia Scraping</strong></p>\n<ul>\n<li>Tool Used: Bright Data Web Unlocker</li>\n<li>Action: Scrape the HTML content of one or multiple Wikipedia article URLs.</li>\n</ul>\n<p><strong>Parse &amp; Extract Structured Data</strong></p>\n<ul>\n<li>The Basic LLM Chain node is responsible for producing a human readable content.</li>\n</ul>\n<p><strong>Summarization</strong></p>\n<ul>\n<li>Summarize the Wikipedia content by utilizing the Summarization Chain node.</li>\n</ul>\n<p><strong>Send to Webhook</strong></p>\n<ul>\n<li>Initiates a Webhook notification to the specified URL as part of the \"<strong>Summary Webhook Notifier</strong>\" node.</li>\n</ul>\n<h3>Setup</h3>\n<ul>\n<li>Sign up at <a href=\"https://brightdata.com/\" rel=\"ugc nofollow\" target=\"_blank\">Bright Data</a>.</li>\n<li>Navigate to Proxies &amp; Scraping and create a new Web Unlocker zone by selecting Web Unlocker API under Scraping Solutions.</li>\n<li>In n8n, configure the Header Auth account under Credentials (Generic Auth Type: Header Authentication).</li>\n<li>A Google Gemini API key (or access through Vertex AI or proxy).</li>\n<li>Update the <strong>Set Wikipedia URL with Bright Data Zone</strong> node with the Wikipedia URL and Bright Data Zone.</li>\n<li>Update the <strong>Summary Webhook Notifier</strong> node with the Webhook endpoint of your choice.</li>\n</ul>\n<h3>How to customize this workflow to your needs</h3>\n<ol>\n<li><strong>Update Wikipedia URL</strong></li>\n</ol>\n<ul>\n<li>Replace with your own Wikipedia URL of your interest.</li>\n<li>Make sure to set the Wikipedia URL as part of the \"<strong>Set Wikipedia URL with Bright Data Zone</strong>\" node.</li>\n</ul>\n<ol>\n<li><strong>Modify Data Extraction Logic</strong></li>\n</ol>\n<ul>\n<li>Extract entire article content or just specific sections by extending the \"<strong>LLM Data Extractor</strong>\" node prompt.</li>\n</ul>\n<ol>\n<li><strong>Extend AI Summarization</strong></li>\n</ol>\n<ul>\n<li>Extract key bullet points or entities.</li>\n<li>Create short-form summaries by extending the \"<strong>Concise Summary Generator</strong>\" node.</li>\n</ul>\n<ol>\n<li><strong>Extend Summary Webhook Notifier</strong></li>\n</ol>\n<ul>\n<li>Send to Slack, Discord, Telegram, MS Teams via the Webhook notification mechanism.</li>\n<li>Connect to your internal database/API via the Webhook notification mechanism.</li>\n</ul>\n</div><!--]-->",
  "readme_zh": "### 适用对象\n\n本工作流通过Bright Data网页解锁器实现维基百科数据抓取自动化，对数据进行解析清洗后，将结果发送至指定Webhook网址，供下游处理、报告或系统集成使用。\n\n### 解决痛点\n\n• 需要定期获取维基百科结构化数据的研究人员  \n• 构建知识库或用事实数据增强数据集的数据工程师  \n• 需要自动化事实核查或内容采编的数字营销/文案人员  \n• 希望通过维基百科丰富内容触发外部系统的自动化爱好者  \n\n### 核心功能\n\n本工作流解决了大规模人工获取、结构化处理和应用维基百科数据的难题。\n\n#### 流程分解\n\n**触发机制**  \n• 类型：定时触发或手动触发  \n• 作用：通过固定周期（如每日）或即时手动/Webhook请求启动工作流  \n\n**Bright Data维基百科抓取**  \n• 工具：Bright Data网页解锁器  \n• 操作：抓取单个或多个维基百科词条的HTML内容  \n\n**解析提取结构化数据**  \n• 基础LLM链节点负责生成人类可读内容  \n\n**摘要生成**  \n• 通过摘要链节点对维基百科内容进行总结  \n\n**Webhook推送**  \n• 通过\"摘要Webhook通知器\"节点向指定URL发送通知  \n\n### 配置说明\n\n1. 注册[Bright Data](https://brightdata.com/)账号  \n2. 进入\"代理与抓取\"板块，在\"抓取解决方案\"下选择网页解锁器API创建新区域  \n3. 在n8n中配置Header Auth凭证（认证类型：Header Authentication）  \n4. 准备Google Gemini API密钥（或通过Vertex AI/代理访问）  \n5. 在\"设置维基百科URL与Bright Data区域\"节点更新目标URL和区域信息  \n6. 在\"摘要Webhook通知器\"节点配置接收端Webhook地址  \n\n### 定制指南\n\n1. **更换维基百科URL**  \n• 在\"设置维基百科URL与Bright Data区域\"节点替换为目标词条链接  \n\n2. **调整数据提取逻辑**  \n• 通过扩展\"LLM数据提取器\"节点提示词，可提取全文或特定章节  \n\n3. **增强AI摘要功能**  \n• 在\"简明摘要生成器\"节点扩展提示词，可生成关键要点或实体列表  \n\n4. **扩展Webhook通知**  \n• 通过Webhook机制推送至Slack/Discord/Telegram/MS Teams等平台  \n• 对接内部数据库/API实现系统集成",
  "title_zh": "使用Bright Data与Gemini AI提取并总结维基百科数据",
  "publish_date_zh": "上次更新于20天前",
  "workflow_json_zh": "{\"id\":\"sczRNO4u1HYc5YV7\",\"meta\":{\"instanceId\":\"885b4fb4a6a9c2cb5621429a7b972df0d05bb724c20ac7dac7171b62f1c7ef40\",\"templateCredsSetupCompleted\":true},\"name\":\"Extract & Summarize Wikipedia Data with Bright Data and Gemini AI\",\"tags\":[{\"id\":\"Kujft2FOjmOVQAmJ\",\"name\":\"Engineering\",\"createdAt\":\"2025-04-09T01:31:00.558Z\",\"updatedAt\":\"2025-04-09T01:31:00.558Z\"},{\"id\":\"ddPkw7Hg5dZhQu2w\",\"name\":\"AI\",\"createdAt\":\"2025-04-13T05:38:08.053Z\",\"updatedAt\":\"2025-04-13T05:38:08.053Z\"}],\"nodes\":[{\"id\":\"0f4b4939-6356-4672-ae61-8d1daf66a168\",\"name\":\"When clicking ‘Test workflow’\",\"type\":\"n8n-nodes-base.manualTrigger\",\"position\":[340,-440],\"parameters\":{},\"typeVersion\":1},{\"id\":\"167e060a-c36c-462a-826c-81ef379c824b\",\"name\":\"Google Gemini Chat Model For Summarization\",\"type\":\"@n8n/n8n-nodes-langchain.lmChatGoogleGemini\",\"position\":[1520,-60],\"parameters\":{\"options\":{},\"modelName\":\"models/gemini-2.0-flash-exp\"},\"credentials\":{\"googlePalmApi\":{\"id\":\"YeO7dHZnuGBVQKVZ\",\"name\":\"Google Gemini(PaLM) Api account\"}},\"typeVersion\":1},{\"id\":\"a51f2634-8b59-4feb-be39-674e8f198714\",\"name\":\"Google Gemini Chat Model2\",\"type\":\"@n8n/n8n-nodes-langchain.lmChatGoogleGemini\",\"position\":[1000,-240],\"parameters\":{\"options\":{},\"modelName\":\"models/gemini-2.0-pro-exp\"},\"credentials\":{\"googlePalmApi\":{\"id\":\"YeO7dHZnuGBVQKVZ\",\"name\":\"Google Gemini(PaLM) Api account\"}},\"typeVersion\":1},{\"id\":\"a1ec001f-6e97-4efb-91d9-9a037fbf472c\",\"name\":\"Summary Webhook Notifier\",\"type\":\"n8n-nodes-base.httpRequest\",\"position\":[1860,-280],\"parameters\":{\"url\":\"https://webhook.site/ce41e056-c097-48c8-a096-9b876d3abbf7\",\"options\":{},\"sendBody\":true,\"bodyParameters\":{\"parameters\":[{\"name\":\"summary\",\"value\":\"={{ $json.response.text }}\"}]}},\"typeVersion\":4.2},{\"id\":\"f4dd93b5-2a33-4ac7-a0c9-9e0956bea363\",\"name\":\"Sticky Note\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[340,-820],\"parameters\":{\"width\":400,\"height\":300,\"content\":\"## 说明\\n\\n本模板用于通过Bright Data实现维基百科数据提取与内容摘要生成。\\n\\nLLM数据提取器负责生成人类可读的内容。\\n\\n简明摘要生成节点负责对从维基百科提取的信息生成简洁摘要。\\n\\n**请确保将维基百科URL更新为Bright Data区域地址，并务必设置Webhook通知URL。**\"},\"typeVersion\":1},{\"id\":\"9bd6f913-c526-4e54-81f8-8885a0fe974f\",\"name\":\"Sticky Note1\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[780,-820],\"parameters\":{\"width\":500,\"height\":300,\"content\":\"## 大语言模型应用场景\\n\\n谷歌Gemini Flash Exp模型正被用于演示数据提取与摘要生成功能\\n\\n基础大语言模型链负责将HTML转换为文本\\n\\n摘要生成链用于对维基百科数据进行内容概括\\n\\n**注：可将谷歌Gemini替换为OpenAI或其他适合的大语言模型服务商**\"},\"typeVersion\":1},{\"id\":\"30008ce4-4de2-43c5-bb03-94db58262f86\",\"name\":\"Wikipedia Web Request\",\"type\":\"n8n-nodes-base.httpRequest\",\"position\":[780,-440],\"parameters\":{\"url\":\"https://api.brightdata.com/request\",\"method\":\"POST\",\"options\":{},\"sendBody\":true,\"sendHeaders\":true,\"authentication\":\"genericCredentialType\",\"bodyParameters\":{\"parameters\":[{\"name\":\"zone\",\"value\":\"={{ $json.zone }}\"},{\"name\":\"url\",\"value\":\"={{ $json.url }}\"},{\"name\":\"format\",\"value\":\"raw\"}]},\"genericAuthType\":\"httpHeaderAuth\",\"headerParameters\":{\"parameters\":[{}]}},\"credentials\":{\"httpHeaderAuth\":{\"id\":\"kdbqXuxIR8qIxF7y\",\"name\":\"Header Auth account\"}},\"typeVersion\":4.2},{\"id\":\"28656a7d-4bd8-41c8-8471-50d19d88e7f2\",\"name\":\"LLM Data Extractor\",\"type\":\"@n8n/n8n-nodes-langchain.chainLlm\",\"position\":[1000,-440],\"parameters\":{\"text\":\"={{ $json.data }}\",\"messages\":{\"messageValues\":[{\"message\":\"You are an expert Data Formatter. Make sure to format the data in a human readable manner. Please output the human readable content without your own thoughts\"}]},\"promptType\":\"define\",\"hasOutputParser\":true},\"typeVersion\":1.6},{\"id\":\"7045af3b-9e74-42ef-92f0-f8d3266f2890\",\"name\":\"Concise Summary Generator\",\"type\":\"@n8n/n8n-nodes-langchain.chainSummarization\",\"position\":[1440,-280],\"parameters\":{\"options\":{\"summarizationMethodAndPrompts\":{\"values\":{\"prompt\":\"Write a concise summary of the following:\\n\\n\\n\\\"{text}\\\"\\n\"}}},\"chunkingMode\":\"advanced\"},\"typeVersion\":2},{\"id\":\"0cc843c1-252a-4c18-9856-5c7dfc732072\",\"name\":\"Set Wikipedia URL with Bright Data Zone\",\"type\":\"n8n-nodes-base.set\",\"notes\":\"Set the URL which you are interested to scrap the data\",\"position\":[560,-440],\"parameters\":{\"options\":{},\"assignments\":{\"assignments\":[{\"id\":\"1c132dd6-31e4-453b-a8cf-cad9845fe55b\",\"name\":\"url\",\"type\":\"string\",\"value\":\"https://en.wikipedia.org/wiki/Cloud_computing?product=unlocker&method=api\"},{\"id\":\"0fa387df-2511-4228-b6aa-237cceb3e9c7\",\"name\":\"zone\",\"type\":\"string\",\"value\":\"web_unlocker1\"}]}},\"notesInFlow\":true,\"typeVersion\":3.4},{\"id\":\"6cb9930f-1924-4762-8150-f5cd0e063348\",\"name\":\"Sticky Note2\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[940,-500],\"parameters\":{\"color\":4,\"width\":380,\"height\":420,\"content\":\"## 基础LLM链式数据提取器\"},\"typeVersion\":1},{\"id\":\"47811535-bce5-4946-aaa6-baef87db1100\",\"name\":\"Sticky Note3\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[1400,-340],\"parameters\":{\"color\":5,\"width\":340,\"height\":420,\"content\":\"## 摘要生成链\"},\"typeVersion\":1}],\"active\":false,\"pinData\":{},\"settings\":{\"executionOrder\":\"v1\"},\"versionId\":\"5b5e78fb-6e5a-4b92-838c-6c4060618e9c\",\"connections\":{\"LLM Data Extractor\":{\"main\":[[{\"node\":\"Concise Summary Generator\",\"type\":\"main\",\"index\":0}]]},\"Wikipedia Web Request\":{\"main\":[[{\"node\":\"LLM Data Extractor\",\"type\":\"main\",\"index\":0}]]},\"Concise Summary Generator\":{\"main\":[[{\"node\":\"Summary Webhook Notifier\",\"type\":\"main\",\"index\":0}]]},\"Google Gemini Chat Model2\":{\"ai_languageModel\":[[{\"node\":\"LLM Data Extractor\",\"type\":\"ai_languageModel\",\"index\":0}]]},\"When clicking ‘Test workflow’\":{\"main\":[[{\"node\":\"Set Wikipedia URL with Bright Data Zone\",\"type\":\"main\",\"index\":0}]]},\"Set Wikipedia URL with Bright Data Zone\":{\"main\":[[{\"node\":\"Wikipedia Web Request\",\"type\":\"main\",\"index\":0}]]},\"Google Gemini Chat Model For Summarization\":{\"ai_languageModel\":[[{\"node\":\"Concise Summary Generator\",\"type\":\"ai_languageModel\",\"index\":0}]]}}}"
}