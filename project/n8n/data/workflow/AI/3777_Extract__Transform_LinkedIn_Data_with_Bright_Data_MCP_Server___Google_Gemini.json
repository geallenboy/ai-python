{
  "title": "Extract, Transform LinkedIn Data with Bright Data MCP Server & Google Gemini",
  "url": "https://n8n.io/workflows/3777-extract-transform-linkedin-data-with-bright-data-mcp-server-and-google-gemini/",
  "category": "AI",
  "category_url": "https://n8n.io/workflows/categories/ai/?sort=createdAt:desc",
  "author": "Ranjan Dailata",
  "publish_date": "Last update 5 days ago",
  "publish_date_absolute": "",
  "content": "",
  "workflow_json": "{\"id\":\"D2RkoPZlkKFRUrNu\",\"meta\":{\"instanceId\":\"885b4fb4a6a9c2cb5621429a7b972df0d05bb724c20ac7dac7171b62f1c7ef40\",\"templateCredsSetupCompleted\":true},\"name\":\"LinkedIn Web Scraping with Bright Data MCP Server & Google Gemini\",\"tags\":[{\"id\":\"ZOwtAMLepQaGW76t\",\"name\":\"Building Blocks\",\"createdAt\":\"2025-04-13T15:23:40.462Z\",\"updatedAt\":\"2025-04-13T15:23:40.462Z\"},{\"id\":\"ddPkw7Hg5dZhQu2w\",\"name\":\"AI\",\"createdAt\":\"2025-04-13T05:38:08.053Z\",\"updatedAt\":\"2025-04-13T05:38:08.053Z\"}],\"nodes\":[{\"id\":\"68715d64-ce99-4e23-81ed-fe8f7d08ebd7\",\"name\":\"When clicking ‘Test workflow’\",\"type\":\"n8n-nodes-base.manualTrigger\",\"position\":[-640,-50],\"parameters\":{},\"typeVersion\":1},{\"id\":\"e0295397-2926-4964-8be5-c0341de29a02\",\"name\":\"Sticky Note1\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[-260,-420],\"parameters\":{\"color\":3,\"width\":440,\"height\":320,\"content\":\"## Bright Data LinkedIn Person Scraper\"},\"typeVersion\":1},{\"id\":\"cdf42164-569e-4140-9847-4751d69c6b7b\",\"name\":\"Set the URLs\",\"type\":\"n8n-nodes-base.set\",\"position\":[-200,-300],\"parameters\":{\"options\":{},\"assignments\":{\"assignments\":[{\"id\":\"214e61a0-3587-453f-baf5-eac013990857\",\"name\":\"url\",\"type\":\"string\",\"value\":\"https://www.linkedin.com/in/ranjan-dailata/\"},{\"id\":\"45014942-0a2e-4f46-b395-f82f97bfa93e\",\"name\":\"webhook_url\",\"type\":\"string\",\"value\":\"https://webhook.site/ce41e056-c097-48c8-a096-9b876d3abbf7\"}]}},\"typeVersion\":3.4},{\"id\":\"5769fce6-bcd7-4a13-b992-cd6d955a2cf1\",\"name\":\"Bright Data MCP Client For LinkedIn Person\",\"type\":\"n8n-nodes-mcp.mcpClient\",\"notes\":\"Scrape a single webpage URL with advanced options for content extraction and get back the results in MarkDown language.\",\"position\":[20,-300],\"parameters\":{\"toolName\":\"web_data_linkedin_person_profile\",\"operation\":\"executeTool\",\"toolParameters\":\"={\\n   \\\"url\\\": \\\"{{ $json.url }}\\\"\\n} \"},\"credentials\":{\"mcpClientApi\":{\"id\":\"JtatFSfA2kkwctYa\",\"name\":\"MCP Client (STDIO) account\"}},\"notesInFlow\":true,\"typeVersion\":1},{\"id\":\"56e37aa6-9719-4879-80af-a10c091377fb\",\"name\":\"Sticky Note\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[-260,-60],\"parameters\":{\"color\":4,\"width\":440,\"height\":320,\"content\":\"## Bright Data LinkedIn Company Scraper\"},\"typeVersion\":1},{\"id\":\"69afab25-32c6-4849-b2f9-4a2b25657c37\",\"name\":\"List all tools for Bright Data\",\"type\":\"n8n-nodes-mcp.mcpClient\",\"position\":[-420,50],\"parameters\":{},\"credentials\":{\"mcpClientApi\":{\"id\":\"JtatFSfA2kkwctYa\",\"name\":\"MCP Client (STDIO) account\"}},\"typeVersion\":1},{\"id\":\"feb16a2b-fdf7-49d4-bcd5-848ccaf66639\",\"name\":\"Bright Data MCP Client For LinkedIn Company\",\"type\":\"n8n-nodes-mcp.mcpClient\",\"notes\":\"Scrape a single webpage URL with advanced options for content extraction and get back the results in MarkDown language.\",\"position\":[20,50],\"parameters\":{\"toolName\":\"web_data_linkedin_company_profile\",\"operation\":\"executeTool\",\"toolParameters\":\"={\\n   \\\"url\\\": \\\"{{ $json.url }}\\\"\\n} \"},\"credentials\":{\"mcpClientApi\":{\"id\":\"JtatFSfA2kkwctYa\",\"name\":\"MCP Client (STDIO) account\"}},\"notesInFlow\":true,\"typeVersion\":1},{\"id\":\"e5117eb1-a757-4c28-965e-87ea03213ed1\",\"name\":\"Set the LinkedIn Company URL\",\"type\":\"n8n-nodes-base.set\",\"position\":[-200,50],\"parameters\":{\"options\":{},\"assignments\":{\"assignments\":[{\"id\":\"214e61a0-3587-453f-baf5-eac013990857\",\"name\":\"url\",\"type\":\"string\",\"value\":\"https://www.linkedin.com/company/bright-data/\"},{\"id\":\"45014942-0a2e-4f46-b395-f82f97bfa93e\",\"name\":\"webhook_url\",\"type\":\"string\",\"value\":\"https://webhook.site/ce41e056-c097-48c8-a096-9b876d3abbf7\"}]}},\"typeVersion\":3.4},{\"id\":\"99f45d7f-ad79-4ffc-8299-c71bd870f8fb\",\"name\":\"Webhook for LinkedIn Company Web Scraper\",\"type\":\"n8n-nodes-base.httpRequest\",\"position\":[1060,40],\"parameters\":{\"url\":\"={{ $('Set the LinkedIn Company URL').item.json.webhook_url }}\",\"options\":{},\"jsonBody\":\"={\\n  \\\"about\\\": {{ JSON.stringify($json.about[0]) }},\\n \\\"story\\\": {{ JSON.stringify($json.company_story[0]) }}\\n}\",\"sendBody\":true,\"specifyBody\":\"json\"},\"typeVersion\":4.2},{\"id\":\"5dfd2630-17d9-4a13-8cd6-57a564ef4a26\",\"name\":\"LinkedIn Data Extractor\",\"type\":\"@n8n/n8n-nodes-langchain.informationExtractor\",\"position\":[240,200],\"parameters\":{\"text\":\"=Write a complete story of the provided company information in JSON. Use the following Company info to produce a story or a blog post. Make sure to incorporate all the provided company context.\\n\\nHere's the Company Info in JSON - {{ $json.input }}\",\"options\":{\"systemPromptTemplate\":\"You are an expert data formatter\"},\"attributes\":{\"attributes\":[{\"name\":\"company_story\",\"required\":true,\"description\":\"Detailed Company Info\"}]}},\"typeVersion\":1},{\"id\":\"d1927c08-5ded-4b0b-b60b-bed126040d38\",\"name\":\"Google Gemini Chat Model\",\"type\":\"@n8n/n8n-nodes-langchain.lmChatGoogleGemini\",\"position\":[328,420],\"parameters\":{\"options\":{},\"modelName\":\"models/gemini-2.0-flash-exp\"},\"credentials\":{\"googlePalmApi\":{\"id\":\"YeO7dHZnuGBVQKVZ\",\"name\":\"Google Gemini(PaLM) Api account\"}},\"typeVersion\":1},{\"id\":\"0de1d200-c35a-41df-b512-8b97b92f14db\",\"name\":\"List all available tools for Bright Data\",\"type\":\"n8n-nodes-mcp.mcpClient\",\"position\":[-420,-300],\"parameters\":{},\"credentials\":{\"mcpClientApi\":{\"id\":\"JtatFSfA2kkwctYa\",\"name\":\"MCP Client (STDIO) account\"}},\"typeVersion\":1},{\"id\":\"3f884694-b8f3-478a-b1a3-f46326a0c96f\",\"name\":\"Code\",\"type\":\"n8n-nodes-base.code\",\"position\":[318,-100],\"parameters\":{\"jsCode\":\"jsonContent = JSON.parse($input.first().json.result.content[0].text) \\nreturn jsonContent\\n\"},\"typeVersion\":2},{\"id\":\"67036198-4d7d-42d9-93cf-ffc65649bae0\",\"name\":\"Merge\",\"type\":\"n8n-nodes-base.merge\",\"position\":[616,50],\"parameters\":{},\"typeVersion\":3.1},{\"id\":\"77423290-bd08-4dc8-9f37-cf8fec9f6a63\",\"name\":\"Aggregate\",\"type\":\"n8n-nodes-base.aggregate\",\"position\":[836,50],\"parameters\":{\"options\":{},\"fieldsToAggregate\":{\"fieldToAggregate\":[{\"fieldToAggregate\":\"about\"},{\"fieldToAggregate\":\"output.company_story\"}]}},\"typeVersion\":1},{\"id\":\"91d25405-afb3-4ed6-b8fa-52ab64a654e2\",\"name\":\"Create a binary data for LinkedIn person info extract\",\"type\":\"n8n-nodes-base.function\",\"position\":[320,-500],\"parameters\":{\"functionCode\":\"items[0].binary = {\\n  data: {\\n    data: new Buffer(JSON.stringify(items[0].json, null, 2)).toString('base64')\\n  }\\n};\\nreturn items;\"},\"typeVersion\":1},{\"id\":\"3e74c49e-eb31-43b1-b8e1-ed960bd83ca1\",\"name\":\"Write the LinkedIn person info to disk\",\"type\":\"n8n-nodes-base.readWriteFile\",\"position\":[520,-500],\"parameters\":{\"options\":{},\"fileName\":\"d:\\\\LinkedIn-Person.json\",\"operation\":\"write\"},\"typeVersion\":1},{\"id\":\"f92b3505-2af6-42aa-bf4b-8b7b6cb97364\",\"name\":\"Create a binary data for LinkedIn company info extract\",\"type\":\"n8n-nodes-base.function\",\"position\":[1000,-180],\"parameters\":{\"functionCode\":\"items[0].binary = {\\n  data: {\\n    data: new Buffer(JSON.stringify(items[0].json, null, 2)).toString('base64')\\n  }\\n};\\nreturn items;\"},\"typeVersion\":1},{\"id\":\"6ed1402b-4858-4311-bede-f0b8f28acb9f\",\"name\":\"Write the LinkedIn company info to disk\",\"type\":\"n8n-nodes-base.readWriteFile\",\"position\":[1220,-180],\"parameters\":{\"options\":{},\"fileName\":\"d:\\\\LinkedIn-Company.json\",\"operation\":\"write\"},\"typeVersion\":1},{\"id\":\"335efc2b-80e3-4fac-b31f-82fff4ac4e65\",\"name\":\"Webhook for LinkedIn Person Web Scraper\",\"type\":\"n8n-nodes-base.httpRequest\",\"position\":[318,-300],\"parameters\":{\"url\":\"={{ $('Set the URLs').item.json.webhook_url }}\",\"options\":{},\"sendBody\":true,\"bodyParameters\":{\"parameters\":[{\"name\":\"response\",\"value\":\"={{ $json.result.content[0].text }}\"}]}},\"typeVersion\":4.2}],\"active\":false,\"pinData\":{},\"settings\":{\"executionOrder\":\"v1\"},\"versionId\":\"35815900-1729-40c7-b128-778eabb62ec1\",\"connections\":{\"Code\":{\"main\":[[{\"node\":\"Merge\",\"type\":\"main\",\"index\":0}]]},\"Merge\":{\"main\":[[{\"node\":\"Aggregate\",\"type\":\"main\",\"index\":0}]]},\"Aggregate\":{\"main\":[[{\"node\":\"Webhook for LinkedIn Company Web Scraper\",\"type\":\"main\",\"index\":0},{\"node\":\"Create a binary data for LinkedIn company info extract\",\"type\":\"main\",\"index\":0}]]},\"Set the URLs\":{\"main\":[[{\"node\":\"Bright Data MCP Client For LinkedIn Person\",\"type\":\"main\",\"index\":0}]]},\"LinkedIn Data Extractor\":{\"main\":[[{\"node\":\"Merge\",\"type\":\"main\",\"index\":1}]]},\"Google Gemini Chat Model\":{\"ai_languageModel\":[[{\"node\":\"LinkedIn Data Extractor\",\"type\":\"ai_languageModel\",\"index\":0}]]},\"Set the LinkedIn Company URL\":{\"main\":[[{\"node\":\"Bright Data MCP Client For LinkedIn Company\",\"type\":\"main\",\"index\":0}]]},\"List all tools for Bright Data\":{\"main\":[[{\"node\":\"Set the LinkedIn Company URL\",\"type\":\"main\",\"index\":0}]]},\"When clicking ‘Test workflow’\":{\"main\":[[{\"node\":\"List all available tools for Bright Data\",\"type\":\"main\",\"index\":0},{\"node\":\"List all tools for Bright Data\",\"type\":\"main\",\"index\":0}]]},\"Webhook for LinkedIn Person Web Scraper\":{\"main\":[[]]},\"List all available tools for Bright Data\":{\"main\":[[{\"node\":\"Set the URLs\",\"type\":\"main\",\"index\":0}]]},\"Bright Data MCP Client For LinkedIn Person\":{\"main\":[[{\"node\":\"Webhook for LinkedIn Person Web Scraper\",\"type\":\"main\",\"index\":0},{\"node\":\"Create a binary data for LinkedIn person info extract\",\"type\":\"main\",\"index\":0}]]},\"Bright Data MCP Client For LinkedIn Company\":{\"main\":[[{\"node\":\"Code\",\"type\":\"main\",\"index\":0},{\"node\":\"LinkedIn Data Extractor\",\"type\":\"main\",\"index\":0}]]},\"Create a binary data for LinkedIn person info extract\":{\"main\":[[{\"node\":\"Write the LinkedIn person info to disk\",\"type\":\"main\",\"index\":0}]]},\"Create a binary data for LinkedIn company info extract\":{\"main\":[[{\"node\":\"Write the LinkedIn company info to disk\",\"type\":\"main\",\"index\":0}]]}}}",
  "readme": "### Who this is for?\n\nThe Extract, Transform LinkedIn Data with Bright Data MCP Server & Google Gemini workflow is an automated solution that scrapes LinkedIn content via Bright Data MCP Server then transforms the response using a Gemini LLM. The final output is sent via webhook notification and also persisted on disk.\n\nThis workflow is tailored for:​\n\n  1. **Data Analysts** : Who require structured LinkedIn datasets for analytics and reporting.\n\n  2. **Marketing and Sales Teams** : Looking to enrich lead databases, track company updates, and identify market trends.\n\n  3. **Recruiters and Talent Acquisition Specialists** : Who want to automate candidate sourcing and company research.\n\n  4. **AI Developers** : Integrating real-time professional data into intelligent applications.\n\n  5. **Business Intelligence Teams** : Needing current and comprehensive LinkedIn data to drive strategic decisions.\n\n\n\n\n### What problem is this workflow solving?\n\nGathering structured and meaningful information from the web is traditionally slow, manual, and error-prone.\n\nThis workflow solves:\n\n  1. Reliable web scraping using Bright Data MCP Server LinkedIn tools.\n\n  2. LinkedIn person and company web scrapping with AI Agents setup with the Bright Data MCP Server tools.\n\n  3. Data extraction and transformation with Google Gemini LLM.\n\n  4. Persists the LinkedIn person and company info to disk.\n\n  5. Performs a Webhook notification with the LinkedIn person and company info.\n\n\n\n\n### What this workflow does?\n\nThis n8n workflow performs the following steps:\n\n  1. **Trigger** : Start manually.\n\n  2. **Input URL(s)** : Specify the LinkedIn person and company URL.\n\n  3. **Web Scraping (Bright Data)** : Use Bright Data's MCP Server, LinkedIn tools for the person and company data extract.\n\n  4. **Data Transformation & Aggregation**: Uses the Google LLM for handling the data transformation.\n\n  5. **Store / Output** : Save results into disk and also performs a Webhook notification.\n\n\n\n\n### Setup\n\n  1. Please make sure to setup n8n locally with MCP Servers by navigating to [n8n-nodes-mcp](https://www.youtube.com/watch?v=NUb73ErUCsA)\n  2. Please make sure to install the Bright Data MCP Server [@brightdata/mcp](https://www.npmjs.com/package/@brightdata/mcp) on your local machine.\n  3. Sign up at [Bright Data](https://brightdata.com/).\n  4. Navigate to Proxies & Scraping and create a new Web Unlocker zone by selecting Web Unlocker API under Scraping Solutions.\n  5. In n8n, configure the Header Auth account under Credentials (Generic Auth Type: Header Authentication).\n  6. In n8n, configure the Google Gemini(PaLM) Api account with the Google Gemini API key (or access through Vertex AI or proxy).\n  7. In n8n, configure the credentials to connect with MCP Client (STDIO) account with the Bright Data MCP Server as shown below.  \n![MCPClientAccount.png](https://n8niostorageaccount.blob.core.windows.net/n8nio-strapi-blobs-prod/assets/MCP_Client_Account_8bc6d83f7f.png)  \nMake sure to copy the Bright Data API_TOKEN within the Environments textbox above.\n  8. Update the LinkedIn URL person and company workflow.\n  9. Update the Webhook HTTP Request node with the Webhook endpoint of your choice.\n  10. Update the file name and path to persist on disk.\n\n\n\n### How to customize this workflow to your needs\n\n  1. **Different Inputs** : Instead of static URLs, accept URLs dynamically via webhook or form submissions.\n\n  2. **Data Extraction** : Modify the **LinkedIn Data Extractor** node with the suitable prompt to format the data as you wish.\n\n  3. **Outputs** : Update the Webhook endpoints to send the response to Slack channels, Airtable, Notion, CRM systems, etc.\n\n\n\n",
  "readme_html": "<!--[--><div data-v-50766329=\"\"><h3>Who this is for?</h3>\n<p>The Extract, Transform LinkedIn Data with Bright Data MCP Server &amp; Google Gemini workflow is an automated solution that scrapes LinkedIn content via Bright Data MCP Server then transforms the response using a Gemini LLM. The final output is sent via webhook notification and also persisted on disk.</p>\n<p>This workflow is tailored for:​</p>\n<ol>\n<li>\n<p><strong>Data Analysts</strong> : Who require structured LinkedIn datasets for analytics and reporting.</p>\n</li>\n<li>\n<p><strong>Marketing and Sales Teams</strong> : Looking to enrich lead databases, track company updates, and identify market trends.</p>\n</li>\n<li>\n<p><strong>Recruiters and Talent Acquisition Specialists</strong> : Who want to automate candidate sourcing and company research.</p>\n</li>\n<li>\n<p><strong>AI Developers</strong> : Integrating real-time professional data into intelligent applications.</p>\n</li>\n<li>\n<p><strong>Business Intelligence Teams</strong> : Needing current and comprehensive LinkedIn data to drive strategic decisions.</p>\n</li>\n</ol>\n<h3>What problem is this workflow solving?</h3>\n<p>Gathering structured and meaningful information from the web is traditionally slow, manual, and error-prone.</p>\n<p>This workflow solves:</p>\n<ol>\n<li>\n<p>Reliable web scraping using Bright Data MCP Server LinkedIn tools.</p>\n</li>\n<li>\n<p>LinkedIn person and company web scrapping with AI Agents setup with the Bright Data MCP Server tools.</p>\n</li>\n<li>\n<p>Data extraction and transformation with Google Gemini LLM.</p>\n</li>\n<li>\n<p>Persists the LinkedIn person and company info to disk.</p>\n</li>\n<li>\n<p>Performs a Webhook notification with the LinkedIn person and company info.</p>\n</li>\n</ol>\n<h3>What this workflow does?</h3>\n<p>This n8n workflow performs the following steps:</p>\n<ol>\n<li>\n<p><strong>Trigger</strong>: Start manually.</p>\n</li>\n<li>\n<p><strong>Input URL(s)</strong>: Specify the LinkedIn person and company URL.</p>\n</li>\n<li>\n<p><strong>Web Scraping (Bright Data)</strong>: Use Bright Data's MCP Server, LinkedIn tools for the person and company data extract.</p>\n</li>\n<li>\n<p><strong>Data Transformation &amp; Aggregation</strong>: Uses the Google LLM for handling the data transformation.</p>\n</li>\n<li>\n<p><strong>Store / Output</strong>: Save results into disk and also performs a Webhook notification.</p>\n</li>\n</ol>\n<h3>Setup</h3>\n<ol>\n<li>Please make sure to setup n8n locally with MCP Servers by navigating to <a href=\"https://www.youtube.com/watch?v=NUb73ErUCsA\" rel=\"ugc nofollow\" target=\"_blank\">n8n-nodes-mcp</a></li>\n<li>Please make sure to install the Bright Data MCP Server <a href=\"https://www.npmjs.com/package/@brightdata/mcp\" rel=\"ugc nofollow\" target=\"_blank\">@brightdata/mcp</a>  on your local machine.</li>\n<li>Sign up at <a href=\"https://brightdata.com/\" rel=\"ugc nofollow\" target=\"_blank\">Bright Data</a>.</li>\n<li>Navigate to Proxies &amp; Scraping and create a new Web Unlocker zone by selecting Web Unlocker API under Scraping Solutions.</li>\n<li>In n8n, configure the Header Auth account under Credentials (Generic Auth Type: Header Authentication).</li>\n<li>In n8n, configure the Google Gemini(PaLM) Api account with the Google Gemini API key (or access through Vertex AI or proxy).</li>\n<li>In n8n, configure the credentials to connect with MCP Client (STDIO) account with the Bright Data MCP Server as shown below.<br>\n<img src=\"https://n8niostorageaccount.blob.core.windows.net/n8nio-strapi-blobs-prod/assets/MCP_Client_Account_8bc6d83f7f.png\" alt=\"MCPClientAccount.png\"><br>\nMake sure to copy the Bright Data API_TOKEN within the Environments textbox above.</li>\n<li>Update the LinkedIn URL person and company workflow.</li>\n<li>Update the Webhook HTTP Request node with the Webhook endpoint of your choice.</li>\n<li>Update the file name and path to persist on disk.</li>\n</ol>\n<h3>How to customize this workflow to your needs</h3>\n<ol>\n<li>\n<p><strong>Different Inputs</strong>: Instead of static URLs, accept URLs dynamically via webhook or form submissions.</p>\n</li>\n<li>\n<p><strong>Data Extraction</strong>: Modify the <strong>LinkedIn Data Extractor</strong> node with the suitable prompt to format the data as you wish.</p>\n</li>\n<li>\n<p><strong>Outputs</strong>: Update the Webhook endpoints to send the response to Slack channels, Airtable, Notion, CRM systems, etc.</p>\n</li>\n</ol>\n</div><!--]-->"
}