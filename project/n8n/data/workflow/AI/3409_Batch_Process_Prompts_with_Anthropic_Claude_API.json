{
  "title": "Batch Process Prompts with Anthropic Claude API",
  "url": "https://n8n.io/workflows/3409-batch-process-prompts-with-anthropic-claude-api/",
  "category": "AI",
  "category_url": "https://n8n.io/workflows/categories/ai/?count=20",
  "author": "Greg Evseev",
  "publish_date": "Last update 21 days ago",
  "content": "",
  "workflow_json": "{\"meta\":{\"instanceId\":\"97d44c78f314fab340d7a5edaf7e2c274a7fbb8a7cd138f53cc742341e706fe7\"},\"nodes\":[{\"id\":\"fa4f8fd6-3272-4a93-8547-32d13873bbc1\",\"name\":\"Submit batch\",\"type\":\"n8n-nodes-base.httpRequest\",\"position\":[180,40],\"parameters\":{\"url\":\"https://api.anthropic.com/v1/messages/batches\",\"method\":\"POST\",\"options\":{},\"jsonBody\":\"={ \\\"requests\\\": {{ JSON.stringify($json.requests) }} }\",\"sendBody\":true,\"sendQuery\":true,\"sendHeaders\":true,\"specifyBody\":\"json\",\"authentication\":\"predefinedCredentialType\",\"queryParameters\":{\"parameters\":[{}]},\"headerParameters\":{\"parameters\":[{\"name\":\"anthropic-version\",\"value\":\"={{ $json[\\\"anthropic-version\\\"] }}\"}]},\"nodeCredentialType\":\"anthropicApi\"},\"credentials\":{\"anthropicApi\":{\"id\":\"ub0zN7IP2V83OeTf\",\"name\":\"Anthropic account\"}},\"typeVersion\":4.2},{\"id\":\"2916dc85-829d-491a-a7a8-de79d5356a53\",\"name\":\"Check batch status\",\"type\":\"n8n-nodes-base.httpRequest\",\"position\":[840,115],\"parameters\":{\"url\":\"=https://api.anthropic.com/v1/messages/batches/{{ $json.id }}\",\"options\":{},\"sendHeaders\":true,\"authentication\":\"predefinedCredentialType\",\"headerParameters\":{\"parameters\":[{\"name\":\"anthropic-version\",\"value\":\"={{ $('When Executed by Another Workflow').item.json[\\\"anthropic-version\\\"] }}\"}]},\"nodeCredentialType\":\"anthropicApi\"},\"credentials\":{\"anthropicApi\":{\"id\":\"ub0zN7IP2V83OeTf\",\"name\":\"Anthropic account\"}},\"typeVersion\":4.2},{\"id\":\"1552ec92-2f18-42f6-b67f-b6f131012b3c\",\"name\":\"When Executed by Another Workflow\",\"type\":\"n8n-nodes-base.executeWorkflowTrigger\",\"position\":[-40,40],\"parameters\":{\"workflowInputs\":{\"values\":[{\"name\":\"anthropic-version\"},{\"name\":\"requests\",\"type\":\"array\"}]}},\"typeVersion\":1.1},{\"id\":\"4bd40f02-caf1-419d-8261-a149cd51a534\",\"name\":\"Get results\",\"type\":\"n8n-nodes-base.httpRequest\",\"position\":[620,-160],\"parameters\":{\"url\":\"={{ $json.results_url }}\",\"options\":{},\"sendHeaders\":true,\"authentication\":\"predefinedCredentialType\",\"headerParameters\":{\"parameters\":[{\"name\":\"anthropic-version\",\"value\":\"={{ $('When Executed by Another Workflow').item.json[\\\"anthropic-version\\\"] }}\"}]},\"nodeCredentialType\":\"anthropicApi\"},\"credentials\":{\"anthropicApi\":{\"id\":\"ub0zN7IP2V83OeTf\",\"name\":\"Anthropic account\"}},\"typeVersion\":4.2},{\"id\":\"5df366af-a54d-4594-a1ab-7a9df968101e\",\"name\":\"Parse response\",\"type\":\"n8n-nodes-base.code\",\"notes\":\"JSONL separated by newlines\",\"position\":[840,-160],\"parameters\":{\"jsCode\":\"for (const item of $input.all()) {\\n  if (item.json && item.json.data) {\\n    // Split the string into individual JSON objects\\n    const jsonStrings = item.json.data.split('\\\\n');\\n\\n    // Parse each JSON string and store them in an array\\n    const parsedData = jsonStrings.filter(str => str.trim() !== '').map(str => JSON.parse(str));\\n\\n    // Replace the original json with the parsed array.\\n    item.json.parsed = parsedData;\\n  }\\n}\\n\\nreturn $input.all();\"},\"notesInFlow\":true,\"typeVersion\":2},{\"id\":\"68aa4ee2-e925-4e30-a7ab-317d8df4d9bc\",\"name\":\"If ended processing\",\"type\":\"n8n-nodes-base.if\",\"position\":[400,40],\"parameters\":{\"options\":{},\"conditions\":{\"options\":{\"version\":2,\"leftValue\":\"\",\"caseSensitive\":true,\"typeValidation\":\"strict\"},\"combinator\":\"and\",\"conditions\":[{\"id\":\"9494c5a3-d093-49c5-837f-99cd700a2f13\",\"operator\":{\"type\":\"string\",\"operation\":\"equals\"},\"leftValue\":\"={{ $json.processing_status }}\",\"rightValue\":\"ended\"}]}},\"typeVersion\":2.2},{\"id\":\"2b974e3b-495b-48af-8080-c7913d7a2ba8\",\"name\":\"Sticky Note\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[-200,-720],\"parameters\":{\"width\":1060,\"height\":520,\"content\":\"### This workflow automates sending batched prompts to Claude using the Anthropic API. It submits multiple prompts at once and retrieves the results.\\n\\n#### How to use\\n\\nCall this workflow with array of `requests`\\n\\n```json\\n{\\n    \\\"anthropic-version\\\": \\\"2023-06-01\\\",\\n    \\\"requests\\\": [\\n        {\\n            \\\"custom_id\\\": \\\"first-prompt-in-my-batch\\\",\\n            \\\"params\\\": {\\n                \\\"max_tokens\\\": 100,\\n                \\\"messages\\\": [\\n                    {\\n                        \\\"content\\\": \\\"Hey Claude, tell me a short fun fact about video games!\\\",\\n                        \\\"role\\\": \\\"user\\\"\\n                    }\\n                ],\\n                \\\"model\\\": \\\"claude-3-5-haiku-20241022\\\"\\n            }\\n        }\\n    ]\\n}\\n```\\n\"},\"typeVersion\":1},{\"id\":\"928a30b5-5d90-4648-a82e-e4f1a01e47a5\",\"name\":\"Sticky Note1\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[1200,-720],\"parameters\":{\"width\":980,\"height\":600,\"content\":\"#### Results\\n\\nThis workflow returns an array of results with custom_ids.\\n\\n```json\\n[\\n    {\\n        \\\"custom_id\\\": \\\"first-prompt-in-my-batch\\\",\\n        \\\"result\\\": {\\n            \\\"message\\\": {\\n                \\\"content\\\": [\\n                    {\\n                        \\\"text\\\": \\\"Did you know that the classic video game Tetris was...\\\",\\n                        \\\"type\\\": \\\"text\\\"\\n                    }\\n                ],\\n                \\\"id\\\": \\\"msg_01AiLiVZT18XnoBD4r2w9x2t\\\",\\n                \\\"model\\\": \\\"claude-3-5-haiku-20241022\\\",\\n                \\\"role\\\": \\\"assistant\\\",\\n                \\\"stop_reason\\\": \\\"end_turn\\\",\\n                \\\"stop_sequence\\\": null,\\n                \\\"type\\\": \\\"message\\\",\\n                \\\"usage\\\": {\\n                    \\\"cache_creation_input_tokens\\\": 0,\\n                    \\\"cache_read_input_tokens\\\": 0,\\n                    \\\"input_tokens\\\": 45,\\n                    \\\"output_tokens\\\": 83\\n                }\\n            },\\n            \\\"type\\\": \\\"succeeded\\\"\\n        }\\n    }\\n]\\n```\"},\"typeVersion\":1},{\"id\":\"5dcb554e-32df-4883-b5a1-b40305756201\",\"name\":\"Batch Status Poll Interval\",\"type\":\"n8n-nodes-base.wait\",\"position\":[620,40],\"webhookId\":\"7efafe72-063a-45c6-8775-fcec14e1d263\",\"parameters\":{\"amount\":10},\"typeVersion\":1.1},{\"id\":\"c25cfde5-ab83-4e5a-a66f-8cc9f23a01f6\",\"name\":\"Sticky Note2\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[-160,325],\"parameters\":{\"color\":4,\"width\":340,\"height\":620,\"content\":\"# Usage example\"},\"typeVersion\":1},{\"id\":\"6062ca7c-aa08-4805-9c96-65e5be8a38fd\",\"name\":\"Run example\",\"type\":\"n8n-nodes-base.manualTrigger\",\"position\":[-40,625],\"parameters\":{},\"typeVersion\":1},{\"id\":\"9878729a-123d-4460-a582-691ca8cedf98\",\"name\":\"One query example\",\"type\":\"n8n-nodes-base.set\",\"position\":[634,775],\"parameters\":{\"options\":{},\"assignments\":{\"assignments\":[{\"id\":\"1ea47ba2-64be-4d69-b3db-3447cde71645\",\"name\":\"query\",\"type\":\"string\",\"value\":\"Hey Claude, tell me a short fun fact about bees!\"}]}},\"typeVersion\":3.4},{\"id\":\"df06c209-8b6a-4b6d-8045-230ebdfcfbad\",\"name\":\"Delete original properties\",\"type\":\"n8n-nodes-base.set\",\"position\":[1528,775],\"parameters\":{\"options\":{},\"assignments\":{\"assignments\":[{\"id\":\"d238d62b-2e91-4242-b509-8cfc698d2252\",\"name\":\"custom_id\",\"type\":\"string\",\"value\":\"={{ $json.custom_id }}\"},{\"id\":\"21e07c09-92e3-41e7-8335-64653722e7e9\",\"name\":\"params\",\"type\":\"object\",\"value\":\"={{ $json.params }}\"}]}},\"typeVersion\":3.4},{\"id\":\"f66d6a89-ee33-4494-9476-46f408976b29\",\"name\":\"Construct 'requests' array\",\"type\":\"n8n-nodes-base.aggregate\",\"position\":[1968,625],\"parameters\":{\"options\":{},\"aggregate\":\"aggregateAllItemData\",\"destinationFieldName\":\"requests\"},\"typeVersion\":1},{\"id\":\"0f9eb605-d629-4cb7-b9cb-39702d201567\",\"name\":\"Set desired 'anthropic-version'\",\"type\":\"n8n-nodes-base.set\",\"notes\":\"2023-06-01\",\"position\":[2188,625],\"parameters\":{\"options\":{},\"assignments\":{\"assignments\":[{\"id\":\"9f9e94a0-304b-487a-8762-d74421ef4cc0\",\"name\":\"anthropic-version\",\"type\":\"string\",\"value\":\"2023-06-01\"}]},\"includeOtherFields\":true},\"notesInFlow\":true,\"typeVersion\":3.4},{\"id\":\"f71f261c-f4ad-4c9f-bd72-42ab386a65e1\",\"name\":\"Execute Workflow 'Process Multiple Prompts in Parallel with Anthropic Claude Batch API'\",\"type\":\"n8n-nodes-base.executeWorkflow\",\"notes\":\"See above\",\"position\":[2408,625],\"parameters\":{\"options\":{\"waitForSubWorkflow\":true},\"workflowId\":{\"__rl\":true,\"mode\":\"list\",\"value\":\"xQU4byMGhgFxnTIH\",\"cachedResultName\":\"Process Multiple Prompts in Parallel with Anthropic Claude Batch API\"},\"workflowInputs\":{\"value\":{\"requests\":\"={{ $json.requests }}\",\"anthropic-version\":\"={{ $json['anthropic-version'] }}\"},\"schema\":[{\"id\":\"anthropic-version\",\"type\":\"string\",\"display\":true,\"removed\":false,\"required\":false,\"displayName\":\"anthropic-version\",\"defaultMatch\":false,\"canBeUsedToMatch\":true},{\"id\":\"requests\",\"type\":\"array\",\"display\":true,\"removed\":false,\"required\":false,\"displayName\":\"requests\",\"defaultMatch\":false,\"canBeUsedToMatch\":true}],\"mappingMode\":\"defineBelow\",\"matchingColumns\":[\"requests\"],\"attemptToConvertTypes\":true,\"convertFieldsToString\":true}},\"notesInFlow\":true,\"typeVersion\":1.2},{\"id\":\"bd27c1a6-572c-420d-84ab-4d8b7d14311b\",\"name\":\"Build batch 'request' object for single query\",\"type\":\"n8n-nodes-base.code\",\"position\":[1308,775],\"parameters\":{\"jsCode\":\"// Loop over input items and modify them to match the response example, then return input.all()\\nfor (const item of $input.all()) {\\n  item.json.params = {\\n    max_tokens: item.json.max_tokens,\\n    messages: [\\n      {\\n        content: item.json.query,\\n        role: \\\"user\\\"\\n      }\\n    ],\\n    model: item.json.model\\n  };\\n}\\n\\nreturn $input.all();\\n\"},\"typeVersion\":2},{\"id\":\"fa342231-ea94-43ab-8808-18c8d04fdaf8\",\"name\":\"Simple Memory Store\",\"type\":\"@n8n/n8n-nodes-langchain.memoryBufferWindow\",\"position\":[644,595],\"parameters\":{\"sessionKey\":\"\\\"Process Multiple Prompts in Parallel with Anthropic Claude Batch API example\\\"\",\"sessionIdType\":\"customKey\"},\"typeVersion\":1.3},{\"id\":\"67047fe6-8658-45ba-be61-52cf6115f4e4\",\"name\":\"Fill Chat Memory with example data\",\"type\":\"@n8n/n8n-nodes-langchain.memoryManager\",\"position\":[556,375],\"parameters\":{\"mode\":\"insert\",\"messages\":{\"messageValues\":[{\"message\":\"You are a helpful AI assistant\"},{\"type\":\"user\",\"message\":\"Hey Claude, tell me a short fun fact about video games!\"},{\"type\":\"ai\",\"message\":\"short fun fact about video games!\"},{\"type\":\"user\",\"message\":\"No, an actual fun fact\"}]}},\"typeVersion\":1.1},{\"id\":\"dbb295b8-01fd-445f-ab66-948442b6c71d\",\"name\":\"Build batch 'request' object from Chat Memory and execution data\",\"type\":\"n8n-nodes-base.code\",\"position\":[1528,475],\"parameters\":{\"jsCode\":\"const output = [];\\n\\nfor (const item of $input.all()) {\\n  const inputMessages = item.json.messages;\\n  const customId = item.json.custom_id;\\n  const model = item.json.model;\\n  const maxTokens = item.json.max_tokens;\\n\\n  if (inputMessages && inputMessages.length > 0) {\\n    let systemMessageContent = undefined;\\n    const transformedMessages = [];\\n\\n    // Process each message entry in sequence\\n    for (const messageObj of inputMessages) {\\n      // Extract system message if present\\n      if ('system' in messageObj) {\\n        systemMessageContent = messageObj.system;\\n      }\\n      \\n      // Process human and AI messages in the order they appear in the object keys\\n      // We need to determine what order the keys appear in the original object\\n      const keys = Object.keys(messageObj);\\n      \\n      for (const key of keys) {\\n        if (key === 'human') {\\n          transformedMessages.push({\\n            role: \\\"user\\\",\\n            content: messageObj.human\\n          });\\n        } else if (key === 'ai') {\\n          transformedMessages.push({\\n            role: \\\"assistant\\\",\\n            content: messageObj.ai\\n          });\\n        }\\n        // Skip 'system' as we already processed it\\n      }\\n    }\\n\\n    const params = {\\n      model: model,\\n      max_tokens: maxTokens,\\n      messages: transformedMessages\\n    };\\n\\n    if (systemMessageContent !== undefined) {\\n      params.system = systemMessageContent;\\n    }\\n\\n    output.push({\\n      custom_id: customId,\\n      params: params\\n    });\\n  }\\n}\\n\\nreturn output;\"},\"typeVersion\":2},{\"id\":\"f9edb335-c33d-45fc-8f9b-12d7f37cc23e\",\"name\":\"Load Chat Memory Data\",\"type\":\"@n8n/n8n-nodes-langchain.memoryManager\",\"position\":[932,475],\"parameters\":{\"options\":{}},\"typeVersion\":1.1},{\"id\":\"22399660-ebe5-4838-bad3-c542d6d921a3\",\"name\":\"First Prompt Result\",\"type\":\"n8n-nodes-base.executionData\",\"position\":[2848,525],\"parameters\":{\"dataToSave\":{\"values\":[{\"key\":\"assistant_response\",\"value\":\"={{ $json.result.message.content[0].text }}\"}]}},\"typeVersion\":1},{\"id\":\"0e7f44f4-c931-4e0f-aebc-1b8f0327647f\",\"name\":\"Second Prompt Result\",\"type\":\"n8n-nodes-base.executionData\",\"position\":[2848,725],\"parameters\":{\"dataToSave\":{\"values\":[{\"key\":\"assistant_response\",\"value\":\"={{ $json.result.message.content[0].text }}\"}]}},\"typeVersion\":1},{\"id\":\"e42b01e0-8fc5-42e1-aa45-aa85477e766b\",\"name\":\"Split Out Parsed Results\",\"type\":\"n8n-nodes-base.splitOut\",\"position\":[1060,-160],\"parameters\":{\"options\":{},\"fieldToSplitOut\":\"parsed\"},\"typeVersion\":1},{\"id\":\"343676b9-f147-4981-b555-8af570374e8c\",\"name\":\"Filter Second Prompt Results\",\"type\":\"n8n-nodes-base.filter\",\"position\":[2628,725],\"parameters\":{\"options\":{},\"conditions\":{\"options\":{\"version\":2,\"leftValue\":\"\",\"caseSensitive\":true,\"typeValidation\":\"strict\"},\"combinator\":\"and\",\"conditions\":[{\"id\":\"9e4b3524-7066-46cc-a365-8d23d08c1bda\",\"operator\":{\"name\":\"filter.operator.equals\",\"type\":\"string\",\"operation\":\"equals\"},\"leftValue\":\"={{ $json.custom_id }}\",\"rightValue\":\"={{ $('Append execution data for single query example').item.json.custom_id }}\"}]}},\"typeVersion\":2.2},{\"id\":\"c9f5f366-27c4-4401-965b-67c314036fb6\",\"name\":\"Filter First Prompt Results\",\"type\":\"n8n-nodes-base.filter\",\"position\":[2628,525],\"parameters\":{\"options\":{},\"conditions\":{\"options\":{\"version\":2,\"leftValue\":\"\",\"caseSensitive\":true,\"typeValidation\":\"strict\"},\"combinator\":\"and\",\"conditions\":[{\"id\":\"9e4b3524-7066-46cc-a365-8d23d08c1bda\",\"operator\":{\"name\":\"filter.operator.equals\",\"type\":\"string\",\"operation\":\"equals\"},\"leftValue\":\"={{ $json.custom_id }}\",\"rightValue\":\"={{ $('Append execution data for chat memory example').item.json.custom_id }}\"}]}},\"typeVersion\":2.2},{\"id\":\"0a5b9c3d-665b-4e35-be9e-c8297314969d\",\"name\":\"Sticky Note3\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[110,-100],\"parameters\":{\"height\":300,\"content\":\"## Submit batch request to Anthropic\"},\"typeVersion\":1},{\"id\":\"f19813a5-f669-45dd-a446-947a30b02b09\",\"name\":\"Sticky Note4\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[350,-5],\"parameters\":{\"width\":640,\"height\":300,\"content\":\"## Loop until processing status is 'ended'\"},\"typeVersion\":1},{\"id\":\"9f424fce-5610-4b85-9be6-4c2c403002db\",\"name\":\"Sticky Note5\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[500,-200],\"parameters\":{\"width\":280,\"height\":180,\"content\":\"### Retrieve Message Batch Results\\n\\n[User guide](https://docs.anthropic.com/en/docs/build-with-claude/batch-processing)\"},\"typeVersion\":1},{\"id\":\"b87673b1-f08d-4c51-8ee5-4d54557cb382\",\"name\":\"Sticky Note6\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[900,380],\"parameters\":{\"color\":5,\"width\":820,\"height\":340,\"content\":\"# Example usage with Chat History Node\"},\"typeVersion\":1},{\"id\":\"d6d8ac02-7005-40a1-9950-9517e98e315c\",\"name\":\"Sticky Note7\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[180,720],\"parameters\":{\"width\":1540,\"height\":220,\"content\":\"# Example usage with single query string\"},\"typeVersion\":1},{\"id\":\"0d63deb0-dece-4502-9020-d67c1f194466\",\"name\":\"Sticky Note8\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[180,320],\"parameters\":{\"color\":3,\"width\":660,\"height\":400,\"content\":\"# Environment setup\\nFor Chat History Node\"},\"typeVersion\":1},{\"id\":\"cab94e09-6b84-4a38-b854-670241744db5\",\"name\":\"Sticky Note9\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[2120,800],\"parameters\":{\"height\":220,\"content\":\"## anthropic-version\\n\\n[Documentation](https://docs.anthropic.com/en/api/versioning)\\n\\nWhen making API requests, you must send an anthropic-version request header. For example, anthropic-version: `2023-06-01` (latest supported version)\"},\"typeVersion\":1},{\"id\":\"ab0a51a1-3c84-4a88-968b-fd46ab07de85\",\"name\":\"Sticky Note10\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[2560,400],\"parameters\":{\"color\":5,\"width\":480,\"height\":300,\"content\":\"# Example usage with Chat History Node (result)\"},\"typeVersion\":1},{\"id\":\"d91b9be7-ef32-48d6-b880-cab0e99ba9bc\",\"name\":\"Sticky Note11\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[2560,700],\"parameters\":{\"width\":480,\"height\":300,\"content\":\"\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n# Example usage with single query string (result)\"},\"typeVersion\":1},{\"id\":\"341811e9-6677-42d9-be28-c388dbf68101\",\"name\":\"Join two example requests into array\",\"type\":\"n8n-nodes-base.merge\",\"position\":[1748,625],\"parameters\":{},\"typeVersion\":3.1},{\"id\":\"45a09f05-7610-4b0a-ab7f-0094c4b3f318\",\"name\":\"Append execution data for single query example\",\"type\":\"n8n-nodes-base.set\",\"notes\":\"custom_id, model and max tokens\",\"position\":[1010,775],\"parameters\":{\"options\":{},\"assignments\":{\"assignments\":[{\"id\":\"8276602f-689f-45c2-bce0-5df8500912b6\",\"name\":\"custom_id\",\"type\":\"string\",\"value\":\"second-prompt-in-my-batch\"},{\"id\":\"2c513dc2-d8cb-4ba3-b3c1-ea79517b9434\",\"name\":\"model\",\"type\":\"string\",\"value\":\"claude-3-5-haiku-20241022\"},{\"id\":\"b052140b-1152-4327-9c5a-5030b78990b7\",\"name\":\"max_tokens\",\"type\":\"number\",\"value\":100}]},\"includeOtherFields\":true},\"notesInFlow\":true,\"typeVersion\":3.4},{\"id\":\"c4e35349-840c-4c81-852c-0d8cd9331364\",\"name\":\"Append execution data for chat memory example\",\"type\":\"n8n-nodes-base.set\",\"notes\":\"custom_id, model and max tokens\",\"position\":[1308,475],\"parameters\":{\"options\":{},\"assignments\":{\"assignments\":[{\"id\":\"8276602f-689f-45c2-bce0-5df8500912b6\",\"name\":\"custom_id\",\"type\":\"string\",\"value\":\"first-prompt-in-my-batch\"},{\"id\":\"2c513dc2-d8cb-4ba3-b3c1-ea79517b9434\",\"name\":\"model\",\"type\":\"string\",\"value\":\"claude-3-5-haiku-20241022\"},{\"id\":\"b052140b-1152-4327-9c5a-5030b78990b7\",\"name\":\"max_tokens\",\"type\":\"number\",\"value\":100}]},\"includeOtherFields\":true},\"notesInFlow\":true,\"typeVersion\":3.4},{\"id\":\"058aedb1-fdfe-4edc-8d51-3b93ec7d232d\",\"name\":\"Truncate Chat Memory\",\"type\":\"@n8n/n8n-nodes-langchain.memoryManager\",\"notes\":\"ensure clean state\",\"position\":[180,475],\"parameters\":{\"mode\":\"delete\",\"deleteMode\":\"all\"},\"notesInFlow\":true,\"typeVersion\":1.1}],\"pinData\":{},\"connections\":{\"Get results\":{\"main\":[[{\"node\":\"Parse response\",\"type\":\"main\",\"index\":0}]]},\"Run example\":{\"main\":[[{\"node\":\"One query example\",\"type\":\"main\",\"index\":0},{\"node\":\"Truncate Chat Memory\",\"type\":\"main\",\"index\":0}]]},\"Submit batch\":{\"main\":[[{\"node\":\"If ended processing\",\"type\":\"main\",\"index\":0}]]},\"Parse response\":{\"main\":[[{\"node\":\"Split Out Parsed Results\",\"type\":\"main\",\"index\":0}]]},\"One query example\":{\"main\":[[{\"node\":\"Append execution data for single query example\",\"type\":\"main\",\"index\":0}]]},\"Check batch status\":{\"main\":[[{\"node\":\"If ended processing\",\"type\":\"main\",\"index\":0}]]},\"If ended processing\":{\"main\":[[{\"node\":\"Get results\",\"type\":\"main\",\"index\":0}],[{\"node\":\"Batch Status Poll Interval\",\"type\":\"main\",\"index\":0}]]},\"Simple Memory Store\":{\"ai_memory\":[[{\"node\":\"Load Chat Memory Data\",\"type\":\"ai_memory\",\"index\":0},{\"node\":\"Fill Chat Memory with example data\",\"type\":\"ai_memory\",\"index\":0},{\"node\":\"Truncate Chat Memory\",\"type\":\"ai_memory\",\"index\":0}]]},\"Truncate Chat Memory\":{\"main\":[[{\"node\":\"Fill Chat Memory with example data\",\"type\":\"main\",\"index\":0}]]},\"Load Chat Memory Data\":{\"main\":[[{\"node\":\"Append execution data for chat memory example\",\"type\":\"main\",\"index\":0}]]},\"Batch Status Poll Interval\":{\"main\":[[{\"node\":\"Check batch status\",\"type\":\"main\",\"index\":0}]]},\"Construct 'requests' array\":{\"main\":[[{\"node\":\"Set desired 'anthropic-version'\",\"type\":\"main\",\"index\":0}]]},\"Delete original properties\":{\"main\":[[{\"node\":\"Join two example requests into array\",\"type\":\"main\",\"index\":1}]]},\"Filter First Prompt Results\":{\"main\":[[{\"node\":\"First Prompt Result\",\"type\":\"main\",\"index\":0}]]},\"Filter Second Prompt Results\":{\"main\":[[{\"node\":\"Second Prompt Result\",\"type\":\"main\",\"index\":0}]]},\"Set desired 'anthropic-version'\":{\"main\":[[{\"node\":\"Execute Workflow 'Process Multiple Prompts in Parallel with Anthropic Claude Batch API'\",\"type\":\"main\",\"index\":0}]]},\"When Executed by Another Workflow\":{\"main\":[[{\"node\":\"Submit batch\",\"type\":\"main\",\"index\":0}]]},\"Fill Chat Memory with example data\":{\"main\":[[{\"node\":\"Load Chat Memory Data\",\"type\":\"main\",\"index\":0}]]},\"Join two example requests into array\":{\"main\":[[{\"node\":\"Construct 'requests' array\",\"type\":\"main\",\"index\":0}]]},\"Append execution data for chat memory example\":{\"main\":[[{\"node\":\"Build batch 'request' object from Chat Memory and execution data\",\"type\":\"main\",\"index\":0}]]},\"Build batch 'request' object for single query\":{\"main\":[[{\"node\":\"Delete original properties\",\"type\":\"main\",\"index\":0}]]},\"Append execution data for single query example\":{\"main\":[[{\"node\":\"Build batch 'request' object for single query\",\"type\":\"main\",\"index\":0}]]},\"Build batch 'request' object from Chat Memory and execution data\":{\"main\":[[{\"node\":\"Join two example requests into array\",\"type\":\"main\",\"index\":0}]]},\"Execute Workflow 'Process Multiple Prompts in Parallel with Anthropic Claude Batch API'\":{\"main\":[[{\"node\":\"Filter First Prompt Results\",\"type\":\"main\",\"index\":0},{\"node\":\"Filter Second Prompt Results\",\"type\":\"main\",\"index\":0}]]}}}",
  "readme": "This workflow template provides a robust solution for efficiently sending multiple prompts to Anthropic's Claude models in a single batch request and retrieving the results. It leverages the Anthropic Batch API endpoint (`/v1/messages/batches`) for optimized processing and outputs each result as a separate item.\n\n**Core Functionality & Example Usage Included**\n\nThis template includes:\n\n  1. **The Core Batch Processing Workflow:** Designed to be called by another n8n workflow.\n  2. **An Example Usage Workflow:** A separate branch demonstrating how to prepare data and trigger the core workflow, including examples using simple strings and n8n's [Langchain Chat Memory nodes](https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.memorybufferwindow/).\n\n\n\n## Who is this for?\n\nThis template is designed for:\n\n  * **Developers, data scientists, and researchers** who need to process large volumes of text prompts using Claude models via n8n.\n  * **Content creators** looking to generate multiple pieces of content (e.g., summaries, Q&As, creative text) based on different inputs simultaneously.\n  * **n8n users** who want to automate interactions with the Anthropic API beyond single requests, improve efficiency, and integrate batch processing into larger automation sequences.\n  * Anyone needing to perform **bulk text generation or analysis** tasks with Claude programmatically.\n\n\n\n## What problem does this workflow solve?\n\nSending prompts to language models one by one can be slow and inefficient, especially when dealing with hundreds or thousands of requests. This workflow addresses that by:\n\n  * **Batching:** Grouping multiple prompts into a single API call to Anthropic's dedicated batch endpoint (`/v1/messages/batches`).\n  * **Efficiency:** Significantly reducing the time required compared to sequential processing.\n  * **Scalability:** Handling large numbers of prompts (up to API limits) systematically.\n  * **Automation:** Providing a ready-to-use, callable n8n structure for batch interactions with Claude.\n  * **Structured Output:** Parsing the results and outputting each individual prompt's result as a separate n8n item.\n\n\n\n**Use Cases:**\n\n  * Bulk content generation (e.g., product descriptions, summaries).\n  * Large-scale question answering based on different contexts.\n  * Sentiment analysis or data extraction across multiple text snippets.\n  * Running the same prompt against many different inputs for research or testing.\n\n\n\n## What the Core Workflow does\n\n_(Triggered by the 'When Executed by Another Workflow' node)_\n\n  1. **Receive Input:** The workflow starts when called by another workflow (e.g., using the 'Execute Workflow' node). It expects input data containing: \n     * `anthropic-version` (string, e.g., \"2023-06-01\")\n     * `requests` (JSON array, where each object represents a single prompt request conforming to the Anthropic Batch API schema).\n  2. **Submit Batch Job:** Sends the formatted `requests` data via `POST` to the Anthropic API `/v1/messages/batches` endpoint to create a new batch job. Requires Anthropic credentials.\n  3. **Wait & Poll:** Enters a loop: \n     * Checks if the `processing_status` of the batch job is `ended`.\n     * If not `ended`, it waits for a set interval (**10 seconds** by default in the 'Batch Status Poll Interval' node).\n     * It then checks the batch job status again via `GET` to `/v1/messages/batches/{batch_id}`. Requires Anthropic credentials.\n     * This loop continues until the status is `ended`.\n  4. **Retrieve Results:** Once the batch job is complete, it fetches the results file by making a `GET` request to the `results_url` provided in the batch status response. Requires Anthropic credentials.\n  5. **Parse Results:** The results are typically returned in JSON Lines (`.jsonl`) format. The 'Parse response' Code node splits the response text by newlines and parses each line into a separate JSON object, storing them in an array field (e.g., `parsed`).\n  6. **Split Output:** The 'Split Out Parsed Results' node takes the array of parsed results and outputs each result object as an individual item from the workflow.\n\n\n\n## Prerequisites\n\n  * An active **n8n instance** (Cloud or self-hosted).\n  * An **Anthropic API account** with access granted to Claude models and the Batch API.\n  * Your **Anthropic API Key**.\n  * Basic understanding of n8n concepts (nodes, workflows, credentials, expressions, 'Execute Workflow' node).\n  * Familiarity with JSON data structures for providing input prompts and understanding the output.\n  * Understanding of the Anthropic Batch API request/response structure.\n  * _(For Example Usage Branch)_ Familiarity with n8n's Langchain nodes (`@n8n/n8n-nodes-langchain`) if you plan to adapt that part.\n\n\n\n## Setup\n\n  1. **Import Template:** Add this template to your n8n instance.\n  2. **Configure Credentials:**\n     * Navigate to the 'Credentials' section in your n8n instance.\n     * Click 'Add Credential'.\n     * Search for 'Anthropic' and select the Anthropic API credential type.\n     * Enter your Anthropic API Key and save the credential (e.g., name it \"Anthropic account\").\n  3. **Assign Credentials:** Open the workflow and locate the **three HTTP Request nodes** in the core workflow: \n     * `Submit batch`\n     * `Check batch status`\n     * `Get results`  \nIn each of these nodes, select the Anthropic credential you just configured from the 'Credential for Anthropic API' dropdown.\n  4. **Review Input Format:** Understand the required input structure for the `When Executed by Another Workflow` trigger node. The primary inputs are `anthropic-version` (string) and `requests` (array). Refer to the **Sticky Notes** in the template and the [Anthropic Batch API documentation](https://docs.anthropic.com/en/api/batch) for the exact schema required within the `requests` array.\n  5. **Activate Workflow:** Save and activate the core workflow so it can be called by other workflows.\n\n\n\n**➡️ Quick Start & Input/Output Examples:** Look for the **Sticky Notes** within the workflow canvas! They provide crucial information, including examples of the required input JSON structure and the expected output format.\n\n## How to customize this workflow\n\n  * **Input Source:** The core workflow is designed to be called. You will build _another_ workflow that prepares the `anthropic-version` and `requests` array and then uses the 'Execute Workflow' node to trigger this template. The included example branch shows how to prepare this data.\n  * **Model Selection & Parameters:** Model (`claude-3-opus-20240229`, etc.), `max_tokens`, `temperature`, and other parameters are defined _within each object_ inside the `requests` array you pass to the workflow trigger. You configure these in the workflow _calling_ this template.\n  * **Polling Interval:** Modify the 'Wait' node ('Batch Status Poll Interval') duration if you need faster or slower status checks (default is 10 seconds). Be mindful of potential rate limits.\n  * **Parsing Logic:** If Anthropic changes the result format or you have specific needs, modify the Javascript code within the 'Parse response' Code node.\n  * **Error Handling:** Enhance the workflow with more specific error handling for API failures (e.g., using 'Error Trigger' or checking HTTP status codes) or batch processing issues (`batch.status === 'failed'`).\n  * **Output Processing:** In the workflow that _calls_ this template, add nodes after the 'Execute Workflow' node to process the individual result items returned (e.g., save to a database, spreadsheet, send notifications).\n\n\n\n## Example Usage Branch (Manual Trigger)\n\nThis template also contains a separate branch starting with the `Run example` Manual Trigger node.\n\n  * **Purpose:** This branch demonstrates how to construct the necessary `anthropic-version` and `requests` array payload.\n  * **Methods Shown:** It includes steps for: \n    * Creating a request object from a simple query string.\n    * Creating a request object using data from n8n's Langchain Chat Memory nodes (`@n8n/n8n-nodes-langchain`).\n  * **Execution:** It merges these examples, constructs the final payload, and then uses the `Execute Workflow` node to call the main batch processing logic described above. It finishes by filtering the results for demonstration.\n  * **Note:** This branch is for demonstration and testing. You would typically build your own data preparation logic in a separate workflow. The use of Langchain nodes is optional for the core batch functionality.\n\n\n\n## Notes\n\n  * **API Limits:** According to the [Anthropic API documentation](https://docs.anthropic.com/en/api/creating-message-batches), batches can contain up to 100,000 requests and be up to 256 MB in total size. Ensure your n8n instance has sufficient resources for large batches.\n  * **API Costs:** Using the Anthropic API, including the Batch API, incurs costs based on token usage. Monitor your usage via the Anthropic dashboard.\n  * **Completion Time:** Batch processing time depends on the number and complexity of prompts and current API load. The polling mechanism accounts for this variability.\n  * **Versioning:** Always include the `anthropic-version` header in your requests, as shown in the workflow and examples. Refer to [Anthropic API versioning documentation](https://docs.anthropic.com/en/api/versioning).\n\n\n",
  "readme_html": "<!--[--><div data-v-006f9244=\"\"><p>This workflow template provides a robust solution for efficiently sending multiple prompts to Anthropic's Claude models in a single batch request and retrieving the results. It leverages the Anthropic Batch API endpoint (<code>/v1/messages/batches</code>) for optimized processing and outputs each result as a separate item.</p>\n<p><strong>Core Functionality &amp; Example Usage Included</strong></p>\n<p>This template includes:</p>\n<ol>\n<li><strong>The Core Batch Processing Workflow:</strong> Designed to be called by another n8n workflow.</li>\n<li><strong>An Example Usage Workflow:</strong> A separate branch demonstrating how to prepare data and trigger the core workflow, including examples using simple strings and n8n's <a href=\"https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.memorybufferwindow/\" rel=\"ugc nofollow\" target=\"_blank\">Langchain Chat Memory nodes</a>.</li>\n</ol>\n<h2>Who is this for?</h2>\n<p>This template is designed for:</p>\n<ul>\n<li><strong>Developers, data scientists, and researchers</strong> who need to process large volumes of text prompts using Claude models via n8n.</li>\n<li><strong>Content creators</strong> looking to generate multiple pieces of content (e.g., summaries, Q&amp;As, creative text) based on different inputs simultaneously.</li>\n<li><strong>n8n users</strong> who want to automate interactions with the Anthropic API beyond single requests, improve efficiency, and integrate batch processing into larger automation sequences.</li>\n<li>Anyone needing to perform <strong>bulk text generation or analysis</strong> tasks with Claude programmatically.</li>\n</ul>\n<h2>What problem does this workflow solve?</h2>\n<p>Sending prompts to language models one by one can be slow and inefficient, especially when dealing with hundreds or thousands of requests. This workflow addresses that by:</p>\n<ul>\n<li><strong>Batching:</strong> Grouping multiple prompts into a single API call to Anthropic's dedicated batch endpoint (<code>/v1/messages/batches</code>).</li>\n<li><strong>Efficiency:</strong> Significantly reducing the time required compared to sequential processing.</li>\n<li><strong>Scalability:</strong> Handling large numbers of prompts (up to API limits) systematically.</li>\n<li><strong>Automation:</strong> Providing a ready-to-use, callable n8n structure for batch interactions with Claude.</li>\n<li><strong>Structured Output:</strong> Parsing the results and outputting each individual prompt's result as a separate n8n item.</li>\n</ul>\n<p><strong>Use Cases:</strong></p>\n<ul>\n<li>Bulk content generation (e.g., product descriptions, summaries).</li>\n<li>Large-scale question answering based on different contexts.</li>\n<li>Sentiment analysis or data extraction across multiple text snippets.</li>\n<li>Running the same prompt against many different inputs for research or testing.</li>\n</ul>\n<h2>What the Core Workflow does</h2>\n<p><em>(Triggered by the 'When Executed by Another Workflow' node)</em></p>\n<ol>\n<li><strong>Receive Input:</strong> The workflow starts when called by another workflow (e.g., using the 'Execute Workflow' node). It expects input data containing:\n<ul>\n<li><code>anthropic-version</code> (string, e.g., \"2023-06-01\")</li>\n<li><code>requests</code> (JSON array, where each object represents a single prompt request conforming to the Anthropic Batch API schema).</li>\n</ul>\n</li>\n<li><strong>Submit Batch Job:</strong> Sends the formatted <code>requests</code> data via <code>POST</code> to the Anthropic API <code>/v1/messages/batches</code> endpoint to create a new batch job. Requires Anthropic credentials.</li>\n<li><strong>Wait &amp; Poll:</strong> Enters a loop:\n<ul>\n<li>Checks if the <code>processing_status</code> of the batch job is <code>ended</code>.</li>\n<li>If not <code>ended</code>, it waits for a set interval (<strong>10 seconds</strong> by default in the 'Batch Status Poll Interval' node).</li>\n<li>It then checks the batch job status again via <code>GET</code> to <code>/v1/messages/batches/{batch_id}</code>. Requires Anthropic credentials.</li>\n<li>This loop continues until the status is <code>ended</code>.</li>\n</ul>\n</li>\n<li><strong>Retrieve Results:</strong> Once the batch job is complete, it fetches the results file by making a <code>GET</code> request to the <code>results_url</code> provided in the batch status response. Requires Anthropic credentials.</li>\n<li><strong>Parse Results:</strong> The results are typically returned in JSON Lines (<code>.jsonl</code>) format. The 'Parse response' Code node splits the response text by newlines and parses each line into a separate JSON object, storing them in an array field (e.g., <code>parsed</code>).</li>\n<li><strong>Split Output:</strong> The 'Split Out Parsed Results' node takes the array of parsed results and outputs each result object as an individual item from the workflow.</li>\n</ol>\n<h2>Prerequisites</h2>\n<ul>\n<li>An active <strong>n8n instance</strong> (Cloud or self-hosted).</li>\n<li>An <strong>Anthropic API account</strong> with access granted to Claude models and the Batch API.</li>\n<li>Your <strong>Anthropic API Key</strong>.</li>\n<li>Basic understanding of n8n concepts (nodes, workflows, credentials, expressions, 'Execute Workflow' node).</li>\n<li>Familiarity with JSON data structures for providing input prompts and understanding the output.</li>\n<li>Understanding of the Anthropic Batch API request/response structure.</li>\n<li><em>(For Example Usage Branch)</em> Familiarity with n8n's Langchain nodes (<code>@n8n/n8n-nodes-langchain</code>) if you plan to adapt that part.</li>\n</ul>\n<h2>Setup</h2>\n<ol>\n<li><strong>Import Template:</strong> Add this template to your n8n instance.</li>\n<li><strong>Configure Credentials:</strong>\n<ul>\n<li>Navigate to the 'Credentials' section in your n8n instance.</li>\n<li>Click 'Add Credential'.</li>\n<li>Search for 'Anthropic' and select the Anthropic API credential type.</li>\n<li>Enter your Anthropic API Key and save the credential (e.g., name it \"Anthropic account\").</li>\n</ul>\n</li>\n<li><strong>Assign Credentials:</strong> Open the workflow and locate the <strong>three HTTP Request nodes</strong> in the core workflow:\n<ul>\n<li><code>Submit batch</code></li>\n<li><code>Check batch status</code></li>\n<li><code>Get results</code><br>\nIn each of these nodes, select the Anthropic credential you just configured from the 'Credential for Anthropic API' dropdown.</li>\n</ul>\n</li>\n<li><strong>Review Input Format:</strong> Understand the required input structure for the <code>When Executed by Another Workflow</code> trigger node. The primary inputs are <code>anthropic-version</code> (string) and <code>requests</code> (array). Refer to the <strong>Sticky Notes</strong> in the template and the <a href=\"https://docs.anthropic.com/en/api/batch\" rel=\"ugc nofollow\" target=\"_blank\">Anthropic Batch API documentation</a> for the exact schema required within the <code>requests</code> array.</li>\n<li><strong>Activate Workflow:</strong> Save and activate the core workflow so it can be called by other workflows.</li>\n</ol>\n<p><strong>➡️ Quick Start &amp; Input/Output Examples:</strong> Look for the <strong>Sticky Notes</strong> within the workflow canvas! They provide crucial information, including examples of the required input JSON structure and the expected output format.</p>\n<h2>How to customize this workflow</h2>\n<ul>\n<li><strong>Input Source:</strong> The core workflow is designed to be called. You will build <em>another</em> workflow that prepares the <code>anthropic-version</code> and <code>requests</code> array and then uses the 'Execute Workflow' node to trigger this template. The included example branch shows how to prepare this data.</li>\n<li><strong>Model Selection &amp; Parameters:</strong> Model (<code>claude-3-opus-20240229</code>, etc.), <code>max_tokens</code>, <code>temperature</code>, and other parameters are defined <em>within each object</em> inside the <code>requests</code> array you pass to the workflow trigger. You configure these in the workflow <em>calling</em> this template.</li>\n<li><strong>Polling Interval:</strong> Modify the 'Wait' node ('Batch Status Poll Interval') duration if you need faster or slower status checks (default is 10 seconds). Be mindful of potential rate limits.</li>\n<li><strong>Parsing Logic:</strong> If Anthropic changes the result format or you have specific needs, modify the Javascript code within the 'Parse response' Code node.</li>\n<li><strong>Error Handling:</strong> Enhance the workflow with more specific error handling for API failures (e.g., using 'Error Trigger' or checking HTTP status codes) or batch processing issues (<code>batch.status === 'failed'</code>).</li>\n<li><strong>Output Processing:</strong> In the workflow that <em>calls</em> this template, add nodes after the 'Execute Workflow' node to process the individual result items returned (e.g., save to a database, spreadsheet, send notifications).</li>\n</ul>\n<h2>Example Usage Branch (Manual Trigger)</h2>\n<p>This template also contains a separate branch starting with the <code>Run example</code> Manual Trigger node.</p>\n<ul>\n<li><strong>Purpose:</strong> This branch demonstrates how to construct the necessary <code>anthropic-version</code> and <code>requests</code> array payload.</li>\n<li><strong>Methods Shown:</strong> It includes steps for:\n<ul>\n<li>Creating a request object from a simple query string.</li>\n<li>Creating a request object using data from n8n's Langchain Chat Memory nodes (<code>@n8n/n8n-nodes-langchain</code>).</li>\n</ul>\n</li>\n<li><strong>Execution:</strong> It merges these examples, constructs the final payload, and then uses the <code>Execute Workflow</code> node to call the main batch processing logic described above. It finishes by filtering the results for demonstration.</li>\n<li><strong>Note:</strong> This branch is for demonstration and testing. You would typically build your own data preparation logic in a separate workflow. The use of Langchain nodes is optional for the core batch functionality.</li>\n</ul>\n<h2>Notes</h2>\n<ul>\n<li><strong>API Limits:</strong> According to the <a href=\"https://docs.anthropic.com/en/api/creating-message-batches\" rel=\"ugc nofollow\" target=\"_blank\">Anthropic API documentation</a>, batches can contain up to 100,000 requests and be up to 256 MB in total size. Ensure your n8n instance has sufficient resources for large batches.</li>\n<li><strong>API Costs:</strong> Using the Anthropic API, including the Batch API, incurs costs based on token usage. Monitor your usage via the Anthropic dashboard.</li>\n<li><strong>Completion Time:</strong> Batch processing time depends on the number and complexity of prompts and current API load. The polling mechanism accounts for this variability.</li>\n<li><strong>Versioning:</strong> Always include the <code>anthropic-version</code> header in your requests, as shown in the workflow and examples. Refer to <a href=\"https://docs.anthropic.com/en/api/versioning\" rel=\"ugc nofollow\" target=\"_blank\">Anthropic API versioning documentation</a>.</li>\n</ul>\n</div><!--]-->",
  "readme_zh": "该工作流模板提供了一个高效解决方案，能够通过单次批量请求向Anthropic的Claude模型发送多个提示词并获取结果。其利用Anthropic批量API端点（`/v1/messages/batches`）进行优化处理，并将每个结果作为独立项输出。\n\n**核心功能与使用示例**\n\n本模板包含：\n1. **核心批量处理工作流**：设计为被其他n8n工作流调用\n2. **示例使用工作流**：独立分支展示如何准备数据并触发核心工作流，包含简单字符串和使用n8n [Langchain聊天记忆节点](https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.memorybufferwindow/)的示例\n\n## 适用对象\n\n本模板适用于：\n* **开发者、数据科学家和研究人员**：需要通过n8n使用Claude模型处理大量文本提示\n* **内容创作者**：需基于不同输入同时生成多份内容（如摘要、问答、创意文本）\n* **n8n用户**：希望在单一请求之外自动化Anthropic API交互，提升效率并将批量处理集成到更大自动化流程中\n* 任何需要**程序化执行Claude批量文本生成或分析**任务的用户\n\n## 解决的问题\n\n逐条发送提示词到语言模型效率低下，本工作流通过以下方式解决：\n* **批量处理**：通过专用端点（`/v1/messages/batches`）将多个提示词合并为单次API调用\n* **高效性**：较顺序处理显著减少时间消耗\n* **可扩展性**：系统化处理大量提示词（在API限制范围内）\n* **自动化**：提供可直接调用的n8n批量交互结构\n* **结构化输出**：解析结果并将每个提示词结果作为独立项输出\n\n**应用场景**：\n* 批量内容生成（如产品描述、摘要）\n* 基于不同上下文的大规模问答\n* 多文本片段的情感分析或数据提取\n* 针对多输入执行相同提示词的研究或测试\n\n## 核心工作流机制\n\n（通过\"被其他工作流执行时\"节点触发）\n1. **接收输入**：被调用时接收包含以下内容的数据：\n   - `anthropic-version`（字符串，如\"2023-06-01\"）\n   - `requests`（JSON数组，每个对象需符合Anthropic批量API格式）\n2. **提交批量任务**：通过POST请求将格式化数据发送至`/v1/messages/batches`端点（需Anthropic凭证）\n3. **等待轮询**：循环检查任务状态：\n   - 默认每10秒通过GET请求检查`/v1/messages/batches/{batch_id}`状态\n   - 持续至状态变为`ended`\n4. **获取结果**：完成后从`results_url`下载结果文件\n5. **解析结果**：将JSON Lines格式响应拆分为独立JSON对象数组\n6. **拆分输出**：将解析结果数组拆分为独立输出项\n\n## 前提条件\n\n* 运行中的**n8n实例**（云版或自托管）\n* 已开通Claude模型和批量API访问权限的**Anthropic账户**\n* **Anthropic API密钥**\n* 基础n8n概念理解（节点、工作流、凭证、表达式、\"执行工作流\"节点）\n* 熟悉JSON数据结构\n* 了解Anthropic批量API请求/响应结构\n* （示例分支）熟悉n8n的Langchain节点（如计划适配该部分）\n\n## 设置流程\n\n1. **导入模板**至n8n实例\n2. **配置凭证**：\n   - 在凭证页面添加Anthropic API凭证\n   - 输入API密钥并保存（如命名为\"Anthropic账户\"）\n3. **分配凭证**：为核心工作流中三个HTTP请求节点选择配置的凭证\n4. **检查输入格式**：理解触发节点所需的`anthropic-version`和`requests`数组结构（参考模板内便签和[官方文档](https://docs.anthropic.com/en/api/batch)）\n5. **激活工作流**：保存并激活核心工作流\n\n**快速入门**：工作流画布内的**便签**提供了关键输入输出示例\n\n## 自定义指南\n\n* **输入源**：需另建工作流准备输入数据并通过\"执行工作流\"节点调用本模板\n* **模型参数**：模型选择（如`claude-3-opus-20240229`）、`max_tokens`等参数应在调用工作流中定义\n* **轮询间隔**：可修改\"等待\"节点默认的10秒间隔（注意速率限制）\n* **解析逻辑**：可通过修改\"解析响应\"代码节点适应格式变化\n* **错误处理**：可增强API失败或批量处理错误（`batch.status === 'failed'`）的专门处理\n* **输出处理**：在调用工作流中添加节点处理返回的独立结果项\n\n## 示例分支（手动触发）\n\n包含从`Run example`手动触发节点开始的独立分支：\n* **功能**：演示如何构建`anthropic-version`和`requests`数组\n* **展示方法**：\n  - 从简单查询字符串创建请求对象\n  - 使用Langchain聊天记忆节点数据创建请求对象\n* **执行**：合并示例构建最终载荷，调用主批量逻辑后过滤结果演示\n* **注意**：该分支仅用于测试，实际使用时应另建数据准备逻辑\n\n## 注意事项\n\n* **API限制**：单批次最多10万请求/256MB（确保n8n实例有足够资源）\n* **计费**：API使用按token计费，需通过Anthropic仪表板监控\n* **完成时间**：取决于提示词数量和复杂度，轮询机制已考虑可变性\n* **版本控制**：必须包含`anthropic-version`头（参考[版本文档](https://docs.anthropic.com/en/api/versioning)）",
  "title_zh": "批量处理提示与Anthropic Claude API",
  "publish_date_absolute": "2025-04-16",
  "publish_date_zh": "Last update 21 days ago",
  "workflow_json_zh": "{\n  \"meta\": {\n    \"instanceId\": \"97d44c78f314fab340d7a5edaf7e2c274a7fbb8a7cd138f53cc742341e706fe7\"\n  },\n  \"nodes\": [\n    {\n      \"id\": \"fa4f8fd6-3272-4a93-8547-32d13873bbc1\",\n      \"name\": \"Submit batch\",\n      \"type\": \"n8n-nodes-base.httpRequest\",\n      \"position\": [\n        180,\n        40\n      ],\n      \"parameters\": {\n        \"url\": \"https://api.anthropic.com/v1/messages/batches\",\n        \"method\": \"POST\",\n        \"options\": {},\n        \"jsonBody\": \"={ \\\"requests\\\": {{ JSON.stringify($json.requests) }} }\",\n        \"sendBody\": true,\n        \"sendQuery\": true,\n        \"sendHeaders\": true,\n        \"specifyBody\": \"json\",\n        \"authentication\": \"predefinedCredentialType\",\n        \"queryParameters\": {\n          \"parameters\": [\n            {}\n          ]\n        },\n        \"headerParameters\": {\n          \"parameters\": [\n            {\n              \"name\": \"anthropic-version\",\n              \"value\": \"={{ $json[\\\"anthropic-version\\\"] }}\"\n            }\n          ]\n        },\n        \"nodeCredentialType\": \"anthropicApi\"\n      },\n      \"credentials\": {\n        \"anthropicApi\": {\n          \"id\": \"ub0zN7IP2V83OeTf\",\n          \"name\": \"Anthropic account\"\n        }\n      },\n      \"typeVersion\": 4.2\n    },\n    {\n      \"id\": \"2916dc85-829d-491a-a7a8-de79d5356a53\",\n      \"name\": \"Check batch status\",\n      \"type\": \"n8n-nodes-base.httpRequest\",\n      \"position\": [\n        840,\n        115\n      ],\n      \"parameters\": {\n        \"url\": \"=https://api.anthropic.com/v1/messages/batches/{{ $json.id }}\",\n        \"options\": {},\n        \"sendHeaders\": true,\n        \"authentication\": \"predefinedCredentialType\",\n        \"headerParameters\": {\n          \"parameters\": [\n            {\n              \"name\": \"anthropic-version\",\n              \"value\": \"={{ $('When Executed by Another Workflow').item.json[\\\"anthropic-version\\\"] }}\"\n            }\n          ]\n        },\n        \"nodeCredentialType\": \"anthropicApi\"\n      },\n      \"credentials\": {\n        \"anthropicApi\": {\n          \"id\": \"ub0zN7IP2V83OeTf\",\n          \"name\": \"Anthropic account\"\n        }\n      },\n      \"typeVersion\": 4.2\n    },\n    {\n      \"id\": \"1552ec92-2f18-42f6-b67f-b6f131012b3c\",\n      \"name\": \"When Executed by Another Workflow\",\n      \"type\": \"n8n-nodes-base.executeWorkflowTrigger\",\n      \"position\": [\n        -40,\n        40\n      ],\n      \"parameters\": {\n        \"workflowInputs\": {\n          \"values\": [\n            {\n              \"name\": \"anthropic-version\"\n            },\n            {\n              \"name\": \"requests\",\n              \"type\": \"array\"\n            }\n          ]\n        }\n      },\n      \"typeVersion\": 1.1\n    },\n    {\n      \"id\": \"4bd40f02-caf1-419d-8261-a149cd51a534\",\n      \"name\": \"Get results\",\n      \"type\": \"n8n-nodes-base.httpRequest\",\n      \"position\": [\n        620,\n        -160\n      ],\n      \"parameters\": {\n        \"url\": \"={{ $json.results_url }}\",\n        \"options\": {},\n        \"sendHeaders\": true,\n        \"authentication\": \"predefinedCredentialType\",\n        \"headerParameters\": {\n          \"parameters\": [\n            {\n              \"name\": \"anthropic-version\",\n              \"value\": \"={{ $('When Executed by Another Workflow').item.json[\\\"anthropic-version\\\"] }}\"\n            }\n          ]\n        },\n        \"nodeCredentialType\": \"anthropicApi\"\n      },\n      \"credentials\": {\n        \"anthropicApi\": {\n          \"id\": \"ub0zN7IP2V83OeTf\",\n          \"name\": \"Anthropic account\"\n        }\n      },\n      \"typeVersion\": 4.2\n    },\n    {\n      \"id\": \"5df366af-a54d-4594-a1ab-7a9df968101e\",\n      \"name\": \"Parse response\",\n      \"type\": \"n8n-nodes-base.code\",\n      \"notes\": \"JSONL separated by newlines\",\n      \"position\": [\n        840,\n        -160\n      ],\n      \"parameters\": {\n        \"jsCode\": \"for (const item of $input.all()) {\\n  if (item.json && item.json.data) {\\n    // Split the string into individual JSON objects\\n    const jsonStrings = item.json.data.split('\\\\n');\\n\\n    // Parse each JSON string and store them in an array\\n    const parsedData = jsonStrings.filter(str => str.trim() !== '').map(str => JSON.parse(str));\\n\\n    // Replace the original json with the parsed array.\\n    item.json.parsed = parsedData;\\n  }\\n}\\n\\nreturn $input.all();\"\n      },\n      \"notesInFlow\": true,\n      \"typeVersion\": 2\n    },\n    {\n      \"id\": \"68aa4ee2-e925-4e30-a7ab-317d8df4d9bc\",\n      \"name\": \"If ended processing\",\n      \"type\": \"n8n-nodes-base.if\",\n      \"position\": [\n        400,\n        40\n      ],\n      \"parameters\": {\n        \"options\": {},\n        \"conditions\": {\n          \"options\": {\n            \"version\": 2,\n            \"leftValue\": \"\",\n            \"caseSensitive\": true,\n            \"typeValidation\": \"strict\"\n          },\n          \"combinator\": \"and\",\n          \"conditions\": [\n            {\n              \"id\": \"9494c5a3-d093-49c5-837f-99cd700a2f13\",\n              \"operator\": {\n                \"type\": \"string\",\n                \"operation\": \"equals\"\n              },\n              \"leftValue\": \"={{ $json.processing_status }}\",\n              \"rightValue\": \"ended\"\n            }\n          ]\n        }\n      },\n      \"typeVersion\": 2.2\n    },\n    {\n      \"id\": \"2b974e3b-495b-48af-8080-c7913d7a2ba8\",\n      \"name\": \"Sticky Note\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"position\": [\n        -200,\n        -720\n      ],\n      \"parameters\": {\n        \"width\": 1060,\n        \"height\": 520,\n        \"content\": \"### 该工作流通过Anthropic API实现了向Claude批量发送提示的自动化处理，可一次性提交多个提示并获取返回结果。\\n\\n#### 使用方法\\n\\n使用包含`requests`数组的参数调用本工作流\\n\\n```json\\n{\\n    \\\"anthropic-version\\\": \\\"2023-06-01\\\",\\n    \\\"requests\\\": [\\n        {\\n            \\\"custom_id\\\": \\\"first-prompt-in-my-batch\\\",\\n            \\\"params\\\": {\\n                \\\"max_tokens\\\": 100,\\n                \\\"messages\\\": [\\n                    {\\n                        \\\"content\\\": \\\"嘿Claude，告诉我一个关于电子游戏的趣味小知识！\\\",\\n                        \\\"role\\\": \\\"user\\\"\\n                    }\\n                ],\\n                \\\"model\\\": \\\"claude-3-5-haiku-20241022\\\"\\n            }\\n        }\\n    ]\\n}\\n```\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"928a30b5-5d90-4648-a82e-e4f1a01e47a5\",\n      \"name\": \"Sticky Note1\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"position\": [\n        1200,\n        -720\n      ],\n      \"parameters\": {\n        \"width\": 980,\n        \"height\": 600,\n        \"content\": \"#### 返回结果\\n\\n该工作流返回一个包含自定义ID的结果数组。\\n\\n```json\\n[\\n    {\\n        \\\"custom_id\\\": \\\"first-prompt-in-my-batch\\\",\\n        \\\"result\\\": {\\n            \\\"message\\\": {\\n                \\\"content\\\": [\\n                    {\\n                        \\\"text\\\": \\\"你知道吗，经典电子游戏俄罗斯方块最初...\\\",\\n                        \\\"type\\\": \\\"text\\\"\\n                    }\\n                ],\\n                \\\"id\\\": \\\"msg_01AiLiVZT18XnoBD4r2w9x2t\\\",\\n                \\\"model\\\": \\\"claude-3-5-haiku-20241022\\\",\\n                \\\"role\\\": \\\"assistant\\\",\\n                \\\"stop_reason\\\": \\\"end_turn\\\",\\n                \\\"stop_sequence\\\": null,\\n                \\\"type\\\": \\\"message\\\",\\n                \\\"usage\\\": {\\n                    \\\"cache_creation_input_tokens\\\": 0,\\n                    \\\"cache_read_input_tokens\\\": 0,\\n                    \\\"input_tokens\\\": 45,\\n                    \\\"output_tokens\\\": 83\\n                }\\n            },\\n            \\\"type\\\": \\\"succeeded\\\"\\n        }\\n    }\\n]\\n```\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"5dcb554e-32df-4883-b5a1-b40305756201\",\n      \"name\": \"Batch Status Poll Interval\",\n      \"type\": \"n8n-nodes-base.wait\",\n      \"position\": [\n        620,\n        40\n      ],\n      \"webhookId\": \"7efafe72-063a-45c6-8775-fcec14e1d263\",\n      \"parameters\": {\n        \"amount\": 10\n      },\n      \"typeVersion\": 1.1\n    },\n    {\n      \"id\": \"c25cfde5-ab83-4e5a-a66f-8cc9f23a01f6\",\n      \"name\": \"Sticky Note2\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"position\": [\n        -160,\n        325\n      ],\n      \"parameters\": {\n        \"color\": 4,\n        \"width\": 340,\n        \"height\": 620,\n        \"content\": \"# 使用示例\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"6062ca7c-aa08-4805-9c96-65e5be8a38fd\",\n      \"name\": \"Run example\",\n      \"type\": \"n8n-nodes-base.manualTrigger\",\n      \"position\": [\n        -40,\n        625\n      ],\n      \"parameters\": {},\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"9878729a-123d-4460-a582-691ca8cedf98\",\n      \"name\": \"One query example\",\n      \"type\": \"n8n-nodes-base.set\",\n      \"position\": [\n        634,\n        775\n      ],\n      \"parameters\": {\n        \"options\": {},\n        \"assignments\": {\n          \"assignments\": [\n            {\n              \"id\": \"1ea47ba2-64be-4d69-b3db-3447cde71645\",\n              \"name\": \"query\",\n              \"type\": \"string\",\n              \"value\": \"Hey Claude, tell me a short fun fact about bees!\"\n            }\n          ]\n        }\n      },\n      \"typeVersion\": 3.4\n    },\n    {\n      \"id\": \"df06c209-8b6a-4b6d-8045-230ebdfcfbad\",\n      \"name\": \"Delete original properties\",\n      \"type\": \"n8n-nodes-base.set\",\n      \"position\": [\n        1528,\n        775\n      ],\n      \"parameters\": {\n        \"options\": {},\n        \"assignments\": {\n          \"assignments\": [\n            {\n              \"id\": \"d238d62b-2e91-4242-b509-8cfc698d2252\",\n              \"name\": \"custom_id\",\n              \"type\": \"string\",\n              \"value\": \"={{ $json.custom_id }}\"\n            },\n            {\n              \"id\": \"21e07c09-92e3-41e7-8335-64653722e7e9\",\n              \"name\": \"params\",\n              \"type\": \"object\",\n              \"value\": \"={{ $json.params }}\"\n            }\n          ]\n        }\n      },\n      \"typeVersion\": 3.4\n    },\n    {\n      \"id\": \"f66d6a89-ee33-4494-9476-46f408976b29\",\n      \"name\": \"Construct 'requests' array\",\n      \"type\": \"n8n-nodes-base.aggregate\",\n      \"position\": [\n        1968,\n        625\n      ],\n      \"parameters\": {\n        \"options\": {},\n        \"aggregate\": \"aggregateAllItemData\",\n        \"destinationFieldName\": \"requests\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"0f9eb605-d629-4cb7-b9cb-39702d201567\",\n      \"name\": \"Set desired 'anthropic-version'\",\n      \"type\": \"n8n-nodes-base.set\",\n      \"notes\": \"2023-06-01\",\n      \"position\": [\n        2188,\n        625\n      ],\n      \"parameters\": {\n        \"options\": {},\n        \"assignments\": {\n          \"assignments\": [\n            {\n              \"id\": \"9f9e94a0-304b-487a-8762-d74421ef4cc0\",\n              \"name\": \"anthropic-version\",\n              \"type\": \"string\",\n              \"value\": \"2023-06-01\"\n            }\n          ]\n        },\n        \"includeOtherFields\": true\n      },\n      \"notesInFlow\": true,\n      \"typeVersion\": 3.4\n    },\n    {\n      \"id\": \"f71f261c-f4ad-4c9f-bd72-42ab386a65e1\",\n      \"name\": \"Execute Workflow 'Process Multiple Prompts in Parallel with Anthropic Claude Batch API'\",\n      \"type\": \"n8n-nodes-base.executeWorkflow\",\n      \"notes\": \"See above\",\n      \"position\": [\n        2408,\n        625\n      ],\n      \"parameters\": {\n        \"options\": {\n          \"waitForSubWorkflow\": true\n        },\n        \"workflowId\": {\n          \"__rl\": true,\n          \"mode\": \"list\",\n          \"value\": \"xQU4byMGhgFxnTIH\",\n          \"cachedResultName\": \"Process Multiple Prompts in Parallel with Anthropic Claude Batch API\"\n        },\n        \"workflowInputs\": {\n          \"value\": {\n            \"requests\": \"={{ $json.requests }}\",\n            \"anthropic-version\": \"={{ $json['anthropic-version'] }}\"\n          },\n          \"schema\": [\n            {\n              \"id\": \"anthropic-version\",\n              \"type\": \"string\",\n              \"display\": true,\n              \"removed\": false,\n              \"required\": false,\n              \"displayName\": \"anthropic-version\",\n              \"defaultMatch\": false,\n              \"canBeUsedToMatch\": true\n            },\n            {\n              \"id\": \"requests\",\n              \"type\": \"array\",\n              \"display\": true,\n              \"removed\": false,\n              \"required\": false,\n              \"displayName\": \"requests\",\n              \"defaultMatch\": false,\n              \"canBeUsedToMatch\": true\n            }\n          ],\n          \"mappingMode\": \"defineBelow\",\n          \"matchingColumns\": [\n            \"requests\"\n          ],\n          \"attemptToConvertTypes\": true,\n          \"convertFieldsToString\": true\n        }\n      },\n      \"notesInFlow\": true,\n      \"typeVersion\": 1.2\n    },\n    {\n      \"id\": \"bd27c1a6-572c-420d-84ab-4d8b7d14311b\",\n      \"name\": \"Build batch 'request' object for single query\",\n      \"type\": \"n8n-nodes-base.code\",\n      \"position\": [\n        1308,\n        775\n      ],\n      \"parameters\": {\n        \"jsCode\": \"// Loop over input items and modify them to match the response example, then return input.all()\\nfor (const item of $input.all()) {\\n  item.json.params = {\\n    max_tokens: item.json.max_tokens,\\n    messages: [\\n      {\\n        content: item.json.query,\\n        role: \\\"user\\\"\\n      }\\n    ],\\n    model: item.json.model\\n  };\\n}\\n\\nreturn $input.all();\\n\"\n      },\n      \"typeVersion\": 2\n    },\n    {\n      \"id\": \"fa342231-ea94-43ab-8808-18c8d04fdaf8\",\n      \"name\": \"Simple Memory Store\",\n      \"type\": \"@n8n/n8n-nodes-langchain.memoryBufferWindow\",\n      \"position\": [\n        644,\n        595\n      ],\n      \"parameters\": {\n        \"sessionKey\": \"\\\"Process Multiple Prompts in Parallel with Anthropic Claude Batch API example\\\"\",\n        \"sessionIdType\": \"customKey\"\n      },\n      \"typeVersion\": 1.3\n    },\n    {\n      \"id\": \"67047fe6-8658-45ba-be61-52cf6115f4e4\",\n      \"name\": \"Fill Chat Memory with example data\",\n      \"type\": \"@n8n/n8n-nodes-langchain.memoryManager\",\n      \"position\": [\n        556,\n        375\n      ],\n      \"parameters\": {\n        \"mode\": \"insert\",\n        \"messages\": {\n          \"messageValues\": [\n            {\n              \"message\": \"You are a helpful AI assistant\"\n            },\n            {\n              \"type\": \"user\",\n              \"message\": \"Hey Claude, tell me a short fun fact about video games!\"\n            },\n            {\n              \"type\": \"ai\",\n              \"message\": \"short fun fact about video games!\"\n            },\n            {\n              \"type\": \"user\",\n              \"message\": \"No, an actual fun fact\"\n            }\n          ]\n        }\n      },\n      \"typeVersion\": 1.1\n    },\n    {\n      \"id\": \"dbb295b8-01fd-445f-ab66-948442b6c71d\",\n      \"name\": \"Build batch 'request' object from Chat Memory and execution data\",\n      \"type\": \"n8n-nodes-base.code\",\n      \"position\": [\n        1528,\n        475\n      ],\n      \"parameters\": {\n        \"jsCode\": \"const output = [];\\n\\nfor (const item of $input.all()) {\\n  const inputMessages = item.json.messages;\\n  const customId = item.json.custom_id;\\n  const model = item.json.model;\\n  const maxTokens = item.json.max_tokens;\\n\\n  if (inputMessages && inputMessages.length > 0) {\\n    let systemMessageContent = undefined;\\n    const transformedMessages = [];\\n\\n    // Process each message entry in sequence\\n    for (const messageObj of inputMessages) {\\n      // Extract system message if present\\n      if ('system' in messageObj) {\\n        systemMessageContent = messageObj.system;\\n      }\\n      \\n      // Process human and AI messages in the order they appear in the object keys\\n      // We need to determine what order the keys appear in the original object\\n      const keys = Object.keys(messageObj);\\n      \\n      for (const key of keys) {\\n        if (key === 'human') {\\n          transformedMessages.push({\\n            role: \\\"user\\\",\\n            content: messageObj.human\\n          });\\n        } else if (key === 'ai') {\\n          transformedMessages.push({\\n            role: \\\"assistant\\\",\\n            content: messageObj.ai\\n          });\\n        }\\n        // Skip 'system' as we already processed it\\n      }\\n    }\\n\\n    const params = {\\n      model: model,\\n      max_tokens: maxTokens,\\n      messages: transformedMessages\\n    };\\n\\n    if (systemMessageContent !== undefined) {\\n      params.system = systemMessageContent;\\n    }\\n\\n    output.push({\\n      custom_id: customId,\\n      params: params\\n    });\\n  }\\n}\\n\\nreturn output;\"\n      },\n      \"typeVersion\": 2\n    },\n    {\n      \"id\": \"f9edb335-c33d-45fc-8f9b-12d7f37cc23e\",\n      \"name\": \"Load Chat Memory Data\",\n      \"type\": \"@n8n/n8n-nodes-langchain.memoryManager\",\n      \"position\": [\n        932,\n        475\n      ],\n      \"parameters\": {\n        \"options\": {}\n      },\n      \"typeVersion\": 1.1\n    },\n    {\n      \"id\": \"22399660-ebe5-4838-bad3-c542d6d921a3\",\n      \"name\": \"First Prompt Result\",\n      \"type\": \"n8n-nodes-base.executionData\",\n      \"position\": [\n        2848,\n        525\n      ],\n      \"parameters\": {\n        \"dataToSave\": {\n          \"values\": [\n            {\n              \"key\": \"assistant_response\",\n              \"value\": \"={{ $json.result.message.content[0].text }}\"\n            }\n          ]\n        }\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"0e7f44f4-c931-4e0f-aebc-1b8f0327647f\",\n      \"name\": \"Second Prompt Result\",\n      \"type\": \"n8n-nodes-base.executionData\",\n      \"position\": [\n        2848,\n        725\n      ],\n      \"parameters\": {\n        \"dataToSave\": {\n          \"values\": [\n            {\n              \"key\": \"assistant_response\",\n              \"value\": \"={{ $json.result.message.content[0].text }}\"\n            }\n          ]\n        }\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"e42b01e0-8fc5-42e1-aa45-aa85477e766b\",\n      \"name\": \"Split Out Parsed Results\",\n      \"type\": \"n8n-nodes-base.splitOut\",\n      \"position\": [\n        1060,\n        -160\n      ],\n      \"parameters\": {\n        \"options\": {},\n        \"fieldToSplitOut\": \"parsed\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"343676b9-f147-4981-b555-8af570374e8c\",\n      \"name\": \"Filter Second Prompt Results\",\n      \"type\": \"n8n-nodes-base.filter\",\n      \"position\": [\n        2628,\n        725\n      ],\n      \"parameters\": {\n        \"options\": {},\n        \"conditions\": {\n          \"options\": {\n            \"version\": 2,\n            \"leftValue\": \"\",\n            \"caseSensitive\": true,\n            \"typeValidation\": \"strict\"\n          },\n          \"combinator\": \"and\",\n          \"conditions\": [\n            {\n              \"id\": \"9e4b3524-7066-46cc-a365-8d23d08c1bda\",\n              \"operator\": {\n                \"name\": \"filter.operator.equals\",\n                \"type\": \"string\",\n                \"operation\": \"equals\"\n              },\n              \"leftValue\": \"={{ $json.custom_id }}\",\n              \"rightValue\": \"={{ $('Append execution data for single query example').item.json.custom_id }}\"\n            }\n          ]\n        }\n      },\n      \"typeVersion\": 2.2\n    },\n    {\n      \"id\": \"c9f5f366-27c4-4401-965b-67c314036fb6\",\n      \"name\": \"Filter First Prompt Results\",\n      \"type\": \"n8n-nodes-base.filter\",\n      \"position\": [\n        2628,\n        525\n      ],\n      \"parameters\": {\n        \"options\": {},\n        \"conditions\": {\n          \"options\": {\n            \"version\": 2,\n            \"leftValue\": \"\",\n            \"caseSensitive\": true,\n            \"typeValidation\": \"strict\"\n          },\n          \"combinator\": \"and\",\n          \"conditions\": [\n            {\n              \"id\": \"9e4b3524-7066-46cc-a365-8d23d08c1bda\",\n              \"operator\": {\n                \"name\": \"filter.operator.equals\",\n                \"type\": \"string\",\n                \"operation\": \"equals\"\n              },\n              \"leftValue\": \"={{ $json.custom_id }}\",\n              \"rightValue\": \"={{ $('Append execution data for chat memory example').item.json.custom_id }}\"\n            }\n          ]\n        }\n      },\n      \"typeVersion\": 2.2\n    },\n    {\n      \"id\": \"0a5b9c3d-665b-4e35-be9e-c8297314969d\",\n      \"name\": \"Sticky Note3\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"position\": [\n        110,\n        -100\n      ],\n      \"parameters\": {\n        \"height\": 300,\n        \"content\": \"## 向Anthropic提交批量请求\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"f19813a5-f669-45dd-a446-947a30b02b09\",\n      \"name\": \"Sticky Note4\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"position\": [\n        350,\n        -5\n      ],\n      \"parameters\": {\n        \"width\": 640,\n        \"height\": 300,\n        \"content\": \"## 循环直至处理状态为“已结束”\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"9f424fce-5610-4b85-9be6-4c2c403002db\",\n      \"name\": \"Sticky Note5\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"position\": [\n        500,\n        -200\n      ],\n      \"parameters\": {\n        \"width\": 280,\n        \"height\": 180,\n        \"content\": \"### 批量获取消息结果\\n\\n[用户指南](https://docs.anthropic.com/en/docs/build-with-claude/batch-processing)\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"b87673b1-f08d-4c51-8ee5-4d54557cb382\",\n      \"name\": \"Sticky Note6\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"position\": [\n        900,\n        380\n      ],\n      \"parameters\": {\n        \"color\": 5,\n        \"width\": 820,\n        \"height\": 340,\n        \"content\": \"# 与聊天历史节点的示例用法\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"d6d8ac02-7005-40a1-9950-9517e98e315c\",\n      \"name\": \"Sticky Note7\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"position\": [\n        180,\n        720\n      ],\n      \"parameters\": {\n        \"width\": 1540,\n        \"height\": 220,\n        \"content\": \"# 单查询字符串的用法示例\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"0d63deb0-dece-4502-9020-d67c1f194466\",\n      \"name\": \"Sticky Note8\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"position\": [\n        180,\n        320\n      ],\n      \"parameters\": {\n        \"color\": 3,\n        \"width\": 660,\n        \"height\": 400,\n        \"content\": \"# 环境设置\\n针对聊天历史节点\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"cab94e09-6b84-4a38-b854-670241744db5\",\n      \"name\": \"Sticky Note9\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"position\": [\n        2120,\n        800\n      ],\n      \"parameters\": {\n        \"height\": 220,\n        \"content\": \"## 版本控制标头\\n\\n[文档说明](https://docs.anthropic.com/en/api/versioning)\\n\\n发起API请求时，必须发送anthropic-version请求头。例如：anthropic-version: `2023-06-01`（当前最新支持版本）\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"ab0a51a1-3c84-4a88-968b-fd46ab07de85\",\n      \"name\": \"Sticky Note10\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"position\": [\n        2560,\n        400\n      ],\n      \"parameters\": {\n        \"color\": 5,\n        \"width\": 480,\n        \"height\": 300,\n        \"content\": \"# 与聊天历史节点配合使用的示例（结果）\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"d91b9be7-ef32-48d6-b880-cab0e99ba9bc\",\n      \"name\": \"Sticky Note11\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"position\": [\n        2560,\n        700\n      ],\n      \"parameters\": {\n        \"width\": 480,\n        \"height\": 300,\n        \"content\": \"# 示例用法：单个查询字符串（结果）\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"341811e9-6677-42d9-be28-c388dbf68101\",\n      \"name\": \"Join two example requests into array\",\n      \"type\": \"n8n-nodes-base.merge\",\n      \"position\": [\n        1748,\n        625\n      ],\n      \"parameters\": {},\n      \"typeVersion\": 3.1\n    },\n    {\n      \"id\": \"45a09f05-7610-4b0a-ab7f-0094c4b3f318\",\n      \"name\": \"Append execution data for single query example\",\n      \"type\": \"n8n-nodes-base.set\",\n      \"notes\": \"custom_id, model and max tokens\",\n      \"position\": [\n        1010,\n        775\n      ],\n      \"parameters\": {\n        \"options\": {},\n        \"assignments\": {\n          \"assignments\": [\n            {\n              \"id\": \"8276602f-689f-45c2-bce0-5df8500912b6\",\n              \"name\": \"custom_id\",\n              \"type\": \"string\",\n              \"value\": \"second-prompt-in-my-batch\"\n            },\n            {\n              \"id\": \"2c513dc2-d8cb-4ba3-b3c1-ea79517b9434\",\n              \"name\": \"model\",\n              \"type\": \"string\",\n              \"value\": \"claude-3-5-haiku-20241022\"\n            },\n            {\n              \"id\": \"b052140b-1152-4327-9c5a-5030b78990b7\",\n              \"name\": \"max_tokens\",\n              \"type\": \"number\",\n              \"value\": 100\n            }\n          ]\n        },\n        \"includeOtherFields\": true\n      },\n      \"notesInFlow\": true,\n      \"typeVersion\": 3.4\n    },\n    {\n      \"id\": \"c4e35349-840c-4c81-852c-0d8cd9331364\",\n      \"name\": \"Append execution data for chat memory example\",\n      \"type\": \"n8n-nodes-base.set\",\n      \"notes\": \"custom_id, model and max tokens\",\n      \"position\": [\n        1308,\n        475\n      ],\n      \"parameters\": {\n        \"options\": {},\n        \"assignments\": {\n          \"assignments\": [\n            {\n              \"id\": \"8276602f-689f-45c2-bce0-5df8500912b6\",\n              \"name\": \"custom_id\",\n              \"type\": \"string\",\n              \"value\": \"first-prompt-in-my-batch\"\n            },\n            {\n              \"id\": \"2c513dc2-d8cb-4ba3-b3c1-ea79517b9434\",\n              \"name\": \"model\",\n              \"type\": \"string\",\n              \"value\": \"claude-3-5-haiku-20241022\"\n            },\n            {\n              \"id\": \"b052140b-1152-4327-9c5a-5030b78990b7\",\n              \"name\": \"max_tokens\",\n              \"type\": \"number\",\n              \"value\": 100\n            }\n          ]\n        },\n        \"includeOtherFields\": true\n      },\n      \"notesInFlow\": true,\n      \"typeVersion\": 3.4\n    },\n    {\n      \"id\": \"058aedb1-fdfe-4edc-8d51-3b93ec7d232d\",\n      \"name\": \"Truncate Chat Memory\",\n      \"type\": \"@n8n/n8n-nodes-langchain.memoryManager\",\n      \"notes\": \"ensure clean state\",\n      \"position\": [\n        180,\n        475\n      ],\n      \"parameters\": {\n        \"mode\": \"delete\",\n        \"deleteMode\": \"all\"\n      },\n      \"notesInFlow\": true,\n      \"typeVersion\": 1.1\n    }\n  ],\n  \"pinData\": {},\n  \"connections\": {\n    \"Get results\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Parse response\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Run example\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"One query example\",\n            \"type\": \"main\",\n            \"index\": 0\n          },\n          {\n            \"node\": \"Truncate Chat Memory\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Submit batch\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"If ended processing\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Parse response\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Split Out Parsed Results\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"One query example\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Append execution data for single query example\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Check batch status\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"If ended processing\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"If ended processing\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Get results\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ],\n        [\n          {\n            \"node\": \"Batch Status Poll Interval\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Simple Memory Store\": {\n      \"ai_memory\": [\n        [\n          {\n            \"node\": \"Load Chat Memory Data\",\n            \"type\": \"ai_memory\",\n            \"index\": 0\n          },\n          {\n            \"node\": \"Fill Chat Memory with example data\",\n            \"type\": \"ai_memory\",\n            \"index\": 0\n          },\n          {\n            \"node\": \"Truncate Chat Memory\",\n            \"type\": \"ai_memory\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Truncate Chat Memory\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Fill Chat Memory with example data\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Load Chat Memory Data\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Append execution data for chat memory example\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Batch Status Poll Interval\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Check batch status\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Construct 'requests' array\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Set desired 'anthropic-version'\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Delete original properties\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Join two example requests into array\",\n            \"type\": \"main\",\n            \"index\": 1\n          }\n        ]\n      ]\n    },\n    \"Filter First Prompt Results\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"First Prompt Result\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Filter Second Prompt Results\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Second Prompt Result\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Set desired 'anthropic-version'\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Execute Workflow 'Process Multiple Prompts in Parallel with Anthropic Claude Batch API'\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"When Executed by Another Workflow\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Submit batch\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Fill Chat Memory with example data\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Load Chat Memory Data\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Join two example requests into array\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Construct 'requests' array\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Append execution data for chat memory example\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Build batch 'request' object from Chat Memory and execution data\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Build batch 'request' object for single query\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Delete original properties\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Append execution data for single query example\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Build batch 'request' object for single query\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Build batch 'request' object from Chat Memory and execution data\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Join two example requests into array\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Execute Workflow 'Process Multiple Prompts in Parallel with Anthropic Claude Batch API'\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Filter First Prompt Results\",\n            \"type\": \"main\",\n            \"index\": 0\n          },\n          {\n            \"node\": \"Filter Second Prompt Results\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    }\n  }\n}"
}