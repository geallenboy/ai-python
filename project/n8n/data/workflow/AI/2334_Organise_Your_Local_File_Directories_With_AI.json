{
  "title": "Organise Your Local File Directories With AI",
  "url": "https://n8n.io/workflows/2334-organise-your-local-file-directories-with-ai/",
  "category": "AI",
  "category_url": "https://n8n.io/workflows/categories/ai/?count=20",
  "author": "Jimleuk",
  "publish_date": "Last update 8 months ago",
  "content": "",
  "workflow_json": "{\"meta\":{\"instanceId\":\"26ba763460b97c249b82942b23b6384876dfeb9327513332e743c5f6219c2b8e\"},\"nodes\":[{\"id\":\"c92e3d01-4385-4e99-a9a7-77279b3d9cb3\",\"name\":\"Local File Trigger\",\"type\":\"n8n-nodes-base.localFileTrigger\",\"position\":[720,120],\"parameters\":{\"path\":\"/home/node/host_mount/shared_drive\",\"events\":[\"add\"],\"options\":{\"awaitWriteFinish\":true},\"triggerOn\":\"folder\"},\"typeVersion\":1},{\"id\":\"a08f5acc-ee46-49e7-be4d-99edc95ab41f\",\"name\":\"Get Files and Folders\",\"type\":\"n8n-nodes-base.executeCommand\",\"position\":[1200,120],\"parameters\":{\"command\":\"=ls -p {{ $json.directory }} | grep -v / || true; \\\\\\necho \\\"===\\\"; \\\\\\nls -p {{ $json.directory }} | grep / || true;\"},\"typeVersion\":1},{\"id\":\"f3ab100a-986d-49bc-aeb5-979f16b2fd46\",\"name\":\"Files and Folders to Array\",\"type\":\"n8n-nodes-base.set\",\"position\":[1380,120],\"parameters\":{\"options\":{},\"assignments\":{\"assignments\":[{\"id\":\"ad893795-cae8-4418-99e0-2c68126337d3\",\"name\":\"files\",\"type\":\"array\",\"value\":\"={{ $json.stdout.split('===')[0].split('\\\\n').filter(item => !item.endsWith('Zone.Identifier')).compact() }}\"},{\"id\":\"0e7e8571-6b86-481d-a20c-3a7c621c562f\",\"name\":\"folders\",\"type\":\"array\",\"value\":\"={{ $json.stdout.split('===')[1].split('\\\\n').compact() }}\"}]}},\"typeVersion\":3.3},{\"id\":\"56c4a8b4-c5b0-4e2f-806b-fef5fb5260b5\",\"name\":\"Mistral Cloud Chat Model\",\"type\":\"@n8n/n8n-nodes-langchain.lmChatMistralCloud\",\"position\":[1860,240],\"parameters\":{\"model\":\"mistral-small-2402\",\"options\":{}},\"credentials\":{\"mistralCloudApi\":{\"id\":\"EIl2QxhXAS9Hkg37\",\"name\":\"Mistral Cloud account\"}},\"typeVersion\":1},{\"id\":\"0d586481-904d-4fbd-9b53-77bc2faf08dd\",\"name\":\"Structured Output Parser\",\"type\":\"@n8n/n8n-nodes-langchain.outputParserStructured\",\"position\":[2040,240],\"parameters\":{\"schemaType\":\"manual\",\"inputSchema\":\"{\\n\\t\\\"type\\\": \\\"array\\\",\\n\\t\\\"items\\\": {\\n    \\t\\\"type\\\": \\\"object\\\",\\n        \\\"properties\\\": {\\n          \\\"folder\\\": { \\\"type\\\": \\\"string\\\" },\\n          \\\"files\\\": {\\n            \\\"type\\\": \\\"array\\\",\\n            \\\"items\\\": { \\\"type\\\": \\\"string\\\" }\\n          }\\n\\t\\t}\\n    }\\n}\"},\"typeVersion\":1.2},{\"id\":\"86025668-aac9-49a2-92ff-ce15df16488c\",\"name\":\"Set Variables\",\"type\":\"n8n-nodes-base.set\",\"position\":[940,120],\"parameters\":{\"options\":{},\"assignments\":{\"assignments\":[{\"id\":\"35ea70c4-8669-4975-a68d-bbaa094713c0\",\"name\":\"directory\",\"type\":\"string\",\"value\":\"={{ $('Local File Trigger').params.path }}\"}]}},\"typeVersion\":3.3},{\"id\":\"457bfd30-5cca-417a-88d3-666afe567fd5\",\"name\":\"Move Files into Folders\",\"type\":\"n8n-nodes-base.executeCommand\",\"position\":[2560,140],\"parameters\":{\"command\":\"=directory=\\\"{{ $('Set Variables').item.json.directory }}\\\"\\nsubdirectory=\\\"$directory/{{ $json.folder }}\\\";\\nfile_list=\\\"{{ $json.files.join(' ') }}\\\";\\n\\n# create subdirectory if not exists\\nmkdir -p $subdirectory;\\n\\n# for each suggestion, move the file into the subdirectory.\\n# If the file in the subdirectory exists, then we'll rename the current file by adding a small random string to the end of the filename.\\nfor filename in $file_list; do\\n    if [ -e \\\"$subdirectory/$filename\\\" ]; then\\n        mv \\\"$directory/$filename-$RANDOM\\\" -t $subdirectory;\\n    else\\n        mv \\\"$directory/$filename\\\" -t $subdirectory;\\n    fi\\ndone\",\"executeOnce\":false},\"typeVersion\":1},{\"id\":\"e9a610bf-b2ae-4b98-870a-2e63790a3b5f\",\"name\":\"Sticky Note\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[635.4233386400999,-161.84747801133517],\"parameters\":{\"color\":7,\"width\":483.7926535356806,\"height\":501.2939838391483,\"content\":\"## Step 1. Select the target folder\\n[Read more about local file trigger](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.localfiletrigger)\\n\\nIn this workflow, we'll monitor a specific folder on disk that n8n has access to. Since we're using docker, we can either use the n8n volume or mount a folder from the host machine.\\n\\nThe local file trigger is useful to execute the workflow whenever changes are made to our target folder.\"},\"typeVersion\":1},{\"id\":\"c8961322-a6da-4fc0-a46d-6119c5eac2b0\",\"name\":\"Sticky Note1\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[1140,-54.28207683557787],\"parameters\":{\"color\":7,\"width\":583.2857596176409,\"height\":391.527066537946,\"content\":\"## Step 2. Identify files that need to be organised\\n[Read more about Execute Command node](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.executecommand)\\n\\nFor all Files in the root level of our selected target folder, we want  them to be sorted and moved into categorised subdirectories. In this step, we'll use linux commands to get a list of files and folders currently present in the target folder.\"},\"typeVersion\":1},{\"id\":\"6e31b2d1-288c-479b-8dd8-a171ecd03dea\",\"name\":\"If Has Target Files...\",\"type\":\"n8n-nodes-base.if\",\"position\":[1560,120],\"parameters\":{\"options\":{},\"conditions\":{\"options\":{\"leftValue\":\"\",\"caseSensitive\":true,\"typeValidation\":\"strict\"},\"combinator\":\"and\",\"conditions\":[{\"id\":\"9be5a175-e7aa-4d68-9ddc-8b43b43e2d37\",\"operator\":{\"type\":\"array\",\"operation\":\"lengthGte\",\"rightType\":\"number\"},\"leftValue\":\"={{ $json.files }}\",\"rightValue\":\"={{ 1 }}\"}]}},\"typeVersion\":2},{\"id\":\"07fd70ca-9126-4846-a2b0-4f3a8fc5eb69\",\"name\":\"Sticky Note2\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[1760,-107.13740439436373],\"parameters\":{\"color\":7,\"width\":631.2649908751414,\"height\":506.8242545618477,\"content\":\"## Step 3. Using Mistral AI to organise our target folder\\n[Read more about Mistral AI](https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmchatmistralcloud)\\n\\nUsing Mistral AI as our AI file manager, it can help us suggest which files go into which categorised subdirectory. If the subdirectory doesn't exist, Mistral can also suggest one to be created.\"},\"typeVersion\":1},{\"id\":\"2ca9a56c-ed1b-4f16-b207-7229c8d90b76\",\"name\":\"Get Suggestions to List\",\"type\":\"n8n-nodes-base.splitOut\",\"position\":[2200,80],\"parameters\":{\"options\":{},\"fieldToSplitOut\":\"output\"},\"typeVersion\":1},{\"id\":\"29d425df-e513-429a-802f-02ad3ad86344\",\"name\":\"Sticky Note3\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[2420,-62.701160902940615],\"parameters\":{\"color\":7,\"width\":401.0065589583014,\"height\":374.8503908496576,\"content\":\"## Step 4. Move the files into subdirectories\\n[Read more about Execute Command node](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.executecommand)\\n\\nFor this step, we'll use the execute command node to execute a shellscript to move the files into their respective subdirectories.\"},\"typeVersion\":1},{\"id\":\"a2ee79ea-6b0d-46c0-876f-8cfe12130a62\",\"name\":\"Sticky Note4\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[240,-160],\"parameters\":{\"width\":372.51107341403605,\"height\":422.70324544339167,\"content\":\"## Try It Out!\\n### This workflow does the following:\\n* Monitors a target folder for changes using the local file trigger\\n* identifies all files and subdirectories in the target folder and passes this to Mistral AI\\n* Mistral AI suggests where to move top level files into which subdirectories. It can also suggest subdirectories tp create if none are suitable.\\n* Finally, we take the AI's suggestions are perform the move operations using the execute command node.\\n\\n### Need Help?\\nJoin the [Discord](https://discord.com/invite/XPKeKXeB7d) or ask in the [Forum](https://community.n8n.io/)!\\n\\nHappy Hacking!\"},\"typeVersion\":1},{\"id\":\"a0db31b1-10e2-40bb-9ec6-b91569bf1072\",\"name\":\"Sticky Note5\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[174.82571715185748,280],\"parameters\":{\"color\":3,\"width\":438.23697639546396,\"height\":97.88076166036412,\"content\":\"### 🚨 Warning! Potential destructive operations ahead!\\nThis workflow manipulates the filesystem. Always make backups of your files before running local workflows.\"},\"typeVersion\":1},{\"id\":\"c932813c-913c-47bd-a4ba-79056bc6dfd7\",\"name\":\"AI File Manager\",\"type\":\"@n8n/n8n-nodes-langchain.chainLlm\",\"position\":[1860,80],\"parameters\":{\"text\":\"=Here is the list of current files in the directory:\\n{{ $json.files.map(file => `* ${file}`).join('\\\\n') }}\\n\\nHere is the list of current folders in the directory:\\n{{ $json.folders.length ? $json.folders.map(item => `* ${item}`).join('\\\\n') : 'There are currently no directories' }}\\n\\nGroup the current files using the filename as a hint and decide which of the current folders should they be moved to. If there are no current folders, then suggest a folder to be created.\\n\\nIf you can't decide which folder to put the file in, the file should be moved to the misc folder.\",\"messages\":{\"messageValues\":[{\"message\":\"You manage a linux directory on behalf of the user.\"}]},\"promptType\":\"define\",\"hasOutputParser\":true},\"typeVersion\":1.4}],\"pinData\":{},\"connections\":{\"Set Variables\":{\"main\":[[{\"node\":\"Get Files and Folders\",\"type\":\"main\",\"index\":0}]]},\"AI File Manager\":{\"main\":[[{\"node\":\"Get Suggestions to List\",\"type\":\"main\",\"index\":0}]]},\"Local File Trigger\":{\"main\":[[{\"node\":\"Set Variables\",\"type\":\"main\",\"index\":0}]]},\"Get Files and Folders\":{\"main\":[[{\"node\":\"Files and Folders to Array\",\"type\":\"main\",\"index\":0}]]},\"If Has Target Files...\":{\"main\":[[{\"node\":\"AI File Manager\",\"type\":\"main\",\"index\":0}]]},\"Get Suggestions to List\":{\"main\":[[{\"node\":\"Move Files into Folders\",\"type\":\"main\",\"index\":0}]]},\"Mistral Cloud Chat Model\":{\"ai_languageModel\":[[{\"node\":\"AI File Manager\",\"type\":\"ai_languageModel\",\"index\":0}]]},\"Structured Output Parser\":{\"ai_outputParser\":[[{\"node\":\"AI File Manager\",\"type\":\"ai_outputParser\",\"index\":0}]]},\"Files and Folders to Array\":{\"main\":[[{\"node\":\"If Has Target Files...\",\"type\":\"main\",\"index\":0}]]}}}",
  "readme": "If you have a shared or personal drive location with a high frequency of files created by humans, it can become difficult to organise. This may not matter... until you need to search for something!\n\nThis n8n workflow works with the local filesystem to target the messy folder and categorise as well as organise its files into sub directories automatically.\n\n## Disclaimer\n\nUnfortunately due to the intended use-case, this workflow will not work on n8n Cloud and a self-hosted version of n8n is required.\n\n## How it works\n\n  * Uses the local file trigger to activate once a new file is introduced to the directory\n  * The new file's filename and filetype are analysed using AI to determine the best location to move this file.\n  * The AI assess the current subdirectories as to not create duplicates. If a relevant subdirectory is not found, a new subdirectory is suggested.\n  * Finally, an Execute Command node uses the AI's suggestions to move the new file into the correct location.\n\n\n\n## Requirements\n\n  * Self-hosted version of n8n. The nodes used in this workflow only work in the self-hosted version.\n  * If you are using docker, you must create a [bind mount](https://docs.docker.com/storage/bind-mounts/) to a host directory.\n  * [Mistral.ai](http://Mistral.ai) account for LLM model\n\n\n\n## Customise this workflow\n\nIf the frequency of files created is high enough, you may not want the trigger to active on every new file created event. Switch to a timer to avoid concurrency issues.\n\n## Want to go fully local?\n\nA version of this workflow is available which uses Ollama instead. You can download this template here:  \n<https://drive.google.com/file/d/1iqJ_zCGussXpfaUBYGrN5opziEFAEQMu/view?usp=sharing>\n",
  "readme_html": "<!--[--><div data-v-006f9244=\"\"><p>If you have a shared or personal drive location with a high frequency of files created by humans, it can become difficult to organise. This may not matter... until you need to search for something!</p>\n<p>This n8n workflow works with the local filesystem to target the messy folder and categorise as well as organise its files into sub directories automatically.</p>\n<h2>Disclaimer</h2>\n<p>Unfortunately due to the intended use-case, this workflow will not work on n8n Cloud and a self-hosted version of n8n is required.</p>\n<h2>How it works</h2>\n<ul>\n<li>Uses the local file trigger to activate once a new file is introduced to the directory</li>\n<li>The new file's filename and filetype are analysed using AI to determine the best location to move this file.</li>\n<li>The AI assess the current subdirectories as to not create duplicates. If a relevant subdirectory is not found, a new subdirectory is suggested.</li>\n<li>Finally, an Execute Command node uses the AI's suggestions to move the new file into the correct location.</li>\n</ul>\n<h2>Requirements</h2>\n<ul>\n<li>Self-hosted version of n8n. The nodes used in this workflow only work in the self-hosted version.</li>\n<li>If you are using docker, you must create a <a href=\"https://docs.docker.com/storage/bind-mounts/\" rel=\"ugc nofollow\" target=\"_blank\">bind mount</a> to a host directory.</li>\n<li><a href=\"http://Mistral.ai\" rel=\"ugc nofollow\" target=\"_blank\">Mistral.ai</a> account for LLM model</li>\n</ul>\n<h2>Customise this workflow</h2>\n<p>If the frequency of files created is high enough, you may not want the trigger to active on every new file created event. Switch to a timer to avoid concurrency issues.</p>\n<h2>Want to go fully local?</h2>\n<p>A version of this workflow is available which uses Ollama instead. You can download this template here:<br>\n<a href=\"https://drive.google.com/file/d/1iqJ_zCGussXpfaUBYGrN5opziEFAEQMu/view?usp=sharing\" rel=\"ugc nofollow\" target=\"_blank\">https://drive.google.com/file/d/1iqJ_zCGussXpfaUBYGrN5opziEFAEQMu/view?usp=sharing</a></p>\n</div><!--]-->",
  "readme_zh": "若您拥有一个共享或个人存储位置，其中频繁产生人工创建的文件，整理工作可能会变得棘手。这种情况或许无关紧要——直到您需要搜索某个文件时！\n\n这个n8n工作流通过与本地文件系统协作，专门针对杂乱文件夹，自动将其文件分类并整理至相应子目录中。\n\n## 免责声明\n\n由于使用场景限制，该工作流无法在n8n云平台上运行，必须使用自托管版本的n8n。\n\n## 运作原理\n\n* 采用本地文件触发器机制，当目录中出现新文件时自动激活\n* 通过AI分析新文件的文件名和类型，智能判定最佳存放位置\n* AI会评估现有子目录结构以避免重复创建。若未找到相关子目录，将建议新建\n* 最终通过执行命令节点，根据AI建议将新文件移至正确位置\n\n## 必备条件\n\n* 自托管版n8n（工作流中的节点仅支持自托管版本）\n* 若使用Docker，需为宿主机目录创建[绑定挂载](https://docs.docker.com/storage/bind-mounts/)\n* [Mistral.ai](http://Mistral.ai)账户（用于LLM模型）\n\n## 自定义设置\n\n若文件生成频率过高，可改用定时触发器替代文件创建事件触发器，以避免并发问题。\n\n## 想要完全本地化运行？\n\n我们提供使用Ollama替代方案的版本，模板下载地址：  \n<https://drive.google.com/file/d/1iqJ_zCGussXpfaUBYGrN5opziEFAEQMu/view?usp=sharing>",
  "title_zh": "用AI整理您的本地文件目录",
  "publish_date_absolute": "2024-08-30",
  "publish_date_zh": "最后更新于8个月前",
  "workflow_json_zh": "{\n  \"meta\": {\n    \"instanceId\": \"26ba763460b97c249b82942b23b6384876dfeb9327513332e743c5f6219c2b8e\"\n  },\n  \"nodes\": [\n    {\n      \"id\": \"c92e3d01-4385-4e99-a9a7-77279b3d9cb3\",\n      \"name\": \"Local File Trigger\",\n      \"type\": \"n8n-nodes-base.localFileTrigger\",\n      \"position\": [\n        720,\n        120\n      ],\n      \"parameters\": {\n        \"path\": \"/home/node/host_mount/shared_drive\",\n        \"events\": [\n          \"add\"\n        ],\n        \"options\": {\n          \"awaitWriteFinish\": true\n        },\n        \"triggerOn\": \"folder\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"a08f5acc-ee46-49e7-be4d-99edc95ab41f\",\n      \"name\": \"Get Files and Folders\",\n      \"type\": \"n8n-nodes-base.executeCommand\",\n      \"position\": [\n        1200,\n        120\n      ],\n      \"parameters\": {\n        \"command\": \"=ls -p {{ $json.directory }} | grep -v / || true; \\\\\\necho \\\"===\\\"; \\\\\\nls -p {{ $json.directory }} | grep / || true;\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"f3ab100a-986d-49bc-aeb5-979f16b2fd46\",\n      \"name\": \"Files and Folders to Array\",\n      \"type\": \"n8n-nodes-base.set\",\n      \"position\": [\n        1380,\n        120\n      ],\n      \"parameters\": {\n        \"options\": {},\n        \"assignments\": {\n          \"assignments\": [\n            {\n              \"id\": \"ad893795-cae8-4418-99e0-2c68126337d3\",\n              \"name\": \"files\",\n              \"type\": \"array\",\n              \"value\": \"={{ $json.stdout.split('===')[0].split('\\\\n').filter(item => !item.endsWith('Zone.Identifier')).compact() }}\"\n            },\n            {\n              \"id\": \"0e7e8571-6b86-481d-a20c-3a7c621c562f\",\n              \"name\": \"folders\",\n              \"type\": \"array\",\n              \"value\": \"={{ $json.stdout.split('===')[1].split('\\\\n').compact() }}\"\n            }\n          ]\n        }\n      },\n      \"typeVersion\": 3.3\n    },\n    {\n      \"id\": \"56c4a8b4-c5b0-4e2f-806b-fef5fb5260b5\",\n      \"name\": \"Mistral Cloud Chat Model\",\n      \"type\": \"@n8n/n8n-nodes-langchain.lmChatMistralCloud\",\n      \"position\": [\n        1860,\n        240\n      ],\n      \"parameters\": {\n        \"model\": \"mistral-small-2402\",\n        \"options\": {}\n      },\n      \"credentials\": {\n        \"mistralCloudApi\": {\n          \"id\": \"EIl2QxhXAS9Hkg37\",\n          \"name\": \"Mistral Cloud account\"\n        }\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"0d586481-904d-4fbd-9b53-77bc2faf08dd\",\n      \"name\": \"Structured Output Parser\",\n      \"type\": \"@n8n/n8n-nodes-langchain.outputParserStructured\",\n      \"position\": [\n        2040,\n        240\n      ],\n      \"parameters\": {\n        \"schemaType\": \"manual\",\n        \"inputSchema\": \"{\\n\\t\\\"type\\\": \\\"array\\\",\\n\\t\\\"items\\\": {\\n    \\t\\\"type\\\": \\\"object\\\",\\n        \\\"properties\\\": {\\n          \\\"folder\\\": { \\\"type\\\": \\\"string\\\" },\\n          \\\"files\\\": {\\n            \\\"type\\\": \\\"array\\\",\\n            \\\"items\\\": { \\\"type\\\": \\\"string\\\" }\\n          }\\n\\t\\t}\\n    }\\n}\"\n      },\n      \"typeVersion\": 1.2\n    },\n    {\n      \"id\": \"86025668-aac9-49a2-92ff-ce15df16488c\",\n      \"name\": \"Set Variables\",\n      \"type\": \"n8n-nodes-base.set\",\n      \"position\": [\n        940,\n        120\n      ],\n      \"parameters\": {\n        \"options\": {},\n        \"assignments\": {\n          \"assignments\": [\n            {\n              \"id\": \"35ea70c4-8669-4975-a68d-bbaa094713c0\",\n              \"name\": \"directory\",\n              \"type\": \"string\",\n              \"value\": \"={{ $('Local File Trigger').params.path }}\"\n            }\n          ]\n        }\n      },\n      \"typeVersion\": 3.3\n    },\n    {\n      \"id\": \"457bfd30-5cca-417a-88d3-666afe567fd5\",\n      \"name\": \"Move Files into Folders\",\n      \"type\": \"n8n-nodes-base.executeCommand\",\n      \"position\": [\n        2560,\n        140\n      ],\n      \"parameters\": {\n        \"command\": \"=directory=\\\"{{ $('Set Variables').item.json.directory }}\\\"\\nsubdirectory=\\\"$directory/{{ $json.folder }}\\\";\\nfile_list=\\\"{{ $json.files.join(' ') }}\\\";\\n\\n# create subdirectory if not exists\\nmkdir -p $subdirectory;\\n\\n# for each suggestion, move the file into the subdirectory.\\n# If the file in the subdirectory exists, then we'll rename the current file by adding a small random string to the end of the filename.\\nfor filename in $file_list; do\\n    if [ -e \\\"$subdirectory/$filename\\\" ]; then\\n        mv \\\"$directory/$filename-$RANDOM\\\" -t $subdirectory;\\n    else\\n        mv \\\"$directory/$filename\\\" -t $subdirectory;\\n    fi\\ndone\",\n        \"executeOnce\": false\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"e9a610bf-b2ae-4b98-870a-2e63790a3b5f\",\n      \"name\": \"Sticky Note\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"position\": [\n        635.4233386400999,\n        -161.84747801133517\n      ],\n      \"parameters\": {\n        \"color\": 7,\n        \"width\": 483.7926535356806,\n        \"height\": 501.2939838391483,\n        \"content\": \"## 第一步：选择目标文件夹\\n[详细了解本地文件触发器](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.localfiletrigger)\\n\\n在本工作流中，我们将监控n8n可访问的磁盘特定目录。由于使用docker环境，我们可以选择使用n8n数据卷或挂载宿主机的文件夹。\\n\\n当目标文件夹内容发生变更时，本地文件触发器能有效启动工作流执行。\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"c8961322-a6da-4fc0-a46d-6119c5eac2b0\",\n      \"name\": \"Sticky Note1\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"position\": [\n        1140,\n        -54.28207683557787\n      ],\n      \"parameters\": {\n        \"color\": 7,\n        \"width\": 583.2857596176409,\n        \"height\": 391.527066537946,\n        \"content\": \"## 第二步：识别需整理的文件  \\n[详细了解执行命令节点](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.executecommand)  \\n\\n对于目标文件夹根目录下的所有文件，我们需要将其分类并移动到对应的子目录中。在此步骤中，我们将使用Linux命令获取目标文件夹当前包含的文件和目录列表。\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"6e31b2d1-288c-479b-8dd8-a171ecd03dea\",\n      \"name\": \"If Has Target Files...\",\n      \"type\": \"n8n-nodes-base.if\",\n      \"position\": [\n        1560,\n        120\n      ],\n      \"parameters\": {\n        \"options\": {},\n        \"conditions\": {\n          \"options\": {\n            \"leftValue\": \"\",\n            \"caseSensitive\": true,\n            \"typeValidation\": \"strict\"\n          },\n          \"combinator\": \"and\",\n          \"conditions\": [\n            {\n              \"id\": \"9be5a175-e7aa-4d68-9ddc-8b43b43e2d37\",\n              \"operator\": {\n                \"type\": \"array\",\n                \"operation\": \"lengthGte\",\n                \"rightType\": \"number\"\n              },\n              \"leftValue\": \"={{ $json.files }}\",\n              \"rightValue\": \"={{ 1 }}\"\n            }\n          ]\n        }\n      },\n      \"typeVersion\": 2\n    },\n    {\n      \"id\": \"07fd70ca-9126-4846-a2b0-4f3a8fc5eb69\",\n      \"name\": \"Sticky Note2\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"position\": [\n        1760,\n        -107.13740439436373\n      ],\n      \"parameters\": {\n        \"color\": 7,\n        \"width\": 631.2649908751414,\n        \"height\": 506.8242545618477,\n        \"content\": \"## 第三步：运用Mistral AI整理目标文件夹\\n[进一步了解Mistral AI](https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmchatmistralcloud)\\n\\n将Mistral AI作为智能文件管理助手，它能协助我们判断文件应归入哪个分类子目录。若对应子目录不存在，Mistral还能建议创建新目录。\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"2ca9a56c-ed1b-4f16-b207-7229c8d90b76\",\n      \"name\": \"Get Suggestions to List\",\n      \"type\": \"n8n-nodes-base.splitOut\",\n      \"position\": [\n        2200,\n        80\n      ],\n      \"parameters\": {\n        \"options\": {},\n        \"fieldToSplitOut\": \"output\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"29d425df-e513-429a-802f-02ad3ad86344\",\n      \"name\": \"Sticky Note3\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"position\": [\n        2420,\n        -62.701160902940615\n      ],\n      \"parameters\": {\n        \"color\": 7,\n        \"width\": 401.0065589583014,\n        \"height\": 374.8503908496576,\n        \"content\": \"## 步骤4. 将文件移至子目录\\n[详细了解执行命令节点](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.executecommand)\\n\\n在此步骤中，我们将使用执行命令节点运行一个shell脚本，将文件移动到它们各自的子目录中。\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"a2ee79ea-6b0d-46c0-876f-8cfe12130a62\",\n      \"name\": \"Sticky Note4\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"position\": [\n        240,\n        -160\n      ],\n      \"parameters\": {\n        \"width\": 372.51107341403605,\n        \"height\": 422.70324544339167,\n        \"content\": \"## 试试看吧！\\n### 该工作流程实现以下功能：\\n* 通过本地文件触发器监控目标文件夹的变动\\n* 识别目标文件夹内所有文件及子目录，并将信息传递至Mistral AI\\n* Mistral AI会建议将顶层文件移至哪个子目录，若无合适子目录还可建议新建\\n* 最后通过执行命令节点，根据AI建议完成文件移动操作\\n\\n### 需要帮助？\\n加入[Discord讨论群](https://discord.com/invite/XPKeKXeB7d) 或访问[官方论坛](https://community.n8n.io/)提问！\\n\\n祝您探索愉快！\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"a0db31b1-10e2-40bb-9ec6-b91569bf1072\",\n      \"name\": \"Sticky Note5\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"position\": [\n        174.82571715185748,\n        280\n      ],\n      \"parameters\": {\n        \"color\": 3,\n        \"width\": 438.23697639546396,\n        \"height\": 97.88076166036412,\n        \"content\": \"### 🚨 警告！即将执行潜在破坏性操作！\\n此工作流涉及文件系统操作。运行本地工作流前，请务必备份您的文件。\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"c932813c-913c-47bd-a4ba-79056bc6dfd7\",\n      \"name\": \"AI File Manager\",\n      \"type\": \"@n8n/n8n-nodes-langchain.chainLlm\",\n      \"position\": [\n        1860,\n        80\n      ],\n      \"parameters\": {\n        \"text\": \"=Here is the list of current files in the directory:\\n{{ $json.files.map(file => `* ${file}`).join('\\\\n') }}\\n\\nHere is the list of current folders in the directory:\\n{{ $json.folders.length ? $json.folders.map(item => `* ${item}`).join('\\\\n') : 'There are currently no directories' }}\\n\\nGroup the current files using the filename as a hint and decide which of the current folders should they be moved to. If there are no current folders, then suggest a folder to be created.\\n\\nIf you can't decide which folder to put the file in, the file should be moved to the misc folder.\",\n        \"messages\": {\n          \"messageValues\": [\n            {\n              \"message\": \"You manage a linux directory on behalf of the user.\"\n            }\n          ]\n        },\n        \"promptType\": \"define\",\n        \"hasOutputParser\": true\n      },\n      \"typeVersion\": 1.4\n    }\n  ],\n  \"pinData\": {},\n  \"connections\": {\n    \"Set Variables\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Get Files and Folders\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"AI File Manager\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Get Suggestions to List\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Local File Trigger\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Set Variables\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Get Files and Folders\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Files and Folders to Array\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"If Has Target Files...\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"AI File Manager\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Get Suggestions to List\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Move Files into Folders\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Mistral Cloud Chat Model\": {\n      \"ai_languageModel\": [\n        [\n          {\n            \"node\": \"AI File Manager\",\n            \"type\": \"ai_languageModel\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Structured Output Parser\": {\n      \"ai_outputParser\": [\n        [\n          {\n            \"node\": \"AI File Manager\",\n            \"type\": \"ai_outputParser\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Files and Folders to Array\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"If Has Target Files...\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    }\n  }\n}"
}