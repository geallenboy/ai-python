{
  "title": "Adaptive RAG with Google Gemini & Qdrant: Context-Aware Query Answering",
  "url": "https://n8n.io/workflows/4043-adaptive-rag-with-google-gemini-and-qdrant-context-aware-query-answering/",
  "category": "AI",
  "category_url": "https://n8n.io/workflows/categories/ai/?sort=createdAt:desc",
  "author": "Nisa",
  "publish_date": "Last update 3 days ago",
  "publish_date_absolute": "2025-05-19",
  "content": "",
  "workflow_json": "{\"id\":\"uZtDG9wLeCBZbaoK\",\"meta\":{\"instanceId\":\"2848b874676d610ec8f8106a5acf41448278a62b14e4a776b42d6977aab508d7\",\"templateId\":\"3459\"},\"name\":\"RAG 2.0 - Answer Architecture\",\"tags\":[],\"nodes\":[{\"id\":\"856bd809-8f41-41af-8f72-a3828229c2a5\",\"name\":\"Query Classification\",\"type\":\"@n8n/n8n-nodes-langchain.agent\",\"notes\":\"Classify a query into one of four categories: Factual, Analytical, Opinion, or Contextual.\\n        \\nReturns:\\nstr: Query category\",\"position\":[420,340],\"parameters\":{\"text\":\"=Classify this query: {{ $('Combined Fields').item.json.user_query }}\",\"options\":{\"systemMessage\":\"You are an expert at classifying questions. \\n\\nClassify the given query into exactly one of these categories:\\n- Factual: Queries seeking specific, verifiable information.\\n- Analytical: Queries requiring comprehensive analysis or explanation.\\n- Opinion: Queries about subjective matters or seeking diverse viewpoints.\\n- Contextual: Queries that depend on user-specific context.\\n\\nReturn ONLY the category name, without any explanation or additional text.\"},\"promptType\":\"define\"},\"typeVersion\":1.8},{\"id\":\"cc2106fc-f1a8-45ef-b37b-ab981ac13466\",\"name\":\"Switch\",\"type\":\"n8n-nodes-base.switch\",\"position\":[780,380],\"parameters\":{\"rules\":{\"values\":[{\"outputKey\":\"Factual\",\"conditions\":{\"options\":{\"version\":2,\"leftValue\":\"\",\"caseSensitive\":true,\"typeValidation\":\"strict\"},\"combinator\":\"and\",\"conditions\":[{\"id\":\"87f3b50c-9f32-4260-ac76-19c05b28d0b4\",\"operator\":{\"type\":\"string\",\"operation\":\"equals\"},\"leftValue\":\"={{ $json.output.trim() }}\",\"rightValue\":\"Factual\"}]},\"renameOutput\":true},{\"outputKey\":\"Analytical\",\"conditions\":{\"options\":{\"version\":2,\"leftValue\":\"\",\"caseSensitive\":true,\"typeValidation\":\"strict\"},\"combinator\":\"and\",\"conditions\":[{\"id\":\"f8651b36-79fa-4be4-91fb-0e6d7deea18f\",\"operator\":{\"name\":\"filter.operator.equals\",\"type\":\"string\",\"operation\":\"equals\"},\"leftValue\":\"={{ $json.output.trim() }}\",\"rightValue\":\"Analytical\"}]},\"renameOutput\":true},{\"outputKey\":\"Opinion\",\"conditions\":{\"options\":{\"version\":2,\"leftValue\":\"\",\"caseSensitive\":true,\"typeValidation\":\"strict\"},\"combinator\":\"and\",\"conditions\":[{\"id\":\"5dde06bc-5fe1-4dca-b6e2-6857c5e96d49\",\"operator\":{\"name\":\"filter.operator.equals\",\"type\":\"string\",\"operation\":\"equals\"},\"leftValue\":\"={{ $json.output.trim() }}\",\"rightValue\":\"Opinion\"}]},\"renameOutput\":true},{\"outputKey\":\"Contextual\",\"conditions\":{\"options\":{\"version\":2,\"leftValue\":\"\",\"caseSensitive\":true,\"typeValidation\":\"strict\"},\"combinator\":\"and\",\"conditions\":[{\"id\":\"bf97926d-7a0b-4e2f-aac0-a820f73344d8\",\"operator\":{\"name\":\"filter.operator.equals\",\"type\":\"string\",\"operation\":\"equals\"},\"leftValue\":\"={{ $json.output.trim() }}\",\"rightValue\":\"Contextual\"}]},\"renameOutput\":true}]},\"options\":{\"fallbackOutput\":0}},\"typeVersion\":3.2},{\"id\":\"63889cad-1283-4dbf-ba16-2b6cf575f24a\",\"name\":\"Factual Strategy - Focus on Precision\",\"type\":\"@n8n/n8n-nodes-langchain.agent\",\"notes\":\"Retrieval strategy for factual queries focusing on precision.\",\"position\":[1180,-440],\"parameters\":{\"text\":\"=Enhance this factual query: {{ $('Combined Fields').item.json.user_query }}\",\"options\":{\"systemMessage\":\"=You are an expert at enhancing search queries.\\n\\nYour task is to reformulate the given factual query to make it more precise and specific for information retrieval. Focus on key entities and their relationships.\\n\\nProvide ONLY the enhanced query without any explanation.\"},\"promptType\":\"define\"},\"typeVersion\":1.7},{\"id\":\"020d2201-9590-400d-b496-48c65801271c\",\"name\":\"Analytical Strategy - Comprehensive Coverage\",\"type\":\"@n8n/n8n-nodes-langchain.agent\",\"notes\":\"Retrieval strategy for analytical queries focusing on comprehensive coverage.\",\"position\":[1180,140],\"parameters\":{\"text\":\"=Generate sub-questions for this analytical query: {{ $('Combined Fields').item.json.user_query }}\",\"options\":{\"systemMessage\":\"=You are an expert at breaking down complex questions.\\n\\nGenerate sub-questions that explore different aspects of the main analytical query.\\nThese sub-questions should cover the breadth of the topic and help retrieve comprehensive information.\\n\\nReturn a list of exactly 3 sub-questions, one per line.\"},\"promptType\":\"define\"},\"typeVersion\":1.7},{\"id\":\"c35d1b95-68c8-4237-932d-4744f620760d\",\"name\":\"Opinion Strategy - Diverse Perspectives\",\"type\":\"@n8n/n8n-nodes-langchain.agent\",\"notes\":\"Retrieval strategy for opinion queries focusing on diverse perspectives.\",\"position\":[1220,700],\"parameters\":{\"text\":\"=Identify different perspectives on: {{ $('Combined Fields').item.json.user_query }}\",\"options\":{\"systemMessage\":\"=You are an expert at identifying different perspectives on a topic.\\n\\nFor the given query about opinions or viewpoints, identify different perspectives that people might have on this topic.\\n\\nReturn a list of exactly 3 different viewpoint angles, one per line.\"},\"promptType\":\"define\"},\"typeVersion\":1.7},{\"id\":\"363a3fc3-112f-40df-891e-0a5aa3669245\",\"name\":\"Contextual Strategy - User Context Integration\",\"type\":\"@n8n/n8n-nodes-langchain.agent\",\"notes\":\"Retrieval strategy for contextual queries integrating user context.\",\"position\":[1180,1320],\"parameters\":{\"text\":\"=Infer the implied context in this query: {{ $('Combined Fields').item.json.user_query }}\",\"options\":{\"systemMessage\":\"=You are an expert at understanding implied context in questions.\\n\\nFor the given query, infer what contextual information might be relevant or implied but not explicitly stated. Focus on what background would help answering this query.\\n\\nReturn a brief description of the implied context.\"},\"promptType\":\"define\"},\"typeVersion\":1.7},{\"id\":\"45887701-5ea5-48b4-9b2b-40a80238ab0c\",\"name\":\"Chat\",\"type\":\"@n8n/n8n-nodes-langchain.chatTrigger\",\"position\":[0,640],\"webhookId\":\"56f626b5-339e-48af-857f-1d4198fc8a4d\",\"parameters\":{\"options\":{}},\"typeVersion\":1.1},{\"id\":\"7f7df364-4829-4e29-be3d-d13a63f65b8f\",\"name\":\"Factual Prompt and Output\",\"type\":\"n8n-nodes-base.set\",\"position\":[1640,-300],\"parameters\":{\"options\":{},\"assignments\":{\"assignments\":[{\"id\":\"a4a28ac2-4a56-46f6-8b86-f5d1a34b2ced\",\"name\":\"output\",\"type\":\"string\",\"value\":\"={{ $json.output }}\"},{\"id\":\"7aa6ce13-afbf-4871-b81c-6e9c722a53dc\",\"name\":\"prompt\",\"type\":\"string\",\"value\":\"You are a helpful assistant providing factual information. Answer the question based on the provided context. Focus on accuracy and precision. If the context doesn't contain the information needed, acknowledge the limitations.\"}]}},\"typeVersion\":3.4},{\"id\":\"590d8667-69eb-4db2-b5be-714c602b319a\",\"name\":\"Contextual Prompt and Output\",\"type\":\"n8n-nodes-base.set\",\"position\":[1640,1400],\"parameters\":{\"options\":{},\"assignments\":{\"assignments\":[{\"id\":\"a4a28ac2-4a56-46f6-8b86-f5d1a34b2ced\",\"name\":\"output\",\"type\":\"string\",\"value\":\"={{ $json.output }}\"},{\"id\":\"7aa6ce13-afbf-4871-b81c-6e9c722a53dc\",\"name\":\"prompt\",\"type\":\"string\",\"value\":\"You are a helpful assistant providing contextually relevant information. Answer the question considering both the query and its context. Make connections between the query context and the information in the provided documents. If the context doesn't fully address the specific situation, acknowledge the limitations.\"}]}},\"typeVersion\":3.4},{\"id\":\"fa3228ee-62d8-4c02-9dca-8a1ebc6afc74\",\"name\":\"Opinion Prompt and Output\",\"type\":\"n8n-nodes-base.set\",\"position\":[1620,820],\"parameters\":{\"options\":{},\"assignments\":{\"assignments\":[{\"id\":\"a4a28ac2-4a56-46f6-8b86-f5d1a34b2ced\",\"name\":\"output\",\"type\":\"string\",\"value\":\"={{ $json.output }}\"},{\"id\":\"7aa6ce13-afbf-4871-b81c-6e9c722a53dc\",\"name\":\"prompt\",\"type\":\"string\",\"value\":\"You are a helpful assistant discussing topics with multiple viewpoints. Based on the provided context, present different perspectives on the topic. Ensure fair representation of diverse opinions without showing bias. Acknowledge where the context presents limited viewpoints.\"}]}},\"typeVersion\":3.4},{\"id\":\"c769a76a-fb26-46a1-a00d-825b689d5f7a\",\"name\":\"Analytical Prompt and Output\",\"type\":\"n8n-nodes-base.set\",\"position\":[1620,220],\"parameters\":{\"options\":{},\"assignments\":{\"assignments\":[{\"id\":\"a4a28ac2-4a56-46f6-8b86-f5d1a34b2ced\",\"name\":\"output\",\"type\":\"string\",\"value\":\"={{ $json.output }}\"},{\"id\":\"7aa6ce13-afbf-4871-b81c-6e9c722a53dc\",\"name\":\"prompt\",\"type\":\"string\",\"value\":\"You are a helpful assistant providing analytical insights. Based on the provided context, offer a comprehensive analysis of the topic. Cover different aspects and perspectives in your explanation. If the context has gaps, acknowledge them while providing the best analysis possible.\"}]}},\"typeVersion\":3.4},{\"id\":\"fcd29f6b-17e8-442c-93f9-b93fbad7cd10\",\"name\":\"Gemini Classification\",\"type\":\"@n8n/n8n-nodes-langchain.lmChatGoogleGemini\",\"position\":[580,600],\"parameters\":{\"options\":{},\"modelName\":\"models/gemini-2.0-flash-lite\"},\"credentials\":{\"googlePalmApi\":{\"id\":\"vGGCUG66DLA8zNyX\",\"name\":\"Google Gemini(PaLM) Api account\"}},\"typeVersion\":1},{\"id\":\"c0828ee3-f184-41f5-9a25-0f1059b03711\",\"name\":\"Gemini Factual\",\"type\":\"@n8n/n8n-nodes-langchain.lmChatGoogleGemini\",\"position\":[1240,-240],\"parameters\":{\"options\":{},\"modelName\":\"models/gemini-2.0-flash\"},\"credentials\":{\"googlePalmApi\":{\"id\":\"vGGCUG66DLA8zNyX\",\"name\":\"Google Gemini(PaLM) Api account\"}},\"typeVersion\":1},{\"id\":\"98f9981d-ea8e-45cb-b91d-3c8d1fe33e25\",\"name\":\"Gemini Analytical\",\"type\":\"@n8n/n8n-nodes-langchain.lmChatGoogleGemini\",\"position\":[1240,340],\"parameters\":{\"options\":{},\"modelName\":\"models/gemini-2.0-flash\"},\"credentials\":{\"googlePalmApi\":{\"id\":\"vGGCUG66DLA8zNyX\",\"name\":\"Google Gemini(PaLM) Api account\"}},\"typeVersion\":1},{\"id\":\"c85f270d-3224-4e60-9acf-91f173dfe377\",\"name\":\"Chat Buffer Memory Analytical\",\"type\":\"@n8n/n8n-nodes-langchain.memoryBufferWindow\",\"position\":[1400,340],\"parameters\":{\"sessionKey\":\"={{ $('Combined Fields').item.json.chat_memory_key }}\",\"sessionIdType\":\"customKey\",\"contextWindowLength\":10},\"typeVersion\":1.3},{\"id\":\"c39ba907-7388-4152-965a-e28e626bc9b2\",\"name\":\"Chat Buffer Memory Factual\",\"type\":\"@n8n/n8n-nodes-langchain.memoryBufferWindow\",\"position\":[1400,-240],\"parameters\":{\"sessionKey\":\"={{ $('Combined Fields').item.json.chat_memory_key }}\",\"sessionIdType\":\"customKey\",\"contextWindowLength\":10},\"typeVersion\":1.3},{\"id\":\"52dcd9f0-e6b3-4d33-bc6f-621ef880178e\",\"name\":\"Gemini Opinion\",\"type\":\"@n8n/n8n-nodes-langchain.lmChatGoogleGemini\",\"position\":[1280,900],\"parameters\":{\"options\":{},\"modelName\":\"models/gemini-2.0-flash\"},\"credentials\":{\"googlePalmApi\":{\"id\":\"vGGCUG66DLA8zNyX\",\"name\":\"Google Gemini(PaLM) Api account\"}},\"typeVersion\":1},{\"id\":\"147a709a-4b46-4835-82cf-7d6b633acd4c\",\"name\":\"Chat Buffer Memory Opinion\",\"type\":\"@n8n/n8n-nodes-langchain.memoryBufferWindow\",\"position\":[1440,900],\"parameters\":{\"sessionKey\":\"={{ $('Combined Fields').item.json.chat_memory_key }}\",\"sessionIdType\":\"customKey\",\"contextWindowLength\":10},\"typeVersion\":1.3},{\"id\":\"3cb6bf32-5937-49b9-acf7-d7d01dc2ddd1\",\"name\":\"Gemini Contextual\",\"type\":\"@n8n/n8n-nodes-langchain.lmChatGoogleGemini\",\"position\":[1240,1500],\"parameters\":{\"options\":{},\"modelName\":\"models/gemini-2.0-flash\"},\"credentials\":{\"googlePalmApi\":{\"id\":\"vGGCUG66DLA8zNyX\",\"name\":\"Google Gemini(PaLM) Api account\"}},\"typeVersion\":1},{\"id\":\"5916c4f1-4369-4d66-8553-2fff006b7e69\",\"name\":\"Chat Buffer Memory Contextual\",\"type\":\"@n8n/n8n-nodes-langchain.memoryBufferWindow\",\"position\":[1420,1500],\"parameters\":{\"sessionKey\":\"={{ $('Combined Fields').item.json.chat_memory_key }}\",\"sessionIdType\":\"customKey\",\"contextWindowLength\":10},\"typeVersion\":1.3},{\"id\":\"d33377c2-6b98-4e4d-968f-f3085354ae50\",\"name\":\"Embeddings\",\"type\":\"@n8n/n8n-nodes-langchain.embeddingsGoogleGemini\",\"notes\":\"{ $node[\\\"Embeddings\\\"].json.response }}\",\"position\":[2400,600],\"parameters\":{\"modelName\":\"models/text-embedding-004\"},\"credentials\":{\"googlePalmApi\":{\"id\":\"vGGCUG66DLA8zNyX\",\"name\":\"Google Gemini(PaLM) Api account\"}},\"typeVersion\":1},{\"id\":\"32d9a0c0-0889-4cb2-a088-8ee9cfecacd3\",\"name\":\"Sticky Note\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[1100,-600],\"parameters\":{\"color\":7,\"width\":700,\"height\":520,\"content\":\"## Factual Strategy\\n**Retrieve precise facts and figures.**\\n## Olgusal Strateji\\n**Kesin gerçeklere ve rakamlara ulaşın.**\"},\"typeVersion\":1},{\"id\":\"064a4729-717c-40c8-824a-508406610a13\",\"name\":\"Sticky Note1\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[1100,-40],\"parameters\":{\"color\":7,\"width\":700,\"height\":520,\"content\":\"## Analytical Strategy\\n**Provide comprehensive coverage of a topics and exploring different aspects.**\\n## Analitik Strateji\\n**Bir konunun kapsamlı bir şekilde ele alınmasını ve farklı yönlerinin keşfedilmesini sağlar.**\"},\"typeVersion\":1},{\"id\":\"9fd52a28-44bc-4dfd-bdb7-90987cc2f4fb\",\"name\":\"Sticky Note2\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[1100,520],\"parameters\":{\"color\":7,\"width\":700,\"height\":520,\"content\":\"## Opinion Strategy\\n**Gather diverse viewpoints on a subjective issue.**\\n## Görüş Stratejisi\\n**Öznel bir konuda farklı bakış açıları toplayın.**\"},\"typeVersion\":1},{\"id\":\"3797b21f-cc2a-4210-aa63-6d181d413c5e\",\"name\":\"Sticky Note3\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[1100,1100],\"parameters\":{\"color\":7,\"width\":700,\"height\":540,\"content\":\"## Contextual Strategy\\n**Incorporate user-specific context to fine-tune the retrieval.**\\n## Bağlamsal Strateji\\n**Getirmeye ince ayar yapmak için kullanıcıya özgü bağlamı dahil edin.**\"},\"typeVersion\":1},{\"id\":\"16fa1531-9fb9-4b12-961c-be12e20b2134\",\"name\":\"Concatenate Context\",\"type\":\"n8n-nodes-base.summarize\",\"position\":[2900,380],\"parameters\":{\"options\":{},\"fieldsToSummarize\":{\"values\":[{\"field\":\"document.pageContent\",\"separateBy\":\"other\",\"aggregation\":\"concatenate\",\"customSeparator\":\"={{ \\\"\\\\n\\\\n---\\\\n\\\\n\\\" }}\"}]}},\"typeVersion\":1.1},{\"id\":\"4d6147d1-7a3d-42ab-b23f-cdafe8ea30b0\",\"name\":\"Retrieve Documents from Vector Store\",\"type\":\"@n8n/n8n-nodes-langchain.vectorStoreQdrant\",\"position\":[2140,380],\"parameters\":{\"mode\":\"load\",\"topK\":10,\"prompt\":\"=Prompt\\n{{ $json.prompt }}\\n\\nUser query: \\n{{ $json.output }}\",\"options\":{},\"qdrantCollection\":{\"__rl\":true,\"mode\":\"id\",\"value\":\"=vector_store_id\"}},\"credentials\":{\"qdrantApi\":{\"id\":\"ivp7KsCQyRCs5owS\",\"name\":\"QdrantApi account\"}},\"executeOnce\":false,\"notesInFlow\":false,\"retryOnFail\":false,\"typeVersion\":1.1,\"alwaysOutputData\":false},{\"id\":\"7e68f9cb-0a0d-4215-8083-3b9ef92cd237\",\"name\":\"Set Prompt and Output\",\"type\":\"n8n-nodes-base.set\",\"position\":[1900,460],\"parameters\":{\"options\":{},\"assignments\":{\"assignments\":[{\"id\":\"1d782243-0571-4845-b8fe-4c6c4b55379e\",\"name\":\"output\",\"type\":\"string\",\"value\":\"={{ $json.output }}\"},{\"id\":\"547091fb-367c-44d4-ac39-24d073da70e0\",\"name\":\"prompt\",\"type\":\"string\",\"value\":\"={{ $json.prompt }}\"}]}},\"typeVersion\":3.4},{\"id\":\"0c623ca1-da85-48a3-9d8b-90d97283a015\",\"name\":\"Gemini Answer\",\"type\":\"@n8n/n8n-nodes-langchain.lmChatGoogleGemini\",\"position\":[3340,620],\"parameters\":{\"options\":{},\"modelName\":\"models/gemini-2.0-flash\"},\"credentials\":{\"googlePalmApi\":{\"id\":\"vGGCUG66DLA8zNyX\",\"name\":\"Google Gemini(PaLM) Api account\"}},\"typeVersion\":1},{\"id\":\"fab91e48-1c62-46a8-b9fc-39704f225274\",\"name\":\"Answer\",\"type\":\"@n8n/n8n-nodes-langchain.agent\",\"position\":[3120,380],\"parameters\":{\"text\":\"=User query: {{ $('Combined Fields').item.json.user_query }}\",\"options\":{\"systemMessage\":\"={{ $('Set Prompt and Output').item.json.prompt }}\\n\\nUse the following context (delimited by <ctx></ctx>) and the chat history to answer the user query.\\n<ctx>\\n{{ $json.concatenated_document_pageContent }}\\n</ctx>\"},\"promptType\":\"define\"},\"typeVersion\":1.8},{\"id\":\"d69f8d62-3064-40a8-b490-22772fbc38cd\",\"name\":\"Chat Buffer Memory\",\"type\":\"@n8n/n8n-nodes-langchain.memoryBufferWindow\",\"position\":[3500,620],\"parameters\":{\"sessionKey\":\"={{ $('Combined Fields').item.json.chat_memory_key }}\",\"sessionIdType\":\"customKey\",\"contextWindowLength\":10},\"typeVersion\":1.3},{\"id\":\"a399f8e6-fafd-4f73-a2de-894f1e3c4bec\",\"name\":\"Sticky Note4\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[1860,160],\"parameters\":{\"color\":7,\"width\":820,\"height\":580,\"content\":\"## Perform adaptive retrieval\\n**Find document considering both query and context.**\\n## Uyarlanabilir RAG gerçekleştirin\\n**Hem sorguyu hem de bağlamı dikkate alarak belge bulun.**\"},\"typeVersion\":1},{\"id\":\"7f10fe70-1af8-47ad-a9b5-2850412c43f8\",\"name\":\"Sticky Note5\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[2760,160],\"parameters\":{\"color\":7,\"width\":1060,\"height\":580,\"content\":\"## Reply to the user integrating retrieval context\\n## Kullanıcıya RAG bağlamını entegre ederek yanıt verin\"},\"typeVersion\":1},{\"id\":\"5cd0dd02-65f4-4351-aeae-c70ecf5f1d66\",\"name\":\"Respond to Webhook\",\"type\":\"n8n-nodes-base.respondToWebhook\",\"position\":[3540,400],\"parameters\":{\"options\":{}},\"typeVersion\":1.1},{\"id\":\"4c56ef8f-8fce-4525-bb87-15df37e91cc4\",\"name\":\"Sticky Note6\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[320,160],\"parameters\":{\"color\":7,\"width\":700,\"height\":580,\"content\":\"## User query classification\\n**Classify the query into one of four categories: Factual, Analytical, Opinion, or Contextual.**\\n## Kullanıcı sorgu sınıflandırması\\n**Sorguyu dört kategoriden birine sınıflandırın: Olgusal, Analitik, Görüş veya Bağlamsal.**\\n\"},\"typeVersion\":1},{\"id\":\"3ef73405-89de-4bed-9673-90e2c1f2e74b\",\"name\":\"When Executed by Another Workflow\",\"type\":\"n8n-nodes-base.executeWorkflowTrigger\",\"position\":[0,340],\"parameters\":{\"workflowInputs\":{\"values\":[{\"name\":\"user_query\"},{\"name\":\"chat_memory_key\"},{\"name\":\"vector_store_id\"}]}},\"typeVersion\":1.1},{\"id\":\"0785714f-c45c-4eda-9937-c97e44c9a449\",\"name\":\"Combined Fields\",\"type\":\"n8n-nodes-base.set\",\"position\":[140,480],\"parameters\":{\"options\":{},\"assignments\":{\"assignments\":[{\"id\":\"90ab73a2-fe01-451a-b9df-bffe950b1599\",\"name\":\"user_query\",\"type\":\"string\",\"value\":\"={{ $json.user_query || $json.chatInput }}\"},{\"id\":\"36686ff5-09fc-40a4-8335-a5dd1576e941\",\"name\":\"chat_memory_key\",\"type\":\"string\",\"value\":\"={{ $json.chat_memory_key || $('Chat').item.json.sessionId }}\"},{\"id\":\"4230c8f3-644c-4985-b710-a4099ccee77c\",\"name\":\"vector_store_id\",\"type\":\"string\",\"value\":\"={{ $json.vector_store_id || \\\"<ID HERE>\\\" }}\"}]}},\"typeVersion\":3.4},{\"id\":\"57a93b72-4233-4ba2-b8c7-99d88f0ed572\",\"name\":\"Sticky Note7\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[-1420,-560],\"parameters\":{\"color\":3,\"width\":1280,\"height\":1680,\"content\":\"# Uyarlanabilir RAG İş Akışı\\n\\nBu n8n iş akışı, Uyarlanabilir Geri Getirme Destekli Üretim (Adaptive RAG) yaklaşımının bir versiyonunu uygular. Kullanıcı sorgularını sınıflandırır ve sorgu türüne (Olgusal, Analitik, Görüş veya Bağlamsal) göre farklı geri getirme ve üretim stratejileri uygulayarak bir Qdrant vektör deposunda saklanan bilgi tabanından daha alakalı ve özel yanıtlar sunar.\\n\\n## Nasıl Çalışır?\\n\\n### Giriş Tetikleyicisi\\n\\n- İş akışı, yerleşik Sohbet arayüzü aracılığıyla veya başka bir n8n iş akışı tarafından tetiklenebilir.\\n- Girdiler beklenir: `user_query` (kullanıcı sorgusu), `chat_memory_key` (konuşma geçmişi için) ve `vector_store_id` (Qdrant koleksiyonunu belirten).\\n- Bir `Set` düğümü (`Combined Fields` - Birleştirilmiş Alanlar) bu girdileri standartlaştırır.\\n\\n### Sorgu Sınıflandırması\\n\\n- Bir Google Gemini ajanı (`Query Classification` - Sorgu Sınıflandırması) `user_query`'yi analiz eder.\\n- Sorguyu dört kategoriden birine sınıflandırır:\\n  - **Olgusal:** Belirli, doğrulanabilir bilgi arayan.\\n  - **Analitik:** Kapsamlı analiz veya açıklama gerektiren.\\n  - **Görüş:** Öznel konular hakkında soru soran veya farklı bakış açıları arayan.\\n  - **Bağlamsal:** Kullanıcıya özel veya örtük bağlama bağlı olan.\\n\\n### Uyarlanabilir Strateji Yönlendirmesi\\n\\n- Bir `Switch` düğümü (Yönlendirme Düğümü), iş akışını bir önceki adımdaki sınıflandırma sonucuna göre yönlendirir.\\n\\n### Strateji Uygulaması (Sorgu Uyarlaması)\\n\\n- Yönlendirmeye bağlı olarak, belirli bir Google Gemini ajanı sorguyu veya yaklaşımı uyarlar:\\n  - **Olgusal Strateji:** Anahtar varlıklara odaklanarak daha iyi kesinlik için sorguyu yeniden yazar (`Factual Strategy - Focus on Precision` - Olgusal Strateji - Kesinliğe Odaklanma).\\n  - **Analitik Strateji:** Kapsamlı bir şekilde ele alınmasını sağlamak için ana sorguyu birden fazla alt soruya böler (`Analytical Strategy - Comprehensive Coverage` - Analitik Strateji - Kapsamlı Ele Alma).\\n  - **Görüş Stratejisi:** Sorguyla ilgili farklı potansiyel bakış açılarını veya yaklaşımları tanımlar (`Opinion Strategy - Diverse Perspectives` - Görüş Stratejisi - Farklı Bakış Açıları).\\n  - **Bağlamsal Strateji:** Sorguyu etkili bir şekilde yanıtlamak için gereken örtük bağlamı çıkarır (`Contextual Strategy - User Context Integration` - Bağlamsal Strateji - Kullanıcı Bağlamı Entegrasyonu).\\n- Her strateji yolu, uyarlama adımı için kendi sohbet belleği tamponunu kullanır.\\n\\n### Geri Getirme İstemcisi ve Çıktı Kurulumu\\n\\n- *Orijinal* sorgu sınıflandırmasına dayanarak, bir `Set` düğümü (`Factual/Analytical/Opinion/Contextual Prompt and Output` - Olgusal/Analitik/Görüş/Bağlamsal İstemci ve Çıktı, `Set Prompt and Output` - İstemci ve Çıktı Ayarla düğümüne bağlantılar aracılığıyla birleştirilir) şunları hazırlar:\\n  - Strateji adımından gelen çıktı (örneğin, yeniden yazılmış sorgu, alt sorular, bakış açıları).\\n  - Son yanıt üretim ajanı için özel olarak hazırlanmış bir sistem istemcisi; sorgu türüne göre nasıl davranacağını belirtir (örneğin, Olgusal için kesinliğe odaklan, Görüş için farklı görüşler sun).\\n\\n### Belge Geri Getirme (RAG)\\n\\n- `Retrieve Documents from Vector Store` (Vektör Deposundan Belgeleri Geri Getir) düğümü, belirtilen Qdrant koleksiyonunda (`vector_store_id`) arama yapmak için strateji adımından gelen uyarlanmış sorguyu/çıktıyı kullanır.\\n- Google Gemini gömülerini (vektörlerini) kullanarak en alakalı belge parçalarını geri getirir.\\n\\n### Bağlam Hazırlığı\\n\\n- Geri getirilen belge parçalarından elde edilen içerik, son yanıt üretimi için tek bir bağlam bloğu oluşturmak üzere birleştirilir (`Concatenate Context` - Bağlamı Birleştir).\\n\\n### Yanıt Üretimi\\n\\n- Son `Answer` (Yanıt) ajanı (Google Gemini tarafından desteklenir) yanıtı üretir.\\n- Şunları kullanır:\\n  - 5. adımda ayarlanan özel sistem istemcisi.\\n  - Geri getirilen belgelerden birleştirilmiş bağlam (7. adım).\\n  - Orijinal `user_query`.\\n  - Paylaşılan sohbet geçmişi (`Chat Buffer Memory` - Sohbet Belleği Tamponu, `chat_memory_key` kullanılarak).\\n\\n### Yanıt\\n\\n- Üretilen yanıt, `Respond to Webhook` (Webhook'a Yanıt Ver) düğümü aracılığıyla kullanıcıya geri gönderilir.\\n\"},\"typeVersion\":1},{\"id\":\"bec8070f-2ce9-4930-b71e-685a2b21d3f2\",\"name\":\"Sticky Note8\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[-40,-20],\"parameters\":{\"color\":7,\"width\":320,\"height\":820,\"content\":\"## ⚠️  Using in Chat mode\\n\\nUpdate the `vector_store_id` variable to the corresponding Qdrant ID needed to perform the documents retrieval.\\n\\n## ⚠️ Sohbet modunda kullanım sağlayın\\n\\nvector_store_id` değişkenini belge alımını gerçekleştirmek için gereken ilgili Qdrant ID'sine güncelleyin.\"},\"typeVersion\":1},{\"id\":\"dc002d7a-df79-4d61-880a-db32917d9814\",\"name\":\"Sticky Note9\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[1220,580],\"parameters\":{},\"typeVersion\":1}],\"active\":true,\"pinData\":{},\"settings\":{},\"versionId\":\"fbee3fa8-a249-4841-b786-817f0992ae6b\",\"connections\":{\"Chat\":{\"main\":[[{\"node\":\"Combined Fields\",\"type\":\"main\",\"index\":0}]]},\"Answer\":{\"main\":[[{\"node\":\"Respond to Webhook\",\"type\":\"main\",\"index\":0}]]},\"Switch\":{\"main\":[[{\"node\":\"Factual Strategy - Focus on Precision\",\"type\":\"main\",\"index\":0}],[{\"node\":\"Analytical Strategy - Comprehensive Coverage\",\"type\":\"main\",\"index\":0}],[{\"node\":\"Opinion Strategy - Diverse Perspectives\",\"type\":\"main\",\"index\":0}],[{\"node\":\"Contextual Strategy - User Context Integration\",\"type\":\"main\",\"index\":0}]]},\"Embeddings\":{\"ai_embedding\":[[{\"node\":\"Retrieve Documents from Vector Store\",\"type\":\"ai_embedding\",\"index\":0}]]},\"Gemini Answer\":{\"ai_languageModel\":[[{\"node\":\"Answer\",\"type\":\"ai_languageModel\",\"index\":0}]]},\"Gemini Factual\":{\"ai_languageModel\":[[{\"node\":\"Factual Strategy - Focus on Precision\",\"type\":\"ai_languageModel\",\"index\":0}]]},\"Gemini Opinion\":{\"ai_languageModel\":[[{\"node\":\"Opinion Strategy - Diverse Perspectives\",\"type\":\"ai_languageModel\",\"index\":0}]]},\"Combined Fields\":{\"main\":[[{\"node\":\"Query Classification\",\"type\":\"main\",\"index\":0}]]},\"Gemini Analytical\":{\"ai_languageModel\":[[{\"node\":\"Analytical Strategy - Comprehensive Coverage\",\"type\":\"ai_languageModel\",\"index\":0}]]},\"Gemini Contextual\":{\"ai_languageModel\":[[{\"node\":\"Contextual Strategy - User Context Integration\",\"type\":\"ai_languageModel\",\"index\":0}]]},\"Chat Buffer Memory\":{\"ai_memory\":[[{\"node\":\"Answer\",\"type\":\"ai_memory\",\"index\":0}]]},\"Concatenate Context\":{\"main\":[[{\"node\":\"Answer\",\"type\":\"main\",\"index\":0}]]},\"Query Classification\":{\"main\":[[{\"node\":\"Switch\",\"type\":\"main\",\"index\":0}]]},\"Gemini Classification\":{\"ai_languageModel\":[[{\"node\":\"Query Classification\",\"type\":\"ai_languageModel\",\"index\":0}]]},\"Set Prompt and Output\":{\"main\":[[{\"node\":\"Retrieve Documents from Vector Store\",\"type\":\"main\",\"index\":0}]]},\"Factual Prompt and Output\":{\"main\":[[{\"node\":\"Set Prompt and Output\",\"type\":\"main\",\"index\":0}]]},\"Opinion Prompt and Output\":{\"main\":[[{\"node\":\"Set Prompt and Output\",\"type\":\"main\",\"index\":0}]]},\"Chat Buffer Memory Factual\":{\"ai_memory\":[[{\"node\":\"Factual Strategy - Focus on Precision\",\"type\":\"ai_memory\",\"index\":0}]]},\"Chat Buffer Memory Opinion\":{\"ai_memory\":[[{\"node\":\"Opinion Strategy - Diverse Perspectives\",\"type\":\"ai_memory\",\"index\":0}]]},\"Analytical Prompt and Output\":{\"main\":[[{\"node\":\"Set Prompt and Output\",\"type\":\"main\",\"index\":0}]]},\"Contextual Prompt and Output\":{\"main\":[[{\"node\":\"Set Prompt and Output\",\"type\":\"main\",\"index\":0}]]},\"Chat Buffer Memory Analytical\":{\"ai_memory\":[[{\"node\":\"Analytical Strategy - Comprehensive Coverage\",\"type\":\"ai_memory\",\"index\":0}]]},\"Chat Buffer Memory Contextual\":{\"ai_memory\":[[{\"node\":\"Contextual Strategy - User Context Integration\",\"type\":\"ai_memory\",\"index\":0}]]},\"When Executed by Another Workflow\":{\"main\":[[{\"node\":\"Combined Fields\",\"type\":\"main\",\"index\":0}]]},\"Retrieve Documents from Vector Store\":{\"main\":[[{\"node\":\"Concatenate Context\",\"type\":\"main\",\"index\":0}]]},\"Factual Strategy - Focus on Precision\":{\"main\":[[{\"node\":\"Factual Prompt and Output\",\"type\":\"main\",\"index\":0}]]},\"Opinion Strategy - Diverse Perspectives\":{\"main\":[[{\"node\":\"Opinion Prompt and Output\",\"type\":\"main\",\"index\":0}]]},\"Analytical Strategy - Comprehensive Coverage\":{\"main\":[[{\"node\":\"Analytical Prompt and Output\",\"type\":\"main\",\"index\":0}]]},\"Contextual Strategy - User Context Integration\":{\"main\":[[{\"node\":\"Contextual Prompt and Output\",\"type\":\"main\",\"index\":0}]]}}}",
  "readme": "**Description**  \nThis workflow automatically classifies user queries and retrieves the most relevant information based on the query type. 🌟 It uses adaptive strategies like;  \nFactual, Analytical, Opinion, and Contextual to deliver more precise and meaningful responses by leveraging n8n's flexibility. Integrated with Qdrant vector store and Google Gemini, it processes each query faster and more effectively. 🚀\n\n**How It Works?**  \nQuery Reception: A user query is triggered (e.g., through a chatbot interface). 💬\n\n_Classification_ : The query is classified into one of four categories:\n\n_Factual_ : Queries seeking verifiable information.\n\n_Analytical_ : Queries that require in-depth analysis or explanation.\n\n_Opinion_ : Queries looking for different perspectives or subjective viewpoints.\n\n_Contextual_ : Queries specific to the user or certain contextual conditions.\n\n_Adaptive Strategy Application_ : Based on classification, the query is restructured using the relevant strategy for better results.\n\nResponse Generation**: The most relevant documents and context are used to generate a tailored response. 🎯\n\n**Set Up Steps**\n\nEstimated Time: ⏳ 10-15 minutes  \nPrerequisites: You need an n8n account and a Qdrant vector store connection.  \nSteps:\n\nImport the n8n workflow: Load the workflow into your n8n instance.\n\nConnect Google Gemini and Qdrant: Link these tools for query processing and data retrieval.\n\nConnect the Trigger Interface: Integrate with a chatbot or API to trigger the workflow.\n\nCustomize: Adjust settings based on the query types you want to handle and the output format. 🔧\n\n**For more detailed instructions, please check the sticky notes inside the workflow. 📌**\n",
  "readme_html": "<!--[--><div data-v-859c7806=\"\"><p><strong>Description</strong><br>\nThis workflow automatically classifies user queries and retrieves the most relevant information based on the query type. 🌟 It uses adaptive strategies like;<br>\nFactual, Analytical, Opinion, and Contextual to deliver more precise and meaningful responses by leveraging n8n's flexibility. Integrated with Qdrant vector store and Google Gemini, it processes each query faster and more effectively. 🚀</p>\n<p><strong>How It Works?</strong><br>\nQuery Reception: A user query is triggered (e.g., through a chatbot interface). 💬</p>\n<p><em>Classification</em>: The query is classified into one of four categories:</p>\n<p><em>Factual</em>: Queries seeking verifiable information.</p>\n<p><em>Analytical</em>: Queries that require in-depth analysis or explanation.</p>\n<p><em>Opinion</em>: Queries looking for different perspectives or subjective viewpoints.</p>\n<p><em>Contextual</em>: Queries specific to the user or certain contextual conditions.</p>\n<p><em>Adaptive Strategy Application</em>: Based on classification, the query is restructured using the relevant strategy for better results.</p>\n<p>Response Generation**: The most relevant documents and context are used to generate a tailored response. 🎯</p>\n<p><strong>Set Up Steps</strong></p>\n<p>Estimated Time: ⏳ 10-15 minutes<br>\nPrerequisites: You need an n8n account and a Qdrant vector store connection.<br>\nSteps:</p>\n<p>Import the n8n workflow: Load the workflow into your n8n instance.</p>\n<p>Connect Google Gemini and Qdrant: Link these tools for query processing and data retrieval.</p>\n<p>Connect the Trigger Interface: Integrate with a chatbot or API to trigger the workflow.</p>\n<p>Customize: Adjust settings based on the query types you want to handle and the output format. 🔧</p>\n<p><strong>For more detailed instructions, please check the sticky notes inside the workflow. 📌</strong></p>\n</div><!--]-->",
  "readme_zh": "**描述**  \n该工作流能自动对用户查询进行分类，并根据查询类型检索最相关的信息。🌟 它采用自适应策略（如事实型、分析型、观点型和情境型），结合n8n的灵活性，提供更精准、有意义的响应。通过与Qdrant向量数据库和Google Gemini集成，可快速高效地处理每项查询。🚀  \n\n**工作原理**  \n查询接收：通过聊天机器人界面等触发用户查询。💬  \n\n_分类_：查询将被归入以下四类之一：  \n\n_事实型_：寻求可验证信息的查询。  \n\n_分析型_：需要深入分析或解释的查询。  \n\n_观点型_：寻求不同视角或主观看法的查询。  \n\n_情境型_：与用户特定情境或条件相关的查询。  \n\n_应用自适应策略_：根据分类结果，使用相应策略重构查询以获得更佳结果。  \n\n_生成响应_：结合最相关的文档和上下文生成定制化回答。🎯  \n\n**设置步骤**  \n\n预计耗时：⏳ 10-15分钟  \n前提条件：需拥有n8n账户并已连接Qdrant向量数据库。  \n步骤：  \n\n1. 导入n8n工作流：将工作流加载至您的n8n实例中。  \n2. 连接Google Gemini与Qdrant：关联这些工具以实现查询处理和数据检索。  \n3. 连接触发接口：与聊天机器人或API集成以触发工作流。  \n4. 自定义：根据需处理的查询类型和输出格式调整设置。🔧  \n\n**更多详细说明，请查看工作流内的置顶注释。📌**",
  "title_zh": "自适应RAG结合Google Gemini与Qdrant：情境感知式查询应答",
  "publish_date_zh": "最后更新于3天前",
  "workflow_json_zh": "{\n  \"id\": \"uZtDG9wLeCBZbaoK\",\n  \"meta\": {\n    \"instanceId\": \"2848b874676d610ec8f8106a5acf41448278a62b14e4a776b42d6977aab508d7\",\n    \"templateId\": \"3459\"\n  },\n  \"name\": \"RAG 2.0 - Answer Architecture\",\n  \"tags\": [],\n  \"nodes\": [\n    {\n      \"id\": \"856bd809-8f41-41af-8f72-a3828229c2a5\",\n      \"name\": \"Query Classification\",\n      \"type\": \"@n8n/n8n-nodes-langchain.agent\",\n      \"notes\": \"Classify a query into one of four categories: Factual, Analytical, Opinion, or Contextual.\\n        \\nReturns:\\nstr: Query category\",\n      \"position\": [\n        420,\n        340\n      ],\n      \"parameters\": {\n        \"text\": \"=Classify this query: {{ $('Combined Fields').item.json.user_query }}\",\n        \"options\": {\n          \"systemMessage\": \"You are an expert at classifying questions. \\n\\nClassify the given query into exactly one of these categories:\\n- Factual: Queries seeking specific, verifiable information.\\n- Analytical: Queries requiring comprehensive analysis or explanation.\\n- Opinion: Queries about subjective matters or seeking diverse viewpoints.\\n- Contextual: Queries that depend on user-specific context.\\n\\nReturn ONLY the category name, without any explanation or additional text.\"\n        },\n        \"promptType\": \"define\"\n      },\n      \"typeVersion\": 1.8\n    },\n    {\n      \"id\": \"cc2106fc-f1a8-45ef-b37b-ab981ac13466\",\n      \"name\": \"Switch\",\n      \"type\": \"n8n-nodes-base.switch\",\n      \"position\": [\n        780,\n        380\n      ],\n      \"parameters\": {\n        \"rules\": {\n          \"values\": [\n            {\n              \"outputKey\": \"Factual\",\n              \"conditions\": {\n                \"options\": {\n                  \"version\": 2,\n                  \"leftValue\": \"\",\n                  \"caseSensitive\": true,\n                  \"typeValidation\": \"strict\"\n                },\n                \"combinator\": \"and\",\n                \"conditions\": [\n                  {\n                    \"id\": \"87f3b50c-9f32-4260-ac76-19c05b28d0b4\",\n                    \"operator\": {\n                      \"type\": \"string\",\n                      \"operation\": \"equals\"\n                    },\n                    \"leftValue\": \"={{ $json.output.trim() }}\",\n                    \"rightValue\": \"Factual\"\n                  }\n                ]\n              },\n              \"renameOutput\": true\n            },\n            {\n              \"outputKey\": \"Analytical\",\n              \"conditions\": {\n                \"options\": {\n                  \"version\": 2,\n                  \"leftValue\": \"\",\n                  \"caseSensitive\": true,\n                  \"typeValidation\": \"strict\"\n                },\n                \"combinator\": \"and\",\n                \"conditions\": [\n                  {\n                    \"id\": \"f8651b36-79fa-4be4-91fb-0e6d7deea18f\",\n                    \"operator\": {\n                      \"name\": \"filter.operator.equals\",\n                      \"type\": \"string\",\n                      \"operation\": \"equals\"\n                    },\n                    \"leftValue\": \"={{ $json.output.trim() }}\",\n                    \"rightValue\": \"Analytical\"\n                  }\n                ]\n              },\n              \"renameOutput\": true\n            },\n            {\n              \"outputKey\": \"Opinion\",\n              \"conditions\": {\n                \"options\": {\n                  \"version\": 2,\n                  \"leftValue\": \"\",\n                  \"caseSensitive\": true,\n                  \"typeValidation\": \"strict\"\n                },\n                \"combinator\": \"and\",\n                \"conditions\": [\n                  {\n                    \"id\": \"5dde06bc-5fe1-4dca-b6e2-6857c5e96d49\",\n                    \"operator\": {\n                      \"name\": \"filter.operator.equals\",\n                      \"type\": \"string\",\n                      \"operation\": \"equals\"\n                    },\n                    \"leftValue\": \"={{ $json.output.trim() }}\",\n                    \"rightValue\": \"Opinion\"\n                  }\n                ]\n              },\n              \"renameOutput\": true\n            },\n            {\n              \"outputKey\": \"Contextual\",\n              \"conditions\": {\n                \"options\": {\n                  \"version\": 2,\n                  \"leftValue\": \"\",\n                  \"caseSensitive\": true,\n                  \"typeValidation\": \"strict\"\n                },\n                \"combinator\": \"and\",\n                \"conditions\": [\n                  {\n                    \"id\": \"bf97926d-7a0b-4e2f-aac0-a820f73344d8\",\n                    \"operator\": {\n                      \"name\": \"filter.operator.equals\",\n                      \"type\": \"string\",\n                      \"operation\": \"equals\"\n                    },\n                    \"leftValue\": \"={{ $json.output.trim() }}\",\n                    \"rightValue\": \"Contextual\"\n                  }\n                ]\n              },\n              \"renameOutput\": true\n            }\n          ]\n        },\n        \"options\": {\n          \"fallbackOutput\": 0\n        }\n      },\n      \"typeVersion\": 3.2\n    },\n    {\n      \"id\": \"63889cad-1283-4dbf-ba16-2b6cf575f24a\",\n      \"name\": \"Factual Strategy - Focus on Precision\",\n      \"type\": \"@n8n/n8n-nodes-langchain.agent\",\n      \"notes\": \"Retrieval strategy for factual queries focusing on precision.\",\n      \"position\": [\n        1180,\n        -440\n      ],\n      \"parameters\": {\n        \"text\": \"=Enhance this factual query: {{ $('Combined Fields').item.json.user_query }}\",\n        \"options\": {\n          \"systemMessage\": \"=You are an expert at enhancing search queries.\\n\\nYour task is to reformulate the given factual query to make it more precise and specific for information retrieval. Focus on key entities and their relationships.\\n\\nProvide ONLY the enhanced query without any explanation.\"\n        },\n        \"promptType\": \"define\"\n      },\n      \"typeVersion\": 1.7\n    },\n    {\n      \"id\": \"020d2201-9590-400d-b496-48c65801271c\",\n      \"name\": \"Analytical Strategy - Comprehensive Coverage\",\n      \"type\": \"@n8n/n8n-nodes-langchain.agent\",\n      \"notes\": \"Retrieval strategy for analytical queries focusing on comprehensive coverage.\",\n      \"position\": [\n        1180,\n        140\n      ],\n      \"parameters\": {\n        \"text\": \"=Generate sub-questions for this analytical query: {{ $('Combined Fields').item.json.user_query }}\",\n        \"options\": {\n          \"systemMessage\": \"=You are an expert at breaking down complex questions.\\n\\nGenerate sub-questions that explore different aspects of the main analytical query.\\nThese sub-questions should cover the breadth of the topic and help retrieve comprehensive information.\\n\\nReturn a list of exactly 3 sub-questions, one per line.\"\n        },\n        \"promptType\": \"define\"\n      },\n      \"typeVersion\": 1.7\n    },\n    {\n      \"id\": \"c35d1b95-68c8-4237-932d-4744f620760d\",\n      \"name\": \"Opinion Strategy - Diverse Perspectives\",\n      \"type\": \"@n8n/n8n-nodes-langchain.agent\",\n      \"notes\": \"Retrieval strategy for opinion queries focusing on diverse perspectives.\",\n      \"position\": [\n        1220,\n        700\n      ],\n      \"parameters\": {\n        \"text\": \"=Identify different perspectives on: {{ $('Combined Fields').item.json.user_query }}\",\n        \"options\": {\n          \"systemMessage\": \"=You are an expert at identifying different perspectives on a topic.\\n\\nFor the given query about opinions or viewpoints, identify different perspectives that people might have on this topic.\\n\\nReturn a list of exactly 3 different viewpoint angles, one per line.\"\n        },\n        \"promptType\": \"define\"\n      },\n      \"typeVersion\": 1.7\n    },\n    {\n      \"id\": \"363a3fc3-112f-40df-891e-0a5aa3669245\",\n      \"name\": \"Contextual Strategy - User Context Integration\",\n      \"type\": \"@n8n/n8n-nodes-langchain.agent\",\n      \"notes\": \"Retrieval strategy for contextual queries integrating user context.\",\n      \"position\": [\n        1180,\n        1320\n      ],\n      \"parameters\": {\n        \"text\": \"=Infer the implied context in this query: {{ $('Combined Fields').item.json.user_query }}\",\n        \"options\": {\n          \"systemMessage\": \"=You are an expert at understanding implied context in questions.\\n\\nFor the given query, infer what contextual information might be relevant or implied but not explicitly stated. Focus on what background would help answering this query.\\n\\nReturn a brief description of the implied context.\"\n        },\n        \"promptType\": \"define\"\n      },\n      \"typeVersion\": 1.7\n    },\n    {\n      \"id\": \"45887701-5ea5-48b4-9b2b-40a80238ab0c\",\n      \"name\": \"Chat\",\n      \"type\": \"@n8n/n8n-nodes-langchain.chatTrigger\",\n      \"position\": [\n        0,\n        640\n      ],\n      \"webhookId\": \"56f626b5-339e-48af-857f-1d4198fc8a4d\",\n      \"parameters\": {\n        \"options\": {}\n      },\n      \"typeVersion\": 1.1\n    },\n    {\n      \"id\": \"7f7df364-4829-4e29-be3d-d13a63f65b8f\",\n      \"name\": \"Factual Prompt and Output\",\n      \"type\": \"n8n-nodes-base.set\",\n      \"position\": [\n        1640,\n        -300\n      ],\n      \"parameters\": {\n        \"options\": {},\n        \"assignments\": {\n          \"assignments\": [\n            {\n              \"id\": \"a4a28ac2-4a56-46f6-8b86-f5d1a34b2ced\",\n              \"name\": \"output\",\n              \"type\": \"string\",\n              \"value\": \"={{ $json.output }}\"\n            },\n            {\n              \"id\": \"7aa6ce13-afbf-4871-b81c-6e9c722a53dc\",\n              \"name\": \"prompt\",\n              \"type\": \"string\",\n              \"value\": \"You are a helpful assistant providing factual information. Answer the question based on the provided context. Focus on accuracy and precision. If the context doesn't contain the information needed, acknowledge the limitations.\"\n            }\n          ]\n        }\n      },\n      \"typeVersion\": 3.4\n    },\n    {\n      \"id\": \"590d8667-69eb-4db2-b5be-714c602b319a\",\n      \"name\": \"Contextual Prompt and Output\",\n      \"type\": \"n8n-nodes-base.set\",\n      \"position\": [\n        1640,\n        1400\n      ],\n      \"parameters\": {\n        \"options\": {},\n        \"assignments\": {\n          \"assignments\": [\n            {\n              \"id\": \"a4a28ac2-4a56-46f6-8b86-f5d1a34b2ced\",\n              \"name\": \"output\",\n              \"type\": \"string\",\n              \"value\": \"={{ $json.output }}\"\n            },\n            {\n              \"id\": \"7aa6ce13-afbf-4871-b81c-6e9c722a53dc\",\n              \"name\": \"prompt\",\n              \"type\": \"string\",\n              \"value\": \"You are a helpful assistant providing contextually relevant information. Answer the question considering both the query and its context. Make connections between the query context and the information in the provided documents. If the context doesn't fully address the specific situation, acknowledge the limitations.\"\n            }\n          ]\n        }\n      },\n      \"typeVersion\": 3.4\n    },\n    {\n      \"id\": \"fa3228ee-62d8-4c02-9dca-8a1ebc6afc74\",\n      \"name\": \"Opinion Prompt and Output\",\n      \"type\": \"n8n-nodes-base.set\",\n      \"position\": [\n        1620,\n        820\n      ],\n      \"parameters\": {\n        \"options\": {},\n        \"assignments\": {\n          \"assignments\": [\n            {\n              \"id\": \"a4a28ac2-4a56-46f6-8b86-f5d1a34b2ced\",\n              \"name\": \"output\",\n              \"type\": \"string\",\n              \"value\": \"={{ $json.output }}\"\n            },\n            {\n              \"id\": \"7aa6ce13-afbf-4871-b81c-6e9c722a53dc\",\n              \"name\": \"prompt\",\n              \"type\": \"string\",\n              \"value\": \"You are a helpful assistant discussing topics with multiple viewpoints. Based on the provided context, present different perspectives on the topic. Ensure fair representation of diverse opinions without showing bias. Acknowledge where the context presents limited viewpoints.\"\n            }\n          ]\n        }\n      },\n      \"typeVersion\": 3.4\n    },\n    {\n      \"id\": \"c769a76a-fb26-46a1-a00d-825b689d5f7a\",\n      \"name\": \"Analytical Prompt and Output\",\n      \"type\": \"n8n-nodes-base.set\",\n      \"position\": [\n        1620,\n        220\n      ],\n      \"parameters\": {\n        \"options\": {},\n        \"assignments\": {\n          \"assignments\": [\n            {\n              \"id\": \"a4a28ac2-4a56-46f6-8b86-f5d1a34b2ced\",\n              \"name\": \"output\",\n              \"type\": \"string\",\n              \"value\": \"={{ $json.output }}\"\n            },\n            {\n              \"id\": \"7aa6ce13-afbf-4871-b81c-6e9c722a53dc\",\n              \"name\": \"prompt\",\n              \"type\": \"string\",\n              \"value\": \"You are a helpful assistant providing analytical insights. Based on the provided context, offer a comprehensive analysis of the topic. Cover different aspects and perspectives in your explanation. If the context has gaps, acknowledge them while providing the best analysis possible.\"\n            }\n          ]\n        }\n      },\n      \"typeVersion\": 3.4\n    },\n    {\n      \"id\": \"fcd29f6b-17e8-442c-93f9-b93fbad7cd10\",\n      \"name\": \"Gemini Classification\",\n      \"type\": \"@n8n/n8n-nodes-langchain.lmChatGoogleGemini\",\n      \"position\": [\n        580,\n        600\n      ],\n      \"parameters\": {\n        \"options\": {},\n        \"modelName\": \"models/gemini-2.0-flash-lite\"\n      },\n      \"credentials\": {\n        \"googlePalmApi\": {\n          \"id\": \"vGGCUG66DLA8zNyX\",\n          \"name\": \"Google Gemini(PaLM) Api account\"\n        }\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"c0828ee3-f184-41f5-9a25-0f1059b03711\",\n      \"name\": \"Gemini Factual\",\n      \"type\": \"@n8n/n8n-nodes-langchain.lmChatGoogleGemini\",\n      \"position\": [\n        1240,\n        -240\n      ],\n      \"parameters\": {\n        \"options\": {},\n        \"modelName\": \"models/gemini-2.0-flash\"\n      },\n      \"credentials\": {\n        \"googlePalmApi\": {\n          \"id\": \"vGGCUG66DLA8zNyX\",\n          \"name\": \"Google Gemini(PaLM) Api account\"\n        }\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"98f9981d-ea8e-45cb-b91d-3c8d1fe33e25\",\n      \"name\": \"Gemini Analytical\",\n      \"type\": \"@n8n/n8n-nodes-langchain.lmChatGoogleGemini\",\n      \"position\": [\n        1240,\n        340\n      ],\n      \"parameters\": {\n        \"options\": {},\n        \"modelName\": \"models/gemini-2.0-flash\"\n      },\n      \"credentials\": {\n        \"googlePalmApi\": {\n          \"id\": \"vGGCUG66DLA8zNyX\",\n          \"name\": \"Google Gemini(PaLM) Api account\"\n        }\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"c85f270d-3224-4e60-9acf-91f173dfe377\",\n      \"name\": \"Chat Buffer Memory Analytical\",\n      \"type\": \"@n8n/n8n-nodes-langchain.memoryBufferWindow\",\n      \"position\": [\n        1400,\n        340\n      ],\n      \"parameters\": {\n        \"sessionKey\": \"={{ $('Combined Fields').item.json.chat_memory_key }}\",\n        \"sessionIdType\": \"customKey\",\n        \"contextWindowLength\": 10\n      },\n      \"typeVersion\": 1.3\n    },\n    {\n      \"id\": \"c39ba907-7388-4152-965a-e28e626bc9b2\",\n      \"name\": \"Chat Buffer Memory Factual\",\n      \"type\": \"@n8n/n8n-nodes-langchain.memoryBufferWindow\",\n      \"position\": [\n        1400,\n        -240\n      ],\n      \"parameters\": {\n        \"sessionKey\": \"={{ $('Combined Fields').item.json.chat_memory_key }}\",\n        \"sessionIdType\": \"customKey\",\n        \"contextWindowLength\": 10\n      },\n      \"typeVersion\": 1.3\n    },\n    {\n      \"id\": \"52dcd9f0-e6b3-4d33-bc6f-621ef880178e\",\n      \"name\": \"Gemini Opinion\",\n      \"type\": \"@n8n/n8n-nodes-langchain.lmChatGoogleGemini\",\n      \"position\": [\n        1280,\n        900\n      ],\n      \"parameters\": {\n        \"options\": {},\n        \"modelName\": \"models/gemini-2.0-flash\"\n      },\n      \"credentials\": {\n        \"googlePalmApi\": {\n          \"id\": \"vGGCUG66DLA8zNyX\",\n          \"name\": \"Google Gemini(PaLM) Api account\"\n        }\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"147a709a-4b46-4835-82cf-7d6b633acd4c\",\n      \"name\": \"Chat Buffer Memory Opinion\",\n      \"type\": \"@n8n/n8n-nodes-langchain.memoryBufferWindow\",\n      \"position\": [\n        1440,\n        900\n      ],\n      \"parameters\": {\n        \"sessionKey\": \"={{ $('Combined Fields').item.json.chat_memory_key }}\",\n        \"sessionIdType\": \"customKey\",\n        \"contextWindowLength\": 10\n      },\n      \"typeVersion\": 1.3\n    },\n    {\n      \"id\": \"3cb6bf32-5937-49b9-acf7-d7d01dc2ddd1\",\n      \"name\": \"Gemini Contextual\",\n      \"type\": \"@n8n/n8n-nodes-langchain.lmChatGoogleGemini\",\n      \"position\": [\n        1240,\n        1500\n      ],\n      \"parameters\": {\n        \"options\": {},\n        \"modelName\": \"models/gemini-2.0-flash\"\n      },\n      \"credentials\": {\n        \"googlePalmApi\": {\n          \"id\": \"vGGCUG66DLA8zNyX\",\n          \"name\": \"Google Gemini(PaLM) Api account\"\n        }\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"5916c4f1-4369-4d66-8553-2fff006b7e69\",\n      \"name\": \"Chat Buffer Memory Contextual\",\n      \"type\": \"@n8n/n8n-nodes-langchain.memoryBufferWindow\",\n      \"position\": [\n        1420,\n        1500\n      ],\n      \"parameters\": {\n        \"sessionKey\": \"={{ $('Combined Fields').item.json.chat_memory_key }}\",\n        \"sessionIdType\": \"customKey\",\n        \"contextWindowLength\": 10\n      },\n      \"typeVersion\": 1.3\n    },\n    {\n      \"id\": \"d33377c2-6b98-4e4d-968f-f3085354ae50\",\n      \"name\": \"Embeddings\",\n      \"type\": \"@n8n/n8n-nodes-langchain.embeddingsGoogleGemini\",\n      \"notes\": \"{ $node[\\\"Embeddings\\\"].json.response }}\",\n      \"position\": [\n        2400,\n        600\n      ],\n      \"parameters\": {\n        \"modelName\": \"models/text-embedding-004\"\n      },\n      \"credentials\": {\n        \"googlePalmApi\": {\n          \"id\": \"vGGCUG66DLA8zNyX\",\n          \"name\": \"Google Gemini(PaLM) Api account\"\n        }\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"32d9a0c0-0889-4cb2-a088-8ee9cfecacd3\",\n      \"name\": \"Sticky Note\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"position\": [\n        1100,\n        -600\n      ],\n      \"parameters\": {\n        \"color\": 7,\n        \"width\": 700,\n        \"height\": 520,\n        \"content\": \"## 事实性策略\\n**获取精确的事实和数据。**\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"064a4729-717c-40c8-824a-508406610a13\",\n      \"name\": \"Sticky Note1\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"position\": [\n        1100,\n        -40\n      ],\n      \"parameters\": {\n        \"color\": 7,\n        \"width\": 700,\n        \"height\": 520,\n        \"content\": \"## 分析策略  \\n**全面涵盖主题内容并探索其不同方面。**  \\n## 分析策略  \\n**确保对某一主题进行全面探讨，并挖掘其不同维度。**  \\n\\n（注：根据中文表达习惯对两处标题进行了统一处理，并采用意译方式使\\\"comprehensive coverage\\\"和\\\"exploring different aspects\\\"更符合中文语境。第二段虽为土耳其语，但内容与首段英文一致，故采用相同译法保持一致性。）\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"9fd52a28-44bc-4dfd-bdb7-90987cc2f4fb\",\n      \"name\": \"Sticky Note2\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"position\": [\n        1100,\n        520\n      ],\n      \"parameters\": {\n        \"color\": 7,\n        \"width\": 700,\n        \"height\": 520,\n        \"content\": \"## 观点策略  \\n**针对主观议题收集多元观点。**\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"3797b21f-cc2a-4210-aa63-6d181d413c5e\",\n      \"name\": \"Sticky Note3\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"position\": [\n        1100,\n        1100\n      ],\n      \"parameters\": {\n        \"color\": 7,\n        \"width\": 700,\n        \"height\": 540,\n        \"content\": \"## 情境化策略  \\n**融入用户专属情境以优化检索效果**  \\n\\n注：根据翻译规范，标题保留了原文的层级结构（##），术语\\\"contextual\\\"译为\\\"情境化\\\"更符合中文技术文本习惯，\\\"fine-tune\\\"采用\\\"优化\\\"而非字面直译以突出功能目的性。土耳其语部分因不在翻译要求范围内未作处理。\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"16fa1531-9fb9-4b12-961c-be12e20b2134\",\n      \"name\": \"Concatenate Context\",\n      \"type\": \"n8n-nodes-base.summarize\",\n      \"position\": [\n        2900,\n        380\n      ],\n      \"parameters\": {\n        \"options\": {},\n        \"fieldsToSummarize\": {\n          \"values\": [\n            {\n              \"field\": \"document.pageContent\",\n              \"separateBy\": \"other\",\n              \"aggregation\": \"concatenate\",\n              \"customSeparator\": \"={{ \\\"\\\\n\\\\n---\\\\n\\\\n\\\" }}\"\n            }\n          ]\n        }\n      },\n      \"typeVersion\": 1.1\n    },\n    {\n      \"id\": \"4d6147d1-7a3d-42ab-b23f-cdafe8ea30b0\",\n      \"name\": \"Retrieve Documents from Vector Store\",\n      \"type\": \"@n8n/n8n-nodes-langchain.vectorStoreQdrant\",\n      \"position\": [\n        2140,\n        380\n      ],\n      \"parameters\": {\n        \"mode\": \"load\",\n        \"topK\": 10,\n        \"prompt\": \"=Prompt\\n{{ $json.prompt }}\\n\\nUser query: \\n{{ $json.output }}\",\n        \"options\": {},\n        \"qdrantCollection\": {\n          \"__rl\": true,\n          \"mode\": \"id\",\n          \"value\": \"=vector_store_id\"\n        }\n      },\n      \"credentials\": {\n        \"qdrantApi\": {\n          \"id\": \"ivp7KsCQyRCs5owS\",\n          \"name\": \"QdrantApi account\"\n        }\n      },\n      \"executeOnce\": false,\n      \"notesInFlow\": false,\n      \"retryOnFail\": false,\n      \"typeVersion\": 1.1,\n      \"alwaysOutputData\": false\n    },\n    {\n      \"id\": \"7e68f9cb-0a0d-4215-8083-3b9ef92cd237\",\n      \"name\": \"Set Prompt and Output\",\n      \"type\": \"n8n-nodes-base.set\",\n      \"position\": [\n        1900,\n        460\n      ],\n      \"parameters\": {\n        \"options\": {},\n        \"assignments\": {\n          \"assignments\": [\n            {\n              \"id\": \"1d782243-0571-4845-b8fe-4c6c4b55379e\",\n              \"name\": \"output\",\n              \"type\": \"string\",\n              \"value\": \"={{ $json.output }}\"\n            },\n            {\n              \"id\": \"547091fb-367c-44d4-ac39-24d073da70e0\",\n              \"name\": \"prompt\",\n              \"type\": \"string\",\n              \"value\": \"={{ $json.prompt }}\"\n            }\n          ]\n        }\n      },\n      \"typeVersion\": 3.4\n    },\n    {\n      \"id\": \"0c623ca1-da85-48a3-9d8b-90d97283a015\",\n      \"name\": \"Gemini Answer\",\n      \"type\": \"@n8n/n8n-nodes-langchain.lmChatGoogleGemini\",\n      \"position\": [\n        3340,\n        620\n      ],\n      \"parameters\": {\n        \"options\": {},\n        \"modelName\": \"models/gemini-2.0-flash\"\n      },\n      \"credentials\": {\n        \"googlePalmApi\": {\n          \"id\": \"vGGCUG66DLA8zNyX\",\n          \"name\": \"Google Gemini(PaLM) Api account\"\n        }\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"fab91e48-1c62-46a8-b9fc-39704f225274\",\n      \"name\": \"Answer\",\n      \"type\": \"@n8n/n8n-nodes-langchain.agent\",\n      \"position\": [\n        3120,\n        380\n      ],\n      \"parameters\": {\n        \"text\": \"=User query: {{ $('Combined Fields').item.json.user_query }}\",\n        \"options\": {\n          \"systemMessage\": \"={{ $('Set Prompt and Output').item.json.prompt }}\\n\\nUse the following context (delimited by <ctx></ctx>) and the chat history to answer the user query.\\n<ctx>\\n{{ $json.concatenated_document_pageContent }}\\n</ctx>\"\n        },\n        \"promptType\": \"define\"\n      },\n      \"typeVersion\": 1.8\n    },\n    {\n      \"id\": \"d69f8d62-3064-40a8-b490-22772fbc38cd\",\n      \"name\": \"Chat Buffer Memory\",\n      \"type\": \"@n8n/n8n-nodes-langchain.memoryBufferWindow\",\n      \"position\": [\n        3500,\n        620\n      ],\n      \"parameters\": {\n        \"sessionKey\": \"={{ $('Combined Fields').item.json.chat_memory_key }}\",\n        \"sessionIdType\": \"customKey\",\n        \"contextWindowLength\": 10\n      },\n      \"typeVersion\": 1.3\n    },\n    {\n      \"id\": \"a399f8e6-fafd-4f73-a2de-894f1e3c4bec\",\n      \"name\": \"Sticky Note4\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"position\": [\n        1860,\n        160\n      ],\n      \"parameters\": {\n        \"color\": 7,\n        \"width\": 820,\n        \"height\": 580,\n        \"content\": \"## 执行自适应检索  \\n**结合查询与上下文查找文档。**  \\n## 实施自适应RAG  \\n**综合考虑查询和上下文以定位文档。**\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"7f10fe70-1af8-47ad-a9b5-2850412c43f8\",\n      \"name\": \"Sticky Note5\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"position\": [\n        2760,\n        160\n      ],\n      \"parameters\": {\n        \"color\": 7,\n        \"width\": 1060,\n        \"height\": 580,\n        \"content\": \"## 结合检索结果向用户回复\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"5cd0dd02-65f4-4351-aeae-c70ecf5f1d66\",\n      \"name\": \"Respond to Webhook\",\n      \"type\": \"n8n-nodes-base.respondToWebhook\",\n      \"position\": [\n        3540,\n        400\n      ],\n      \"parameters\": {\n        \"options\": {}\n      },\n      \"typeVersion\": 1.1\n    },\n    {\n      \"id\": \"4c56ef8f-8fce-4525-bb87-15df37e91cc4\",\n      \"name\": \"Sticky Note6\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"position\": [\n        320,\n        160\n      ],\n      \"parameters\": {\n        \"color\": 7,\n        \"width\": 700,\n        \"height\": 580,\n        \"content\": \"## 用户查询分类  \\n**将查询归类为以下四种类型之一：事实型、分析型、观点型或情境型。**\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"3ef73405-89de-4bed-9673-90e2c1f2e74b\",\n      \"name\": \"When Executed by Another Workflow\",\n      \"type\": \"n8n-nodes-base.executeWorkflowTrigger\",\n      \"position\": [\n        0,\n        340\n      ],\n      \"parameters\": {\n        \"workflowInputs\": {\n          \"values\": [\n            {\n              \"name\": \"user_query\"\n            },\n            {\n              \"name\": \"chat_memory_key\"\n            },\n            {\n              \"name\": \"vector_store_id\"\n            }\n          ]\n        }\n      },\n      \"typeVersion\": 1.1\n    },\n    {\n      \"id\": \"0785714f-c45c-4eda-9937-c97e44c9a449\",\n      \"name\": \"Combined Fields\",\n      \"type\": \"n8n-nodes-base.set\",\n      \"position\": [\n        140,\n        480\n      ],\n      \"parameters\": {\n        \"options\": {},\n        \"assignments\": {\n          \"assignments\": [\n            {\n              \"id\": \"90ab73a2-fe01-451a-b9df-bffe950b1599\",\n              \"name\": \"user_query\",\n              \"type\": \"string\",\n              \"value\": \"={{ $json.user_query || $json.chatInput }}\"\n            },\n            {\n              \"id\": \"36686ff5-09fc-40a4-8335-a5dd1576e941\",\n              \"name\": \"chat_memory_key\",\n              \"type\": \"string\",\n              \"value\": \"={{ $json.chat_memory_key || $('Chat').item.json.sessionId }}\"\n            },\n            {\n              \"id\": \"4230c8f3-644c-4985-b710-a4099ccee77c\",\n              \"name\": \"vector_store_id\",\n              \"type\": \"string\",\n              \"value\": \"={{ $json.vector_store_id || \\\"<ID HERE>\\\" }}\"\n            }\n          ]\n        }\n      },\n      \"typeVersion\": 3.4\n    },\n    {\n      \"id\": \"57a93b72-4233-4ba2-b8c7-99d88f0ed572\",\n      \"name\": \"Sticky Note7\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"position\": [\n        -1420,\n        -560\n      ],\n      \"parameters\": {\n        \"color\": 3,\n        \"width\": 1280,\n        \"height\": 1680,\n        \"content\": \"# 自适应RAG工作流\\n\\n该n8n工作流实现了自适应检索增强生成（Adaptive RAG）方法的一个版本。它通过分类用户查询并根据查询类型（事实型、分析型、观点型或情境型）应用不同的检索与生成策略，从存储在Qdrant向量数据库的知识库中提供更相关、更定制化的响应。\\n\\n## 工作原理\\n\\n### 输入触发\\n- 工作流可通过内置聊天界面或其他n8n工作流触发\\n- 预期输入：`user_query`（用户查询）、`chat_memory_key`（对话历史标识）和`vector_store_id`（指定Qdrant集合）\\n- 标准化节点（`Combined Fields`）会统一处理这些输入\\n\\n### 查询分类\\n- Google Gemini代理（`Query Classification`）分析`user_query`\\n- 将查询归类至四种类型之一：\\n  - **事实型**：寻求具体可验证信息\\n  - **分析型**：需要全面分析或解释\\n  - **观点型**：询问主观话题或寻求不同视角\\n  - **情境型**：依赖用户特定或隐含上下文\\n\\n### 自适应策略路由\\n- 路由节点（`Switch`）根据上一步分类结果引导工作流\\n\\n### 策略实施（查询适配）\\n- 根据路由结果，特定Google Gemini代理会调整查询方式：\\n  - **事实策略**：聚焦关键实体重写查询以提高精确度（`Factual Strategy - Focus on Precision`）\\n  - **分析策略**：将主查询拆解为多个子问题确保全面覆盖（`Analytical Strategy - Comprehensive Coverage`）\\n  - **观点策略**：识别与查询相关的不同潜在视角（`Opinion Strategy - Diverse Perspectives`）\\n  - **情境策略**：提取有效响应所需的隐含上下文（`Contextual Strategy - User Context Integration`）\\n- 每个策略路径使用独立的对话记忆缓冲区进行适配\\n\\n### 检索提示与输出设置\\n- 基于原始查询分类，设置节点（通过`Set Prompt and Output`节点链接）将准备：\\n  - 策略步骤的输出（如重写查询/子问题/观点）\\n  - 为最终响应生成代理定制的系统提示，指定根据查询类型的行为模式（如事实型聚焦精确性，观点型呈现多元视角）\\n\\n### 文档检索（RAG）\\n- `Retrieve Documents from Vector Store`节点使用适配后的查询/输出在指定Qdrant集合（`vector_store_id`）中检索\\n- 利用Google Gemini嵌入向量获取最相关文档片段\\n\\n### 上下文准备\\n- 将检索到的文档内容合并为单一上下文块用于最终响应生成（`Concatenate Context`）\\n\\n### 响应生成\\n- 最终响应代理（由Google Gemini驱动）生成答案，使用：\\n  - 第5步设置的自定义系统提示\\n  - 第7步合并的检索文档上下文\\n  - 原始`user_query`\\n  - 共享对话历史（通过`chat_memory_key`使用`Chat Buffer Memory`）\\n\\n### 响应返回\\n- 生成响应通过`Respond to Webhook`节点返回用户\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"bec8070f-2ce9-4930-b71e-685a2b21d3f2\",\n      \"name\": \"Sticky Note8\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"position\": [\n        -40,\n        -20\n      ],\n      \"parameters\": {\n        \"color\": 7,\n        \"width\": 320,\n        \"height\": 820,\n        \"content\": \"## ⚠️ 在聊天模式下使用\\n\\n请将 `vector_store_id` 变量更新为执行文档检索所需的对应 Qdrant ID。\\n\\n## ⚠️ 聊天模组中使用\\n\\n将 `vector_store_id` 变量更新为执行文档检索所需的相应 Qdrant ID。\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"dc002d7a-df79-4d61-880a-db32917d9814\",\n      \"name\": \"Sticky Note9\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"position\": [\n        1220,\n        580\n      ],\n      \"parameters\": {},\n      \"typeVersion\": 1\n    }\n  ],\n  \"active\": true,\n  \"pinData\": {},\n  \"settings\": {},\n  \"versionId\": \"fbee3fa8-a249-4841-b786-817f0992ae6b\",\n  \"connections\": {\n    \"Chat\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Combined Fields\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Answer\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Respond to Webhook\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Switch\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Factual Strategy - Focus on Precision\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ],\n        [\n          {\n            \"node\": \"Analytical Strategy - Comprehensive Coverage\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ],\n        [\n          {\n            \"node\": \"Opinion Strategy - Diverse Perspectives\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ],\n        [\n          {\n            \"node\": \"Contextual Strategy - User Context Integration\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Embeddings\": {\n      \"ai_embedding\": [\n        [\n          {\n            \"node\": \"Retrieve Documents from Vector Store\",\n            \"type\": \"ai_embedding\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Gemini Answer\": {\n      \"ai_languageModel\": [\n        [\n          {\n            \"node\": \"Answer\",\n            \"type\": \"ai_languageModel\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Gemini Factual\": {\n      \"ai_languageModel\": [\n        [\n          {\n            \"node\": \"Factual Strategy - Focus on Precision\",\n            \"type\": \"ai_languageModel\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Gemini Opinion\": {\n      \"ai_languageModel\": [\n        [\n          {\n            \"node\": \"Opinion Strategy - Diverse Perspectives\",\n            \"type\": \"ai_languageModel\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Combined Fields\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Query Classification\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Gemini Analytical\": {\n      \"ai_languageModel\": [\n        [\n          {\n            \"node\": \"Analytical Strategy - Comprehensive Coverage\",\n            \"type\": \"ai_languageModel\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Gemini Contextual\": {\n      \"ai_languageModel\": [\n        [\n          {\n            \"node\": \"Contextual Strategy - User Context Integration\",\n            \"type\": \"ai_languageModel\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Chat Buffer Memory\": {\n      \"ai_memory\": [\n        [\n          {\n            \"node\": \"Answer\",\n            \"type\": \"ai_memory\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Concatenate Context\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Answer\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Query Classification\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Switch\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Gemini Classification\": {\n      \"ai_languageModel\": [\n        [\n          {\n            \"node\": \"Query Classification\",\n            \"type\": \"ai_languageModel\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Set Prompt and Output\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Retrieve Documents from Vector Store\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Factual Prompt and Output\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Set Prompt and Output\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Opinion Prompt and Output\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Set Prompt and Output\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Chat Buffer Memory Factual\": {\n      \"ai_memory\": [\n        [\n          {\n            \"node\": \"Factual Strategy - Focus on Precision\",\n            \"type\": \"ai_memory\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Chat Buffer Memory Opinion\": {\n      \"ai_memory\": [\n        [\n          {\n            \"node\": \"Opinion Strategy - Diverse Perspectives\",\n            \"type\": \"ai_memory\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Analytical Prompt and Output\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Set Prompt and Output\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Contextual Prompt and Output\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Set Prompt and Output\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Chat Buffer Memory Analytical\": {\n      \"ai_memory\": [\n        [\n          {\n            \"node\": \"Analytical Strategy - Comprehensive Coverage\",\n            \"type\": \"ai_memory\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Chat Buffer Memory Contextual\": {\n      \"ai_memory\": [\n        [\n          {\n            \"node\": \"Contextual Strategy - User Context Integration\",\n            \"type\": \"ai_memory\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"When Executed by Another Workflow\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Combined Fields\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Retrieve Documents from Vector Store\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Concatenate Context\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Factual Strategy - Focus on Precision\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Factual Prompt and Output\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Opinion Strategy - Diverse Perspectives\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Opinion Prompt and Output\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Analytical Strategy - Comprehensive Coverage\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Analytical Prompt and Output\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Contextual Strategy - User Context Integration\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Contextual Prompt and Output\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    }\n  }\n}"
}