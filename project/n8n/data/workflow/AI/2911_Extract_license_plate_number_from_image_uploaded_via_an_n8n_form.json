{
  "title": "Extract license plate number from image uploaded via an n8n form",
  "url": "https://n8n.io/workflows/2911-extract-license-plate-number-from-image-uploaded-via-an-n8n-form/",
  "category": "AI",
  "category_url": "https://n8n.io/workflows/categories/ai/?count=20",
  "author": "Daniel Nolde",
  "publish_date": "Last update 2 months ago",
  "content": "",
  "workflow_json": "{\"id\":\"B37wvB0tdKgjuabw\",\"meta\":{\"instanceId\":\"98bf0d6aef1dd8b7a752798121440fb171bf7686b95727fd617f43452393daa3\",\"templateCredsSetupCompleted\":true},\"name\":\"Image to license plate number\",\"tags\":[],\"nodes\":[{\"id\":\"a656334a-0135-4d93-a6df-ca97222c9753\",\"name\":\"Basic LLM Chain\",\"type\":\"@n8n/n8n-nodes-langchain.chainLlm\",\"position\":[-140,-380],\"parameters\":{\"text\":\"={{ $json.prompt }}\",\"messages\":{\"messageValues\":[{\"type\":\"HumanMessagePromptTemplate\",\"messageType\":\"imageBinary\",\"binaryImageDataKey\":\"Image\"}]},\"promptType\":\"define\"},\"typeVersion\":1.5},{\"id\":\"41a90592-2a91-40ff-abf4-3a795733d521\",\"name\":\"FormResultPage\",\"type\":\"n8n-nodes-base.form\",\"position\":[220,-380],\"webhookId\":\"218822fe-5eb9-4451-ae8a-14b8f484fdde\",\"parameters\":{\"options\":{\"formTitle\":\"\"},\"operation\":\"completion\",\"completionTitle\":\"Extracted information:\",\"completionMessage\":\"={{ $json.text }}\"},\"typeVersion\":1},{\"id\":\"c23b95d9-b7a2-4e9e-a019-5724a9662abd\",\"name\":\"OpenRouter LLM\",\"type\":\"@n8n/n8n-nodes-langchain.lmChatOpenRouter\",\"position\":[-60,-180],\"parameters\":{\"model\":\"={{ $json.model }}\",\"options\":{}},\"credentials\":{\"openRouterApi\":{\"id\":\"bs7tPtvgDTJNGAFJ\",\"name\":\"OpenRouter account\"}},\"typeVersion\":1},{\"id\":\"8298cd51-8c47-4bc4-af78-2c216207ef76\",\"name\":\"Settings\",\"type\":\"n8n-nodes-base.set\",\"position\":[-340,-380],\"parameters\":{\"options\":{},\"assignments\":{\"assignments\":[{\"id\":\"1b8381dc-5b9a-42a2-8a67-cc706b433180\",\"name\":\"model\",\"type\":\"string\",\"value\":\"openai/gpt-4o\"},{\"id\":\"72aec130-ab56-4e61-b60b-9a31dd8d02e6\",\"name\":\"prompt\",\"type\":\"string\",\"value\":\"Extract the number of the license plate on the front-most car depicted in the attached image and return only the extracted characters without any other text or structure.\"}]},\"includeOtherFields\":true},\"typeVersion\":3.4},{\"id\":\"fae79fc9-b510-44a4-beec-4dc26dc2a13a\",\"name\":\"FromTrigger\",\"type\":\"n8n-nodes-base.formTrigger\",\"position\":[-560,-380],\"webhookId\":\"41e3f34b-7abe-4c64-95cd-2942503d5e98\",\"parameters\":{\"options\":{},\"formTitle\":\"Analyse image\",\"formFields\":{\"values\":[{\"fieldType\":\"file\",\"fieldLabel\":\"Image\",\"requiredField\":true,\"acceptFileTypes\":\".jpg, .png\"}]},\"responseMode\":\"lastNode\",\"formDescription\":\"To analyse an image, upload it here.\"},\"typeVersion\":2.2}],\"active\":true,\"pinData\":{},\"settings\":{\"executionOrder\":\"v1\"},\"versionId\":\"5b9c53b9-3998-4676-999d-1ba117bf6695\",\"connections\":{\"Settings\":{\"main\":[[{\"node\":\"Basic LLM Chain\",\"type\":\"main\",\"index\":0}]]},\"FromTrigger\":{\"main\":[[{\"node\":\"Settings\",\"type\":\"main\",\"index\":0}]]},\"OpenRouter LLM\":{\"ai_languageModel\":[[{\"node\":\"Basic LLM Chain\",\"type\":\"ai_languageModel\",\"index\":0}]]},\"Basic LLM Chain\":{\"main\":[[{\"node\":\"FormResultPage\",\"type\":\"main\",\"index\":0}]]}}}",
  "readme": "## What it does\n\nThis is a simplistic demo workflow showing how to extract a license plate number from an image of a car submitted via a form – or in more general terms showcasing how you can:\n\n  * use a form trigger to upload files and feed it into an LLM\n  * use a changeable LLM model for image-to-text analysis\n\n\n\n## Set up steps\n\n  * Import the workflow\n  * Ensure you have registered and account, purchased some credits and created and API key for [OpenRouter.ai](https://openrouter.ai)\n  * Create/adapt the OpenRouter credential with your indivial API key for OpenRouter\n  * \"Test workflow\" and submit an image of a car with license plate to extract its number\n\n\n\n## How to adapt\n\nBy changing the \"prompt\" in th \"Settings\" node you can quickly adapt this exemplatory workflow to other image-to-text use cases, such as:\n\n  * summarization: \"summarize what's seen in the image\"\n  * location finding: \"identify the location where the image was taken\"\n  * text extraction: \"extract all text from the image and return it as markdown\"\n\n\n\nThanks to using OpenRouter, you also can quickly experiment with finding good model choices by simply changing the \"model\" in the \"Settings\" node. The following models gave good results for this demo use-case:\n\n  * google/gemini-2.0-flash-001\n  * meta-llama/llama-3.2-90b-vision-instruct\n  * openai/gpt-4o\n\n\n\nThe llama-3.2-11b and even claude-3.5-sonnet didn't recognize all characters in all test images.\n\nUsing a generic LLM-model offers a quick way of prototyping an image-to-text application. For specific use cases in serious and scalable production deployments, consider using an API based service specifically made to that purpose, such as:\n\n  * Google Cloud Vision API\n  * Microsoft Azure Computer Vision\n  * Azure AI Document Intelligence\n  * Amazon Textract\n\n\n",
  "readme_html": "<!--[--><div data-v-006f9244=\"\"><h2>What it does</h2>\n<p>This is a simplistic demo workflow showing how to extract a license plate number from an image of a car submitted via a form – or in more general terms showcasing how you can:</p>\n<ul>\n<li>use a form trigger to upload files and feed it into an LLM</li>\n<li>use a changeable LLM model for image-to-text analysis</li>\n</ul>\n<h2>Set up steps</h2>\n<ul>\n<li>Import the workflow</li>\n<li>Ensure you have registered and account, purchased some credits and created and API key for <a href=\"https://openrouter.ai\" rel=\"ugc nofollow\" target=\"_blank\">OpenRouter.ai</a></li>\n<li>Create/adapt the OpenRouter credential with your indivial API key for OpenRouter</li>\n<li>\"Test workflow\" and submit an image of a car with license plate to extract its number</li>\n</ul>\n<h2>How to adapt</h2>\n<p>By changing the \"prompt\" in th \"Settings\" node you can quickly adapt this exemplatory workflow to other image-to-text use cases, such as:</p>\n<ul>\n<li>summarization: \"summarize what's seen in the image\"</li>\n<li>location finding: \"identify the location where the image was taken\"</li>\n<li>text extraction: \"extract all text from the image and return it as markdown\"</li>\n</ul>\n<p>Thanks to using OpenRouter, you also can quickly experiment with finding good model choices by simply changing the \"model\" in the \"Settings\" node. The following models gave good results for this demo use-case:</p>\n<ul>\n<li>google/gemini-2.0-flash-001</li>\n<li>meta-llama/llama-3.2-90b-vision-instruct</li>\n<li>openai/gpt-4o</li>\n</ul>\n<p>The llama-3.2-11b and even claude-3.5-sonnet didn't recognize all characters in all test images.</p>\n<p>Using a generic LLM-model offers a quick way of prototyping an image-to-text application. For specific use cases in serious and scalable production deployments, consider using an API based service specifically made to that purpose, such as:</p>\n<ul>\n<li>Google Cloud Vision API</li>\n<li>Microsoft Azure Computer Vision</li>\n<li>Azure AI Document Intelligence</li>\n<li>Amazon Textract</li>\n</ul>\n</div><!--]-->"
}