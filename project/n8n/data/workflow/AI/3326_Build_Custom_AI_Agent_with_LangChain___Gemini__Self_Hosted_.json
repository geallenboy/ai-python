{
  "title": "Build Custom AI Agent with LangChain & Gemini (Self-Hosted)",
  "url": "https://n8n.io/workflows/3326-build-custom-ai-agent-with-langchain-and-gemini-self-hosted/",
  "category": "AI",
  "category_url": "https://n8n.io/workflows/categories/ai/?count=20",
  "author": "shepard",
  "publish_date": "Last update a month ago",
  "content": "",
  "workflow_json": "",
  "readme": "## Overview\n\nThis workflow leverages the LangChain code node to implement a fully customizable conversational agent. Ideal for users who need granular control over their agent's prompts while reducing unnecessary token consumption from reserved tool-calling functionality (compared to n8n's built-in Conversation Agent).  \n![截屏20250327 17.53.50.png](https://n8niostorageaccount.blob.core.windows.net/n8nio-strapi-blobs-prod/assets/2025_03_27_17_53_50_52bfbca02f.png)\n\n## Setup Instructions\n\n  1. **Configure Gemini Credentials** : Set up your Google Gemini API key ([Get API key here](https://ai.google.dev/) if needed). Alternatively, you may use other AI provider nodes.\n  2. **Interaction Methods** : \n     * Test directly in the workflow editor using the \"Chat\" button\n     * Activate the workflow and access the chat interface via the URL provided by the `When Chat Message Received` node\n\n\n\n## Customization Options\n\n  1. **Interface Settings** : Configure chat UI elements (e.g., title) in the `When Chat Message Received` node\n  2. **Prompt Engineering** : \n     * Define agent personality and conversation structure in the `Construct & Execute LLM Prompt` node's template variable\n     * ⚠️ Template must preserve `{chat_history}` and `{input}` placeholders for proper LangChain operation\n  3. **Model Selection** : Swap language models through the `language model` input field in `Construct & Execute LLM Prompt`\n  4. **Memory Control** : Adjust conversation history length in the `Store Conversation History` node\n\n\n\n## Requirements:\n\n⚠️ This workflow uses the **LangChain Code node** , which only works on **self-hosted n8n**.  \n_(Refer to[LangChain Code node docs](https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.code/))_\n",
  "readme_html": "<!--[--><div data-v-006f9244=\"\"><h2>Overview</h2>\n<p>This workflow leverages the LangChain code node to implement a fully customizable conversational agent. Ideal for users who need granular control over their agent's prompts while reducing unnecessary token consumption from reserved tool-calling functionality (compared to n8n's built-in Conversation Agent).<br>\n<img src=\"https://n8niostorageaccount.blob.core.windows.net/n8nio-strapi-blobs-prod/assets/2025_03_27_17_53_50_52bfbca02f.png\" alt=\"截屏20250327 17.53.50.png\"></p>\n<h2>Setup Instructions</h2>\n<ol>\n<li><strong>Configure Gemini Credentials</strong>: Set up your Google Gemini API key (<a href=\"https://ai.google.dev/\" rel=\"ugc nofollow\" target=\"_blank\">Get API key here</a> if needed). Alternatively, you may use other AI provider nodes.</li>\n<li><strong>Interaction Methods</strong>:\n<ul>\n<li>Test directly in the workflow editor using the \"Chat\" button</li>\n<li>Activate the workflow and access the chat interface via the URL provided by the <code>When Chat Message Received</code> node</li>\n</ul>\n</li>\n</ol>\n<h2>Customization Options</h2>\n<ol>\n<li><strong>Interface Settings</strong>: Configure chat UI elements (e.g., title) in the <code>When Chat Message Received</code> node</li>\n<li><strong>Prompt Engineering</strong>:\n<ul>\n<li>Define agent personality and conversation structure in the <code>Construct &amp; Execute LLM Prompt</code> node's template variable</li>\n<li>⚠️ Template must preserve <code>{chat_history}</code> and <code>{input}</code> placeholders for proper LangChain operation</li>\n</ul>\n</li>\n<li><strong>Model Selection</strong>: Swap language models through the <code>language model</code> input field in <code>Construct &amp; Execute LLM Prompt</code></li>\n<li><strong>Memory Control</strong>: Adjust conversation history length in the <code>Store Conversation History</code> node</li>\n</ol>\n<h2>Requirements:</h2>\n<p>⚠️ This workflow uses the <strong>LangChain Code node</strong>, which only works on <strong>self-hosted n8n</strong>.<br>\n<em>(Refer to <a href=\"https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.code/\" rel=\"ugc nofollow\" target=\"_blank\">LangChain Code node docs</a>)</em></p>\n</div><!--]-->",
  "readme_zh": "##  概述\n\n本工作流利用LangChain代码节点实现了一个高度可定制的对话代理。相比n8n内置的对话代理，该方案特别适合需要精细控制代理提示词，同时希望减少工具调用功能冗余token消耗的用户。  \n![截屏20250327 17.53.50.png](https://n8niostorageaccount.blob.core.windows.net/n8nio-strapi-blobs-prod/assets/2025_03_27_17_53_50_52bfbca02f.png)\n\n##  配置说明\n\n  1. **配置Gemini凭证**：设置Google Gemini API密钥（如需获取请访问[此链接](https://ai.google.dev/)）。也可替换为其他AI服务提供节点。\n  2. **交互方式**：  \n     * 通过工作流编辑器的\"Chat\"按钮直接测试\n     * 激活工作流后，通过`When Chat Message Received`节点提供的URL访问聊天界面\n\n##  定制选项\n\n  1. **界面设置**：在`When Chat Message Received`节点配置聊天UI元素（如标题）\n  2. **提示词设计**：  \n     * 在`Construct & Execute LLM Prompt`节点的模板变量中定义代理性格与对话结构\n     * ⚠️ 模板必须保留`{chat_history}`和`{input}`占位符以确保LangChain正常运行\n  3. **模型切换**：通过`Construct & Execute LLM Prompt`中的`language model`字段更换语言模型\n  4. **记忆控制**：在`Store Conversation History`节点调整对话历史记录长度\n\n##  使用要求：\n\n⚠️ 本工作流依赖**LangChain代码节点**，仅适用于**自托管版n8n**。  \n（详见[LangChain代码节点文档](https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.code/)）",
  "title_zh": "使用LangChain与Gemini构建自定义AI代理（自托管版）",
  "publish_date_absolute": "",
  "publish_date_zh": "上次更新于一个月前"
}