{
  "title": "Build an On-Premises AI Kaggle Competition Assistant with Qdrant RAG and Ollama",
  "url": "https://n8n.io/workflows/3967-build-an-on-premises-ai-kaggle-competition-assistant-with-qdrant-rag-and-ollama/",
  "category": "AI",
  "category_url": "https://n8n.io/workflows/categories/ai/?sort=createdAt:desc",
  "author": "JHH",
  "publish_date": "Last update 3 days ago",
  "publish_date_absolute": "2025-05-19",
  "content": "",
  "workflow_json": "{\"meta\":{\"instanceId\":\"13a0050774c7f2acc1474b06f046215039c01087a78215e5a78461e6efc6cb1a\",\"templateCredsSetupCompleted\":true},\"nodes\":[{\"id\":\"70b42807-a6c6-4159-b278-e77311727798\",\"name\":\"Local File Trigger\",\"type\":\"n8n-nodes-base.localFileTrigger\",\"position\":[-3060,-40],\"parameters\":{\"path\":\"C:\\\\\\\\ipynb\\\\\\\\loadme\",\"events\":[\"add\"],\"options\":{\"usePolling\":true,\"followSymlinks\":true,\"awaitWriteFinish\":true},\"triggerOn\":\"folder\"},\"typeVersion\":1},{\"id\":\"893f1157-6c00-4b8e-b726-462ab371fadf\",\"name\":\"Default Data Loader\",\"type\":\"@n8n/n8n-nodes-langchain.documentDefaultDataLoader\",\"position\":[-1500,300],\"parameters\":{\"options\":{}},\"typeVersion\":1},{\"id\":\"9a9bfcee-1966-415c-a59f-552e1f35aae9\",\"name\":\"Recursive Character Text Splitter\",\"type\":\"@n8n/n8n-nodes-langchain.textSplitterRecursiveCharacterTextSplitter\",\"position\":[-1360,440],\"parameters\":{\"options\":{},\"chunkSize\":40,\"chunkOverlap\":10},\"typeVersion\":1},{\"id\":\"a7c971a5-39ac-4715-9e1b-a56af9713b06\",\"name\":\"Settings\",\"type\":\"n8n-nodes-base.set\",\"position\":[-3040,180],\"parameters\":{\"options\":{},\"assignments\":{\"assignments\":[{\"id\":\"6b7d26f9-3a38-417e-85d0-4e9d42476465\",\"name\":\"path\",\"type\":\"string\",\"value\":\"=C:\\\\\\\\ipynb\\\\\\\\loadme\\\\\\\\\"},{\"id\":\"bb4471c7-d894-4739-99a6-4be247794ffa\",\"name\":\"filename\",\"type\":\"string\",\"value\":\"={{ $json.path.split('\\\\\\\\').last() }}\"}]}},\"typeVersion\":3.3},{\"id\":\"6384792b-de76-4e43-b26e-12c2d15c2dd2\",\"name\":\"Merge\",\"type\":\"n8n-nodes-base.merge\",\"position\":[-1740,260],\"parameters\":{},\"typeVersion\":2.1},{\"id\":\"db4de019-755e-4b91-ac70-f30825f14033\",\"name\":\"Get FileType\",\"type\":\"n8n-nodes-base.switch\",\"position\":[-2620,80],\"parameters\":{\"rules\":{\"values\":[{\"outputKey\":\"html\",\"conditions\":{\"options\":{\"version\":1,\"leftValue\":\"\",\"caseSensitive\":true,\"typeValidation\":\"strict\"},\"combinator\":\"and\",\"conditions\":[{\"id\":\"75188d2f-4bea-44ea-a579-9b9a1bd1ea93\",\"operator\":{\"type\":\"string\",\"operation\":\"equals\"},\"leftValue\":\"={{ $json.fileType }}\",\"rightValue\":\"html\"}]},\"renameOutput\":true}]},\"options\":{}},\"typeVersion\":3},{\"id\":\"4c56a14c-6c56-4cc1-b7fb-a09caa3d646d\",\"name\":\"Import File\",\"type\":\"n8n-nodes-base.readWriteFile\",\"position\":[-2840,80],\"parameters\":{\"options\":{},\"fileSelector\":\"={{ $json.path }}{{ $json.filename }}\"},\"typeVersion\":1},{\"id\":\"c14a711f-29ab-475f-aeff-3a070c797537\",\"name\":\"Extract from TEXT\",\"type\":\"n8n-nodes-base.extractFromFile\",\"position\":[-2440,80],\"parameters\":{\"options\":{},\"operation\":\"text\"},\"typeVersion\":1},{\"id\":\"22ff782e-c612-4928-9033-111cf516d07e\",\"name\":\"Summarization Chain\",\"type\":\"@n8n/n8n-nodes-langchain.chainSummarization\",\"position\":[-2040,-20],\"parameters\":{\"options\":{\"summarizationMethodAndPrompts\":{\"values\":{\"summarizationMethod\":\"refine\"}}},\"chunkSize\":4000},\"typeVersion\":2},{\"id\":\"70fa17a5-3ec9-4a81-86bc-503581505ea1\",\"name\":\"Sticky Note\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[-3100,-180],\"parameters\":{\"color\":7,\"width\":995,\"height\":554,\"content\":\"## Step 1. Watch Folder and Import New Documents\\n[Read more about Local File Trigger](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.localfiletrigger)\\n\\nWith n8n's local file trigger, we're able to trigger the workflow when files are created in our target folder. We still have to import them however as the trigger will only give the file's path. The \\\"Extract From\\\" node is used to get at the file's contents.\"},\"typeVersion\":1},{\"id\":\"a51cc8ac-e310-4825-adc6-fc57c68c09aa\",\"name\":\"Sticky Note1\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[-2060,-200],\"parameters\":{\"color\":7,\"width\":824,\"height\":770,\"content\":\"## Step 2. Summarise and Vectorise Document Contents\\n[Learn more about using the Qdrant VectorStore](https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.vectorstoreqdrant)\\n\\nCapturing the document into our vector store is intended for a technique we'll use later known as Retrieval Augumented Generation or \\\"RAG\\\" for short. For our scenario, this allows our LLM to retrieve context more efficiently which produces better respsonses.\"},\"typeVersion\":1},{\"id\":\"6d59dc6a-692a-4752-a811-8b3033898fa4\",\"name\":\"Qdrant Vector Store\",\"type\":\"@n8n/n8n-nodes-langchain.vectorStoreQdrant\",\"position\":[-1600,60],\"parameters\":{\"mode\":\"insert\",\"options\":{},\"qdrantCollection\":{\"__rl\":true,\"mode\":\"id\",\"value\":\"test_rag\"}},\"credentials\":{\"qdrantApi\":{\"id\":\"wqHGuxoW5RJJYSIl\",\"name\":\"QdrantApi account\"}},\"typeVersion\":1},{\"id\":\"f75f45cd-4aed-48a2-bb09-5db20b00a029\",\"name\":\"Markdown\",\"type\":\"n8n-nodes-base.markdown\",\"position\":[-2260,80],\"parameters\":{\"html\":\"={{ $json.data }}\",\"options\":{}},\"typeVersion\":1},{\"id\":\"34fdd670-f568-4351-81c7-79fde68b8192\",\"name\":\"Embeddings Ollama\",\"type\":\"@n8n/n8n-nodes-langchain.embeddingsOllama\",\"position\":[-1560,420],\"parameters\":{\"model\":\"mxbai-embed-large:latest\"},\"credentials\":{\"ollamaApi\":{\"id\":\"jBqODDnXWJw9rGcS\",\"name\":\"Ollama account\"}},\"typeVersion\":1},{\"id\":\"4c4f71db-e496-4528-b0e5-dc5ffb27a2e8\",\"name\":\"Ollama Summarizer\",\"type\":\"@n8n/n8n-nodes-langchain.lmOllama\",\"position\":[-1900,140],\"parameters\":{\"model\":\"ALIENTELLIGENCE/contentsummarizer:latest\",\"options\":{}},\"credentials\":{\"ollamaApi\":{\"id\":\"jBqODDnXWJw9rGcS\",\"name\":\"Ollama account\"}},\"typeVersion\":1},{\"id\":\"0a2954cc-bec6-4750-ae75-6362761e41b6\",\"name\":\"When chat message received\",\"type\":\"@n8n/n8n-nodes-langchain.chatTrigger\",\"position\":[-3020,540],\"webhookId\":\"9dd3e051-58a3-4c46-bd41-58c001f009f9\",\"parameters\":{\"options\":{}},\"typeVersion\":1.1},{\"id\":\"1ebe053c-0e26-44c6-b543-756ad551b99d\",\"name\":\"AI Agent\",\"type\":\"@n8n/n8n-nodes-langchain.agent\",\"position\":[-2840,540],\"parameters\":{\"options\":{\"systemMessage\":\"This is a helpful and exacting data science LLM model and master Kaggle python programmer.\\n\\nIf Kaggle contest requirements are given from the chat input; first deeply research the problem.\\n\\nAccess the tool: \\\"previous_entry\\\" when preparing your background research.\\n\\nThen Ask any needed questions to clarify and understand the requirements necessary to build a program to address the challenge.\\n\\nReview your proposed program for errors and bugs.\\n\\nThen present the program.\\n\\nIf errors are returned; then iteratively debug with the chat user.\"}},\"typeVersion\":1.7},{\"id\":\"e042ec84-3bb6-466f-9957-0509a181d61b\",\"name\":\"Vector Store Tool\",\"type\":\"@n8n/n8n-nodes-langchain.toolVectorStore\",\"position\":[-2580,740],\"parameters\":{\"name\":\"previous_entry\",\"description\":\"={{ $('When chat message received').item.json.chatInput }}\"},\"typeVersion\":1},{\"id\":\"fbae9bc0-6ea4-4a26-ad76-eb84bc5d06c2\",\"name\":\"Window Buffer Memory\",\"type\":\"@n8n/n8n-nodes-langchain.memoryBufferWindow\",\"position\":[-2760,780],\"parameters\":{\"contextWindowLength\":15},\"typeVersion\":1.3},{\"id\":\"2f567628-fd1d-406b-aec7-46684bd6f5e6\",\"name\":\"Qdrant Vector Store2\",\"type\":\"@n8n/n8n-nodes-langchain.vectorStoreQdrant\",\"position\":[-2680,920],\"parameters\":{\"options\":{},\"qdrantCollection\":{\"__rl\":true,\"mode\":\"list\",\"value\":\"test_rag\",\"cachedResultName\":\"test_rag\"}},\"credentials\":{\"qdrantApi\":{\"id\":\"wqHGuxoW5RJJYSIl\",\"name\":\"QdrantApi account\"}},\"typeVersion\":1},{\"id\":\"3aea837f-7676-45da-b6b1-fb2f6c5f8cd9\",\"name\":\"Ollama Chat Model3\",\"type\":\"@n8n/n8n-nodes-langchain.lmChatOllama\",\"position\":[-2900,760],\"parameters\":{\"model\":\"qwen3:8b\",\"options\":{}},\"credentials\":{\"ollamaApi\":{\"id\":\"jBqODDnXWJw9rGcS\",\"name\":\"Ollama account\"}},\"typeVersion\":1},{\"id\":\"a9298132-e5b9-44a2-9928-a1adf7cf9fc4\",\"name\":\"Embeddings Ollama2\",\"type\":\"@n8n/n8n-nodes-langchain.embeddingsOllama\",\"position\":[-2660,1080],\"parameters\":{\"model\":\"mxbai-embed-large:latest\"},\"credentials\":{\"ollamaApi\":{\"id\":\"jBqODDnXWJw9rGcS\",\"name\":\"Ollama account\"}},\"typeVersion\":1},{\"id\":\"a1c71691-8e41-4633-a1ab-4991833fb7c6\",\"name\":\"Ollama Chat Model4\",\"type\":\"@n8n/n8n-nodes-langchain.lmChatOllama\",\"position\":[-2360,900],\"parameters\":{\"model\":\"qwen3:8b\",\"options\":{}},\"credentials\":{\"ollamaApi\":{\"id\":\"jBqODDnXWJw9rGcS\",\"name\":\"Ollama account\"}},\"typeVersion\":1}],\"pinData\":{},\"connections\":{\"Merge\":{\"main\":[[{\"node\":\"Qdrant Vector Store\",\"type\":\"main\",\"index\":0}]]},\"Markdown\":{\"main\":[[{\"node\":\"Summarization Chain\",\"type\":\"main\",\"index\":0},{\"node\":\"Merge\",\"type\":\"main\",\"index\":1}]]},\"Settings\":{\"main\":[[{\"node\":\"Import File\",\"type\":\"main\",\"index\":0}]]},\"Import File\":{\"main\":[[{\"node\":\"Get FileType\",\"type\":\"main\",\"index\":0}]]},\"Get FileType\":{\"main\":[[{\"node\":\"Extract from TEXT\",\"type\":\"main\",\"index\":0}]]},\"Embeddings Ollama\":{\"ai_embedding\":[[{\"node\":\"Qdrant Vector Store\",\"type\":\"ai_embedding\",\"index\":0}]]},\"Extract from TEXT\":{\"main\":[[{\"node\":\"Markdown\",\"type\":\"main\",\"index\":0}]]},\"Ollama Summarizer\":{\"ai_languageModel\":[[{\"node\":\"Summarization Chain\",\"type\":\"ai_languageModel\",\"index\":0}]]},\"Vector Store Tool\":{\"ai_tool\":[[{\"node\":\"AI Agent\",\"type\":\"ai_tool\",\"index\":0}]]},\"Embeddings Ollama2\":{\"ai_embedding\":[[{\"node\":\"Qdrant Vector Store2\",\"type\":\"ai_embedding\",\"index\":0}]]},\"Local File Trigger\":{\"main\":[[{\"node\":\"Settings\",\"type\":\"main\",\"index\":0}]]},\"Ollama Chat Model3\":{\"ai_languageModel\":[[{\"node\":\"AI Agent\",\"type\":\"ai_languageModel\",\"index\":0}]]},\"Ollama Chat Model4\":{\"ai_languageModel\":[[{\"node\":\"Vector Store Tool\",\"type\":\"ai_languageModel\",\"index\":0}]]},\"Default Data Loader\":{\"ai_document\":[[{\"node\":\"Qdrant Vector Store\",\"type\":\"ai_document\",\"index\":0}]]},\"Qdrant Vector Store\":{\"main\":[[]]},\"Summarization Chain\":{\"main\":[[{\"node\":\"Merge\",\"type\":\"main\",\"index\":0}]]},\"Qdrant Vector Store2\":{\"ai_vectorStore\":[[{\"node\":\"Vector Store Tool\",\"type\":\"ai_vectorStore\",\"index\":0}]]},\"Window Buffer Memory\":{\"ai_memory\":[[{\"node\":\"AI Agent\",\"type\":\"ai_memory\",\"index\":0}]]},\"When chat message received\":{\"main\":[[{\"node\":\"AI Agent\",\"type\":\"main\",\"index\":0}]]},\"Recursive Character Text Splitter\":{\"ai_textSplitter\":[[{\"node\":\"Default Data Loader\",\"type\":\"ai_textSplitter\",\"index\":0}]]}}}",
  "readme": "# LLM/RAG Kaggle Development Assistant\n\n## An on-premises, domain-specific AI assistant for Kaggle (tested on binary disaster-tweet classification), combining LLM, an n8n workflow engine, and Qdrant-backed Retrieval-Augmented Generation (RAG).  \nDeploy via containerized starter kit.  \nNeeds high end GPU support or patience.  \nInitial chat should contain guidelines on what to to produce and the challenge guidelines.\n\n## Features\n\n  * **Coding Assistance**  \n• \"Real\"-time Python code recommendations, debugging help, and data-science best practices  \n• Multi-turn conversational context\n  * **Workflow Automation**  \n• n8n orchestration for LLM calls, document ingestion, and external API integrations\n  * **Retrieval-Augmented Generation (RAG)**  \n• Qdrant vector-database for competition-specific document lookup  \n• On-demand retrieval of Kaggle competition guidelines, tutorials, and notebooks after convertion to HTML and ingestion into RAG\n  * **entirly On-Premises for Privacy**  \n• Locally hosted LLM (via Ollama) – no external code or data transfer\n\n\n\nALIENTELLIGENCE/contentsummarizer:latest for summarizing  \nqwen3:8b for chat and coding  \nmxbai-embed-large:latest for embedding\n\n• GPU acceleration required\n\nBased on:  \n<https://n8n.io/workflows/2339> breakdown documents into study notes using templating mistralai and qdrant/\n",
  "readme_html": "<!--[--><div data-v-859c7806=\"\"><h1>LLM/RAG Kaggle Development Assistant</h1>\n<h2>An on-premises, domain-specific AI assistant for Kaggle (tested on binary disaster-tweet classification), combining LLM, an n8n workflow engine, and Qdrant-backed Retrieval-Augmented Generation (RAG).<br>\nDeploy via containerized starter kit.<br>\nNeeds high end GPU support or patience.<br>\nInitial chat should contain guidelines on what to to produce and the challenge guidelines.</h2>\n<h2>Features</h2>\n<ul>\n<li><strong>Coding Assistance</strong><br>\n• \"Real\"-time Python code recommendations, debugging help, and data-science best practices<br>\n• Multi-turn conversational context</li>\n<li><strong>Workflow Automation</strong><br>\n• n8n orchestration for LLM calls, document ingestion, and external API integrations</li>\n<li><strong>Retrieval-Augmented Generation (RAG)</strong><br>\n• Qdrant vector-database for competition-specific document lookup<br>\n• On-demand retrieval of Kaggle competition guidelines, tutorials, and notebooks after convertion to HTML and ingestion into RAG</li>\n<li><strong>entirly On-Premises for Privacy</strong><br>\n• Locally hosted LLM (via Ollama) – no external code or data transfer</li>\n</ul>\n<p>ALIENTELLIGENCE/contentsummarizer:latest for summarizing<br>\nqwen3:8b for chat and coding<br>\nmxbai-embed-large:latest for embedding</p>\n<p>• GPU acceleration required</p>\n<p>Based on:<br>\n<a href=\"https://n8n.io/workflows/2339\" rel=\"ugc nofollow\" target=\"_blank\">https://n8n.io/workflows/2339</a> breakdown documents into study notes using templating mistralai and qdrant/</p>\n</div><!--]-->",
  "readme_zh": "# LLM/RAG Kaggle开发助手\n\n## 专为Kaggle打造的本地化领域AI助手（已在灾害推文二分类任务测试），整合LLM、n8n工作流引擎与Qdrant驱动的检索增强生成（RAG）技术  \n通过容器化入门套件部署  \n需高端GPU支持或充足耐心  \n初始对话需包含任务产出指南及竞赛规则说明\n\n## 核心功能\n\n  * **编程辅助**  \n• \"实时\"Python代码建议、调试支持及数据科学最佳实践  \n• 多轮对话上下文保持\n  * **工作流自动化**  \n• n8n编排LLM调用、文档摄取及外部API集成\n  * **检索增强生成**  \n• Qdrant向量数据库实现竞赛专属文档检索  \n• 将Kaggle竞赛指南/教程/笔记本转为HTML后，即时检索RAG库获取相关内容\n  * **全本地化隐私保护**  \n• 本地托管LLM（通过Ollama）——杜绝外部代码或数据传输",
  "title_zh": "Build an On-Premises AI Kaggle Competition Assistant with Qdrant RAG and Ollama",
  "publish_date_zh": "最后更新于3天前",
  "workflow_json_zh": "{\"meta\":{\"instanceId\":\"13a0050774c7f2acc1474b06f046215039c01087a78215e5a78461e6efc6cb1a\",\"templateCredsSetupCompleted\":true},\"nodes\":[{\"id\":\"70b42807-a6c6-4159-b278-e77311727798\",\"name\":\"Local File Trigger\",\"type\":\"n8n-nodes-base.localFileTrigger\",\"position\":[-3060,-40],\"parameters\":{\"path\":\"C:\\\\\\\\ipynb\\\\\\\\loadme\",\"events\":[\"add\"],\"options\":{\"usePolling\":true,\"followSymlinks\":true,\"awaitWriteFinish\":true},\"triggerOn\":\"folder\"},\"typeVersion\":1},{\"id\":\"893f1157-6c00-4b8e-b726-462ab371fadf\",\"name\":\"Default Data Loader\",\"type\":\"@n8n/n8n-nodes-langchain.documentDefaultDataLoader\",\"position\":[-1500,300],\"parameters\":{\"options\":{}},\"typeVersion\":1},{\"id\":\"9a9bfcee-1966-415c-a59f-552e1f35aae9\",\"name\":\"Recursive Character Text Splitter\",\"type\":\"@n8n/n8n-nodes-langchain.textSplitterRecursiveCharacterTextSplitter\",\"position\":[-1360,440],\"parameters\":{\"options\":{},\"chunkSize\":40,\"chunkOverlap\":10},\"typeVersion\":1},{\"id\":\"a7c971a5-39ac-4715-9e1b-a56af9713b06\",\"name\":\"Settings\",\"type\":\"n8n-nodes-base.set\",\"position\":[-3040,180],\"parameters\":{\"options\":{},\"assignments\":{\"assignments\":[{\"id\":\"6b7d26f9-3a38-417e-85d0-4e9d42476465\",\"name\":\"path\",\"type\":\"string\",\"value\":\"=C:\\\\\\\\ipynb\\\\\\\\loadme\\\\\\\\\"},{\"id\":\"bb4471c7-d894-4739-99a6-4be247794ffa\",\"name\":\"filename\",\"type\":\"string\",\"value\":\"={{ $json.path.split('\\\\\\\\').last() }}\"}]}},\"typeVersion\":3.3},{\"id\":\"6384792b-de76-4e43-b26e-12c2d15c2dd2\",\"name\":\"Merge\",\"type\":\"n8n-nodes-base.merge\",\"position\":[-1740,260],\"parameters\":{},\"typeVersion\":2.1},{\"id\":\"db4de019-755e-4b91-ac70-f30825f14033\",\"name\":\"Get FileType\",\"type\":\"n8n-nodes-base.switch\",\"position\":[-2620,80],\"parameters\":{\"rules\":{\"values\":[{\"outputKey\":\"html\",\"conditions\":{\"options\":{\"version\":1,\"leftValue\":\"\",\"caseSensitive\":true,\"typeValidation\":\"strict\"},\"combinator\":\"and\",\"conditions\":[{\"id\":\"75188d2f-4bea-44ea-a579-9b9a1bd1ea93\",\"operator\":{\"type\":\"string\",\"operation\":\"equals\"},\"leftValue\":\"={{ $json.fileType }}\",\"rightValue\":\"html\"}]},\"renameOutput\":true}]},\"options\":{}},\"typeVersion\":3},{\"id\":\"4c56a14c-6c56-4cc1-b7fb-a09caa3d646d\",\"name\":\"Import File\",\"type\":\"n8n-nodes-base.readWriteFile\",\"position\":[-2840,80],\"parameters\":{\"options\":{},\"fileSelector\":\"={{ $json.path }}{{ $json.filename }}\"},\"typeVersion\":1},{\"id\":\"c14a711f-29ab-475f-aeff-3a070c797537\",\"name\":\"Extract from TEXT\",\"type\":\"n8n-nodes-base.extractFromFile\",\"position\":[-2440,80],\"parameters\":{\"options\":{},\"operation\":\"text\"},\"typeVersion\":1},{\"id\":\"22ff782e-c612-4928-9033-111cf516d07e\",\"name\":\"Summarization Chain\",\"type\":\"@n8n/n8n-nodes-langchain.chainSummarization\",\"position\":[-2040,-20],\"parameters\":{\"options\":{\"summarizationMethodAndPrompts\":{\"values\":{\"summarizationMethod\":\"refine\"}}},\"chunkSize\":4000},\"typeVersion\":2},{\"id\":\"70fa17a5-3ec9-4a81-86bc-503581505ea1\",\"name\":\"Sticky Note\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[-3100,-180],\"parameters\":{\"color\":7,\"width\":995,\"height\":554,\"content\":\"## 第一步：监控文件夹并导入新文档\\n[详细了解本地文件触发器](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.localfiletrigger)\\n\\n通过n8n的本地文件触发器，我们能够在目标文件夹中创建文件时触发工作流。不过仍需手动导入这些文件，因为触发器仅提供文件路径信息。此时需使用\\\"内容提取\\\"节点来获取文件的具体内容。\"},\"typeVersion\":1},{\"id\":\"a51cc8ac-e310-4825-adc6-fc57c68c09aa\",\"name\":\"Sticky Note1\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[-2060,-200],\"parameters\":{\"color\":7,\"width\":824,\"height\":770,\"content\":\"## 第二步：总结并向量化文档内容\\n[详细了解如何使用Qdrant向量数据库](https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.vectorstoreqdrant)\\n\\n将文档存入向量数据库是为了后续采用\\\"检索增强生成\\\"（Retrieval Augmented Generation，简称RAG）技术做准备。在当前场景中，这能让大语言模型更高效地获取上下文信息，从而生成更优质的响应。\"},\"typeVersion\":1},{\"id\":\"6d59dc6a-692a-4752-a811-8b3033898fa4\",\"name\":\"Qdrant Vector Store\",\"type\":\"@n8n/n8n-nodes-langchain.vectorStoreQdrant\",\"position\":[-1600,60],\"parameters\":{\"mode\":\"insert\",\"options\":{},\"qdrantCollection\":{\"__rl\":true,\"mode\":\"id\",\"value\":\"test_rag\"}},\"credentials\":{\"qdrantApi\":{\"id\":\"wqHGuxoW5RJJYSIl\",\"name\":\"QdrantApi account\"}},\"typeVersion\":1},{\"id\":\"f75f45cd-4aed-48a2-bb09-5db20b00a029\",\"name\":\"Markdown\",\"type\":\"n8n-nodes-base.markdown\",\"position\":[-2260,80],\"parameters\":{\"html\":\"={{ $json.data }}\",\"options\":{}},\"typeVersion\":1},{\"id\":\"34fdd670-f568-4351-81c7-79fde68b8192\",\"name\":\"Embeddings Ollama\",\"type\":\"@n8n/n8n-nodes-langchain.embeddingsOllama\",\"position\":[-1560,420],\"parameters\":{\"model\":\"mxbai-embed-large:latest\"},\"credentials\":{\"ollamaApi\":{\"id\":\"jBqODDnXWJw9rGcS\",\"name\":\"Ollama account\"}},\"typeVersion\":1},{\"id\":\"4c4f71db-e496-4528-b0e5-dc5ffb27a2e8\",\"name\":\"Ollama Summarizer\",\"type\":\"@n8n/n8n-nodes-langchain.lmOllama\",\"position\":[-1900,140],\"parameters\":{\"model\":\"ALIENTELLIGENCE/contentsummarizer:latest\",\"options\":{}},\"credentials\":{\"ollamaApi\":{\"id\":\"jBqODDnXWJw9rGcS\",\"name\":\"Ollama account\"}},\"typeVersion\":1},{\"id\":\"0a2954cc-bec6-4750-ae75-6362761e41b6\",\"name\":\"When chat message received\",\"type\":\"@n8n/n8n-nodes-langchain.chatTrigger\",\"position\":[-3020,540],\"webhookId\":\"9dd3e051-58a3-4c46-bd41-58c001f009f9\",\"parameters\":{\"options\":{}},\"typeVersion\":1.1},{\"id\":\"1ebe053c-0e26-44c6-b543-756ad551b99d\",\"name\":\"AI Agent\",\"type\":\"@n8n/n8n-nodes-langchain.agent\",\"position\":[-2840,540],\"parameters\":{\"options\":{\"systemMessage\":\"This is a helpful and exacting data science LLM model and master Kaggle python programmer.\\n\\nIf Kaggle contest requirements are given from the chat input; first deeply research the problem.\\n\\nAccess the tool: \\\"previous_entry\\\" when preparing your background research.\\n\\nThen Ask any needed questions to clarify and understand the requirements necessary to build a program to address the challenge.\\n\\nReview your proposed program for errors and bugs.\\n\\nThen present the program.\\n\\nIf errors are returned; then iteratively debug with the chat user.\"}},\"typeVersion\":1.7},{\"id\":\"e042ec84-3bb6-466f-9957-0509a181d61b\",\"name\":\"Vector Store Tool\",\"type\":\"@n8n/n8n-nodes-langchain.toolVectorStore\",\"position\":[-2580,740],\"parameters\":{\"name\":\"previous_entry\",\"description\":\"={{ $('When chat message received').item.json.chatInput }}\"},\"typeVersion\":1},{\"id\":\"fbae9bc0-6ea4-4a26-ad76-eb84bc5d06c2\",\"name\":\"Window Buffer Memory\",\"type\":\"@n8n/n8n-nodes-langchain.memoryBufferWindow\",\"position\":[-2760,780],\"parameters\":{\"contextWindowLength\":15},\"typeVersion\":1.3},{\"id\":\"2f567628-fd1d-406b-aec7-46684bd6f5e6\",\"name\":\"Qdrant Vector Store2\",\"type\":\"@n8n/n8n-nodes-langchain.vectorStoreQdrant\",\"position\":[-2680,920],\"parameters\":{\"options\":{},\"qdrantCollection\":{\"__rl\":true,\"mode\":\"list\",\"value\":\"test_rag\",\"cachedResultName\":\"test_rag\"}},\"credentials\":{\"qdrantApi\":{\"id\":\"wqHGuxoW5RJJYSIl\",\"name\":\"QdrantApi account\"}},\"typeVersion\":1},{\"id\":\"3aea837f-7676-45da-b6b1-fb2f6c5f8cd9\",\"name\":\"Ollama Chat Model3\",\"type\":\"@n8n/n8n-nodes-langchain.lmChatOllama\",\"position\":[-2900,760],\"parameters\":{\"model\":\"qwen3:8b\",\"options\":{}},\"credentials\":{\"ollamaApi\":{\"id\":\"jBqODDnXWJw9rGcS\",\"name\":\"Ollama account\"}},\"typeVersion\":1},{\"id\":\"a9298132-e5b9-44a2-9928-a1adf7cf9fc4\",\"name\":\"Embeddings Ollama2\",\"type\":\"@n8n/n8n-nodes-langchain.embeddingsOllama\",\"position\":[-2660,1080],\"parameters\":{\"model\":\"mxbai-embed-large:latest\"},\"credentials\":{\"ollamaApi\":{\"id\":\"jBqODDnXWJw9rGcS\",\"name\":\"Ollama account\"}},\"typeVersion\":1},{\"id\":\"a1c71691-8e41-4633-a1ab-4991833fb7c6\",\"name\":\"Ollama Chat Model4\",\"type\":\"@n8n/n8n-nodes-langchain.lmChatOllama\",\"position\":[-2360,900],\"parameters\":{\"model\":\"qwen3:8b\",\"options\":{}},\"credentials\":{\"ollamaApi\":{\"id\":\"jBqODDnXWJw9rGcS\",\"name\":\"Ollama account\"}},\"typeVersion\":1}],\"pinData\":{},\"connections\":{\"Merge\":{\"main\":[[{\"node\":\"Qdrant Vector Store\",\"type\":\"main\",\"index\":0}]]},\"Markdown\":{\"main\":[[{\"node\":\"Summarization Chain\",\"type\":\"main\",\"index\":0},{\"node\":\"Merge\",\"type\":\"main\",\"index\":1}]]},\"Settings\":{\"main\":[[{\"node\":\"Import File\",\"type\":\"main\",\"index\":0}]]},\"Import File\":{\"main\":[[{\"node\":\"Get FileType\",\"type\":\"main\",\"index\":0}]]},\"Get FileType\":{\"main\":[[{\"node\":\"Extract from TEXT\",\"type\":\"main\",\"index\":0}]]},\"Embeddings Ollama\":{\"ai_embedding\":[[{\"node\":\"Qdrant Vector Store\",\"type\":\"ai_embedding\",\"index\":0}]]},\"Extract from TEXT\":{\"main\":[[{\"node\":\"Markdown\",\"type\":\"main\",\"index\":0}]]},\"Ollama Summarizer\":{\"ai_languageModel\":[[{\"node\":\"Summarization Chain\",\"type\":\"ai_languageModel\",\"index\":0}]]},\"Vector Store Tool\":{\"ai_tool\":[[{\"node\":\"AI Agent\",\"type\":\"ai_tool\",\"index\":0}]]},\"Embeddings Ollama2\":{\"ai_embedding\":[[{\"node\":\"Qdrant Vector Store2\",\"type\":\"ai_embedding\",\"index\":0}]]},\"Local File Trigger\":{\"main\":[[{\"node\":\"Settings\",\"type\":\"main\",\"index\":0}]]},\"Ollama Chat Model3\":{\"ai_languageModel\":[[{\"node\":\"AI Agent\",\"type\":\"ai_languageModel\",\"index\":0}]]},\"Ollama Chat Model4\":{\"ai_languageModel\":[[{\"node\":\"Vector Store Tool\",\"type\":\"ai_languageModel\",\"index\":0}]]},\"Default Data Loader\":{\"ai_document\":[[{\"node\":\"Qdrant Vector Store\",\"type\":\"ai_document\",\"index\":0}]]},\"Qdrant Vector Store\":{\"main\":[[]]},\"Summarization Chain\":{\"main\":[[{\"node\":\"Merge\",\"type\":\"main\",\"index\":0}]]},\"Qdrant Vector Store2\":{\"ai_vectorStore\":[[{\"node\":\"Vector Store Tool\",\"type\":\"ai_vectorStore\",\"index\":0}]]},\"Window Buffer Memory\":{\"ai_memory\":[[{\"node\":\"AI Agent\",\"type\":\"ai_memory\",\"index\":0}]]},\"When chat message received\":{\"main\":[[{\"node\":\"AI Agent\",\"type\":\"main\",\"index\":0}]]},\"Recursive Character Text Splitter\":{\"ai_textSplitter\":[[{\"node\":\"Default Data Loader\",\"type\":\"ai_textSplitter\",\"index\":0}]]}}}"
}