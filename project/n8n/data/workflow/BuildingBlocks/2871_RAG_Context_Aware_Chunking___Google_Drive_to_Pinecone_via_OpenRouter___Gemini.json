{
  "title": "RAG:Context-Aware Chunking | Google Drive to Pinecone via OpenRouter & Gemini",
  "url": "https://n8n.io/workflows/2871-ragcontext-aware-chunking-or-google-drive-to-pinecone-via-openrouter-and-gemini/",
  "category": "BuildingBlocks",
  "category_url": "https://n8n.io/workflows/categories/building-blocks/?sort=createdAt:desc",
  "author": "Udit Rawat",
  "publish_date": "Last update 3 months ago",
  "publish_date_absolute": "",
  "content": "",
  "workflow_json": "{\"id\":\"VY4WBXuNDPxmOO5e\",\"meta\":{\"instanceId\":\"d16fb7d4b3eb9b9d4ad2ee6a7fbae593d73e9715e51f583c2a0e9acd1781c08e\",\"templateCredsSetupCompleted\":true},\"name\":\"RAG:Context-Aware Chunking | Google Drive to Pinecone via OpenRouter & Gemini\",\"tags\":[{\"id\":\"XZIQK6NdzGvgbZFd\",\"name\":\"Sell\",\"createdAt\":\"2025-01-15T12:28:48.424Z\",\"updatedAt\":\"2025-01-15T12:28:48.424Z\"}],\"nodes\":[{\"id\":\"7abbfa6e-4b17-4656-9b82-377b1bacf539\",\"name\":\"When clicking â€˜Test workflowâ€™\",\"type\":\"n8n-nodes-base.manualTrigger\",\"position\":[0,0],\"parameters\":{},\"typeVersion\":1},{\"id\":\"448ec137-bf64-46b4-bf15-c7a040faa306\",\"name\":\"Loop Over Items\",\"type\":\"n8n-nodes-base.splitInBatches\",\"position\":[1100,0],\"parameters\":{\"options\":{}},\"typeVersion\":3},{\"id\":\"f22557ee-7f37-40cd-9063-a9a759274663\",\"name\":\"OpenRouter Chat Model\",\"type\":\"@n8n/n8n-nodes-langchain.lmChatOpenRouter\",\"position\":[20,440],\"parameters\":{\"options\":{}},\"credentials\":{\"openRouterApi\":{\"id\":\"ddH6iNlm09UxrXvu\",\"name\":\"Auto: OpenRouter\"}},\"typeVersion\":1},{\"id\":\"57e8792e-25ae-43d5-b4e9-e87642365ee9\",\"name\":\"Pinecone Vector Store\",\"type\":\"@n8n/n8n-nodes-langchain.vectorStorePinecone\",\"position\":[780,360],\"parameters\":{\"mode\":\"insert\",\"options\":{},\"pineconeIndex\":{\"__rl\":true,\"mode\":\"list\",\"value\":\"context-rag-test\",\"cachedResultName\":\"context-rag-test\"}},\"credentials\":{\"pineconeApi\":{\"id\":\"R3QGXSEIRTEAZttK\",\"name\":\"Auto: PineconeApi\"}},\"typeVersion\":1},{\"id\":\"0a8c2426-0aaf-424a-b246-336a9034aba8\",\"name\":\"Embeddings Google Gemini\",\"type\":\"@n8n/n8n-nodes-langchain.embeddingsGoogleGemini\",\"position\":[720,540],\"parameters\":{\"modelName\":\"models/text-embedding-004\"},\"credentials\":{\"googlePalmApi\":{\"id\":\"9idxGZRZ3BAKDoxq\",\"name\":\"Google Gemini(PaLM) Api account\"}},\"typeVersion\":1},{\"id\":\"edc587bd-494d-43e8-b6d6-26adab7af3dc\",\"name\":\"Default Data Loader\",\"type\":\"@n8n/n8n-nodes-langchain.documentDefaultDataLoader\",\"position\":[920,540],\"parameters\":{\"options\":{}},\"typeVersion\":1},{\"id\":\"a82d4e0b-248e-426d-9ef3-f25e7078ceb3\",\"name\":\"Recursive Character Text Splitter\",\"type\":\"@n8n/n8n-nodes-langchain.textSplitterRecursiveCharacterTextSplitter\",\"position\":[840,680],\"parameters\":{\"options\":{},\"chunkSize\":100000},\"typeVersion\":1},{\"id\":\"8571b92f-5587-454f-9700-ea04ca35311b\",\"name\":\"Get Document From Google Drive\",\"type\":\"n8n-nodes-base.googleDrive\",\"position\":[220,0],\"parameters\":{\"fileId\":{\"__rl\":true,\"mode\":\"list\",\"value\":\"1gm0jxFTLuiWB5u4esEjzoCPImrVqu0AEMIKBIesTf9M\",\"cachedResultUrl\":\"https://docs.google.com/document/d/1gm0jxFTLuiWB5u4esEjzoCPImrVqu0AEMIKBIesTf9M/edit?usp=drivesdk\",\"cachedResultName\":\"Udit Rawat - Details\"},\"options\":{\"googleFileConversion\":{\"conversion\":{\"docsToFormat\":\"text/plain\"}}},\"operation\":\"download\"},\"credentials\":{\"googleDriveOAuth2Api\":{\"id\":\"SsiQguNA8w3Wwv4w\",\"name\":\"Auto: Google Drive\"}},\"typeVersion\":3},{\"id\":\"2bed3d0f-3d65-4394-87f1-e73320a43a4a\",\"name\":\"Extract Text Data From Google Document\",\"type\":\"n8n-nodes-base.extractFromFile\",\"position\":[440,0],\"parameters\":{\"options\":{},\"operation\":\"text\"},\"typeVersion\":1},{\"id\":\"837fa691-6c66-434b-ba82-d1cad9aecdf7\",\"name\":\"Split Document Text Into Sections\",\"type\":\"n8n-nodes-base.code\",\"position\":[660,0],\"parameters\":{\"jsCode\":\"let split_text = \\\"â€”---------------------------â€”-------------[SECTIONEND]â€”---------------------------â€”-------------\\\";\\nfor (const item of $input.all()) {\\n  item.json.section = item.json.data.split(split_text);\\n  item.json.document = JSON.stringify(item.json.section)\\n}\\nreturn $input.all();\"},\"typeVersion\":2},{\"id\":\"cc801e7e-e01b-421a-9211-08322ef8a0b2\",\"name\":\"Prepare Sections For Looping\",\"type\":\"n8n-nodes-base.splitOut\",\"position\":[880,0],\"parameters\":{\"options\":{},\"fieldToSplitOut\":\"section\"},\"typeVersion\":1},{\"id\":\"658cb8df-92e3-4b25-8f37-e5f959d913dc\",\"name\":\"Sticky Note\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[-40,-100],\"parameters\":{\"width\":1300,\"height\":280,\"content\":\"## Prepare Document. \\nThis section is responsible for downloading the file from Google Drive, splitting the text into sections by detecting separators, and preparing them for looping.\"},\"typeVersion\":1},{\"id\":\"82ee9194-484a-46db-b75c-bec34201c7e2\",\"name\":\"Sticky Note1\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[-220,220],\"parameters\":{\"width\":780,\"height\":360,\"content\":\"## Prepare context\\nIn this section, the \\nagent node will prepare \\ncontext for a section \\n(chunk of text), which \\nwill then be passed for \\nconversion into a vectors \\nalong with the section itself.\"},\"typeVersion\":1},{\"id\":\"2f6950df-ead1-479a-aa51-7768121a4eb2\",\"name\":\"AI Agent - Prepare Context\",\"type\":\"@n8n/n8n-nodes-langchain.agent\",\"position\":[40,260],\"parameters\":{\"text\":\"=<document> \\n{{ $('Split Document Text Into Sections').item.json.document }}\\n</document> \\nHere is the chunk we want to situate within the whole document \\n<chunk> \\n{{ $json.section }}\\n</chunk> \\nPlease give a short succinct context to situate this chunk within the overall document for the purposes of improving search retrieval of the chunk. Answer only with the succinct context and nothing else. \",\"agent\":\"conversationalAgent\",\"options\":{},\"promptType\":\"define\"},\"typeVersion\":1.7},{\"id\":\"34a465fc-a505-445a-9211-bcd830381354\",\"name\":\"Concatenate the context and section text\",\"type\":\"n8n-nodes-base.set\",\"position\":[400,260],\"parameters\":{\"options\":{},\"assignments\":{\"assignments\":[{\"id\":\"e5fb0381-5d23-46e2-a0d1-438240b80a3e\",\"name\":\"=section_chunk\",\"type\":\"string\",\"value\":\"={{ $json.output }}. {{ $('Loop Over Items').item.json.section }}\"}]}},\"typeVersion\":3.4},{\"id\":\"4a7a788c-8e5b-453c-ae52-a4522048992d\",\"name\":\"Sticky Note2\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[640,220],\"parameters\":{\"width\":580,\"height\":600,\"content\":\"## Convert Text To Vectors\\nIn this step, the Pinecone node converts the provided text into vectors using Google Gemini and stores them in the Pinecone vector database.\"},\"typeVersion\":1},{\"id\":\"45798b49-fc78-417c-a752-4dd1a8882cd7\",\"name\":\"Sticky Note3\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[-460,-120],\"parameters\":{\"width\":400,\"height\":300,\"content\":\"## Video Demo\\n[![Video Thumbnail](https://img.youtube.com/vi/qBeWP65I4hg/maxresdefault.jpg)](https://www.youtube.com/watch?v=qBeWP65I4hg)\"},\"typeVersion\":1}],\"active\":false,\"pinData\":{},\"settings\":{\"executionOrder\":\"v1\"},\"versionId\":\"4f0e2203-5850-4a32-b1dd-5adc57fa43ff\",\"connections\":{\"Loop Over Items\":{\"main\":[[],[{\"node\":\"AI Agent - Prepare Context\",\"type\":\"main\",\"index\":0}]]},\"Default Data Loader\":{\"ai_document\":[[{\"node\":\"Pinecone Vector Store\",\"type\":\"ai_document\",\"index\":0}]]},\"OpenRouter Chat Model\":{\"ai_languageModel\":[[{\"node\":\"AI Agent - Prepare Context\",\"type\":\"ai_languageModel\",\"index\":0}]]},\"Pinecone Vector Store\":{\"main\":[[{\"node\":\"Loop Over Items\",\"type\":\"main\",\"index\":0}]]},\"Embeddings Google Gemini\":{\"ai_embedding\":[[{\"node\":\"Pinecone Vector Store\",\"type\":\"ai_embedding\",\"index\":0}]]},\"AI Agent - Prepare Context\":{\"main\":[[{\"node\":\"Concatenate the context and section text\",\"type\":\"main\",\"index\":0}]]},\"Prepare Sections For Looping\":{\"main\":[[{\"node\":\"Loop Over Items\",\"type\":\"main\",\"index\":0}]]},\"Get Document From Google Drive\":{\"main\":[[{\"node\":\"Extract Text Data From Google Document\",\"type\":\"main\",\"index\":0}]]},\"Recursive Character Text Splitter\":{\"ai_textSplitter\":[[{\"node\":\"Default Data Loader\",\"type\":\"ai_textSplitter\",\"index\":0}]]},\"Split Document Text Into Sections\":{\"main\":[[{\"node\":\"Prepare Sections For Looping\",\"type\":\"main\",\"index\":0}]]},\"When clicking â€˜Test workflowâ€™\":{\"main\":[[{\"node\":\"Get Document From Google Drive\",\"type\":\"main\",\"index\":0}]]},\"Extract Text Data From Google Document\":{\"main\":[[{\"node\":\"Split Document Text Into Sections\",\"type\":\"main\",\"index\":0}]]},\"Concatenate the context and section text\":{\"main\":[[{\"node\":\"Pinecone Vector Store\",\"type\":\"main\",\"index\":0}]]}}}",
  "readme": "Workflow based **on** the following article.  \n<https://www.anthropic.com/news/contextual-retrieval>\n\nThis n8n automation is designed to extract, process, and store content from documents into a **Pinecone** vector store using context-based chunking. The workflow enhances retrieval accuracy in **RAG (Retrieval-Augmented Generation)** setups by ensuring each chunk retains meaningful context.\n\n**Workflow Breakdown:**  \nðŸ”¹ **Google Drive** \\- Retrieve Document:  \nThe automation starts by fetching a source document from Google Drive. This document contains structured content, with predefined boundary markers for easy segmentation.\n\nðŸ”¹ **Extract Text Content** \\- Once retrieved, the documentâ€™s text is extracted for processing. Special section boundary markers are used to divide the text into logical sections.\n\nðŸ”¹ **Code Node** \\- Create Context-Based Chunks:  \nA custom code node processes the extracted text, identifying section boundaries and splitting the document into meaningful chunks. Each chunk is structured to retain its context within the entire document.\n\nðŸ”¹ **Loop Node** \\- Process Each Chunk:  \nThe workflow loops through each chunk, ensuring they are processed individually while maintaining a connection to the overall document context.\n\nðŸ”¹ **Agent Node** \\- Generate Context for Each Chunk:  \nWe use an Agent node powered by OpenAIâ€™s GPT-4.0-mini via OpenRouter to generate contextual metadata for each chunk, ensuring better retrieval accuracy.\n\nðŸ”¹ **Prepend Context to Chunks & Create Embeddings** \\- The generated context is prepended to the original chunk, creating context-rich embeddings that improve searchability.\n\nðŸ”¹ **Google Gemini** \\- Text Embeddings:  \nThe processed text is passed through Google Gemini text-embedding-004, which converts the text into semantic vector representations.\n\nðŸ”¹ **Pinecone Vector Store** \\- Store Embeddings:  \nThe final embeddings, along with the enriched chunk content and metadata, are stored in Pinecone, making them easily retrievable for RAG-based AI applications.\n\n**Use Case:**  \nThis automation enhances RAG retrieval by ensuring each chunk is contextually aware of the entire document, leading to more accurate AI responses. Itâ€™s perfect for applications that require semantic search, AI-powered knowledge management, or intelligent document retrieval.\n\nBy implementing context-based chunking, this workflow ensures that LLMs retrieve the most relevant data, improving response quality and accuracy in AI-driven applications.\n\n[![Video Thumbnail](https://img.youtube.com/vi/qBeWP65I4hg/maxresdefault.jpg)](https://www.youtube.com/watch?v=qBeWP65I4hg)\n",
  "readme_html": "<!--[--><div data-v-50766329=\"\"><p>Workflow based <strong>on</strong> the following article.<br>\n<a href=\"https://www.anthropic.com/news/contextual-retrieval\" rel=\"ugc nofollow\" target=\"_blank\">https://www.anthropic.com/news/contextual-retrieval</a></p>\n<p>This n8n automation is designed to extract, process, and store content from documents into a <strong>Pinecone</strong> vector store using context-based chunking. The workflow enhances retrieval accuracy in <strong>RAG (Retrieval-Augmented Generation)</strong> setups by ensuring each chunk retains meaningful context.</p>\n<p><strong>Workflow Breakdown:</strong><br>\nðŸ”¹ <strong>Google Drive</strong> - Retrieve Document:<br>\nThe automation starts by fetching a source document from Google Drive. This document contains structured content, with predefined boundary markers for easy segmentation.</p>\n<p>ðŸ”¹ <strong>Extract Text Content</strong> - Once retrieved, the documentâ€™s text is extracted for processing. Special section boundary markers are used to divide the text into logical sections.</p>\n<p>ðŸ”¹ <strong>Code Node</strong> - Create Context-Based Chunks:<br>\nA custom code node processes the extracted text, identifying section boundaries and splitting the document into meaningful chunks. Each chunk is structured to retain its context within the entire document.</p>\n<p>ðŸ”¹ <strong>Loop Node</strong> - Process Each Chunk:<br>\nThe workflow loops through each chunk, ensuring they are processed individually while maintaining a connection to the overall document context.</p>\n<p>ðŸ”¹ <strong>Agent Node</strong> - Generate Context for Each Chunk:<br>\nWe use an Agent node powered by OpenAIâ€™s GPT-4.0-mini via OpenRouter to generate contextual metadata for each chunk, ensuring better retrieval accuracy.</p>\n<p>ðŸ”¹ <strong>Prepend Context to Chunks &amp; Create Embeddings</strong> - The generated context is prepended to the original chunk, creating context-rich embeddings that improve searchability.</p>\n<p>ðŸ”¹ <strong>Google Gemini</strong> - Text Embeddings:<br>\nThe processed text is passed through Google Gemini text-embedding-004, which converts the text into semantic vector representations.</p>\n<p>ðŸ”¹ <strong>Pinecone Vector Store</strong> - Store Embeddings:<br>\nThe final embeddings, along with the enriched chunk content and metadata, are stored in Pinecone, making them easily retrievable for RAG-based AI applications.</p>\n<p><strong>Use Case:</strong><br>\nThis automation enhances RAG retrieval by ensuring each chunk is contextually aware of the entire document, leading to more accurate AI responses. Itâ€™s perfect for applications that require semantic search, AI-powered knowledge management, or intelligent document retrieval.</p>\n<p>By implementing context-based chunking, this workflow ensures that LLMs retrieve the most relevant data, improving response quality and accuracy in AI-driven applications.</p>\n<p><a href=\"https://www.youtube.com/watch?v=qBeWP65I4hg\" rel=\"ugc nofollow\" target=\"_blank\"><img src=\"https://img.youtube.com/vi/qBeWP65I4hg/maxresdefault.jpg\" alt=\"Video Thumbnail\"></a></p>\n</div><!--]-->"
}