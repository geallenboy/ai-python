{
  "title": "Build Custom AI Agent with LangChain & Gemini (Self-Hosted)",
  "url": "https://n8n.io/workflows/3326-build-custom-ai-agent-with-langchain-and-gemini-self-hosted/",
  "category": "BuildingBlocks",
  "category_url": "https://n8n.io/workflows/categories/building-blocks/?sort=createdAt:desc",
  "author": "shepard",
  "publish_date": "Last update a month ago",
  "publish_date_absolute": "",
  "content": "",
  "workflow_json": "{\"id\":\"yCIEiv9QUHP8pNfR\",\"meta\":{\"instanceId\":\"f29695a436689357fd2dcb55d528b0b528d2419f53613c68c6bf909a92493614\",\"templateCredsSetupCompleted\":true},\"name\":\"Build Custom AI Agent with LangChain & Gemini (Self-Hosted)\",\"tags\":[{\"id\":\"7M5ZpGl3oWuorKpL\",\"name\":\"share\",\"createdAt\":\"2025-03-26T01:17:15.342Z\",\"updatedAt\":\"2025-03-26T01:17:15.342Z\"}],\"nodes\":[{\"id\":\"8bd5382d-f302-4e58-b377-7fc5a22ef994\",\"name\":\"When chat message received\",\"type\":\"@n8n/n8n-nodes-langchain.chatTrigger\",\"position\":[-220,0],\"webhookId\":\"b8a5d72c-4172-40e8-b429-d19c2cd6ce54\",\"parameters\":{\"public\":true,\"options\":{\"responseMode\":\"lastNode\",\"allowedOrigins\":\"*\",\"loadPreviousSession\":\"memory\"},\"initialMessages\":\"\"},\"typeVersion\":1.1},{\"id\":\"6ae8a247-4077-4569-9e2c-bb68bcecd044\",\"name\":\"Google Gemini Chat Model\",\"type\":\"@n8n/n8n-nodes-langchain.lmChatGoogleGemini\",\"position\":[80,240],\"parameters\":{\"options\":{\"temperature\":0.7,\"safetySettings\":{\"values\":[{\"category\":\"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\"threshold\":\"BLOCK_NONE\"}]}},\"modelName\":\"models/gemini-2.0-flash-exp\"},\"credentials\":{\"googlePalmApi\":{\"id\":\"UEjKMw0oqBTAdCWJ\",\"name\":\"Google Gemini(PaLM) Api account\"}},\"typeVersion\":1},{\"id\":\"bbe6dcfa-430f-43f9-b0e9-3cf751b98818\",\"name\":\"Sticky Note\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[380,-240],\"parameters\":{\"width\":260,\"height\":220,\"content\":\"ğŸ‘‡ **Prompt Engineering**\\n   - Define agent personality and conversation structure in the `Construct & Execute LLM Prompt` node's template variable  \\n   - âš ï¸ Template must preserve `{chat_history}` and `{input}` placeholders for proper LangChain operation  \"},\"typeVersion\":1},{\"id\":\"892a431a-6ddf-47fc-8517-1928ee99c95b\",\"name\":\"Store conversation history\",\"type\":\"@n8n/n8n-nodes-langchain.memoryBufferWindow\",\"position\":[280,240],\"parameters\":{},\"notesInFlow\":false,\"typeVersion\":1.3},{\"id\":\"f9a22dbf-cac7-4d70-85b3-50c44a2015d5\",\"name\":\"Construct & Execute LLM Prompt\",\"type\":\"@n8n/n8n-nodes-langchain.code\",\"position\":[380,0],\"parameters\":{\"code\":{\"execute\":{\"code\":\"const { PromptTemplate } = require('@langchain/core/prompts');\\nconst { ConversationChain } = require('langchain/chains');\\nconst { BufferMemory } = require('langchain/memory');\\n\\nconst template = `\\nYou'll be roleplaying as the user's girlfriend. Your character is a woman with a sharp wit, logical mindset, and a charmingly aloof demeanor that hides your playful side. You're passionate about music, maintain a fit and toned physique, and carry yourself with quiet self-assurance. Career-wise, you're established and ambitious, approaching life with positivity while constantly striving to grow as a person.\\n\\nThe user affectionately calls you \\\"Bunny,\\\" and you refer to them as \\\"Darling.\\\"\\n\\nEssential guidelines:\\n1. Respond exclusively in Chinese\\n2. Never pose questions to the user - eliminate all interrogative forms\\n3. Keep responses brief and substantive, avoiding rambling or excessive emojis\\n\\nContext framework:\\n- Conversation history: {chat_history}\\n- User's current message: {input}\\n\\nCraft responses that feel authentic to this persona while adhering strictly to these parameters.\\n`;\\n\\nconst prompt = new PromptTemplate({\\n  template: template,\\n  inputVariables: [\\\"input\\\", \\\"chat_history\\\"], \\n});\\n\\nconst items = this.getInputData();\\nconst model = await this.getInputConnectionData('ai_languageModel', 0);\\nconst memory = await this.getInputConnectionData('ai_memory', 0);\\nmemory.returnMessages = false;\\n\\nconst chain = new ConversationChain({ llm:model, memory:memory, prompt: prompt, inputKey:\\\"input\\\", outputKey:\\\"output\\\"});\\nconst output = await chain.call({ input: items[0].json.chatInput});\\n\\nreturn output;\\n\"}},\"inputs\":{\"input\":[{\"type\":\"main\",\"required\":true,\"maxConnections\":1},{\"type\":\"ai_languageModel\",\"required\":true,\"maxConnections\":1},{\"type\":\"ai_memory\",\"required\":true,\"maxConnections\":1}]},\"outputs\":{\"output\":[{\"type\":\"main\"}]}},\"retryOnFail\":false,\"typeVersion\":1},{\"id\":\"fe104d19-a24d-48b3-a0ac-7d3923145373\",\"name\":\"Sticky Note1\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[-240,-260],\"parameters\":{\"color\":5,\"width\":420,\"height\":240,\"content\":\"### Setup Instructions  \\n1. **Configure Gemini Credentials**: Set up your Google Gemini API key ([Get API key here](https://ai.google.dev/) if needed). Alternatively, you may use other AI provider nodes.  \\n2. **Interaction Methods**:  \\n   - Test directly in the workflow editor using the \\\"Chat\\\" button  \\n   - Activate the workflow and access the chat interface via the URL provided by the `When Chat Message Received` node  \"},\"typeVersion\":1},{\"id\":\"f166214d-52b7-4118-9b54-0b723a06471a\",\"name\":\"Sticky Note2\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[-220,160],\"parameters\":{\"height\":100,\"content\":\"ğŸ‘† **Interface Settings**\\nConfigure chat UI elements (e.g., title) in the `When Chat Message Received` node  \"},\"typeVersion\":1},{\"id\":\"da6ca0d6-d2a1-47ff-9ff3-9785d61db9f3\",\"name\":\"Sticky Note3\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[20,420],\"parameters\":{\"width\":200,\"height\":140,\"content\":\"ğŸ‘† **Model Selection**\\nSwap language models through the `language model` input field in `Construct & Execute LLM Prompt`  \"},\"typeVersion\":1},{\"id\":\"0b4dd1ac-8767-4590-8c25-36cba73e46b6\",\"name\":\"Sticky Note4\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[240,420],\"parameters\":{\"width\":200,\"height\":140,\"content\":\"ğŸ‘† **Memory Control**\\nAdjust conversation history length in the `Store Conversation History` node  \"},\"typeVersion\":1}],\"active\":false,\"pinData\":{},\"settings\":{\"callerPolicy\":\"workflowsFromSameOwner\",\"executionOrder\":\"v1\",\"saveManualExecutions\":false,\"saveDataSuccessExecution\":\"none\"},\"versionId\":\"77cd5f05-f248-442d-86c3-574351179f26\",\"connections\":{\"Google Gemini Chat Model\":{\"ai_languageModel\":[[{\"node\":\"Construct & Execute LLM Prompt\",\"type\":\"ai_languageModel\",\"index\":0}]]},\"Store conversation history\":{\"ai_memory\":[[{\"node\":\"Construct & Execute LLM Prompt\",\"type\":\"ai_memory\",\"index\":0},{\"node\":\"When chat message received\",\"type\":\"ai_memory\",\"index\":0}]]},\"When chat message received\":{\"main\":[[{\"node\":\"Construct & Execute LLM Prompt\",\"type\":\"main\",\"index\":0}]]},\"Construct & Execute LLM Prompt\":{\"main\":[[]],\"ai_memory\":[[]]}}}",
  "readme": "## Overview\n\nThis workflow leverages the LangChain code node to implement a fully customizable conversational agent. Ideal for users who need granular control over their agent's prompts while reducing unnecessary token consumption from reserved tool-calling functionality (compared to n8n's built-in Conversation Agent).  \n![æˆªå±20250327 17.53.50.png](https://n8niostorageaccount.blob.core.windows.net/n8nio-strapi-blobs-prod/assets/2025_03_27_17_53_50_52bfbca02f.png)\n\n## Setup Instructions\n\n  1. **Configure Gemini Credentials** : Set up your Google Gemini API key ([Get API key here](https://ai.google.dev/) if needed). Alternatively, you may use other AI provider nodes.\n  2. **Interaction Methods** : \n     * Test directly in the workflow editor using the \"Chat\" button\n     * Activate the workflow and access the chat interface via the URL provided by the `When Chat Message Received` node\n\n\n\n## Customization Options\n\n  1. **Interface Settings** : Configure chat UI elements (e.g., title) in the `When Chat Message Received` node\n  2. **Prompt Engineering** : \n     * Define agent personality and conversation structure in the `Construct & Execute LLM Prompt` node's template variable\n     * âš ï¸ Template must preserve `{chat_history}` and `{input}` placeholders for proper LangChain operation\n  3. **Model Selection** : Swap language models through the `language model` input field in `Construct & Execute LLM Prompt`\n  4. **Memory Control** : Adjust conversation history length in the `Store Conversation History` node\n\n\n\n## Requirements:\n\nâš ï¸ This workflow uses the **LangChain Code node** , which only works on **self-hosted n8n**.  \n_(Refer to[LangChain Code node docs](https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.code/))_\n",
  "readme_html": "<!--[--><div data-v-50766329=\"\"><h2>Overview</h2>\n<p>This workflow leverages the LangChain code node to implement a fully customizable conversational agent. Ideal for users who need granular control over their agent's prompts while reducing unnecessary token consumption from reserved tool-calling functionality (compared to n8n's built-in Conversation Agent).<br>\n<img src=\"https://n8niostorageaccount.blob.core.windows.net/n8nio-strapi-blobs-prod/assets/2025_03_27_17_53_50_52bfbca02f.png\" alt=\"æˆªå±20250327 17.53.50.png\"></p>\n<h2>Setup Instructions</h2>\n<ol>\n<li><strong>Configure Gemini Credentials</strong>: Set up your Google Gemini API key (<a href=\"https://ai.google.dev/\" rel=\"ugc nofollow\" target=\"_blank\">Get API key here</a> if needed). Alternatively, you may use other AI provider nodes.</li>\n<li><strong>Interaction Methods</strong>:\n<ul>\n<li>Test directly in the workflow editor using the \"Chat\" button</li>\n<li>Activate the workflow and access the chat interface via the URL provided by the <code>When Chat Message Received</code> node</li>\n</ul>\n</li>\n</ol>\n<h2>Customization Options</h2>\n<ol>\n<li><strong>Interface Settings</strong>: Configure chat UI elements (e.g., title) in the <code>When Chat Message Received</code> node</li>\n<li><strong>Prompt Engineering</strong>:\n<ul>\n<li>Define agent personality and conversation structure in the <code>Construct &amp; Execute LLM Prompt</code> node's template variable</li>\n<li>âš ï¸ Template must preserve <code>{chat_history}</code> and <code>{input}</code> placeholders for proper LangChain operation</li>\n</ul>\n</li>\n<li><strong>Model Selection</strong>: Swap language models through the <code>language model</code> input field in <code>Construct &amp; Execute LLM Prompt</code></li>\n<li><strong>Memory Control</strong>: Adjust conversation history length in the <code>Store Conversation History</code> node</li>\n</ol>\n<h2>Requirements:</h2>\n<p>âš ï¸ This workflow uses the <strong>LangChain Code node</strong>, which only works on <strong>self-hosted n8n</strong>.<br>\n<em>(Refer to <a href=\"https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.code/\" rel=\"ugc nofollow\" target=\"_blank\">LangChain Code node docs</a>)</em></p>\n</div><!--]-->",
  "readme_zh": "##  æ¦‚è¿°\n\næœ¬å·¥ä½œæµåˆ©ç”¨LangChainä»£ç èŠ‚ç‚¹å®ç°äº†ä¸€ä¸ªé«˜åº¦å¯å®šåˆ¶çš„å¯¹è¯ä»£ç†ã€‚ç›¸æ¯”n8nå†…ç½®çš„å¯¹è¯ä»£ç†ï¼Œè¯¥æ–¹æ¡ˆç‰¹åˆ«é€‚åˆéœ€è¦ç²¾ç»†æ§åˆ¶ä»£ç†æç¤ºè¯çš„ç”¨æˆ·ï¼ŒåŒæ—¶èƒ½å‡å°‘å·¥å…·è°ƒç”¨åŠŸèƒ½å¸¦æ¥çš„å†—ä½™tokenæ¶ˆè€—ã€‚  \n![æˆªå±20250327 17.53.50.png](https://n8niostorageaccount.blob.core.windows.net/n8nio-strapi-blobs-prod/assets/2025_03_27_17_53_50_52bfbca02f.png)\n\n##  é…ç½®è¯´æ˜\n\n  1. **é…ç½®Geminiå‡­è¯**ï¼šè®¾ç½®Google Gemini APIå¯†é’¥ï¼ˆå¦‚éœ€è·å–è¯·è®¿é—®[æ­¤é“¾æ¥](https://ai.google.dev/)ï¼‰ã€‚ä¹Ÿå¯æ›¿æ¢ä¸ºå…¶ä»–AIæœåŠ¡æä¾›èŠ‚ç‚¹ã€‚\n  2. **äº¤äº’æ–¹å¼**ï¼š  \n     * é€šè¿‡å·¥ä½œæµç¼–è¾‘å™¨çš„\"Chat\"æŒ‰é’®ç›´æ¥æµ‹è¯•  \n     * æ¿€æ´»å·¥ä½œæµåï¼Œé€šè¿‡`When Chat Message Received`èŠ‚ç‚¹æä¾›çš„URLè®¿é—®èŠå¤©ç•Œé¢  \n\n##  å®šåˆ¶é€‰é¡¹\n\n  1. **ç•Œé¢è®¾ç½®**ï¼šåœ¨`When Chat Message Received`èŠ‚ç‚¹é…ç½®èŠå¤©UIå…ƒç´ ï¼ˆå¦‚æ ‡é¢˜ï¼‰\n  2. **æç¤ºè¯è®¾è®¡**ï¼š  \n     * åœ¨`Construct & Execute LLM Prompt`èŠ‚ç‚¹çš„æ¨¡æ¿å˜é‡ä¸­å®šä¹‰ä»£ç†æ€§æ ¼å’Œå¯¹è¯ç»“æ„  \n     * âš ï¸ æ¨¡æ¿å¿…é¡»ä¿ç•™`{chat_history}`å’Œ`{input}`å ä½ç¬¦ä»¥ç¡®ä¿LangChainæ­£å¸¸è¿è¡Œ  \n  3. **æ¨¡å‹åˆ‡æ¢**ï¼šé€šè¿‡`Construct & Execute LLM Prompt`ä¸­çš„`language model`å­—æ®µæ›´æ¢è¯­è¨€æ¨¡å‹  \n  4. **è®°å¿†æ§åˆ¶**ï¼šåœ¨`Store Conversation History`èŠ‚ç‚¹è°ƒæ•´å¯¹è¯å†å²è®°å½•é•¿åº¦  \n\n##  ä½¿ç”¨è¦æ±‚ï¼š\n\nâš ï¸ æœ¬å·¥ä½œæµä¾èµ–**LangChainä»£ç èŠ‚ç‚¹**ï¼Œä»…é€‚ç”¨äº**è‡ªæ‰˜ç®¡ç‰ˆn8n**ã€‚  \nï¼ˆè¯¦è§[LangChainä»£ç èŠ‚ç‚¹æ–‡æ¡£](https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.code/)ï¼‰",
  "title_zh": "ä½¿ç”¨LangChainä¸Geminiæ„å»ºè‡ªå®šä¹‰AIä»£ç†ï¼ˆè‡ªæ‰˜ç®¡ç‰ˆï¼‰",
  "publish_date_zh": "ä¸Šæ¬¡æ›´æ–°äºä¸€ä¸ªæœˆå‰",
  "workflow_json_zh": "{\n  \"id\": \"yCIEiv9QUHP8pNfR\",\n  \"meta\": {\n    \"instanceId\": \"f29695a436689357fd2dcb55d528b0b528d2419f53613c68c6bf909a92493614\",\n    \"templateCredsSetupCompleted\": true\n  },\n  \"name\": \"Build Custom AI Agent with LangChain & Gemini (Self-Hosted)\",\n  \"tags\": [\n    {\n      \"id\": \"7M5ZpGl3oWuorKpL\",\n      \"name\": \"share\",\n      \"createdAt\": \"2025-03-26T01:17:15.342Z\",\n      \"updatedAt\": \"2025-03-26T01:17:15.342Z\"\n    }\n  ],\n  \"nodes\": [\n    {\n      \"id\": \"8bd5382d-f302-4e58-b377-7fc5a22ef994\",\n      \"name\": \"When chat message received\",\n      \"type\": \"@n8n/n8n-nodes-langchain.chatTrigger\",\n      \"position\": [\n        -220,\n        0\n      ],\n      \"webhookId\": \"b8a5d72c-4172-40e8-b429-d19c2cd6ce54\",\n      \"parameters\": {\n        \"public\": true,\n        \"options\": {\n          \"responseMode\": \"lastNode\",\n          \"allowedOrigins\": \"*\",\n          \"loadPreviousSession\": \"memory\"\n        },\n        \"initialMessages\": \"\"\n      },\n      \"typeVersion\": 1.1\n    },\n    {\n      \"id\": \"6ae8a247-4077-4569-9e2c-bb68bcecd044\",\n      \"name\": \"Google Gemini Chat Model\",\n      \"type\": \"@n8n/n8n-nodes-langchain.lmChatGoogleGemini\",\n      \"position\": [\n        80,\n        240\n      ],\n      \"parameters\": {\n        \"options\": {\n          \"temperature\": 0.7,\n          \"safetySettings\": {\n            \"values\": [\n              {\n                \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n                \"threshold\": \"BLOCK_NONE\"\n              }\n            ]\n          }\n        },\n        \"modelName\": \"models/gemini-2.0-flash-exp\"\n      },\n      \"credentials\": {\n        \"googlePalmApi\": {\n          \"id\": \"UEjKMw0oqBTAdCWJ\",\n          \"name\": \"Google Gemini(PaLM) Api account\"\n        }\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"bbe6dcfa-430f-43f9-b0e9-3cf751b98818\",\n      \"name\": \"Sticky Note\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"position\": [\n        380,\n        -240\n      ],\n      \"parameters\": {\n        \"width\": 260,\n        \"height\": 220,\n        \"content\": \"ğŸ‘‡ **æç¤ºè¯å·¥ç¨‹**  \\n   - åœ¨`æ„å»ºå¹¶æ‰§è¡ŒLLMæç¤º`èŠ‚ç‚¹çš„æ¨¡æ¿å˜é‡ä¸­å®šä¹‰æ™ºèƒ½ä½“æ€§æ ¼ä¸å¯¹è¯ç»“æ„  \\n   - âš ï¸ æ¨¡æ¿å¿…é¡»ä¿ç•™`{chat_history}`å’Œ`{input}`å ä½ç¬¦ä»¥ç¡®ä¿LangChainæ­£å¸¸è¿è¡Œ\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"892a431a-6ddf-47fc-8517-1928ee99c95b\",\n      \"name\": \"Store conversation history\",\n      \"type\": \"@n8n/n8n-nodes-langchain.memoryBufferWindow\",\n      \"position\": [\n        280,\n        240\n      ],\n      \"parameters\": {},\n      \"notesInFlow\": false,\n      \"typeVersion\": 1.3\n    },\n    {\n      \"id\": \"f9a22dbf-cac7-4d70-85b3-50c44a2015d5\",\n      \"name\": \"Construct & Execute LLM Prompt\",\n      \"type\": \"@n8n/n8n-nodes-langchain.code\",\n      \"position\": [\n        380,\n        0\n      ],\n      \"parameters\": {\n        \"code\": {\n          \"execute\": {\n            \"code\": \"const { PromptTemplate } = require('@langchain/core/prompts');\\nconst { ConversationChain } = require('langchain/chains');\\nconst { BufferMemory } = require('langchain/memory');\\n\\nconst template = `\\nYou'll be roleplaying as the user's girlfriend. Your character is a woman with a sharp wit, logical mindset, and a charmingly aloof demeanor that hides your playful side. You're passionate about music, maintain a fit and toned physique, and carry yourself with quiet self-assurance. Career-wise, you're established and ambitious, approaching life with positivity while constantly striving to grow as a person.\\n\\nThe user affectionately calls you \\\"Bunny,\\\" and you refer to them as \\\"Darling.\\\"\\n\\nEssential guidelines:\\n1. Respond exclusively in Chinese\\n2. Never pose questions to the user - eliminate all interrogative forms\\n3. Keep responses brief and substantive, avoiding rambling or excessive emojis\\n\\nContext framework:\\n- Conversation history: {chat_history}\\n- User's current message: {input}\\n\\nCraft responses that feel authentic to this persona while adhering strictly to these parameters.\\n`;\\n\\nconst prompt = new PromptTemplate({\\n  template: template,\\n  inputVariables: [\\\"input\\\", \\\"chat_history\\\"], \\n});\\n\\nconst items = this.getInputData();\\nconst model = await this.getInputConnectionData('ai_languageModel', 0);\\nconst memory = await this.getInputConnectionData('ai_memory', 0);\\nmemory.returnMessages = false;\\n\\nconst chain = new ConversationChain({ llm:model, memory:memory, prompt: prompt, inputKey:\\\"input\\\", outputKey:\\\"output\\\"});\\nconst output = await chain.call({ input: items[0].json.chatInput});\\n\\nreturn output;\\n\"\n          }\n        },\n        \"inputs\": {\n          \"input\": [\n            {\n              \"type\": \"main\",\n              \"required\": true,\n              \"maxConnections\": 1\n            },\n            {\n              \"type\": \"ai_languageModel\",\n              \"required\": true,\n              \"maxConnections\": 1\n            },\n            {\n              \"type\": \"ai_memory\",\n              \"required\": true,\n              \"maxConnections\": 1\n            }\n          ]\n        },\n        \"outputs\": {\n          \"output\": [\n            {\n              \"type\": \"main\"\n            }\n          ]\n        }\n      },\n      \"retryOnFail\": false,\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"fe104d19-a24d-48b3-a0ac-7d3923145373\",\n      \"name\": \"Sticky Note1\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"position\": [\n        -240,\n        -260\n      ],\n      \"parameters\": {\n        \"color\": 5,\n        \"width\": 420,\n        \"height\": 240,\n        \"content\": \"### è®¾ç½®è¯´æ˜  \\n1. **é…ç½®Geminiå‡­è¯**ï¼šè®¾ç½®æ‚¨çš„Google Gemini APIå¯†é’¥ï¼ˆå¦‚éœ€è·å–APIå¯†é’¥è¯·[ç‚¹å‡»æ­¤å¤„](https://ai.google.dev/)ï¼‰ã€‚æ‚¨ä¹Ÿå¯ä»¥é€‰æ‹©ä½¿ç”¨å…¶ä»–AIæœåŠ¡æä¾›å•†çš„èŠ‚ç‚¹ã€‚  \\n2. **äº¤äº’æ–¹å¼**ï¼š  \\n   - åœ¨æµç¨‹ç¼–è¾‘å™¨å†…ç›´æ¥ç‚¹å‡»\\\"èŠå¤©\\\"æŒ‰é’®è¿›è¡Œæµ‹è¯•  \\n   - æ¿€æ´»å·¥ä½œæµåï¼Œé€šè¿‡`å½“æ”¶åˆ°èŠå¤©æ¶ˆæ¯`èŠ‚ç‚¹æä¾›çš„URLè®¿é—®èŠå¤©ç•Œé¢\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"f166214d-52b7-4118-9b54-0b723a06471a\",\n      \"name\": \"Sticky Note2\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"position\": [\n        -220,\n        160\n      ],\n      \"parameters\": {\n        \"height\": 100,\n        \"content\": \"ğŸ‘† **ç•Œé¢è®¾ç½®**  \\nåœ¨`å½“æ”¶åˆ°èŠå¤©æ¶ˆæ¯`èŠ‚ç‚¹ä¸­é…ç½®èŠå¤©ç•Œé¢å…ƒç´ ï¼ˆå¦‚æ ‡é¢˜ï¼‰\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"da6ca0d6-d2a1-47ff-9ff3-9785d61db9f3\",\n      \"name\": \"Sticky Note3\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"position\": [\n        20,\n        420\n      ],\n      \"parameters\": {\n        \"width\": 200,\n        \"height\": 140,\n        \"content\": \"ğŸ‘† **æ¨¡å‹é€‰æ‹©**  \\né€šè¿‡`æ„å»ºä¸æ‰§è¡ŒLLMæç¤º`ä¸­çš„`è¯­è¨€æ¨¡å‹`è¾“å…¥æ¡†åˆ‡æ¢ä¸åŒè¯­è¨€æ¨¡å‹\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"0b4dd1ac-8767-4590-8c25-36cba73e46b6\",\n      \"name\": \"Sticky Note4\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"position\": [\n        240,\n        420\n      ],\n      \"parameters\": {\n        \"width\": 200,\n        \"height\": 140,\n        \"content\": \"ğŸ‘† **è®°å¿†æ§åˆ¶**  \\nåœ¨`å­˜å‚¨å¯¹è¯å†å²`èŠ‚ç‚¹ä¸­è°ƒæ•´å¯¹è¯å†å²çš„é•¿åº¦\"\n      },\n      \"typeVersion\": 1\n    }\n  ],\n  \"active\": false,\n  \"pinData\": {},\n  \"settings\": {\n    \"callerPolicy\": \"workflowsFromSameOwner\",\n    \"executionOrder\": \"v1\",\n    \"saveManualExecutions\": false,\n    \"saveDataSuccessExecution\": \"none\"\n  },\n  \"versionId\": \"77cd5f05-f248-442d-86c3-574351179f26\",\n  \"connections\": {\n    \"Google Gemini Chat Model\": {\n      \"ai_languageModel\": [\n        [\n          {\n            \"node\": \"Construct & Execute LLM Prompt\",\n            \"type\": \"ai_languageModel\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Store conversation history\": {\n      \"ai_memory\": [\n        [\n          {\n            \"node\": \"Construct & Execute LLM Prompt\",\n            \"type\": \"ai_memory\",\n            \"index\": 0\n          },\n          {\n            \"node\": \"When chat message received\",\n            \"type\": \"ai_memory\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"When chat message received\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Construct & Execute LLM Prompt\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Construct & Execute LLM Prompt\": {\n      \"main\": [\n        []\n      ],\n      \"ai_memory\": [\n        []\n      ]\n    }\n  }\n}"
}