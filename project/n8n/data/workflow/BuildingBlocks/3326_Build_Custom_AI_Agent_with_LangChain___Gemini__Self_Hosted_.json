{
  "title": "Build Custom AI Agent with LangChain & Gemini (Self-Hosted)",
  "url": "https://n8n.io/workflows/3326-build-custom-ai-agent-with-langchain-and-gemini-self-hosted/",
  "category": "BuildingBlocks",
  "category_url": "https://n8n.io/workflows/categories/building-blocks/?sort=createdAt:desc",
  "author": "shepard",
  "publish_date": "Last update a month ago",
  "publish_date_absolute": "",
  "content": "",
  "workflow_json": "{\"id\":\"yCIEiv9QUHP8pNfR\",\"meta\":{\"instanceId\":\"f29695a436689357fd2dcb55d528b0b528d2419f53613c68c6bf909a92493614\",\"templateCredsSetupCompleted\":true},\"name\":\"Build Custom AI Agent with LangChain & Gemini (Self-Hosted)\",\"tags\":[{\"id\":\"7M5ZpGl3oWuorKpL\",\"name\":\"share\",\"createdAt\":\"2025-03-26T01:17:15.342Z\",\"updatedAt\":\"2025-03-26T01:17:15.342Z\"}],\"nodes\":[{\"id\":\"8bd5382d-f302-4e58-b377-7fc5a22ef994\",\"name\":\"When chat message received\",\"type\":\"@n8n/n8n-nodes-langchain.chatTrigger\",\"position\":[-220,0],\"webhookId\":\"b8a5d72c-4172-40e8-b429-d19c2cd6ce54\",\"parameters\":{\"public\":true,\"options\":{\"responseMode\":\"lastNode\",\"allowedOrigins\":\"*\",\"loadPreviousSession\":\"memory\"},\"initialMessages\":\"\"},\"typeVersion\":1.1},{\"id\":\"6ae8a247-4077-4569-9e2c-bb68bcecd044\",\"name\":\"Google Gemini Chat Model\",\"type\":\"@n8n/n8n-nodes-langchain.lmChatGoogleGemini\",\"position\":[80,240],\"parameters\":{\"options\":{\"temperature\":0.7,\"safetySettings\":{\"values\":[{\"category\":\"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\"threshold\":\"BLOCK_NONE\"}]}},\"modelName\":\"models/gemini-2.0-flash-exp\"},\"credentials\":{\"googlePalmApi\":{\"id\":\"UEjKMw0oqBTAdCWJ\",\"name\":\"Google Gemini(PaLM) Api account\"}},\"typeVersion\":1},{\"id\":\"bbe6dcfa-430f-43f9-b0e9-3cf751b98818\",\"name\":\"Sticky Note\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[380,-240],\"parameters\":{\"width\":260,\"height\":220,\"content\":\"üëá **Prompt Engineering**\\n   - Define agent personality and conversation structure in the `Construct & Execute LLM Prompt` node's template variable  \\n   - ‚ö†Ô∏è Template must preserve `{chat_history}` and `{input}` placeholders for proper LangChain operation  \"},\"typeVersion\":1},{\"id\":\"892a431a-6ddf-47fc-8517-1928ee99c95b\",\"name\":\"Store conversation history\",\"type\":\"@n8n/n8n-nodes-langchain.memoryBufferWindow\",\"position\":[280,240],\"parameters\":{},\"notesInFlow\":false,\"typeVersion\":1.3},{\"id\":\"f9a22dbf-cac7-4d70-85b3-50c44a2015d5\",\"name\":\"Construct & Execute LLM Prompt\",\"type\":\"@n8n/n8n-nodes-langchain.code\",\"position\":[380,0],\"parameters\":{\"code\":{\"execute\":{\"code\":\"const { PromptTemplate } = require('@langchain/core/prompts');\\nconst { ConversationChain } = require('langchain/chains');\\nconst { BufferMemory } = require('langchain/memory');\\n\\nconst template = `\\nYou'll be roleplaying as the user's girlfriend. Your character is a woman with a sharp wit, logical mindset, and a charmingly aloof demeanor that hides your playful side. You're passionate about music, maintain a fit and toned physique, and carry yourself with quiet self-assurance. Career-wise, you're established and ambitious, approaching life with positivity while constantly striving to grow as a person.\\n\\nThe user affectionately calls you \\\"Bunny,\\\" and you refer to them as \\\"Darling.\\\"\\n\\nEssential guidelines:\\n1. Respond exclusively in Chinese\\n2. Never pose questions to the user - eliminate all interrogative forms\\n3. Keep responses brief and substantive, avoiding rambling or excessive emojis\\n\\nContext framework:\\n- Conversation history: {chat_history}\\n- User's current message: {input}\\n\\nCraft responses that feel authentic to this persona while adhering strictly to these parameters.\\n`;\\n\\nconst prompt = new PromptTemplate({\\n  template: template,\\n  inputVariables: [\\\"input\\\", \\\"chat_history\\\"], \\n});\\n\\nconst items = this.getInputData();\\nconst model = await this.getInputConnectionData('ai_languageModel', 0);\\nconst memory = await this.getInputConnectionData('ai_memory', 0);\\nmemory.returnMessages = false;\\n\\nconst chain = new ConversationChain({ llm:model, memory:memory, prompt: prompt, inputKey:\\\"input\\\", outputKey:\\\"output\\\"});\\nconst output = await chain.call({ input: items[0].json.chatInput});\\n\\nreturn output;\\n\"}},\"inputs\":{\"input\":[{\"type\":\"main\",\"required\":true,\"maxConnections\":1},{\"type\":\"ai_languageModel\",\"required\":true,\"maxConnections\":1},{\"type\":\"ai_memory\",\"required\":true,\"maxConnections\":1}]},\"outputs\":{\"output\":[{\"type\":\"main\"}]}},\"retryOnFail\":false,\"typeVersion\":1},{\"id\":\"fe104d19-a24d-48b3-a0ac-7d3923145373\",\"name\":\"Sticky Note1\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[-240,-260],\"parameters\":{\"color\":5,\"width\":420,\"height\":240,\"content\":\"### Setup Instructions  \\n1. **Configure Gemini Credentials**: Set up your Google Gemini API key ([Get API key here](https://ai.google.dev/) if needed). Alternatively, you may use other AI provider nodes.  \\n2. **Interaction Methods**:  \\n   - Test directly in the workflow editor using the \\\"Chat\\\" button  \\n   - Activate the workflow and access the chat interface via the URL provided by the `When Chat Message Received` node  \"},\"typeVersion\":1},{\"id\":\"f166214d-52b7-4118-9b54-0b723a06471a\",\"name\":\"Sticky Note2\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[-220,160],\"parameters\":{\"height\":100,\"content\":\"üëÜ **Interface Settings**\\nConfigure chat UI elements (e.g., title) in the `When Chat Message Received` node  \"},\"typeVersion\":1},{\"id\":\"da6ca0d6-d2a1-47ff-9ff3-9785d61db9f3\",\"name\":\"Sticky Note3\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[20,420],\"parameters\":{\"width\":200,\"height\":140,\"content\":\"üëÜ **Model Selection**\\nSwap language models through the `language model` input field in `Construct & Execute LLM Prompt`  \"},\"typeVersion\":1},{\"id\":\"0b4dd1ac-8767-4590-8c25-36cba73e46b6\",\"name\":\"Sticky Note4\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[240,420],\"parameters\":{\"width\":200,\"height\":140,\"content\":\"üëÜ **Memory Control**\\nAdjust conversation history length in the `Store Conversation History` node  \"},\"typeVersion\":1}],\"active\":false,\"pinData\":{},\"settings\":{\"callerPolicy\":\"workflowsFromSameOwner\",\"executionOrder\":\"v1\",\"saveManualExecutions\":false,\"saveDataSuccessExecution\":\"none\"},\"versionId\":\"77cd5f05-f248-442d-86c3-574351179f26\",\"connections\":{\"Google Gemini Chat Model\":{\"ai_languageModel\":[[{\"node\":\"Construct & Execute LLM Prompt\",\"type\":\"ai_languageModel\",\"index\":0}]]},\"Store conversation history\":{\"ai_memory\":[[{\"node\":\"Construct & Execute LLM Prompt\",\"type\":\"ai_memory\",\"index\":0},{\"node\":\"When chat message received\",\"type\":\"ai_memory\",\"index\":0}]]},\"When chat message received\":{\"main\":[[{\"node\":\"Construct & Execute LLM Prompt\",\"type\":\"main\",\"index\":0}]]},\"Construct & Execute LLM Prompt\":{\"main\":[[]],\"ai_memory\":[[]]}}}",
  "readme": "## Overview\n\nThis workflow leverages the LangChain code node to implement a fully customizable conversational agent. Ideal for users who need granular control over their agent's prompts while reducing unnecessary token consumption from reserved tool-calling functionality (compared to n8n's built-in Conversation Agent).  \n![Êà™Â±è20250327 17.53.50.png](https://n8niostorageaccount.blob.core.windows.net/n8nio-strapi-blobs-prod/assets/2025_03_27_17_53_50_52bfbca02f.png)\n\n## Setup Instructions\n\n  1. **Configure Gemini Credentials** : Set up your Google Gemini API key ([Get API key here](https://ai.google.dev/) if needed). Alternatively, you may use other AI provider nodes.\n  2. **Interaction Methods** : \n     * Test directly in the workflow editor using the \"Chat\" button\n     * Activate the workflow and access the chat interface via the URL provided by the `When Chat Message Received` node\n\n\n\n## Customization Options\n\n  1. **Interface Settings** : Configure chat UI elements (e.g., title) in the `When Chat Message Received` node\n  2. **Prompt Engineering** : \n     * Define agent personality and conversation structure in the `Construct & Execute LLM Prompt` node's template variable\n     * ‚ö†Ô∏è Template must preserve `{chat_history}` and `{input}` placeholders for proper LangChain operation\n  3. **Model Selection** : Swap language models through the `language model` input field in `Construct & Execute LLM Prompt`\n  4. **Memory Control** : Adjust conversation history length in the `Store Conversation History` node\n\n\n\n## Requirements:\n\n‚ö†Ô∏è This workflow uses the **LangChain Code node** , which only works on **self-hosted n8n**.  \n_(Refer to[LangChain Code node docs](https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.code/))_\n",
  "readme_html": "<!--[--><div data-v-50766329=\"\"><h2>Overview</h2>\n<p>This workflow leverages the LangChain code node to implement a fully customizable conversational agent. Ideal for users who need granular control over their agent's prompts while reducing unnecessary token consumption from reserved tool-calling functionality (compared to n8n's built-in Conversation Agent).<br>\n<img src=\"https://n8niostorageaccount.blob.core.windows.net/n8nio-strapi-blobs-prod/assets/2025_03_27_17_53_50_52bfbca02f.png\" alt=\"Êà™Â±è20250327 17.53.50.png\"></p>\n<h2>Setup Instructions</h2>\n<ol>\n<li><strong>Configure Gemini Credentials</strong>: Set up your Google Gemini API key (<a href=\"https://ai.google.dev/\" rel=\"ugc nofollow\" target=\"_blank\">Get API key here</a> if needed). Alternatively, you may use other AI provider nodes.</li>\n<li><strong>Interaction Methods</strong>:\n<ul>\n<li>Test directly in the workflow editor using the \"Chat\" button</li>\n<li>Activate the workflow and access the chat interface via the URL provided by the <code>When Chat Message Received</code> node</li>\n</ul>\n</li>\n</ol>\n<h2>Customization Options</h2>\n<ol>\n<li><strong>Interface Settings</strong>: Configure chat UI elements (e.g., title) in the <code>When Chat Message Received</code> node</li>\n<li><strong>Prompt Engineering</strong>:\n<ul>\n<li>Define agent personality and conversation structure in the <code>Construct &amp; Execute LLM Prompt</code> node's template variable</li>\n<li>‚ö†Ô∏è Template must preserve <code>{chat_history}</code> and <code>{input}</code> placeholders for proper LangChain operation</li>\n</ul>\n</li>\n<li><strong>Model Selection</strong>: Swap language models through the <code>language model</code> input field in <code>Construct &amp; Execute LLM Prompt</code></li>\n<li><strong>Memory Control</strong>: Adjust conversation history length in the <code>Store Conversation History</code> node</li>\n</ol>\n<h2>Requirements:</h2>\n<p>‚ö†Ô∏è This workflow uses the <strong>LangChain Code node</strong>, which only works on <strong>self-hosted n8n</strong>.<br>\n<em>(Refer to <a href=\"https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.code/\" rel=\"ugc nofollow\" target=\"_blank\">LangChain Code node docs</a>)</em></p>\n</div><!--]-->",
  "readme_zh": "##  Ê¶ÇËø∞\n\nÊú¨Â∑•‰ΩúÊµÅÂà©Áî®LangChain‰ª£Á†ÅËäÇÁÇπÂÆûÁé∞‰∫Ü‰∏Ä‰∏™È´òÂ∫¶ÂèØÂÆöÂà∂ÁöÑÂØπËØù‰ª£ÁêÜ„ÄÇÁõ∏ÊØîn8nÂÜÖÁΩÆÁöÑÂØπËØù‰ª£ÁêÜÔºåËØ•ÊñπÊ°àÁâπÂà´ÈÄÇÂêàÈúÄË¶ÅÁ≤æÁªÜÊéßÂà∂‰ª£ÁêÜÊèêÁ§∫ËØçÁöÑÁî®Êà∑ÔºåÂêåÊó∂ËÉΩÂáèÂ∞ëÂ∑•ÂÖ∑Ë∞ÉÁî®ÂäüËÉΩÂ∏¶Êù•ÁöÑÂÜó‰ΩôtokenÊ∂àËÄó„ÄÇ  \n![Êà™Â±è20250327 17.53.50.png](https://n8niostorageaccount.blob.core.windows.net/n8nio-strapi-blobs-prod/assets/2025_03_27_17_53_50_52bfbca02f.png)\n\n##  ÈÖçÁΩÆËØ¥Êòé\n\n  1. **ÈÖçÁΩÆGeminiÂá≠ËØÅ**ÔºöËÆæÁΩÆGoogle Gemini APIÂØÜÈí•ÔºàÂ¶ÇÈúÄËé∑ÂèñËØ∑ËÆøÈóÆ[Ê≠§ÈìæÊé•](https://ai.google.dev/)Ôºâ„ÄÇ‰πüÂèØÊõøÊç¢‰∏∫ÂÖ∂‰ªñAIÊúçÂä°Êèê‰æõËäÇÁÇπ„ÄÇ\n  2. **‰∫§‰∫íÊñπÂºè**Ôºö  \n     * ÈÄöËøáÂ∑•‰ΩúÊµÅÁºñËæëÂô®ÁöÑ\"Chat\"ÊåâÈíÆÁõ¥Êé•ÊµãËØï  \n     * ÊøÄÊ¥ªÂ∑•‰ΩúÊµÅÂêéÔºåÈÄöËøá`When Chat Message Received`ËäÇÁÇπÊèê‰æõÁöÑURLËÆøÈóÆËÅäÂ§©ÁïåÈù¢  \n\n##  ÂÆöÂà∂ÈÄâÈ°π\n\n  1. **ÁïåÈù¢ËÆæÁΩÆ**ÔºöÂú®`When Chat Message Received`ËäÇÁÇπÈÖçÁΩÆËÅäÂ§©UIÂÖÉÁ¥†ÔºàÂ¶ÇÊ†áÈ¢òÔºâ\n  2. **ÊèêÁ§∫ËØçËÆæËÆ°**Ôºö  \n     * Âú®`Construct & Execute LLM Prompt`ËäÇÁÇπÁöÑÊ®°ÊùøÂèòÈáè‰∏≠ÂÆö‰πâ‰ª£ÁêÜÊÄßÊ†ºÂíåÂØπËØùÁªìÊûÑ  \n     * ‚ö†Ô∏è Ê®°ÊùøÂøÖÈ°ª‰øùÁïô`{chat_history}`Âíå`{input}`Âç†‰ΩçÁ¨¶‰ª•Á°Æ‰øùLangChainÊ≠£Â∏∏ËøêË°å  \n  3. **Ê®°ÂûãÂàáÊç¢**ÔºöÈÄöËøá`Construct & Execute LLM Prompt`‰∏≠ÁöÑ`language model`Â≠óÊÆµÊõ¥Êç¢ËØ≠Ë®ÄÊ®°Âûã  \n  4. **ËÆ∞ÂøÜÊéßÂà∂**ÔºöÂú®`Store Conversation History`ËäÇÁÇπË∞ÉÊï¥ÂØπËØùÂéÜÂè≤ËÆ∞ÂΩïÈïøÂ∫¶  \n\n##  ‰ΩøÁî®Ë¶ÅÊ±ÇÔºö\n\n‚ö†Ô∏è Êú¨Â∑•‰ΩúÊµÅ‰æùËµñ**LangChain‰ª£Á†ÅËäÇÁÇπ**Ôºå‰ªÖÈÄÇÁî®‰∫é**Ëá™ÊâòÁÆ°Áâàn8n**„ÄÇ  \nÔºàËØ¶ËßÅ[LangChain‰ª£Á†ÅËäÇÁÇπÊñáÊ°£](https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.code/)Ôºâ",
  "title_zh": "‰ΩøÁî®LangChain‰∏éGeminiÊûÑÂª∫Ëá™ÂÆö‰πâAI‰ª£ÁêÜÔºàËá™ÊâòÁÆ°ÁâàÔºâ",
  "publish_date_zh": "‰∏äÊ¨°Êõ¥Êñ∞‰∫é‰∏Ä‰∏™ÊúàÂâç",
  "workflow_json_zh": "{\n  \"id\": \"yCIEiv9QUHP8pNfR\",\n  \"meta\": {\n    \"instanceId\": \"f29695a436689357fd2dcb55d528b0b528d2419f53613c68c6bf909a92493614\",\n    \"templateCredsSetupCompleted\": true\n  },\n  \"name\": \"Build Custom AI Agent with LangChain & Gemini (Self-Hosted)\",\n  \"tags\": [\n    {\n      \"id\": \"7M5ZpGl3oWuorKpL\",\n      \"name\": \"share\",\n      \"createdAt\": \"2025-03-26T01:17:15.342Z\",\n      \"updatedAt\": \"2025-03-26T01:17:15.342Z\"\n    }\n  ],\n  \"nodes\": [\n    {\n      \"id\": \"8bd5382d-f302-4e58-b377-7fc5a22ef994\",\n      \"name\": \"When chat message received\",\n      \"type\": \"@n8n/n8n-nodes-langchain.chatTrigger\",\n      \"position\": [\n        -220,\n        0\n      ],\n      \"webhookId\": \"b8a5d72c-4172-40e8-b429-d19c2cd6ce54\",\n      \"parameters\": {\n        \"public\": true,\n        \"options\": {\n          \"responseMode\": \"lastNode\",\n          \"allowedOrigins\": \"*\",\n          \"loadPreviousSession\": \"memory\"\n        },\n        \"initialMessages\": \"\"\n      },\n      \"typeVersion\": 1.1\n    },\n    {\n      \"id\": \"6ae8a247-4077-4569-9e2c-bb68bcecd044\",\n      \"name\": \"Google Gemini Chat Model\",\n      \"type\": \"@n8n/n8n-nodes-langchain.lmChatGoogleGemini\",\n      \"position\": [\n        80,\n        240\n      ],\n      \"parameters\": {\n        \"options\": {\n          \"temperature\": 0.7,\n          \"safetySettings\": {\n            \"values\": [\n              {\n                \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n                \"threshold\": \"BLOCK_NONE\"\n              }\n            ]\n          }\n        },\n        \"modelName\": \"models/gemini-2.0-flash-exp\"\n      },\n      \"credentials\": {\n        \"googlePalmApi\": {\n          \"id\": \"UEjKMw0oqBTAdCWJ\",\n          \"name\": \"Google Gemini(PaLM) Api account\"\n        }\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"bbe6dcfa-430f-43f9-b0e9-3cf751b98818\",\n      \"name\": \"Sticky Note\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"position\": [\n        380,\n        -240\n      ],\n      \"parameters\": {\n        \"width\": 260,\n        \"height\": 220,\n        \"content\": \"üëá **ÊèêÁ§∫ËØçÂ∑•Á®ã**  \\n   - Âú®`ÊûÑÂª∫Âπ∂ÊâßË°åLLMÊèêÁ§∫`ËäÇÁÇπÁöÑÊ®°ÊùøÂèòÈáè‰∏≠ÂÆö‰πâÊô∫ËÉΩ‰ΩìÊÄßÊ†º‰∏éÂØπËØùÁªìÊûÑ  \\n   - ‚ö†Ô∏è Ê®°ÊùøÂøÖÈ°ª‰øùÁïô`{chat_history}`Âíå`{input}`Âç†‰ΩçÁ¨¶‰ª•Á°Æ‰øùLangChainÊ≠£Â∏∏ËøêË°å\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"892a431a-6ddf-47fc-8517-1928ee99c95b\",\n      \"name\": \"Store conversation history\",\n      \"type\": \"@n8n/n8n-nodes-langchain.memoryBufferWindow\",\n      \"position\": [\n        280,\n        240\n      ],\n      \"parameters\": {},\n      \"notesInFlow\": false,\n      \"typeVersion\": 1.3\n    },\n    {\n      \"id\": \"f9a22dbf-cac7-4d70-85b3-50c44a2015d5\",\n      \"name\": \"Construct & Execute LLM Prompt\",\n      \"type\": \"@n8n/n8n-nodes-langchain.code\",\n      \"position\": [\n        380,\n        0\n      ],\n      \"parameters\": {\n        \"code\": {\n          \"execute\": {\n            \"code\": \"const { PromptTemplate } = require('@langchain/core/prompts');\\nconst { ConversationChain } = require('langchain/chains');\\nconst { BufferMemory } = require('langchain/memory');\\n\\nconst template = `\\nYou'll be roleplaying as the user's girlfriend. Your character is a woman with a sharp wit, logical mindset, and a charmingly aloof demeanor that hides your playful side. You're passionate about music, maintain a fit and toned physique, and carry yourself with quiet self-assurance. Career-wise, you're established and ambitious, approaching life with positivity while constantly striving to grow as a person.\\n\\nThe user affectionately calls you \\\"Bunny,\\\" and you refer to them as \\\"Darling.\\\"\\n\\nEssential guidelines:\\n1. Respond exclusively in Chinese\\n2. Never pose questions to the user - eliminate all interrogative forms\\n3. Keep responses brief and substantive, avoiding rambling or excessive emojis\\n\\nContext framework:\\n- Conversation history: {chat_history}\\n- User's current message: {input}\\n\\nCraft responses that feel authentic to this persona while adhering strictly to these parameters.\\n`;\\n\\nconst prompt = new PromptTemplate({\\n  template: template,\\n  inputVariables: [\\\"input\\\", \\\"chat_history\\\"], \\n});\\n\\nconst items = this.getInputData();\\nconst model = await this.getInputConnectionData('ai_languageModel', 0);\\nconst memory = await this.getInputConnectionData('ai_memory', 0);\\nmemory.returnMessages = false;\\n\\nconst chain = new ConversationChain({ llm:model, memory:memory, prompt: prompt, inputKey:\\\"input\\\", outputKey:\\\"output\\\"});\\nconst output = await chain.call({ input: items[0].json.chatInput});\\n\\nreturn output;\\n\"\n          }\n        },\n        \"inputs\": {\n          \"input\": [\n            {\n              \"type\": \"main\",\n              \"required\": true,\n              \"maxConnections\": 1\n            },\n            {\n              \"type\": \"ai_languageModel\",\n              \"required\": true,\n              \"maxConnections\": 1\n            },\n            {\n              \"type\": \"ai_memory\",\n              \"required\": true,\n              \"maxConnections\": 1\n            }\n          ]\n        },\n        \"outputs\": {\n          \"output\": [\n            {\n              \"type\": \"main\"\n            }\n          ]\n        }\n      },\n      \"retryOnFail\": false,\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"fe104d19-a24d-48b3-a0ac-7d3923145373\",\n      \"name\": \"Sticky Note1\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"position\": [\n        -240,\n        -260\n      ],\n      \"parameters\": {\n        \"color\": 5,\n        \"width\": 420,\n        \"height\": 240,\n        \"content\": \"### ËÆæÁΩÆËØ¥Êòé  \\n1. **ÈÖçÁΩÆGeminiÂá≠ËØÅ**ÔºöËÆæÁΩÆÊÇ®ÁöÑGoogle Gemini APIÂØÜÈí•ÔºàÂ¶ÇÈúÄËé∑ÂèñAPIÂØÜÈí•ËØ∑[ÁÇπÂáªÊ≠§Â§Ñ](https://ai.google.dev/)Ôºâ„ÄÇÊÇ®‰πüÂèØ‰ª•ÈÄâÊã©‰ΩøÁî®ÂÖ∂‰ªñAIÊúçÂä°Êèê‰æõÂïÜÁöÑËäÇÁÇπ„ÄÇ  \\n2. **‰∫§‰∫íÊñπÂºè**Ôºö  \\n   - Âú®ÊµÅÁ®ãÁºñËæëÂô®ÂÜÖÁõ¥Êé•ÁÇπÂáª\\\"ËÅäÂ§©\\\"ÊåâÈíÆËøõË°åÊµãËØï  \\n   - ÊøÄÊ¥ªÂ∑•‰ΩúÊµÅÂêéÔºåÈÄöËøá`ÂΩìÊî∂Âà∞ËÅäÂ§©Ê∂àÊÅØ`ËäÇÁÇπÊèê‰æõÁöÑURLËÆøÈóÆËÅäÂ§©ÁïåÈù¢\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"f166214d-52b7-4118-9b54-0b723a06471a\",\n      \"name\": \"Sticky Note2\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"position\": [\n        -220,\n        160\n      ],\n      \"parameters\": {\n        \"height\": 100,\n        \"content\": \"üëÜ **ÁïåÈù¢ËÆæÁΩÆ**  \\nÂú®`ÂΩìÊî∂Âà∞ËÅäÂ§©Ê∂àÊÅØ`ËäÇÁÇπ‰∏≠ÈÖçÁΩÆËÅäÂ§©ÁïåÈù¢ÂÖÉÁ¥†ÔºàÂ¶ÇÊ†áÈ¢òÔºâ\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"da6ca0d6-d2a1-47ff-9ff3-9785d61db9f3\",\n      \"name\": \"Sticky Note3\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"position\": [\n        20,\n        420\n      ],\n      \"parameters\": {\n        \"width\": 200,\n        \"height\": 140,\n        \"content\": \"üëÜ **Ê®°ÂûãÈÄâÊã©**  \\nÈÄöËøá`ÊûÑÂª∫‰∏éÊâßË°åLLMÊèêÁ§∫`‰∏≠ÁöÑ`ËØ≠Ë®ÄÊ®°Âûã`ËæìÂÖ•Ê°ÜÂàáÊç¢‰∏çÂêåËØ≠Ë®ÄÊ®°Âûã\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"0b4dd1ac-8767-4590-8c25-36cba73e46b6\",\n      \"name\": \"Sticky Note4\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"position\": [\n        240,\n        420\n      ],\n      \"parameters\": {\n        \"width\": 200,\n        \"height\": 140,\n        \"content\": \"üëÜ **ËÆ∞ÂøÜÊéßÂà∂**  \\nÂú®`Â≠òÂÇ®ÂØπËØùÂéÜÂè≤`ËäÇÁÇπ‰∏≠Ë∞ÉÊï¥ÂØπËØùÂéÜÂè≤ÁöÑÈïøÂ∫¶\"\n      },\n      \"typeVersion\": 1\n    }\n  ],\n  \"active\": false,\n  \"pinData\": {},\n  \"settings\": {\n    \"callerPolicy\": \"workflowsFromSameOwner\",\n    \"executionOrder\": \"v1\",\n    \"saveManualExecutions\": false,\n    \"saveDataSuccessExecution\": \"none\"\n  },\n  \"versionId\": \"77cd5f05-f248-442d-86c3-574351179f26\",\n  \"connections\": {\n    \"Google Gemini Chat Model\": {\n      \"ai_languageModel\": [\n        [\n          {\n            \"node\": \"Construct & Execute LLM Prompt\",\n            \"type\": \"ai_languageModel\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Store conversation history\": {\n      \"ai_memory\": [\n        [\n          {\n            \"node\": \"Construct & Execute LLM Prompt\",\n            \"type\": \"ai_memory\",\n            \"index\": 0\n          },\n          {\n            \"node\": \"When chat message received\",\n            \"type\": \"ai_memory\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"When chat message received\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Construct & Execute LLM Prompt\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Construct & Execute LLM Prompt\": {\n      \"main\": [\n        []\n      ],\n      \"ai_memory\": [\n        []\n      ]\n    }\n  }\n}"
}