{
  "title": "Extract personal data with self-hosted LLM Mistral NeMo",
  "url": "https://n8n.io/workflows/2766-extract-personal-data-with-self-hosted-llm-mistral-nemo/",
  "category": "BuildingBlocks",
  "category_url": "https://n8n.io/workflows/categories/building-blocks/?sort=createdAt:desc",
  "author": "Yulia",
  "publish_date": "Last update 3 months ago",
  "publish_date_absolute": "2025-02-07",
  "content": "",
  "workflow_json": "{\"id\":\"HMoUOg8J7RzEcslH\",\"meta\":{\"instanceId\":\"3f91626b10fcfa8a3d3ab8655534ff3e94151838fd2709ecd2dcb14afb3d061a\",\"templateCredsSetupCompleted\":true},\"name\":\"Extract personal data with a self-hosted LLM Mistral NeMo\",\"tags\":[],\"nodes\":[{\"id\":\"7e67ae65-88aa-4e48-aa63-2d3a4208cf4b\",\"name\":\"When chat message received\",\"type\":\"@n8n/n8n-nodes-langchain.chatTrigger\",\"position\":[-500,20],\"webhookId\":\"3a7b0ea1-47f3-4a94-8ff2-f5e1f3d9dc32\",\"parameters\":{\"options\":{}},\"typeVersion\":1.1},{\"id\":\"e064921c-69e6-4cfe-a86e-4e3aa3a5314a\",\"name\":\"Ollama Chat Model\",\"type\":\"@n8n/n8n-nodes-langchain.lmChatOllama\",\"position\":[-280,420],\"parameters\":{\"model\":\"mistral-nemo:latest\",\"options\":{\"useMLock\":true,\"keepAlive\":\"2h\",\"temperature\":0.1}},\"credentials\":{\"ollamaApi\":{\"id\":\"vgKP7LGys9TXZ0KK\",\"name\":\"Ollama account\"}},\"typeVersion\":1},{\"id\":\"fe1379da-a12e-4051-af91-9d67a7c9a76b\",\"name\":\"Auto-fixing Output Parser\",\"type\":\"@n8n/n8n-nodes-langchain.outputParserAutofixing\",\"position\":[-200,220],\"parameters\":{\"options\":{\"prompt\":\"Instructions:\\n--------------\\n{instructions}\\n--------------\\nCompletion:\\n--------------\\n{completion}\\n--------------\\n\\nAbove, the Completion did not satisfy the constraints given in the Instructions.\\nError:\\n--------------\\n{error}\\n--------------\\n\\nPlease try again. Please only respond with an answer that satisfies the constraints laid out in the Instructions:\"}},\"typeVersion\":1},{\"id\":\"b6633b00-6ebb-43ca-8e5c-664a53548c17\",\"name\":\"Structured Output Parser\",\"type\":\"@n8n/n8n-nodes-langchain.outputParserStructured\",\"position\":[60,400],\"parameters\":{\"schemaType\":\"manual\",\"inputSchema\":\"{\\n  \\\"type\\\": \\\"object\\\",\\n  \\\"properties\\\": {\\n    \\\"name\\\": {\\n      \\\"type\\\": \\\"string\\\",\\n      \\\"description\\\": \\\"Name of the user\\\"\\n    },\\n    \\\"surname\\\": {\\n      \\\"type\\\": \\\"string\\\",\\n      \\\"description\\\": \\\"Surname of the user\\\"\\n    },\\n    \\\"commtype\\\": {\\n      \\\"type\\\": \\\"string\\\",\\n      \\\"enum\\\": [\\\"email\\\", \\\"phone\\\", \\\"other\\\"],\\n      \\\"description\\\": \\\"Method of communication\\\"\\n    },\\n    \\\"contacts\\\": {\\n      \\\"type\\\": \\\"string\\\",\\n      \\\"description\\\": \\\"Contact details. ONLY IF PROVIDED\\\"\\n    },\\n    \\\"timestamp\\\": {\\n      \\\"type\\\": \\\"string\\\",\\n      \\\"format\\\": \\\"date-time\\\",\\n      \\\"description\\\": \\\"When the communication occurred\\\"\\n    },\\n    \\\"subject\\\": {\\n      \\\"type\\\": \\\"string\\\",\\n      \\\"description\\\": \\\"Brief description of the communication topic\\\"\\n    }\\n  },\\n  \\\"required\\\": [\\\"name\\\", \\\"commtype\\\"]\\n}\"},\"typeVersion\":1.2},{\"id\":\"23681a6c-cf62-48cb-86ee-08d5ce39bc0a\",\"name\":\"Basic LLM Chain\",\"type\":\"@n8n/n8n-nodes-langchain.chainLlm\",\"onError\":\"continueErrorOutput\",\"position\":[-240,20],\"parameters\":{\"messages\":{\"messageValues\":[{\"message\":\"=Please analyse the incoming user request. Extract information according to the JSON schema. Today is: \\\"{{ $now.toISO() }}\\\"\"}]},\"hasOutputParser\":true},\"typeVersion\":1.5},{\"id\":\"8f4d1b4b-58c0-41ec-9636-ac555e440821\",\"name\":\"On Error\",\"type\":\"n8n-nodes-base.noOp\",\"position\":[200,140],\"parameters\":{},\"typeVersion\":1},{\"id\":\"f4d77736-4470-48b4-8f61-149e09b70e3e\",\"name\":\"Sticky Note\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[-560,-160],\"parameters\":{\"color\":2,\"width\":960,\"height\":500,\"content\":\"## Update data source\\nWhen you change the data source, remember to update the `Prompt Source (User Message)` setting in the **Basic LLM Chain node**.\"},\"typeVersion\":1},{\"id\":\"5fd273c8-e61d-452b-8eac-8ac4b7fff6c2\",\"name\":\"Sticky Note1\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[-560,340],\"parameters\":{\"color\":2,\"width\":440,\"height\":220,\"content\":\"## Configure local LLM\\nOllama offers additional settings \\nto optimize model performance\\nor memory usage.\"},\"typeVersion\":1},{\"id\":\"63cbf762-0134-48da-a6cd-0363e870decd\",\"name\":\"Sticky Note2\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[0,340],\"parameters\":{\"color\":2,\"width\":400,\"height\":220,\"content\":\"## Define JSON Schema\"},\"typeVersion\":1},{\"id\":\"9625294f-3cb4-4465-9dae-9976e0cf5053\",\"name\":\"Extract JSON Output\",\"type\":\"n8n-nodes-base.set\",\"position\":[200,-80],\"parameters\":{\"mode\":\"raw\",\"options\":{},\"jsonOutput\":\"={{ $json.output }}\\n\"},\"typeVersion\":3.4},{\"id\":\"2c6fba3b-0ffe-4112-b904-823f52cc220b\",\"name\":\"Sticky Note3\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[-560,200],\"parameters\":{\"width\":960,\"height\":120,\"content\":\"If the LLM response does not pass \\nthe **Structured Output Parser** checks,\\n**Auto-Fixer** will call the model again with a different \\nprompt to correct the original response.\"},\"typeVersion\":1},{\"id\":\"c73ba1ca-d727-4904-a5fd-01dd921a4738\",\"name\":\"Sticky Note6\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[-560,460],\"parameters\":{\"height\":80,\"content\":\"The same LLM connects to both **Basic LLM Chain** and to the **Auto-fixing Output Parser**. \\n\"},\"typeVersion\":1},{\"id\":\"193dd153-8511-4326-aaae-47b89d0cd049\",\"name\":\"Sticky Note7\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[200,440],\"parameters\":{\"width\":200,\"height\":100,\"content\":\"When the LLM model responds, the output is checked in the **Structured Output Parser**\"},\"typeVersion\":1}],\"active\":false,\"pinData\":{},\"settings\":{\"executionOrder\":\"v1\"},\"versionId\":\"9f3721a8-f340-43d5-89e7-3175c29c2f3a\",\"connections\":{\"Basic LLM Chain\":{\"main\":[[{\"node\":\"Extract JSON Output\",\"type\":\"main\",\"index\":0}],[{\"node\":\"On Error\",\"type\":\"main\",\"index\":0}]]},\"Ollama Chat Model\":{\"ai_languageModel\":[[{\"node\":\"Auto-fixing Output Parser\",\"type\":\"ai_languageModel\",\"index\":0},{\"node\":\"Basic LLM Chain\",\"type\":\"ai_languageModel\",\"index\":0}]]},\"Structured Output Parser\":{\"ai_outputParser\":[[{\"node\":\"Auto-fixing Output Parser\",\"type\":\"ai_outputParser\",\"index\":0}]]},\"Auto-fixing Output Parser\":{\"ai_outputParser\":[[{\"node\":\"Basic LLM Chain\",\"type\":\"ai_outputParser\",\"index\":0}]]},\"When chat message received\":{\"main\":[[{\"node\":\"Basic LLM Chain\",\"type\":\"main\",\"index\":0}]]}}}",
  "readme": "This workflow shows how to use a self-hosted Large Language Model (LLM) with n8n's LangChain integration to extract personal information from user input. This is particularly useful for enterprise environments where data privacy is crucial, as it allows sensitive information to be processed locally.\n\nüìñ For a detailed explanation and more insights on using open-source LLMs with n8n, take a look at our [comprehensive guide on open-source LLMs](https://blog.n8n.io/open-source-llm/).\n\n## üîë Key Features\n\n  1. **Local LLM**\n\n     * Connect Ollama to run Mistral NeMo LLM locally\n     * Provide a foundation for compliant data processing, keeping sensitive information on-premises\n  2. **Data extraction**\n\n     * Convert unstructured text to a consistent JSON format\n     * Adjust the JSON schema to meet your specific data extraction needs.\n  3. **Error handling**\n\n     * Implement auto-fixing for LLM outputs\n     * Include error output for further processing\n\n\n\n## ‚öôÔ∏è Setup and —Åonfiguration\n\n### Prerequisites\n\n  * [n8n AI Starter Kit](https://docs.n8n.io/hosting/starter-kits/ai-starter-kit/) installed\n\n\n\n### Configuration steps\n\n  1. Add the **Basic LLM Chain** node with system prompts.\n  2. Set up the **Ollama Chat Model** with optimized parameters.\n  3. Define the JSON schema in the **Structured Output Parser** node.\n\n\n\n## üîç Further resources\n\n  * [Run LLMs locally with n8n](https://blog.n8n.io/local-llm/)\n  * [Video tutorial on using local AI with n8n](https://www.youtube.com/watch?v=xz_X2N-hPg0)\n\n\n\nApply the power of self-hosted LLMs in your n8n workflows while maintaining control over your data processing pipeline!\n",
  "readme_html": "<!--[--><div data-v-50766329=\"\"><p>This workflow shows how to use a self-hosted Large Language Model (LLM) with n8n's LangChain integration to extract personal information from user input. This is particularly useful for enterprise environments where data privacy is crucial, as it allows sensitive information to be processed locally.</p>\n<p>üìñ For a detailed explanation and more insights on using open-source LLMs with n8n, take a look at our <a href=\"https://blog.n8n.io/open-source-llm/\" rel=\"ugc nofollow\" target=\"_blank\">comprehensive guide on open-source LLMs</a>.</p>\n<h2>üîë Key Features</h2>\n<ol>\n<li>\n<p><strong>Local LLM</strong></p>\n<ul>\n<li>Connect Ollama to run Mistral NeMo LLM locally</li>\n<li>Provide a foundation for compliant data processing, keeping sensitive information on-premises</li>\n</ul>\n</li>\n<li>\n<p><strong>Data extraction</strong></p>\n<ul>\n<li>Convert unstructured text to a consistent JSON format</li>\n<li>Adjust the JSON schema to meet your specific data extraction needs.</li>\n</ul>\n</li>\n<li>\n<p><strong>Error handling</strong></p>\n<ul>\n<li>Implement auto-fixing for LLM outputs</li>\n<li>Include error output for further processing</li>\n</ul>\n</li>\n</ol>\n<h2>‚öôÔ∏è Setup and —Åonfiguration</h2>\n<h3>Prerequisites</h3>\n<ul>\n<li><a href=\"https://docs.n8n.io/hosting/starter-kits/ai-starter-kit/\" rel=\"ugc nofollow\" target=\"_blank\">n8n AI Starter Kit</a> installed</li>\n</ul>\n<h3>Configuration steps</h3>\n<ol>\n<li>Add the <strong>Basic LLM Chain</strong> node with system prompts.</li>\n<li>Set up the <strong>Ollama Chat Model</strong> with optimized parameters.</li>\n<li>Define the JSON schema in the <strong>Structured Output Parser</strong> node.</li>\n</ol>\n<h2>üîç Further resources</h2>\n<ul>\n<li><a href=\"https://blog.n8n.io/local-llm/\" rel=\"ugc nofollow\" target=\"_blank\">Run LLMs locally with n8n</a></li>\n<li><a href=\"https://www.youtube.com/watch?v=xz_X2N-hPg0\" rel=\"ugc nofollow\" target=\"_blank\">Video tutorial on using local AI with n8n</a></li>\n</ul>\n<p>Apply the power of self-hosted LLMs in your n8n workflows while maintaining control over your data processing pipeline!</p>\n</div><!--]-->",
  "readme_zh": "Êú¨Â∑•‰ΩúÊµÅÊºîÁ§∫‰∫ÜÂ¶Ç‰ΩïÈÄöËøán8nÁöÑLangChainÈõÜÊàêÔºå‰ΩøÁî®Ëá™ÊâòÁÆ°Â§ßËØ≠Ë®ÄÊ®°ÂûãÔºàLLMÔºâ‰ªéÁî®Êà∑ËæìÂÖ•‰∏≠ÊèêÂèñ‰∏™‰∫∫‰ø°ÊÅØ„ÄÇËøôÂØπÊï∞ÊçÆÈöêÁßÅËá≥ÂÖ≥ÈáçË¶ÅÁöÑ‰ºÅ‰∏öÁéØÂ¢ÉÂ∞§‰∏∫ÂÆûÁî®ÔºåÂèØÂÆûÁé∞ÊïèÊÑü‰ø°ÊÅØÁöÑÊú¨Âú∞ÂåñÂ§ÑÁêÜ„ÄÇ\n\nüìñ Â¶ÇÈúÄÊ∑±ÂÖ•‰∫ÜËß£Â¶Ç‰ΩïÂú®n8n‰∏≠‰ΩøÁî®ÂºÄÊ∫êLLMÔºåËØ∑ÂèÇÈòÖÊàë‰ª¨ÁöÑ[ÂºÄÊ∫êLLMÁªºÂêàÊåáÂçó](https://blog.n8n.io/open-source-llm/)„ÄÇ\n\n## üîë Ê†∏ÂøÉÂäüËÉΩ\n\n  1. **Êú¨Âú∞ÂåñLLM**\n     * ËøûÊé•OllamaÊú¨Âú∞ËøêË°åMistral NeMoÂ§ßÊ®°Âûã\n     * ‰∏∫ÂêàËßÑÊï∞ÊçÆÂ§ÑÁêÜÊèê‰æõÂü∫Á°ÄÊû∂ÊûÑÔºåÁ°Æ‰øùÊïèÊÑü‰ø°ÊÅØ‰øùÁïôÂú®Êú¨Âú∞\n  2. **Êï∞ÊçÆÊèêÂèñ**\n     * Â∞ÜÈùûÁªìÊûÑÂåñÊñáÊú¨ËΩ¨Êç¢‰∏∫Ê†áÂáÜJSONÊ†ºÂºè\n     * ÂèØËá™ÂÆö‰πâJSONÁªìÊûÑ‰ª•Êª°Ë∂≥ÁâπÂÆöÊï∞ÊçÆÊèêÂèñÈúÄÊ±Ç\n  3. **ÈîôËØØÂ§ÑÁêÜ**\n     * ÂÆûÁé∞LLMËæìÂá∫ÁöÑËá™Âä®‰øÆÊ≠£\n     * ÂåÖÂê´ÈîôËØØËæìÂá∫ÈÄöÈÅì‰æõÂêéÁª≠Â§ÑÁêÜ\n\n## ‚öôÔ∏è ËÆæÁΩÆ‰∏éÈÖçÁΩÆ\n\n### ÂÖàÂÜ≥Êù°‰ª∂\n  * Â∑≤ÂÆâË£Ö[n8n AIÂÖ•Èó®Â•ó‰ª∂](https://docs.n8n.io/hosting/starter-kits/ai-starter-kit/)\n\n### ÈÖçÁΩÆÊ≠•È™§\n  1. Ê∑ªÂä†ÈÖçÁΩÆÁ≥ªÁªüÊèêÁ§∫ËØçÁöÑ**Âü∫Á°ÄLLMÈìæ**ËäÇÁÇπ\n  2. Âú®**OllamaËÅäÂ§©Ê®°Âûã**‰∏≠ËÆæÁΩÆ‰ºòÂåñÂèÇÊï∞\n  3. ÈÄöËøá**ÁªìÊûÑÂåñËæìÂá∫Ëß£ÊûêÂô®**ËäÇÁÇπÂÆö‰πâJSONÊû∂ÊûÑ\n\n## üîç Êâ©Â±ïËµÑÊ∫ê\n  * [n8nÊú¨Âú∞ËøêË°åLLMÊåáÂçó](https://blog.n8n.io/local-llm/)\n  * [n8nÊú¨Âú∞AIÂ∫îÁî®ËßÜÈ¢ëÊïôÁ®ã](https://www.youtube.com/watch?v=xz_X2N-hPg0)\n\nÂú®n8nÂ∑•‰ΩúÊµÅ‰∏≠ÂèëÊå•Ëá™ÊâòÁÆ°LLMÁöÑÂº∫Â§ßËÉΩÂäõÔºåÂêåÊó∂‰øùÊåÅÂØπÊï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ãÁöÑÂÆåÂÖ®ÊéåÊéßÔºÅ",
  "title_zh": "‰ΩøÁî®Ëá™ÊâòÁÆ°Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãMistral NeMoÊèêÂèñ‰∏™‰∫∫Êï∞ÊçÆ",
  "publish_date_zh": "ÊúÄÂêéÊõ¥Êñ∞‰∫é3‰∏™ÊúàÂâç",
  "workflow_json_zh": "{\n  \"id\": \"HMoUOg8J7RzEcslH\",\n  \"meta\": {\n    \"instanceId\": \"3f91626b10fcfa8a3d3ab8655534ff3e94151838fd2709ecd2dcb14afb3d061a\",\n    \"templateCredsSetupCompleted\": true\n  },\n  \"name\": \"Extract personal data with a self-hosted LLM Mistral NeMo\",\n  \"tags\": [],\n  \"nodes\": [\n    {\n      \"id\": \"7e67ae65-88aa-4e48-aa63-2d3a4208cf4b\",\n      \"name\": \"When chat message received\",\n      \"type\": \"@n8n/n8n-nodes-langchain.chatTrigger\",\n      \"position\": [\n        -500,\n        20\n      ],\n      \"webhookId\": \"3a7b0ea1-47f3-4a94-8ff2-f5e1f3d9dc32\",\n      \"parameters\": {\n        \"options\": {}\n      },\n      \"typeVersion\": 1.1\n    },\n    {\n      \"id\": \"e064921c-69e6-4cfe-a86e-4e3aa3a5314a\",\n      \"name\": \"Ollama Chat Model\",\n      \"type\": \"@n8n/n8n-nodes-langchain.lmChatOllama\",\n      \"position\": [\n        -280,\n        420\n      ],\n      \"parameters\": {\n        \"model\": \"mistral-nemo:latest\",\n        \"options\": {\n          \"useMLock\": true,\n          \"keepAlive\": \"2h\",\n          \"temperature\": 0.1\n        }\n      },\n      \"credentials\": {\n        \"ollamaApi\": {\n          \"id\": \"vgKP7LGys9TXZ0KK\",\n          \"name\": \"Ollama account\"\n        }\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"fe1379da-a12e-4051-af91-9d67a7c9a76b\",\n      \"name\": \"Auto-fixing Output Parser\",\n      \"type\": \"@n8n/n8n-nodes-langchain.outputParserAutofixing\",\n      \"position\": [\n        -200,\n        220\n      ],\n      \"parameters\": {\n        \"options\": {\n          \"prompt\": \"Instructions:\\n--------------\\n{instructions}\\n--------------\\nCompletion:\\n--------------\\n{completion}\\n--------------\\n\\nAbove, the Completion did not satisfy the constraints given in the Instructions.\\nError:\\n--------------\\n{error}\\n--------------\\n\\nPlease try again. Please only respond with an answer that satisfies the constraints laid out in the Instructions:\"\n        }\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"b6633b00-6ebb-43ca-8e5c-664a53548c17\",\n      \"name\": \"Structured Output Parser\",\n      \"type\": \"@n8n/n8n-nodes-langchain.outputParserStructured\",\n      \"position\": [\n        60,\n        400\n      ],\n      \"parameters\": {\n        \"schemaType\": \"manual\",\n        \"inputSchema\": \"{\\n  \\\"type\\\": \\\"object\\\",\\n  \\\"properties\\\": {\\n    \\\"name\\\": {\\n      \\\"type\\\": \\\"string\\\",\\n      \\\"description\\\": \\\"Name of the user\\\"\\n    },\\n    \\\"surname\\\": {\\n      \\\"type\\\": \\\"string\\\",\\n      \\\"description\\\": \\\"Surname of the user\\\"\\n    },\\n    \\\"commtype\\\": {\\n      \\\"type\\\": \\\"string\\\",\\n      \\\"enum\\\": [\\\"email\\\", \\\"phone\\\", \\\"other\\\"],\\n      \\\"description\\\": \\\"Method of communication\\\"\\n    },\\n    \\\"contacts\\\": {\\n      \\\"type\\\": \\\"string\\\",\\n      \\\"description\\\": \\\"Contact details. ONLY IF PROVIDED\\\"\\n    },\\n    \\\"timestamp\\\": {\\n      \\\"type\\\": \\\"string\\\",\\n      \\\"format\\\": \\\"date-time\\\",\\n      \\\"description\\\": \\\"When the communication occurred\\\"\\n    },\\n    \\\"subject\\\": {\\n      \\\"type\\\": \\\"string\\\",\\n      \\\"description\\\": \\\"Brief description of the communication topic\\\"\\n    }\\n  },\\n  \\\"required\\\": [\\\"name\\\", \\\"commtype\\\"]\\n}\"\n      },\n      \"typeVersion\": 1.2\n    },\n    {\n      \"id\": \"23681a6c-cf62-48cb-86ee-08d5ce39bc0a\",\n      \"name\": \"Basic LLM Chain\",\n      \"type\": \"@n8n/n8n-nodes-langchain.chainLlm\",\n      \"onError\": \"continueErrorOutput\",\n      \"position\": [\n        -240,\n        20\n      ],\n      \"parameters\": {\n        \"messages\": {\n          \"messageValues\": [\n            {\n              \"message\": \"=Please analyse the incoming user request. Extract information according to the JSON schema. Today is: \\\"{{ $now.toISO() }}\\\"\"\n            }\n          ]\n        },\n        \"hasOutputParser\": true\n      },\n      \"typeVersion\": 1.5\n    },\n    {\n      \"id\": \"8f4d1b4b-58c0-41ec-9636-ac555e440821\",\n      \"name\": \"On Error\",\n      \"type\": \"n8n-nodes-base.noOp\",\n      \"position\": [\n        200,\n        140\n      ],\n      \"parameters\": {},\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"f4d77736-4470-48b4-8f61-149e09b70e3e\",\n      \"name\": \"Sticky Note\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"position\": [\n        -560,\n        -160\n      ],\n      \"parameters\": {\n        \"color\": 2,\n        \"width\": 960,\n        \"height\": 500,\n        \"content\": \"## Êõ¥Êñ∞Êï∞ÊçÆÊ∫ê\\nÂΩìÊÇ®Êõ¥ÊîπÊï∞ÊçÆÊ∫êÊó∂ÔºåËØ∑ËÆ∞ÂæóÂú®**Âü∫Á°ÄLLMÈìæËäÇÁÇπ**‰∏≠Êõ¥Êñ∞`ÊèêÁ§∫Êù•Ê∫êÔºàÁî®Êà∑Ê∂àÊÅØÔºâ`ËÆæÁΩÆ„ÄÇ\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"5fd273c8-e61d-452b-8eac-8ac4b7fff6c2\",\n      \"name\": \"Sticky Note1\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"position\": [\n        -560,\n        340\n      ],\n      \"parameters\": {\n        \"color\": 2,\n        \"width\": 440,\n        \"height\": 220,\n        \"content\": \"## ÈÖçÁΩÆÊú¨Âú∞Â§ßËØ≠Ë®ÄÊ®°Âûã\\nOllamaÊèê‰æõÈ¢ùÂ§ñËÆæÁΩÆÈÄâÈ°π\\nÁî®‰∫é‰ºòÂåñÊ®°ÂûãÊÄßËÉΩ\\nÊàñÂÜÖÂ≠òÂç†Áî®\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"63cbf762-0134-48da-a6cd-0363e870decd\",\n      \"name\": \"Sticky Note2\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"position\": [\n        0,\n        340\n      ],\n      \"parameters\": {\n        \"color\": 2,\n        \"width\": 400,\n        \"height\": 220,\n        \"content\": \"## ÂÆö‰πâJSONÊ®°Âºè\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"9625294f-3cb4-4465-9dae-9976e0cf5053\",\n      \"name\": \"Extract JSON Output\",\n      \"type\": \"n8n-nodes-base.set\",\n      \"position\": [\n        200,\n        -80\n      ],\n      \"parameters\": {\n        \"mode\": \"raw\",\n        \"options\": {},\n        \"jsonOutput\": \"={{ $json.output }}\\n\"\n      },\n      \"typeVersion\": 3.4\n    },\n    {\n      \"id\": \"2c6fba3b-0ffe-4112-b904-823f52cc220b\",\n      \"name\": \"Sticky Note3\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"position\": [\n        -560,\n        200\n      ],\n      \"parameters\": {\n        \"width\": 960,\n        \"height\": 120,\n        \"content\": \"Ëã•Â§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑÂìçÂ∫îÊú™ËÉΩÈÄöËøá  \\n**ÁªìÊûÑÂåñËæìÂá∫Ëß£ÊûêÂô®**ÁöÑÊ†°È™åÔºå  \\n**Ëá™Âä®‰øÆÊ≠£Âô®**Â∞ÜË∞ÉÁî®Ê®°ÂûãÈáçÊñ∞ÁîüÊàêÔºå  \\n‰ΩøÁî®‰∏çÂêåÁöÑÊèêÁ§∫Êù•‰øÆÊ≠£ÂéüÂßãÂìçÂ∫î„ÄÇ\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"c73ba1ca-d727-4904-a5fd-01dd921a4738\",\n      \"name\": \"Sticky Note6\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"position\": [\n        -560,\n        460\n      ],\n      \"parameters\": {\n        \"height\": 80,\n        \"content\": \"Âêå‰∏Ä‰∏™LLMÂêåÊó∂ËøûÊé•Ëá≥**Âü∫Á°ÄLLMÈìæ**Âíå**Ëá™Âä®‰øÆÊ≠£ËæìÂá∫Ëß£ÊûêÂô®**„ÄÇ\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"193dd153-8511-4326-aaae-47b89d0cd049\",\n      \"name\": \"Sticky Note7\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"position\": [\n        200,\n        440\n      ],\n      \"parameters\": {\n        \"width\": 200,\n        \"height\": 100,\n        \"content\": \"ÂΩìLLMÊ®°ÂûãÂìçÂ∫îÊó∂ÔºåËæìÂá∫‰ºöÂú®**ÁªìÊûÑÂåñËæìÂá∫Ëß£ÊûêÂô®**‰∏≠ËøõË°åÊ£ÄÊü•„ÄÇ\"\n      },\n      \"typeVersion\": 1\n    }\n  ],\n  \"active\": false,\n  \"pinData\": {},\n  \"settings\": {\n    \"executionOrder\": \"v1\"\n  },\n  \"versionId\": \"9f3721a8-f340-43d5-89e7-3175c29c2f3a\",\n  \"connections\": {\n    \"Basic LLM Chain\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Extract JSON Output\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ],\n        [\n          {\n            \"node\": \"On Error\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Ollama Chat Model\": {\n      \"ai_languageModel\": [\n        [\n          {\n            \"node\": \"Auto-fixing Output Parser\",\n            \"type\": \"ai_languageModel\",\n            \"index\": 0\n          },\n          {\n            \"node\": \"Basic LLM Chain\",\n            \"type\": \"ai_languageModel\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Structured Output Parser\": {\n      \"ai_outputParser\": [\n        [\n          {\n            \"node\": \"Auto-fixing Output Parser\",\n            \"type\": \"ai_outputParser\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Auto-fixing Output Parser\": {\n      \"ai_outputParser\": [\n        [\n          {\n            \"node\": \"Basic LLM Chain\",\n            \"type\": \"ai_outputParser\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"When chat message received\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Basic LLM Chain\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    }\n  }\n}"
}