{
  "title": "Enhance AI Prompts with GPT-4o-mini and Telegram Delivery",
  "url": "https://n8n.io/workflows/3496-enhance-ai-prompts-with-gpt-4o-mini-and-telegram-delivery/",
  "category": "Engineering",
  "category_url": "https://n8n.io/workflows/categories/engineering/?sort=createdAt:desc",
  "author": "Jesse Davids",
  "publish_date": "Last update 8 days ago",
  "publish_date_absolute": "2025-05-14",
  "content": "",
  "workflow_json": "{\"id\":\"heyKyETy1uK0xoX4\",\"meta\":{\"instanceId\":\"d00caf92aa0876c596905aea78b35fa33a722cc8e479133822c17064d15c2c1d\",\"templateCredsSetupCompleted\":true},\"name\":\"Optimize Prompt\",\"tags\":[],\"nodes\":[{\"id\":\"a58be0f5-d11d-4bec-bd8c-0c3a7325b22b\",\"name\":\"When Executed by Another Workflow\",\"type\":\"n8n-nodes-base.executeWorkflowTrigger\",\"position\":[-1880,820],\"parameters\":{\"inputSource\":\"passthrough\"},\"typeVersion\":1.1},{\"id\":\"67fe408f-e889-4eeb-9e48-f60a579c69f0\",\"name\":\"AI Agent\",\"type\":\"@n8n/n8n-nodes-langchain.agent\",\"position\":[-1600,720],\"parameters\":{\"text\":\"={{ $json.query }}\",\"options\":{\"systemMessage\":\"Given the user's initial prompt below, please enhance it. Start with a clear, precise instruction at the beginning. Include specific details about the desired context, outcome, length, format, and style. Provide examples of the desired output format, if applicable. Use appropriate leading words or phrases to guide the desired output, especially for code generation. Avoid any vague or imprecise language. Rather than only stating what not to do, provide guidance on what should be done instead. Ensure the revised prompt remains true to the user's original intent. Do not provide examples of desired prompt format, only describe it. Format your response in markdown.\"},\"promptType\":\"define\",\"hasOutputParser\":true},\"typeVersion\":1.7},{\"id\":\"8a041b31-1873-4559-96d0-35d313bffbbd\",\"name\":\"Telegram3\",\"type\":\"n8n-nodes-base.telegram\",\"onError\":\"continueErrorOutput\",\"position\":[-1000,820],\"webhookId\":\"4f57022f-14cf-4c3e-b810-ae9395bf3d04\",\"parameters\":{\"text\":\"={{ $json.text }}\",\"chatId\":\"={{ $('When Executed by Another Workflow').item.json.chat_id }}\",\"additionalFields\":{}},\"credentials\":{\"telegramApi\":{\"id\":\"Vh36aBswWhClYxBM\",\"name\":\"Telegram account 2\"}},\"typeVersion\":1.1},{\"id\":\"5161b177-0663-41c5-b778-ac14756f699c\",\"name\":\"OpenAI Chat Model\",\"type\":\"@n8n/n8n-nodes-langchain.lmChatOpenAi\",\"position\":[-1680,860],\"parameters\":{\"model\":{\"__rl\":true,\"mode\":\"list\",\"value\":\"gpt-4o-mini\"},\"options\":{}},\"credentials\":{\"openAiApi\":{\"id\":\"vIXW5likFrTSZUgz\",\"name\":\"Litellm-account\"}},\"typeVersion\":1.2},{\"id\":\"d5f36955-74a0-4a9a-b49d-0230d6ee35bf\",\"name\":\"Split into chunks1\",\"type\":\"n8n-nodes-base.code\",\"position\":[-1180,820],\"parameters\":{\"jsCode\":\"// Get the entire output of the previous node\\nlet text = $input.all() || '';\\n\\n// Convert the output to a string if it's not already\\nif (typeof text !== 'string') {\\n  text = JSON.stringify(text, null, 2); // Pretty-print JSON objects\\n}\\n\\n// Replace multiple newlines (\\\\n\\\\n+) with a single newline (\\\\n)\\ntext = text.replace(/\\\\n{2,}/g, '\\\\n');\\n\\nconst maxLength = 3072; // Telegram message character limit\\nconst messages = [];\\n\\n// Add an optional header for the first chunk\\nconst header = `# Optimized prompt\\\\n\\\\n`;\\nlet currentText = header + text;\\n\\n// Split the output into chunks of maxLength without splitting words\\nwhile (currentText.length > 0) {\\n  let chunk = currentText.slice(0, maxLength);\\n\\n  // Ensure we don't split in the middle of a word\\n  if (chunk.length === maxLength && currentText[maxLength] !== ' ') {\\n    const lastSpaceIndex = chunk.lastIndexOf(' ');\\n    if (lastSpaceIndex > -1) {\\n      chunk = chunk.slice(0, lastSpaceIndex);\\n    }\\n  }\\n\\n  messages.push(chunk.trim()); // Trim extra whitespace for cleaner output\\n  currentText = currentText.slice(chunk.length).trim(); // Remove the chunk from the remaining text\\n}\\n\\n// Return the split messages in Markdown format\\nreturn messages.map((chunk) => ({ json: { text: `\\\\`\\\\`\\\\`markdown\\\\n${chunk}\\\\n\\\\`\\\\`\\\\`` } }));\\n\"},\"typeVersion\":2},{\"id\":\"b22f3481-caeb-4506-8fe0-c7e2597772b9\",\"name\":\"Sticky Note\",\"type\":\"n8n-nodes-base.stickyNote\",\"disabled\":true,\"position\":[-2120,600],\"parameters\":{\"color\":5,\"width\":389,\"height\":381,\"content\":\"## Trigger\\n\\n- Trigger can be anything. For this example the trigger is a call from another workflow and a received Telegram message. \\n\\n- Note that this workflow can be integrated in the middle of another larger workflow.\"},\"typeVersion\":1},{\"id\":\"2bf7ebcc-2d34-4c56-b9de-c930ccb4f30f\",\"name\":\"Sticky Note1\",\"type\":\"n8n-nodes-base.stickyNote\",\"disabled\":true,\"position\":[-1720,600],\"parameters\":{\"color\":6,\"width\":489,\"height\":381,\"content\":\"# Inference / Optimization\\n- Incoming trigger is processed by a LLM with a specific system prompt set aimed at improving the input prompt.\"},\"typeVersion\":1},{\"id\":\"ccc5f97e-6215-41fc-9633-f57857743282\",\"name\":\"Simple Memory\",\"type\":\"@n8n/n8n-nodes-langchain.memoryBufferWindow\",\"position\":[-1340,860],\"parameters\":{},\"typeVersion\":1.3},{\"id\":\"3bfb31b6-add3-4d5b-989e-df88d69e07e8\",\"name\":\"Sticky Note3\",\"type\":\"n8n-nodes-base.stickyNote\",\"disabled\":true,\"position\":[-1220,600],\"parameters\":{\"width\":349,\"height\":381,\"content\":\"# Improved prompt:\\n\\n- Send as a response\\n\\n- Use as input for next nodes\"},\"typeVersion\":1},{\"id\":\"a36fdc9d-d000-4120-99e8-53d49edec74a\",\"name\":\"Sticky Note2\",\"type\":\"n8n-nodes-base.stickyNote\",\"disabled\":true,\"position\":[-2120,1000],\"parameters\":{\"color\":7,\"width\":1249,\"height\":541,\"content\":\"# Workflow Documentation\\n\\n## Description:\\nThis workflow is designed to optimize prompts by enhancing user inputs for clarity and specificity using AI. The workflow takes a user-provided prompt as input and uses a Natural Language Processing (NLP) model to refine and improve the prompt. The optimized prompt is then sent back to the user, ready for use in further workflows or processes.\\n\\n## Setup:\\n1. This workflow is suitable for users who want to improve their prompts for better communication and understanding in their workflows.\\n2. The workflow utilizes an AI Agent powered by an OpenAI Chat Model to enhance user prompts.\\n3. A Telegram node is used to deliver the optimized prompt back to the user.\\n4. Ensure you have the necessary credentials set up for Telegram and OpenAI accounts.\\n5. Customize the workflow's settings, such as the AI model used for prompt optimization, to suit your requirements.\\n6. Activate the workflow once all configurations are set to start optimizing prompts efficiently.\\n\\n## Expected Outcomes:\\n- Users can provide vague or imprecise prompts as input to the workflow.\\n- The AI Agent will refine and optimize the prompt, adding clarity and specific details.\\n- The optimized prompt will be delivered back to the user via Telegram for further use in workflows or processes.\\n\\nFor more detailed instructions and guidelines on using this workflow, refer to the detailed setup guide above.\"},\"typeVersion\":1}],\"active\":false,\"pinData\":{},\"settings\":{\"executionOrder\":\"v1\"},\"versionId\":\"05beb500-d266-45e7-8f5a-ad3a8c9a72e1\",\"connections\":{\"AI Agent\":{\"main\":[[{\"node\":\"Split into chunks1\",\"type\":\"main\",\"index\":0}]]},\"Simple Memory\":{\"ai_memory\":[[{\"node\":\"AI Agent\",\"type\":\"ai_memory\",\"index\":0}]]},\"OpenAI Chat Model\":{\"ai_languageModel\":[[{\"node\":\"AI Agent\",\"type\":\"ai_languageModel\",\"index\":0}]]},\"Split into chunks1\":{\"main\":[[{\"node\":\"Telegram3\",\"type\":\"main\",\"index\":0}]]},\"When Executed by Another Workflow\":{\"main\":[[{\"node\":\"AI Agent\",\"type\":\"main\",\"index\":0}]]}}}",
  "readme": "# Workflow Documentation\n\n## Description:\n\nThis workflow is designed to optimize prompts by enhancing user inputs for clarity and specificity using AI. The workflow takes a user-provided prompt as input and uses a Natural Language Processing (NLP) model to refine and improve the prompt. The optimized prompt is then sent back to the user, ready for use in further workflows or processes.\n\n## Setup:\n\n  1. This workflow is suitable for users who want to improve their prompts for better communication and understanding in their workflows.\n  2. The workflow utilizes an AI Agent powered by an OpenAI Chat Model to enhance user prompts.\n\n\n\n## Expected Outcomes:\n\n  * Users can provide vague or imprecise prompts as input to the workflow.\n  * The AI Agent will refine and optimize the prompt, adding clarity and specific details.\n  * The optimized prompt will be delivered back to the user via Telegram or can be input for the next nodes.\n\n\n\n## Extra Information:\n\nA. A Telegram node is used to deliver the optimized prompt back to the user.  \nB. Ensure you have the necessary credentials set up for Telegram and OpenAI accounts.  \nC. Customize the workflow's settings, such as the AI model used for prompt optimization, to suit your requirements.  \nD. Activate the workflow once all configurations are set to start optimizing prompts efficiently.\n",
  "readme_html": "<!--[--><div data-v-859c7806=\"\"><h1>Workflow Documentation</h1>\n<h2>Description:</h2>\n<p>This workflow is designed to optimize prompts by enhancing user inputs for clarity and specificity using AI. The workflow takes a user-provided prompt as input and uses a Natural Language Processing (NLP) model to refine and improve the prompt. The optimized prompt is then sent back to the user, ready for use in further workflows or processes.</p>\n<h2>Setup:</h2>\n<ol>\n<li>This workflow is suitable for users who want to improve their prompts for better communication and understanding in their workflows.</li>\n<li>The workflow utilizes an AI Agent powered by an OpenAI Chat Model to enhance user prompts.</li>\n</ol>\n<h2>Expected Outcomes:</h2>\n<ul>\n<li>Users can provide vague or imprecise prompts as input to the workflow.</li>\n<li>The AI Agent will refine and optimize the prompt, adding clarity and specific details.</li>\n<li>The optimized prompt will be delivered back to the user via Telegram or can be input for the next nodes.</li>\n</ul>\n<h2>Extra Information:</h2>\n<p>A. A Telegram node is used to deliver the optimized prompt back to the user.<br>\nB. Ensure you have the necessary credentials set up for Telegram and OpenAI accounts.<br>\nC. Customize the workflow's settings, such as the AI model used for prompt optimization, to suit your requirements.<br>\nD. Activate the workflow once all configurations are set to start optimizing prompts efficiently.</p>\n</div><!--]-->",
  "readme_zh": "# 工作流文档\n\n## 描述：\n\n本工作流旨在通过人工智能增强用户输入的清晰度和特异性来优化提示语。该工作流接收用户提供的初始提示，利用自然语言处理（NLP）模型进行精细化改进。优化后的提示语将返回给用户，可直接用于后续工作流或流程中。\n\n## 配置说明：\n\n1. 本工作流适用于希望提升提示语质量以优化工作流沟通效果的用户\n2. 工作流采用基于OpenAI聊天模型的AI智能体来增强用户提示\n\n## 预期效果：\n\n* 用户可向工作流输入模糊或不精确的初始提示\n* AI智能体将优化提示内容，增强表述清晰度和细节丰富度\n* 优化后的提示将通过Telegram返回用户，或作为下一节点的输入内容\n\n## 补充信息：\n\nA. 采用Telegram节点向用户回传优化后的提示  \nB. 请确保已配置Telegram和OpenAI账户的访问凭证  \nC. 可根据需求自定义工作流设置（如用于提示优化的AI模型选择）  \nD. 完成所有配置后激活工作流，即可开始高效优化提示语",
  "title_zh": "利用GPT-4o-mini优化AI提示并通过Telegram交付",
  "publish_date_zh": "上次更新于8天前",
  "workflow_json_zh": "{\n  \"id\": \"heyKyETy1uK0xoX4\",\n  \"meta\": {\n    \"instanceId\": \"d00caf92aa0876c596905aea78b35fa33a722cc8e479133822c17064d15c2c1d\",\n    \"templateCredsSetupCompleted\": true\n  },\n  \"name\": \"Optimize Prompt\",\n  \"tags\": [],\n  \"nodes\": [\n    {\n      \"id\": \"a58be0f5-d11d-4bec-bd8c-0c3a7325b22b\",\n      \"name\": \"When Executed by Another Workflow\",\n      \"type\": \"n8n-nodes-base.executeWorkflowTrigger\",\n      \"position\": [\n        -1880,\n        820\n      ],\n      \"parameters\": {\n        \"inputSource\": \"passthrough\"\n      },\n      \"typeVersion\": 1.1\n    },\n    {\n      \"id\": \"67fe408f-e889-4eeb-9e48-f60a579c69f0\",\n      \"name\": \"AI Agent\",\n      \"type\": \"@n8n/n8n-nodes-langchain.agent\",\n      \"position\": [\n        -1600,\n        720\n      ],\n      \"parameters\": {\n        \"text\": \"={{ $json.query }}\",\n        \"options\": {\n          \"systemMessage\": \"Given the user's initial prompt below, please enhance it. Start with a clear, precise instruction at the beginning. Include specific details about the desired context, outcome, length, format, and style. Provide examples of the desired output format, if applicable. Use appropriate leading words or phrases to guide the desired output, especially for code generation. Avoid any vague or imprecise language. Rather than only stating what not to do, provide guidance on what should be done instead. Ensure the revised prompt remains true to the user's original intent. Do not provide examples of desired prompt format, only describe it. Format your response in markdown.\"\n        },\n        \"promptType\": \"define\",\n        \"hasOutputParser\": true\n      },\n      \"typeVersion\": 1.7\n    },\n    {\n      \"id\": \"8a041b31-1873-4559-96d0-35d313bffbbd\",\n      \"name\": \"Telegram3\",\n      \"type\": \"n8n-nodes-base.telegram\",\n      \"onError\": \"continueErrorOutput\",\n      \"position\": [\n        -1000,\n        820\n      ],\n      \"webhookId\": \"4f57022f-14cf-4c3e-b810-ae9395bf3d04\",\n      \"parameters\": {\n        \"text\": \"={{ $json.text }}\",\n        \"chatId\": \"={{ $('When Executed by Another Workflow').item.json.chat_id }}\",\n        \"additionalFields\": {}\n      },\n      \"credentials\": {\n        \"telegramApi\": {\n          \"id\": \"Vh36aBswWhClYxBM\",\n          \"name\": \"Telegram account 2\"\n        }\n      },\n      \"typeVersion\": 1.1\n    },\n    {\n      \"id\": \"5161b177-0663-41c5-b778-ac14756f699c\",\n      \"name\": \"OpenAI Chat Model\",\n      \"type\": \"@n8n/n8n-nodes-langchain.lmChatOpenAi\",\n      \"position\": [\n        -1680,\n        860\n      ],\n      \"parameters\": {\n        \"model\": {\n          \"__rl\": true,\n          \"mode\": \"list\",\n          \"value\": \"gpt-4o-mini\"\n        },\n        \"options\": {}\n      },\n      \"credentials\": {\n        \"openAiApi\": {\n          \"id\": \"vIXW5likFrTSZUgz\",\n          \"name\": \"Litellm-account\"\n        }\n      },\n      \"typeVersion\": 1.2\n    },\n    {\n      \"id\": \"d5f36955-74a0-4a9a-b49d-0230d6ee35bf\",\n      \"name\": \"Split into chunks1\",\n      \"type\": \"n8n-nodes-base.code\",\n      \"position\": [\n        -1180,\n        820\n      ],\n      \"parameters\": {\n        \"jsCode\": \"// Get the entire output of the previous node\\nlet text = $input.all() || '';\\n\\n// Convert the output to a string if it's not already\\nif (typeof text !== 'string') {\\n  text = JSON.stringify(text, null, 2); // Pretty-print JSON objects\\n}\\n\\n// Replace multiple newlines (\\\\n\\\\n+) with a single newline (\\\\n)\\ntext = text.replace(/\\\\n{2,}/g, '\\\\n');\\n\\nconst maxLength = 3072; // Telegram message character limit\\nconst messages = [];\\n\\n// Add an optional header for the first chunk\\nconst header = `# Optimized prompt\\\\n\\\\n`;\\nlet currentText = header + text;\\n\\n// Split the output into chunks of maxLength without splitting words\\nwhile (currentText.length > 0) {\\n  let chunk = currentText.slice(0, maxLength);\\n\\n  // Ensure we don't split in the middle of a word\\n  if (chunk.length === maxLength && currentText[maxLength] !== ' ') {\\n    const lastSpaceIndex = chunk.lastIndexOf(' ');\\n    if (lastSpaceIndex > -1) {\\n      chunk = chunk.slice(0, lastSpaceIndex);\\n    }\\n  }\\n\\n  messages.push(chunk.trim()); // Trim extra whitespace for cleaner output\\n  currentText = currentText.slice(chunk.length).trim(); // Remove the chunk from the remaining text\\n}\\n\\n// Return the split messages in Markdown format\\nreturn messages.map((chunk) => ({ json: { text: `\\\\`\\\\`\\\\`markdown\\\\n${chunk}\\\\n\\\\`\\\\`\\\\`` } }));\\n\"\n      },\n      \"typeVersion\": 2\n    },\n    {\n      \"id\": \"b22f3481-caeb-4506-8fe0-c7e2597772b9\",\n      \"name\": \"Sticky Note\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"disabled\": true,\n      \"position\": [\n        -2120,\n        600\n      ],\n      \"parameters\": {\n        \"color\": 5,\n        \"width\": 389,\n        \"height\": 381,\n        \"content\": \"## 触发器\\n\\n- 触发器可以是任何形式。在本示例中，触发器是来自另一个工作流的调用以及接收到的Telegram消息。\\n\\n- 请注意，此工作流可以作为一个模块集成到另一个更大的工作流中间。\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"2bf7ebcc-2d34-4c56-b9de-c930ccb4f30f\",\n      \"name\": \"Sticky Note1\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"disabled\": true,\n      \"position\": [\n        -1720,\n        600\n      ],\n      \"parameters\": {\n        \"color\": 6,\n        \"width\": 489,\n        \"height\": 381,\n        \"content\": \"# 推理/优化\\n- 传入的触发指令会由配备特定系统提示集的LLM处理，旨在优化输入提示的质量。\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"ccc5f97e-6215-41fc-9633-f57857743282\",\n      \"name\": \"Simple Memory\",\n      \"type\": \"@n8n/n8n-nodes-langchain.memoryBufferWindow\",\n      \"position\": [\n        -1340,\n        860\n      ],\n      \"parameters\": {},\n      \"typeVersion\": 1.3\n    },\n    {\n      \"id\": \"3bfb31b6-add3-4d5b-989e-df88d69e07e8\",\n      \"name\": \"Sticky Note3\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"disabled\": true,\n      \"position\": [\n        -1220,\n        600\n      ],\n      \"parameters\": {\n        \"width\": 349,\n        \"height\": 381,\n        \"content\": \"# 改进后的提示：\\n\\n- 作为回复发送\\n\\n- 用作下一节点的输入\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"a36fdc9d-d000-4120-99e8-53d49edec74a\",\n      \"name\": \"Sticky Note2\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"disabled\": true,\n      \"position\": [\n        -2120,\n        1000\n      ],\n      \"parameters\": {\n        \"color\": 7,\n        \"width\": 1249,\n        \"height\": 541,\n        \"content\": \"# 工作流文档\\n\\n## 描述：\\n本工作流旨在通过AI技术增强用户输入的清晰度和特异性来优化提示语。该流程接收用户提供的初始提示，利用自然语言处理（NLP）模型进行精细化改进，最终将优化后的提示语反馈给用户，以便在后续工作流或流程中使用。\\n\\n## 配置说明：\\n1. 本工作流适用于希望提升提示语质量以优化工作流沟通效果的用户\\n2. 采用基于OpenAI聊天模型的AI代理进行提示语增强\\n3. 通过Telegram节点将优化后的提示语返回给用户\\n4. 使用前需确保已配置Telegram和OpenAI账户的访问凭证\\n5. 可根据需求自定义工作流设置（如选择用于提示优化的AI模型）\\n6. 完成所有配置后激活工作流，即可开始高效优化提示语\\n\\n## 预期效果：\\n- 用户可输入模糊或不精确的初始提示语\\n- AI代理将对提示语进行细化优化，补充清晰说明和具体细节\\n- 优化后的提示语将通过Telegram返回，可供后续工作流直接使用\\n\\n更多详细操作指南请参阅上文中的完整配置说明。\"\n      },\n      \"typeVersion\": 1\n    }\n  ],\n  \"active\": false,\n  \"pinData\": {},\n  \"settings\": {\n    \"executionOrder\": \"v1\"\n  },\n  \"versionId\": \"05beb500-d266-45e7-8f5a-ad3a8c9a72e1\",\n  \"connections\": {\n    \"AI Agent\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Split into chunks1\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Simple Memory\": {\n      \"ai_memory\": [\n        [\n          {\n            \"node\": \"AI Agent\",\n            \"type\": \"ai_memory\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"OpenAI Chat Model\": {\n      \"ai_languageModel\": [\n        [\n          {\n            \"node\": \"AI Agent\",\n            \"type\": \"ai_languageModel\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Split into chunks1\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Telegram3\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"When Executed by Another Workflow\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"AI Agent\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    }\n  }\n}"
}