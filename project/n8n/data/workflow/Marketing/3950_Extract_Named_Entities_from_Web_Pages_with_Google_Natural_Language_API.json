{
  "title": "Extract Named Entities from Web Pages with Google Natural Language API",
  "url": "https://n8n.io/workflows/3950-extract-named-entities-from-web-pages-with-google-natural-language-api/",
  "category": "Marketing",
  "category_url": "https://n8n.io/workflows/categories/marketing/?sort=createdAt:desc",
  "author": "Hueston",
  "publish_date": "Last update a day ago",
  "publish_date_absolute": "",
  "content": "",
  "workflow_json": "{\"id\":\"4wPgPbxtojrUO7Dx\",\"meta\":{\"instanceId\":\"f46651348590f9c7e3e7fe91218ed49590c553ab737d5cc247951397ff85fa93\"},\"name\":\"Google Page Entity Extraction Template\",\"tags\":[{\"id\":\"hBkrfz3jN0GbUgJa\",\"name\":\"Google Page Entity Extraction Template\",\"createdAt\":\"2025-05-08T23:29:39.011Z\",\"updatedAt\":\"2025-05-08T23:29:39.011Z\"}],\"nodes\":[{\"id\":\"8719f1de-2a3e-4c34-9edc-e4b8f993b525\",\"name\":\"Respond to Webhook\",\"type\":\"n8n-nodes-base.respondToWebhook\",\"position\":[1240,-420],\"parameters\":{\"options\":{}},\"typeVersion\":1.1},{\"id\":\"01420fd5-3483-4e74-b9fc-971199898449\",\"name\":\"Google Entities\",\"type\":\"n8n-nodes-base.httpRequest\",\"position\":[1020,-420],\"parameters\":{\"url\":\"https://language.googleapis.com/v1/documents:analyzeEntities\",\"method\":\"POST\",\"options\":{},\"jsonBody\":\"={{ $json.apiRequest }}\",\"sendBody\":true,\"sendQuery\":true,\"sendHeaders\":true,\"specifyBody\":\"json\",\"queryParameters\":{\"parameters\":[{\"name\":\"key\",\"value\":\"YOUR-GOOGLE-API-KEY\"}]},\"headerParameters\":{\"parameters\":[{\"name\":\"Content-Type\",\"value\":\"application/json\"}]}},\"typeVersion\":4.2},{\"id\":\"5c1c258a-44ed-4d5a-a22d-cddb4df09018\",\"name\":\"Sticky Note\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[-300,-700],\"parameters\":{\"color\":4,\"width\":620,\"height\":880,\"content\":\"# Google Page Entity Extraction Template\\n\\n## What this workflow does\\nThis workflow allows you to extract named entities (people, organizations, locations, etc.) from any web page using Google's Natural Language API. Simply send a URL to the webhook endpoint, and the workflow will fetch the page content, process it through Google's entity recognition service, and return the structured entity data.\\n\\n### How to use\\n1. Replace \\\"YOUR-GOOGLE-API-KEY\\\" with your actual Google Cloud API key (Natural Language API must be enabled)\\n2. Activate the workflow and use the webhook URL as your endpoint\\n3. Send a POST request to the webhook with a JSON body containing the URL you want to analyze: {\\\"url\\\": \\\"https://example.com/page\\\"}\\n4. Review the returned entity analysis with categories, salience scores, and metadata\\n\\n## Webhook Input Format\\nThe webhook expects a POST request with a JSON body in this format:\\n```json\\n{\\n  \\\"url\\\": \\\"https://website-to-analyze.com/page\\\"\\n}\\n```\\n### Response Format\\nThe webhook returns a JSON response containing the full entity analysis from Google's Natural Language API, including:\\n\\nEntity names and types (PERSON, LOCATION, ORGANIZATION, etc.)\\nSalience scores indicating entity importance\\nMetadata and mentions within the text\\nEntity sentiment (if available)\"},\"typeVersion\":1},{\"id\":\"79add9a7-adca-4ce5-8a6a-5fcb75288846\",\"name\":\"Get Url\",\"type\":\"n8n-nodes-base.webhook\",\"position\":[360,-420],\"webhookId\":\"2944c8f6-03cd-4ab8-8b8e-cb033edf877a\",\"parameters\":{\"path\":\"2944c8f6-03cd-4ab8-8b8e-cb033edf877a\",\"options\":{},\"httpMethod\":\"POST\",\"responseMode\":\"responseNode\"},\"typeVersion\":2},{\"id\":\"081a52bc-2da7-44fb-bdc3-4cb73cbf8dd3\",\"name\":\"Get URL Page Contents\",\"type\":\"n8n-nodes-base.httpRequest\",\"position\":[580,-420],\"parameters\":{\"url\":\"={{ $json.body.url }}\",\"options\":{}},\"typeVersion\":4.2},{\"id\":\"dda5ef3d-f031-4dd6-b117-c1f69aa66b63\",\"name\":\"Respond with detected entities\",\"type\":\"n8n-nodes-base.code\",\"position\":[800,-420],\"parameters\":{\"jsCode\":\"// Clean and prepare HTML for API request\\nconst html = $input.item.json.data;\\n// Trim if too large (optional)\\nconst trimmedHtml = html.length > 100000 ? html.substring(0, 100000) : html;\\n\\nreturn {\\n  json: {\\n    apiRequest: {\\n      document: {\\n        type: \\\"HTML\\\",\\n        content: trimmedHtml\\n      },\\n      encodingType: \\\"UTF8\\\"\\n    }\\n  }\\n}\"},\"typeVersion\":2}],\"active\":false,\"pinData\":{},\"settings\":{\"executionOrder\":\"v1\"},\"versionId\":\"432203af-190a-4a89-81d8-f86682a0b63f\",\"connections\":{\"Get Url\":{\"main\":[[{\"node\":\"Get URL Page Contents\",\"type\":\"main\",\"index\":0}]]},\"Google Entities\":{\"main\":[[{\"node\":\"Respond to Webhook\",\"type\":\"main\",\"index\":0}]]},\"Get URL Page Contents\":{\"main\":[[{\"node\":\"Respond with detected entities\",\"type\":\"main\",\"index\":0}]]},\"Respond with detected entities\":{\"main\":[[{\"node\":\"Google Entities\",\"type\":\"main\",\"index\":0}]]}}}",
  "readme": "### Who is this for?\n\n  * Content strategists analyzing web page semantic content\n  * SEO professionals conducting entity-based analysis\n  * Data analysts extracting structured data from web pages\n  * Marketers researching competitor content strategies\n  * Researchers organizing and categorizing web content\n  * Anyone needing to automatically extract entities from web pages\n\n\n\n### What problem is this workflow solving?\n\nManually identifying and categorizing entities (people, organizations, locations, etc.) on web pages is time-consuming and error-prone. This workflow solves this challenge by:\n\n  * Automating the extraction of named entities from any web page\n  * Leveraging Google's powerful Natural Language API for accurate entity recognition\n  * Processing web pages through a simple webhook interface\n  * Providing structured entity data that can be used for analysis or further processing\n  * Eliminating hours of manual content analysis and categorization\n\n\n\n## What this workflow does\n\nThis workflow creates an automated pipeline between a webhook and Google's Natural Language API to:\n\n  1. Receive a URL through a webhook endpoint\n  2. Fetch the HTML content from the specified URL\n  3. Clean and prepare the HTML for processing\n  4. Submit the HTML to Google's Natural Language API for entity analysis\n  5. Return the structured entity data through the webhook response\n  6. Extract entities including people, organizations, locations, and more with their salience scores\n\n\n\n### Setup\n\nPrerequisites:\n\n  * An n8n instance (cloud or self-hosted)\n  * Google Cloud Platform account with Natural Language API enabled\n  * Google API key with access to the Natural Language API\n\n\n\n### Google Cloud Setup:\n\n  * Create a project in Google Cloud Platform\n  * Enable the Natural Language API for your project\n  * Create an API key with access to the Natural Language API\n  * Copy your API key for use in the workflow\n\n\n\n### n8n Setup:\n\n  * Import the workflow JSON into your n8n instance\n  * Replace \"YOUR-GOOGLE-API-KEY\" in the \"Google Entities\" node with your actual API key\n  * Activate the workflow to enable the webhook endpoint\n  * Copy the webhook URL from the \"Webhook\" node for later use\n\n\n\n### Testing:\n\n  * Use a tool like Postman or cURL to send a POST request to your webhook URL\n  * Include a JSON body with the URL you want to analyze: {\"url\": \"<https://example.com>\"}\n  * Verify that you receive a response containing the entity analysis data\n\n\n\n### How to customize this workflow to your needs\n\n### Analyzing Specific Entity\n\n  * Modify the \"Google Entities\" node parameters to include entityType filters\n  * Add a \"Function\" node after \"Google Entities\" to filter specific entity types\n  * Create conditions to extract only entities of interest (people, organizations, etc.)\n\n\n\n### Processing Multiple URLs in Batch:\n\n  * Replace the webhook with a different trigger (HTTP Request, Google Sheets, etc.)\n  * Add a \"Split In Batches\" node to process multiple URLs\n  * Use a \"Merge\" node to combine results before sending the response\n\n\n\n### Enhancing Entity Data:\n\n  * Add additional API calls to enrich extracted entities with more information\n  * Implement sentiment analysis alongside entity extraction\n  * Create a data transformation node to format entities by type or relevance\n\n\n\n### Additional Notes\n\n  * This workflow respects Google's API rate limits by processing one URL at a time\n  * The Natural Language API may not identify all entities on a page, particularly for highly technical content\n  * HTML content is trimmed to 100,000 characters if longer to avoid API limitations\n  * Consider legal and privacy implications when analyzing and storing entity data from web pages\n  * You may want to adjust the HTML cleaning process for specific website structures\n\n\n\n❤️ [Hueston SEO Team](https://hueston.co)\n",
  "readme_html": "<!--[--><div data-v-859c7806=\"\"><h3>Who is this for?</h3>\n<ul>\n<li>Content strategists analyzing web page semantic content</li>\n<li>SEO professionals conducting entity-based analysis</li>\n<li>Data analysts extracting structured data from web pages</li>\n<li>Marketers researching competitor content strategies</li>\n<li>Researchers organizing and categorizing web content</li>\n<li>Anyone needing to automatically extract entities from web pages</li>\n</ul>\n<h3>What problem is this workflow solving?</h3>\n<p>Manually identifying and categorizing entities (people, organizations, locations, etc.) on web pages is time-consuming and error-prone. This workflow solves this challenge by:</p>\n<ul>\n<li>Automating the extraction of named entities from any web page</li>\n<li>Leveraging Google's powerful Natural Language API for accurate entity recognition</li>\n<li>Processing web pages through a simple webhook interface</li>\n<li>Providing structured entity data that can be used for analysis or further processing</li>\n<li>Eliminating hours of manual content analysis and categorization</li>\n</ul>\n<h2>What this workflow does</h2>\n<p>This workflow creates an automated pipeline between a webhook and Google's Natural Language API to:</p>\n<ol>\n<li>Receive a URL through a webhook endpoint</li>\n<li>Fetch the HTML content from the specified URL</li>\n<li>Clean and prepare the HTML for processing</li>\n<li>Submit the HTML to Google's Natural Language API for entity analysis</li>\n<li>Return the structured entity data through the webhook response</li>\n<li>Extract entities including people, organizations, locations, and more with their salience scores</li>\n</ol>\n<h3>Setup</h3>\n<p>Prerequisites:</p>\n<ul>\n<li>An n8n instance (cloud or self-hosted)</li>\n<li>Google Cloud Platform account with Natural Language API enabled</li>\n<li>Google API key with access to the Natural Language API</li>\n</ul>\n<h3>Google Cloud Setup:</h3>\n<ul>\n<li>Create a project in Google Cloud Platform</li>\n<li>Enable the Natural Language API for your project</li>\n<li>Create an API key with access to the Natural Language API</li>\n<li>Copy your API key for use in the workflow</li>\n</ul>\n<h3>n8n Setup:</h3>\n<ul>\n<li>Import the workflow JSON into your n8n instance</li>\n<li>Replace \"YOUR-GOOGLE-API-KEY\" in the \"Google Entities\" node with your actual API key</li>\n<li>Activate the workflow to enable the webhook endpoint</li>\n<li>Copy the webhook URL from the \"Webhook\" node for later use</li>\n</ul>\n<h3>Testing:</h3>\n<ul>\n<li>Use a tool like Postman or cURL to send a POST request to your webhook URL</li>\n<li>Include a JSON body with the URL you want to analyze: {\"url\": \"<a href=\"https://example.com\" rel=\"ugc nofollow\" target=\"_blank\">https://example.com</a>\"}</li>\n<li>Verify that you receive a response containing the entity analysis data</li>\n</ul>\n<h3>How to customize this workflow to your needs</h3>\n<h3>Analyzing Specific Entity</h3>\n<ul>\n<li>Modify the \"Google Entities\" node parameters to include entityType filters</li>\n<li>Add a \"Function\" node after \"Google Entities\" to filter specific entity types</li>\n<li>Create conditions to extract only entities of interest (people, organizations, etc.)</li>\n</ul>\n<h3>Processing Multiple URLs in Batch:</h3>\n<ul>\n<li>Replace the webhook with a different trigger (HTTP Request, Google Sheets, etc.)</li>\n<li>Add a \"Split In Batches\" node to process multiple URLs</li>\n<li>Use a \"Merge\" node to combine results before sending the response</li>\n</ul>\n<h3>Enhancing Entity Data:</h3>\n<ul>\n<li>Add additional API calls to enrich extracted entities with more information</li>\n<li>Implement sentiment analysis alongside entity extraction</li>\n<li>Create a data transformation node to format entities by type or relevance</li>\n</ul>\n<h3>Additional Notes</h3>\n<ul>\n<li>This workflow respects Google's API rate limits by processing one URL at a time</li>\n<li>The Natural Language API may not identify all entities on a page, particularly for highly technical content</li>\n<li>HTML content is trimmed to 100,000 characters if longer to avoid API limitations</li>\n<li>Consider legal and privacy implications when analyzing and storing entity data from web pages</li>\n<li>You may want to adjust the HTML cleaning process for specific website structures</li>\n</ul>\n<p>❤️ <a href=\"https://hueston.co\" rel=\"ugc nofollow\" target=\"_blank\">Hueston SEO Team</a></p>\n</div><!--]-->"
}