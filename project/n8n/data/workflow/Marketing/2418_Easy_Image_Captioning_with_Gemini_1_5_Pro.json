{
  "title": "Easy Image Captioning with Gemini 1.5 Pro",
  "url": "https://n8n.io/workflows/2418-easy-image-captioning-with-gemini-15-pro/",
  "category": "Marketing",
  "category_url": "https://n8n.io/workflows/categories/marketing/?sort=createdAt:desc",
  "author": "Jimleuk",
  "publish_date": "Last update 7 months ago",
  "publish_date_absolute": "2024-10-19",
  "content": "",
  "workflow_json": "{\"meta\":{\"instanceId\":\"408f9fb9940c3cb18ffdef0e0150fe342d6e655c3a9fac21f0f644e8bedabcd9\"},\"nodes\":[{\"id\":\"0b64edf1-57e0-4704-b78c-c8ab2b91f74d\",\"name\":\"When clicking ‘Test workflow’\",\"type\":\"n8n-nodes-base.manualTrigger\",\"position\":[480,300],\"parameters\":{},\"typeVersion\":1},{\"id\":\"a875d1c5-ccfe-4bbf-b429-56a42b0ca778\",\"name\":\"Google Gemini Chat Model\",\"type\":\"@n8n/n8n-nodes-langchain.lmChatGoogleGemini\",\"position\":[1280,720],\"parameters\":{\"options\":{},\"modelName\":\"models/gemini-1.5-flash\"},\"credentials\":{\"googlePalmApi\":{\"id\":\"dSxo6ns5wn658r8N\",\"name\":\"Google Gemini(PaLM) Api account\"}},\"typeVersion\":1},{\"id\":\"a5e00543-dbaa-4e62-afb0-825ebefae3f3\",\"name\":\"Structured Output Parser\",\"type\":\"@n8n/n8n-nodes-langchain.outputParserStructured\",\"position\":[1480,720],\"parameters\":{\"jsonSchemaExample\":\"{\\n\\t\\\"caption_title\\\": \\\"\\\",\\n\\t\\\"caption_text\\\": \\\"\\\"\\n}\"},\"typeVersion\":1.2},{\"id\":\"bb9af9c6-6c81-4e92-a29f-18ab3afbe327\",\"name\":\"Get Info\",\"type\":\"n8n-nodes-base.editImage\",\"position\":[1100,400],\"parameters\":{\"operation\":\"information\"},\"typeVersion\":1},{\"id\":\"8a0dbd5d-5886-484a-80a0-486f349a9856\",\"name\":\"Resize For AI\",\"type\":\"n8n-nodes-base.editImage\",\"position\":[1100,560],\"parameters\":{\"width\":512,\"height\":512,\"options\":{},\"operation\":\"resize\"},\"typeVersion\":1},{\"id\":\"d29f254a-5fa3-46fa-b153-19dfd8e8c6a7\",\"name\":\"Calculate Positioning\",\"type\":\"n8n-nodes-base.code\",\"position\":[2020,720],\"parameters\":{\"mode\":\"runOnceForEachItem\",\"jsCode\":\"const { size, output } = $input.item.json;\\n\\nconst lineHeight = 35;\\nconst fontSize = Math.round(size.height / lineHeight);\\nconst maxLineLength = Math.round(size.width/fontSize) * 2;\\nconst text = `\\\"${output.caption_title}\\\". ${output.caption_text}`;\\nconst numLinesOccupied = Math.round(text.length / maxLineLength);\\n\\nconst verticalPadding = size.height * 0.02;\\nconst horizontalPadding = size.width * 0.02;\\nconst rectPosX = 0;\\nconst rectPosY = size.height - (verticalPadding * 2.5) - (numLinesOccupied * fontSize);\\nconst textPosX = horizontalPadding;\\nconst textPosY = size.height - (numLinesOccupied * fontSize) - (verticalPadding/2);\\n\\nreturn {\\n  caption: {\\n    fontSize,\\n    maxLineLength,\\n    numLinesOccupied,\\n    rectPosX,\\n    rectPosY,\\n    textPosX,\\n    textPosY,\\n    verticalPadding,\\n    horizontalPadding,\\n  }\\n}\\n\"},\"typeVersion\":2},{\"id\":\"12a7f2d6-8684-48a5-aa41-40a8a4f98c79\",\"name\":\"Apply Caption to Image\",\"type\":\"n8n-nodes-base.editImage\",\"position\":[2380,560],\"parameters\":{\"options\":{},\"operation\":\"multiStep\",\"operations\":{\"operations\":[{\"color\":\"=#0000008c\",\"operation\":\"draw\",\"endPositionX\":\"={{ $json.size.width }}\",\"endPositionY\":\"={{ $json.size.height }}\",\"startPositionX\":\"={{ $json.caption.rectPosX }}\",\"startPositionY\":\"={{ $json.caption.rectPosY }}\"},{\"font\":\"/usr/share/fonts/truetype/msttcorefonts/Arial.ttf\",\"text\":\"=\\\"{{ $json.output.caption_title }}\\\". {{ $json.output.caption_text }}\",\"fontSize\":\"={{ $json.caption.fontSize }}\",\"fontColor\":\"#FFFFFF\",\"operation\":\"text\",\"positionX\":\"={{ $json.caption.textPosX }}\",\"positionY\":\"={{ $json.caption.textPosY }}\",\"lineLength\":\"={{ $json.caption.maxLineLength }}\"}]}},\"typeVersion\":1},{\"id\":\"4d569ec8-04c2-4d21-96e1-86543b26892d\",\"name\":\"Sticky Note\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[-120,80],\"parameters\":{\"width\":423.75,\"height\":431.76353488372104,\"content\":\"## Try it out!\\n\\n### This workflow takes an image and generates a caption for it using AI. The OpenAI node has been able to do this for a while but this workflow demonstrates how to achieve the same with other multimodal vision models such as Google's Gemini.\\n\\nAdditional, we'll use the Edit Image node to overlay the generated caption onto the image. This can be useful for publications or can be repurposed for copyrights and/or watermarks.\\n\\n### Need Help?\\nJoin the [Discord](https://discord.com/invite/XPKeKXeB7d) or ask in the [Forum](https://community.n8n.io/)!\\n\"},\"typeVersion\":1},{\"id\":\"45d37945-5a7a-42eb-8c8c-5940ea276072\",\"name\":\"Merge Image & Caption\",\"type\":\"n8n-nodes-base.merge\",\"position\":[1620,400],\"parameters\":{\"mode\":\"combine\",\"options\":{},\"combineBy\":\"combineByPosition\"},\"typeVersion\":3},{\"id\":\"53a26842-ad56-4c8d-a59d-4f6d3f9e2407\",\"name\":\"Merge Caption & Positions\",\"type\":\"n8n-nodes-base.merge\",\"position\":[2200,560],\"parameters\":{\"mode\":\"combine\",\"options\":{},\"combineBy\":\"combineByPosition\"},\"typeVersion\":3},{\"id\":\"b6c28913-b16a-4c59-aa49-47e9bb97f86d\",\"name\":\"Get Image\",\"type\":\"n8n-nodes-base.httpRequest\",\"position\":[680,300],\"parameters\":{\"url\":\"https://images.pexels.com/photos/1267338/pexels-photo-1267338.jpeg?auto=compress&cs=tinysrgb&w=600\",\"options\":{}},\"typeVersion\":4.2},{\"id\":\"6c25054d-8103-4be9-bea7-6c3dd47f49a3\",\"name\":\"Sticky Note1\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[340,80],\"parameters\":{\"color\":7,\"width\":586.25,\"height\":486.25,\"content\":\"## 1. Import an Image \\n[Read more about the HTTP request node](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.httprequest)\\n\\nFor this demonstration, we'll grab an image off Pexels.com - a popular free stock photography site - by using the HTTP request node to download.\\n\\nIn your own workflows, this can be replaces by other triggers such as webhooks.\"},\"typeVersion\":1},{\"id\":\"d1b708e2-31c3-4cd1-a353-678bc33d4022\",\"name\":\"Sticky Note2\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[960,140],\"parameters\":{\"color\":7,\"width\":888.75,\"height\":783.75,\"content\":\"## 2. Using Vision Model to Generate Caption\\n[Learn more about the Basic LLM Chain](https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.chainllm)\\n\\nn8n's basic LLM node supports multimodal input by allowing you to specify either a binary or an image url to send to a compatible LLM. This makes it easy to start utilising this powerful feature for visual classification or OCR tasks which have previously depended on more dedicated OCR models.\\n\\nHere, we've simply passed our image binary as a \\\"user message\\\" option, asking the LLM to help us generate a caption title and text which is appropriate for the given subject. Once generated, we'll pass this text along with the image to combine them both.\"},\"typeVersion\":1},{\"id\":\"36a39871-340f-4c44-90e6-74393b9be324\",\"name\":\"Sticky Note3\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[1880,280],\"parameters\":{\"color\":7,\"width\":753.75,\"height\":635,\"content\":\"## 3. Overlay Caption on Image \\n[Read more about the Edit Image node](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.editimage)\\n\\nFinally, we’ll perform some basic calculations to place the generated caption onto the image. With n8n's user-friendly image editing features, this can be done entirely within the workflow!\\n\\nThe Code node tool is ideal for these types of calculations and is used here to position the caption at the bottom of the image. To create the overlay, the Edit Image node enables us to insert text onto the image, which we’ll use to add the generated caption.\"},\"typeVersion\":1},{\"id\":\"d175fe97-064e-41da-95fd-b15668c330c4\",\"name\":\"Sticky Note4\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[2660,280],\"parameters\":{\"width\":563.75,\"height\":411.25,\"content\":\"**FIG 1.** Example input image with AI generated caption\\n![Example Output](https://res.cloudinary.com/daglih2g8/image/upload/f_auto,q_auto/v1/n8n-workflows/l5xbb4ze4wyxwwefqmnc#full-width)\"},\"typeVersion\":1},{\"id\":\"23db0c90-45b6-4b85-b017-a52ad5a9ad5b\",\"name\":\"Image Captioning Agent\",\"type\":\"@n8n/n8n-nodes-langchain.chainLlm\",\"position\":[1280,560],\"parameters\":{\"text\":\"Generate a caption for this image.\",\"messages\":{\"messageValues\":[{\"message\":\"=You role is to provide an appropriate image caption for user provided images.\\n\\nThe individual components of a caption are as follows: who, when, where, context and miscellaneous. For a really good caption, follow this template: who + when + where + context + miscellaneous\\n\\nGive the caption a punny title.\"},{\"type\":\"HumanMessagePromptTemplate\",\"messageType\":\"imageBinary\"}]},\"promptType\":\"define\",\"hasOutputParser\":true},\"typeVersion\":1.4}],\"pinData\":{},\"connections\":{\"Get Info\":{\"main\":[[{\"node\":\"Merge Image & Caption\",\"type\":\"main\",\"index\":0}]]},\"Get Image\":{\"main\":[[{\"node\":\"Resize For AI\",\"type\":\"main\",\"index\":0},{\"node\":\"Get Info\",\"type\":\"main\",\"index\":0}]]},\"Resize For AI\":{\"main\":[[{\"node\":\"Image Captioning Agent\",\"type\":\"main\",\"index\":0}]]},\"Calculate Positioning\":{\"main\":[[{\"node\":\"Merge Caption & Positions\",\"type\":\"main\",\"index\":1}]]},\"Merge Image & Caption\":{\"main\":[[{\"node\":\"Calculate Positioning\",\"type\":\"main\",\"index\":0},{\"node\":\"Merge Caption & Positions\",\"type\":\"main\",\"index\":0}]]},\"Image Captioning Agent\":{\"main\":[[{\"node\":\"Merge Image & Caption\",\"type\":\"main\",\"index\":1}]]},\"Google Gemini Chat Model\":{\"ai_languageModel\":[[{\"node\":\"Image Captioning Agent\",\"type\":\"ai_languageModel\",\"index\":0}]]},\"Structured Output Parser\":{\"ai_outputParser\":[[{\"node\":\"Image Captioning Agent\",\"type\":\"ai_outputParser\",\"index\":0}]]},\"Merge Caption & Positions\":{\"main\":[[{\"node\":\"Apply Caption to Image\",\"type\":\"main\",\"index\":0}]]},\"When clicking ‘Test workflow’\":{\"main\":[[{\"node\":\"Get Image\",\"type\":\"main\",\"index\":0}]]}}}",
  "readme": "This n8n workflow demonstrates how to automate image captioning tasks using Gemini 1.5 Pro - a multimodal LLM which can accept and analyse images. This is a really simple example of how easy it is to build and leverage powerful AI models in your repetitive tasks.\n\n## How it works\n\n  * For this demo, we'll import a public image from a popular stock photography website, [Pexel.com](http://Pexel.com), into our workflow using the HTTP request node.\n  * With multimodal LLMs, there is little do preprocess other than ensuring the image dimensions fit within the LLMs accepted limits. Though not essential, we'll resize the image using the Edit image node to achieve fast processing.\n  * The image is used as an input to the basic LLM node by defining a \"user message\" entry with the binary (data) type.\n  * The LLM node has the Gemini 1.5 Pro language model attached and we'll prompt it to generate a caption title and text appropriate for the image it sees.\n  * Once generated, the generated caption text is positioning over the original image to complete the task. We can calculate the positioning relative to the amount of characters produced using the code node.\n\n\n\nAn example of the combined image and caption can be found here: <https://res.cloudinary.com/daglih2g8/image/upload/f_auto,q_auto/v1/n8n-workflows/l5xbb4ze4wyxwwefqmnc>\n\n## Requirements\n\n  * Google Gemini API Key.\n  * Access to Google Drive.\n\n\n\n## Customising the workflow\n\n  * Not using Google Gemini? n8n's basic LLM node supports the standard syntax for image content for models that support it - try using GPT4o, Claude or LLava (via Ollama).\n\n  * Google Drive is only used for demonstration purposes. Feel free to swap this out for other triggers such as webhooks to fit your use case.\n\n\n\n",
  "readme_html": "<!--[--><div data-v-50766329=\"\"><p>This n8n workflow demonstrates how to automate image captioning tasks using Gemini 1.5 Pro - a multimodal LLM which can accept and analyse images. This is a really simple example of how easy it is to build and leverage powerful AI models in your repetitive tasks.</p>\n<h2>How it works</h2>\n<ul>\n<li>For this demo, we'll import a public image from a popular stock photography website, <a href=\"http://Pexel.com\" rel=\"ugc nofollow\" target=\"_blank\">Pexel.com</a>, into our workflow using the HTTP request node.</li>\n<li>With multimodal LLMs, there is little do preprocess other than ensuring the image dimensions fit within the LLMs accepted limits. Though not essential, we'll resize the image using the Edit image node to achieve fast processing.</li>\n<li>The image is used as an input to the basic LLM node by defining a \"user message\" entry with the binary (data) type.</li>\n<li>The LLM node has the Gemini 1.5 Pro language model attached and we'll prompt it to generate a caption title and text appropriate for the image it sees.</li>\n<li>Once generated, the generated caption text is positioning over the original image to complete the task. We can calculate the positioning relative to the amount of characters produced using the code node.</li>\n</ul>\n<p>An example of the combined image and caption can be found here: <a href=\"https://res.cloudinary.com/daglih2g8/image/upload/f_auto,q_auto/v1/n8n-workflows/l5xbb4ze4wyxwwefqmnc\" rel=\"ugc nofollow\" target=\"_blank\">https://res.cloudinary.com/daglih2g8/image/upload/f_auto,q_auto/v1/n8n-workflows/l5xbb4ze4wyxwwefqmnc</a></p>\n<h2>Requirements</h2>\n<ul>\n<li>Google Gemini API Key.</li>\n<li>Access to Google Drive.</li>\n</ul>\n<h2>Customising the workflow</h2>\n<ul>\n<li>\n<p>Not using Google Gemini? n8n's basic LLM node supports the standard syntax for image content for models that support it - try using GPT4o, Claude or LLava (via Ollama).</p>\n</li>\n<li>\n<p>Google Drive is only used for demonstration purposes. Feel free to swap this out for other triggers such as webhooks to fit your use case.</p>\n</li>\n</ul>\n</div><!--]-->",
  "readme_zh": "这个n8n工作流展示了如何利用Gemini 1.5 Pro（一款能接收分析图像的多模态大语言模型）实现自动化图片标注任务。这个简单示例揭示了如何轻松将强大AI模型融入重复性工作流程。\n\n## 运行原理\n\n* 本演示通过HTTP请求节点从知名图库网站[Pexel.com](http://Pexel.com)获取公开图片\n* 多模态大语言模型基本无需预处理，仅需确保图像尺寸符合模型限制。虽然非必需，但我们会使用图像编辑节点调整尺寸以加速处理\n* 通过定义二进制数据类型\"用户消息\"，将图像作为基础LLM节点的输入\n* 配置了Gemini 1.5 Pro模型的LLM节点会根据所见图像生成合适的标题和描述文本\n* 生成文本后，通过代码节点计算字符量确定排版位置，最终将标注文字叠加到原图完成处理\n\n效果示例参见：<https://res.cloudinary.com/daglih2g8/image/upload/f_auto,q_auto/v1/n8n-workflows/l5xbb4ze4wyxwwefqmnc>\n\n## 环境要求\n\n* 谷歌Gemini API密钥\n* 谷歌云盘访问权限\n\n## 定制建议\n\n* 若未使用Gemini：n8n基础LLM节点支持标准图像输入语法，可尝试GPT4o、Claude或通过Ollama使用LLava等支持图像处理的模型\n* 谷歌云盘仅作演示用途，可根据实际需求替换为Webhook等其他触发方式",
  "title_zh": "使用Gemini 1.5 Pro轻松实现图像描述生成",
  "publish_date_zh": "最后更新于7个月前",
  "workflow_json_zh": "{\n  \"meta\": {\n    \"instanceId\": \"408f9fb9940c3cb18ffdef0e0150fe342d6e655c3a9fac21f0f644e8bedabcd9\"\n  },\n  \"nodes\": [\n    {\n      \"id\": \"0b64edf1-57e0-4704-b78c-c8ab2b91f74d\",\n      \"name\": \"When clicking ‘Test workflow’\",\n      \"type\": \"n8n-nodes-base.manualTrigger\",\n      \"position\": [\n        480,\n        300\n      ],\n      \"parameters\": {},\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"a875d1c5-ccfe-4bbf-b429-56a42b0ca778\",\n      \"name\": \"Google Gemini Chat Model\",\n      \"type\": \"@n8n/n8n-nodes-langchain.lmChatGoogleGemini\",\n      \"position\": [\n        1280,\n        720\n      ],\n      \"parameters\": {\n        \"options\": {},\n        \"modelName\": \"models/gemini-1.5-flash\"\n      },\n      \"credentials\": {\n        \"googlePalmApi\": {\n          \"id\": \"dSxo6ns5wn658r8N\",\n          \"name\": \"Google Gemini(PaLM) Api account\"\n        }\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"a5e00543-dbaa-4e62-afb0-825ebefae3f3\",\n      \"name\": \"Structured Output Parser\",\n      \"type\": \"@n8n/n8n-nodes-langchain.outputParserStructured\",\n      \"position\": [\n        1480,\n        720\n      ],\n      \"parameters\": {\n        \"jsonSchemaExample\": \"{\\n\\t\\\"caption_title\\\": \\\"\\\",\\n\\t\\\"caption_text\\\": \\\"\\\"\\n}\"\n      },\n      \"typeVersion\": 1.2\n    },\n    {\n      \"id\": \"bb9af9c6-6c81-4e92-a29f-18ab3afbe327\",\n      \"name\": \"Get Info\",\n      \"type\": \"n8n-nodes-base.editImage\",\n      \"position\": [\n        1100,\n        400\n      ],\n      \"parameters\": {\n        \"operation\": \"information\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"8a0dbd5d-5886-484a-80a0-486f349a9856\",\n      \"name\": \"Resize For AI\",\n      \"type\": \"n8n-nodes-base.editImage\",\n      \"position\": [\n        1100,\n        560\n      ],\n      \"parameters\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"options\": {},\n        \"operation\": \"resize\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"d29f254a-5fa3-46fa-b153-19dfd8e8c6a7\",\n      \"name\": \"Calculate Positioning\",\n      \"type\": \"n8n-nodes-base.code\",\n      \"position\": [\n        2020,\n        720\n      ],\n      \"parameters\": {\n        \"mode\": \"runOnceForEachItem\",\n        \"jsCode\": \"const { size, output } = $input.item.json;\\n\\nconst lineHeight = 35;\\nconst fontSize = Math.round(size.height / lineHeight);\\nconst maxLineLength = Math.round(size.width/fontSize) * 2;\\nconst text = `\\\"${output.caption_title}\\\". ${output.caption_text}`;\\nconst numLinesOccupied = Math.round(text.length / maxLineLength);\\n\\nconst verticalPadding = size.height * 0.02;\\nconst horizontalPadding = size.width * 0.02;\\nconst rectPosX = 0;\\nconst rectPosY = size.height - (verticalPadding * 2.5) - (numLinesOccupied * fontSize);\\nconst textPosX = horizontalPadding;\\nconst textPosY = size.height - (numLinesOccupied * fontSize) - (verticalPadding/2);\\n\\nreturn {\\n  caption: {\\n    fontSize,\\n    maxLineLength,\\n    numLinesOccupied,\\n    rectPosX,\\n    rectPosY,\\n    textPosX,\\n    textPosY,\\n    verticalPadding,\\n    horizontalPadding,\\n  }\\n}\\n\"\n      },\n      \"typeVersion\": 2\n    },\n    {\n      \"id\": \"12a7f2d6-8684-48a5-aa41-40a8a4f98c79\",\n      \"name\": \"Apply Caption to Image\",\n      \"type\": \"n8n-nodes-base.editImage\",\n      \"position\": [\n        2380,\n        560\n      ],\n      \"parameters\": {\n        \"options\": {},\n        \"operation\": \"multiStep\",\n        \"operations\": {\n          \"operations\": [\n            {\n              \"color\": \"=#0000008c\",\n              \"operation\": \"draw\",\n              \"endPositionX\": \"={{ $json.size.width }}\",\n              \"endPositionY\": \"={{ $json.size.height }}\",\n              \"startPositionX\": \"={{ $json.caption.rectPosX }}\",\n              \"startPositionY\": \"={{ $json.caption.rectPosY }}\"\n            },\n            {\n              \"font\": \"/usr/share/fonts/truetype/msttcorefonts/Arial.ttf\",\n              \"text\": \"=\\\"{{ $json.output.caption_title }}\\\". {{ $json.output.caption_text }}\",\n              \"fontSize\": \"={{ $json.caption.fontSize }}\",\n              \"fontColor\": \"#FFFFFF\",\n              \"operation\": \"text\",\n              \"positionX\": \"={{ $json.caption.textPosX }}\",\n              \"positionY\": \"={{ $json.caption.textPosY }}\",\n              \"lineLength\": \"={{ $json.caption.maxLineLength }}\"\n            }\n          ]\n        }\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"4d569ec8-04c2-4d21-96e1-86543b26892d\",\n      \"name\": \"Sticky Note\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"position\": [\n        -120,\n        80\n      ],\n      \"parameters\": {\n        \"width\": 423.75,\n        \"height\": 431.76353488372104,\n        \"content\": \"## 试试看吧！\\n\\n### 该工作流通过AI为输入的图像生成描述文字。虽然OpenAI节点早已支持此功能，但本示例将展示如何利用谷歌Gemini等多模态视觉模型实现相同效果。\\n\\n我们还使用了图像编辑节点，将生成的文字直接叠加到原图上。这个功能既适用于出版物场景，也能灵活运用于版权声明或水印添加等用途。\\n\\n### 需要帮助？\\n加入[Discord讨论群](https://discord.com/invite/XPKeKXeB7d) 或访问[官方论坛](https://community.n8n.io/)提问！\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"45d37945-5a7a-42eb-8c8c-5940ea276072\",\n      \"name\": \"Merge Image & Caption\",\n      \"type\": \"n8n-nodes-base.merge\",\n      \"position\": [\n        1620,\n        400\n      ],\n      \"parameters\": {\n        \"mode\": \"combine\",\n        \"options\": {},\n        \"combineBy\": \"combineByPosition\"\n      },\n      \"typeVersion\": 3\n    },\n    {\n      \"id\": \"53a26842-ad56-4c8d-a59d-4f6d3f9e2407\",\n      \"name\": \"Merge Caption & Positions\",\n      \"type\": \"n8n-nodes-base.merge\",\n      \"position\": [\n        2200,\n        560\n      ],\n      \"parameters\": {\n        \"mode\": \"combine\",\n        \"options\": {},\n        \"combineBy\": \"combineByPosition\"\n      },\n      \"typeVersion\": 3\n    },\n    {\n      \"id\": \"b6c28913-b16a-4c59-aa49-47e9bb97f86d\",\n      \"name\": \"Get Image\",\n      \"type\": \"n8n-nodes-base.httpRequest\",\n      \"position\": [\n        680,\n        300\n      ],\n      \"parameters\": {\n        \"url\": \"https://images.pexels.com/photos/1267338/pexels-photo-1267338.jpeg?auto=compress&cs=tinysrgb&w=600\",\n        \"options\": {}\n      },\n      \"typeVersion\": 4.2\n    },\n    {\n      \"id\": \"6c25054d-8103-4be9-bea7-6c3dd47f49a3\",\n      \"name\": \"Sticky Note1\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"position\": [\n        340,\n        80\n      ],\n      \"parameters\": {\n        \"color\": 7,\n        \"width\": 586.25,\n        \"height\": 486.25,\n        \"content\": \"## 1. Import an Image \\n[Read more about the HTTP request node](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.httprequest)\\n\\nFor this demonstration, we'll grab an image off Pexels.com - a popular free stock photography site - by using the HTTP request node to download.\\n\\nIn your own workflows, this can be replaces by other triggers such as webhooks.\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"d1b708e2-31c3-4cd1-a353-678bc33d4022\",\n      \"name\": \"Sticky Note2\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"position\": [\n        960,\n        140\n      ],\n      \"parameters\": {\n        \"color\": 7,\n        \"width\": 888.75,\n        \"height\": 783.75,\n        \"content\": \"## 2. Using Vision Model to Generate Caption\\n[Learn more about the Basic LLM Chain](https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.chainllm)\\n\\nn8n's basic LLM node supports multimodal input by allowing you to specify either a binary or an image url to send to a compatible LLM. This makes it easy to start utilising this powerful feature for visual classification or OCR tasks which have previously depended on more dedicated OCR models.\\n\\nHere, we've simply passed our image binary as a \\\"user message\\\" option, asking the LLM to help us generate a caption title and text which is appropriate for the given subject. Once generated, we'll pass this text along with the image to combine them both.\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"36a39871-340f-4c44-90e6-74393b9be324\",\n      \"name\": \"Sticky Note3\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"position\": [\n        1880,\n        280\n      ],\n      \"parameters\": {\n        \"color\": 7,\n        \"width\": 753.75,\n        \"height\": 635,\n        \"content\": \"## 3. Overlay Caption on Image \\n[Read more about the Edit Image node](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.editimage)\\n\\nFinally, we’ll perform some basic calculations to place the generated caption onto the image. With n8n's user-friendly image editing features, this can be done entirely within the workflow!\\n\\nThe Code node tool is ideal for these types of calculations and is used here to position the caption at the bottom of the image. To create the overlay, the Edit Image node enables us to insert text onto the image, which we’ll use to add the generated caption.\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"d175fe97-064e-41da-95fd-b15668c330c4\",\n      \"name\": \"Sticky Note4\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"position\": [\n        2660,\n        280\n      ],\n      \"parameters\": {\n        \"width\": 563.75,\n        \"height\": 411.25,\n        \"content\": \"**FIG 1.** Example input image with AI generated caption\\n![Example Output](https://res.cloudinary.com/daglih2g8/image/upload/f_auto,q_auto/v1/n8n-workflows/l5xbb4ze4wyxwwefqmnc#full-width)\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"23db0c90-45b6-4b85-b017-a52ad5a9ad5b\",\n      \"name\": \"Image Captioning Agent\",\n      \"type\": \"@n8n/n8n-nodes-langchain.chainLlm\",\n      \"position\": [\n        1280,\n        560\n      ],\n      \"parameters\": {\n        \"text\": \"Generate a caption for this image.\",\n        \"messages\": {\n          \"messageValues\": [\n            {\n              \"message\": \"=You role is to provide an appropriate image caption for user provided images.\\n\\nThe individual components of a caption are as follows: who, when, where, context and miscellaneous. For a really good caption, follow this template: who + when + where + context + miscellaneous\\n\\nGive the caption a punny title.\"\n            },\n            {\n              \"type\": \"HumanMessagePromptTemplate\",\n              \"messageType\": \"imageBinary\"\n            }\n          ]\n        },\n        \"promptType\": \"define\",\n        \"hasOutputParser\": true\n      },\n      \"typeVersion\": 1.4\n    }\n  ],\n  \"pinData\": {},\n  \"connections\": {\n    \"Get Info\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Merge Image & Caption\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Get Image\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Resize For AI\",\n            \"type\": \"main\",\n            \"index\": 0\n          },\n          {\n            \"node\": \"Get Info\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Resize For AI\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Image Captioning Agent\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Calculate Positioning\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Merge Caption & Positions\",\n            \"type\": \"main\",\n            \"index\": 1\n          }\n        ]\n      ]\n    },\n    \"Merge Image & Caption\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Calculate Positioning\",\n            \"type\": \"main\",\n            \"index\": 0\n          },\n          {\n            \"node\": \"Merge Caption & Positions\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Image Captioning Agent\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Merge Image & Caption\",\n            \"type\": \"main\",\n            \"index\": 1\n          }\n        ]\n      ]\n    },\n    \"Google Gemini Chat Model\": {\n      \"ai_languageModel\": [\n        [\n          {\n            \"node\": \"Image Captioning Agent\",\n            \"type\": \"ai_languageModel\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Structured Output Parser\": {\n      \"ai_outputParser\": [\n        [\n          {\n            \"node\": \"Image Captioning Agent\",\n            \"type\": \"ai_outputParser\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Merge Caption & Positions\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Apply Caption to Image\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"When clicking ‘Test workflow’\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Get Image\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    }\n  }\n}"
}