{
  "title": "Scrape Web Data with Bright Data, Google Gemini and MCP Automated AI Agent",
  "url": "https://n8n.io/workflows/3778-scrape-web-data-with-bright-data-google-gemini-and-mcp-automated-ai-agent/",
  "category": "ITOps",
  "category_url": "https://n8n.io/workflows/categories/it-ops/?sort=createdAt:desc",
  "author": "Ranjan Dailata",
  "publish_date": "Last update 10 hours ago",
  "publish_date_absolute": "",
  "content": "",
  "workflow_json": "{\"id\":\"U6cY7PPR0vaRl1I0\",\"meta\":{\"instanceId\":\"885b4fb4a6a9c2cb5621429a7b972df0d05bb724c20ac7dac7171b62f1c7ef40\",\"templateCredsSetupCompleted\":true},\"name\":\"Scrape Web Data with Bright Data, Google Gemini and MCP Automated AI Agent\",\"tags\":[{\"id\":\"ZOwtAMLepQaGW76t\",\"name\":\"Building Blocks\",\"createdAt\":\"2025-04-13T15:23:40.462Z\",\"updatedAt\":\"2025-04-13T15:23:40.462Z\"},{\"id\":\"ddPkw7Hg5dZhQu2w\",\"name\":\"AI\",\"createdAt\":\"2025-04-13T05:38:08.053Z\",\"updatedAt\":\"2025-04-13T05:38:08.053Z\"}],\"nodes\":[{\"id\":\"0c747f5b-ef72-4e00-a028-4a08461dae28\",\"name\":\"AI Agent\",\"type\":\"@n8n/n8n-nodes-langchain.agent\",\"notes\":\"Bright Data Web Scraping Agent\",\"position\":[-140,60],\"parameters\":{\"text\":\"=Scrape the web data as per the provided URL:  {{ $json.url }} using the format as {{ $json.format }}\",\"options\":{\"systemMessage\":\"=You are a helpful assistant.\"},\"promptType\":\"define\"},\"notesInFlow\":true,\"typeVersion\":1.8},{\"id\":\"16c7cd90-39da-47a4-8020-a0aa8f87275a\",\"name\":\"When clicking ‘Test workflow’\",\"type\":\"n8n-nodes-base.manualTrigger\",\"position\":[-640,-300],\"parameters\":{},\"typeVersion\":1},{\"id\":\"7b544505-6b6b-4500-a2ad-f7cf62f98c13\",\"name\":\"MCP Client list all tools for Bright Data\",\"type\":\"n8n-nodes-mcp.mcpClient\",\"position\":[-380,-300],\"parameters\":{},\"credentials\":{\"mcpClientApi\":{\"id\":\"JtatFSfA2kkwctYa\",\"name\":\"MCP Client (STDIO) account\"}},\"typeVersion\":1},{\"id\":\"9f5bf319-9414-4974-bad2-ea24f09ae351\",\"name\":\"Sticky Note1\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[-220,-400],\"parameters\":{\"color\":3,\"width\":440,\"height\":320,\"content\":\"## Bright Data Web Scraper\"},\"typeVersion\":1},{\"id\":\"222e81cf-878e-42de-a325-6b6659145f98\",\"name\":\"MCP Client List all tools\",\"type\":\"n8n-nodes-mcp.mcpClientTool\",\"position\":[440,420],\"parameters\":{},\"credentials\":{\"mcpClientApi\":{\"id\":\"JtatFSfA2kkwctYa\",\"name\":\"MCP Client (STDIO) account\"}},\"typeVersion\":1},{\"id\":\"a10dfd4f-cadf-4952-8449-1865406358d4\",\"name\":\"MCP Client Bright Data Web Scraper\",\"type\":\"n8n-nodes-mcp.mcpClient\",\"notes\":\"Scrape a single webpage URL with advanced options for content extraction and get back the results in MarkDown language.\",\"position\":[60,-300],\"parameters\":{\"toolName\":\"=scrape_as_markdown\",\"operation\":\"executeTool\",\"toolParameters\":\"={\\n   \\\"url\\\": \\\"{{ $json.url }}\\\"\\n} \"},\"credentials\":{\"mcpClientApi\":{\"id\":\"JtatFSfA2kkwctYa\",\"name\":\"MCP Client (STDIO) account\"}},\"notesInFlow\":true,\"typeVersion\":1},{\"id\":\"0acbd4ff-ce4a-4ff2-b213-2d80dd91e302\",\"name\":\"Webhook for web scraper\",\"type\":\"n8n-nodes-base.httpRequest\",\"position\":[280,-300],\"parameters\":{\"url\":\"=https://webhook.site/daf9d591-a130-4010-b1d3-0c66f8fcf467\",\"options\":{},\"sendBody\":true,\"bodyParameters\":{\"parameters\":[{\"name\":\"response\",\"value\":\"={{ $json.result.content[0].text }}\"}]}},\"typeVersion\":4.2},{\"id\":\"009ac29f-8cad-4b58-9ca4-e75470a52dcc\",\"name\":\"Set the URLs\",\"type\":\"n8n-nodes-base.set\",\"position\":[-160,-300],\"parameters\":{\"options\":{},\"assignments\":{\"assignments\":[{\"id\":\"214e61a0-3587-453f-baf5-eac013990857\",\"name\":\"url\",\"type\":\"string\",\"value\":\"https://about.google/\"},{\"id\":\"45014942-0a2e-4f46-b395-f82f97bfa93e\",\"name\":\"webhook_url\",\"type\":\"string\",\"value\":\"https://webhook.site/ce41e056-c097-48c8-a096-9b876d3abbf7\"}]}},\"typeVersion\":3.4},{\"id\":\"104706dd-ae58-47fd-8fea-cefa986ae40c\",\"name\":\"MCP Client to Scrape as Markdown\",\"type\":\"n8n-nodes-mcp.mcpClientTool\",\"notes\":\"Scrape a single webpage URL with advanced options for content extraction and get back the results in MarkDown language.\",\"position\":[-60,400],\"parameters\":{\"toolName\":\"scrape_as_markdown\",\"operation\":\"executeTool\",\"toolParameters\":\"={\\n  \\\"url\\\": \\\"{{ $json.url }}\\\"\\n} \",\"descriptionType\":\"manual\",\"toolDescription\":\"Scrape a single webpage URL with advanced options for content extraction and get back the results in MarkDown language.\"},\"credentials\":{\"mcpClientApi\":{\"id\":\"JtatFSfA2kkwctYa\",\"name\":\"MCP Client (STDIO) account\"}},\"notesInFlow\":false,\"typeVersion\":1},{\"id\":\"c03c655e-45c8-4278-a01f-ba48282459c5\",\"name\":\"MCP Client to Scrape as HTML\",\"type\":\"n8n-nodes-mcp.mcpClientTool\",\"notes\":\"Scrape a single webpage URL with advanced options for content extraction and get back the results in HTML.\",\"position\":[200,400],\"parameters\":{\"toolName\":\"scrape_as_html\",\"operation\":\"executeTool\",\"toolParameters\":\"{\\n  \\\"url\\\": \\\"{{ $json.url }}\\\"\\n} \",\"descriptionType\":\"manual\",\"toolDescription\":\"Scrape a single webpage URL with advanced options for content extraction and get back the results in HTML.\"},\"credentials\":{\"mcpClientApi\":{\"id\":\"JtatFSfA2kkwctYa\",\"name\":\"MCP Client (STDIO) account\"}},\"notesInFlow\":true,\"typeVersion\":1},{\"id\":\"587300ff-44e5-4ff2-9dee-a4f8720ca26b\",\"name\":\"Google Gemini Chat Model for AI Agent\",\"type\":\"@n8n/n8n-nodes-langchain.lmChatGoogleGemini\",\"position\":[-520,400],\"parameters\":{\"options\":{},\"modelName\":\"models/gemini-2.0-flash-exp\"},\"credentials\":{\"googlePalmApi\":{\"id\":\"YeO7dHZnuGBVQKVZ\",\"name\":\"Google Gemini(PaLM) Api account\"}},\"typeVersion\":1},{\"id\":\"38ba13a1-f8f7-48ce-a05d-2c2526de606d\",\"name\":\"Sticky Note\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[-140,340],\"parameters\":{\"color\":4,\"width\":480,\"height\":260,\"content\":\"## Bright Data Web Scraper Tools\"},\"typeVersion\":1},{\"id\":\"e7c8d333-e256-4944-a584-575162072ca4\",\"name\":\"Simple Memory\",\"type\":\"@n8n/n8n-nodes-langchain.memoryBufferWindow\",\"position\":[-280,400],\"parameters\":{\"sessionKey\":\"=Perform the web scraping for the below URL\\n\\n{{ $json.url }}\",\"sessionIdType\":\"customKey\",\"contextWindowLength\":10},\"typeVersion\":1.3},{\"id\":\"5e89519e-8ee5-4c3b-807d-21cef6e36c32\",\"name\":\"Webhook for Web Scraper AI Agent\",\"type\":\"n8n-nodes-base.httpRequest\",\"position\":[260,120],\"parameters\":{\"url\":\"={{ $('Set the URL with the Webhook URL and data format').item.json.webhook_url }}\",\"options\":{},\"sendBody\":true,\"bodyParameters\":{\"parameters\":[{\"name\":\"response\",\"value\":\"={{ $json.output }}\"}]}},\"typeVersion\":4.2},{\"id\":\"2de093f4-15e5-4710-83d9-e6d9ed852873\",\"name\":\"Set the URL with the Webhook URL and data format\",\"type\":\"n8n-nodes-base.set\",\"position\":[-400,60],\"parameters\":{\"options\":{},\"assignments\":{\"assignments\":[{\"id\":\"214e61a0-3587-453f-baf5-eac013990857\",\"name\":\"url\",\"type\":\"string\",\"value\":\"https://about.google/\"},{\"id\":\"45014942-0a2e-4f46-b395-f82f97bfa93e\",\"name\":\"webhook_url\",\"type\":\"string\",\"value\":\"https://webhook.site/daf9d591-a130-4010-b1d3-0c66f8fcf467\"},{\"id\":\"7f6c03f6-9fa3-45f9-bf81-243b7106bdac\",\"name\":\"format\",\"type\":\"string\",\"value\":\"scrape_as_markdown\"}]}},\"typeVersion\":3.4},{\"id\":\"04a5b11f-1990-440e-be23-2fbcb985dd4a\",\"name\":\"Create a binary data\",\"type\":\"n8n-nodes-base.function\",\"position\":[260,-80],\"parameters\":{\"functionCode\":\"items[0].binary = {\\n  data: {\\n    data: new Buffer(JSON.stringify(items[0].json, null, 2)).toString('base64')\\n  }\\n};\\nreturn items;\"},\"typeVersion\":1},{\"id\":\"0765ffcd-4746-45f7-add8-f82d66709321\",\"name\":\"Write the scraped content to disk\",\"type\":\"n8n-nodes-base.readWriteFile\",\"position\":[460,-80],\"parameters\":{\"options\":{},\"fileName\":\"d:\\\\Scraped-Content.json\",\"operation\":\"write\"},\"typeVersion\":1},{\"id\":\"16cd9b48-765d-4f0d-8e78-6c41cfc50b03\",\"name\":\"Sticky Note2\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[-220,-540],\"parameters\":{\"width\":440,\"height\":120,\"content\":\"## Disclaimer\\nThis template is only available on n8n self-hosted as it's making use of the community node for MCP Client.\"},\"typeVersion\":1},{\"id\":\"ff4b9e9c-a0f0-4cdb-ad53-55dc412794fc\",\"name\":\"Sticky Note3\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[-1080,-80],\"parameters\":{\"color\":5,\"width\":480,\"height\":380,\"content\":\"## Note\\nThe AI agent utilizes Bright Data's MCP tools to perform web scraping based on user requests. It intelligently selects the most suitable web scraping tool to fulfill the user's query.\\n\\nOnce the web scraping is complete, the AI agent's response is:\\n\\n1. Used to trigger a webhook call.\\n\\n2. Persisted to disk for future reference.\\n\\nGoogle Gemini is employed by the AI agent to understand and interpret user queries. Based on this interpretation, the agent initiates a call to the appropriate MCP client to perform the required web scraping task.\\n\\nSource - https://github.com/luminati-io/brightdata-mcp\"},\"typeVersion\":1}],\"active\":false,\"pinData\":{},\"settings\":{\"executionOrder\":\"v1\"},\"versionId\":\"ccf9f9af-82d5-4751-b06d-497c043c85fc\",\"connections\":{\"AI Agent\":{\"main\":[[{\"node\":\"Webhook for Web Scraper AI Agent\",\"type\":\"main\",\"index\":0},{\"node\":\"Create a binary data\",\"type\":\"main\",\"index\":0}]]},\"Set the URLs\":{\"main\":[[{\"node\":\"MCP Client Bright Data Web Scraper\",\"type\":\"main\",\"index\":0}]]},\"Simple Memory\":{\"ai_memory\":[[{\"node\":\"AI Agent\",\"type\":\"ai_memory\",\"index\":0}]]},\"Create a binary data\":{\"main\":[[{\"node\":\"Write the scraped content to disk\",\"type\":\"main\",\"index\":0}]]},\"MCP Client List all tools\":{\"ai_tool\":[[{\"node\":\"AI Agent\",\"type\":\"ai_tool\",\"index\":0}]]},\"MCP Client to Scrape as HTML\":{\"ai_tool\":[[{\"node\":\"AI Agent\",\"type\":\"ai_tool\",\"index\":0}]]},\"MCP Client to Scrape as Markdown\":{\"ai_tool\":[[{\"node\":\"AI Agent\",\"type\":\"ai_tool\",\"index\":0}]]},\"Webhook for Web Scraper AI Agent\":{\"main\":[[]]},\"When clicking ‘Test workflow’\":{\"main\":[[{\"node\":\"MCP Client list all tools for Bright Data\",\"type\":\"main\",\"index\":0},{\"node\":\"Set the URL with the Webhook URL and data format\",\"type\":\"main\",\"index\":0}]]},\"MCP Client Bright Data Web Scraper\":{\"main\":[[{\"node\":\"Webhook for web scraper\",\"type\":\"main\",\"index\":0}]]},\"Google Gemini Chat Model for AI Agent\":{\"ai_languageModel\":[[{\"node\":\"AI Agent\",\"type\":\"ai_languageModel\",\"index\":0}]]},\"MCP Client list all tools for Bright Data\":{\"main\":[[{\"node\":\"Set the URLs\",\"type\":\"main\",\"index\":0}]]},\"Set the URL with the Webhook URL and data format\":{\"main\":[[{\"node\":\"AI Agent\",\"type\":\"main\",\"index\":0}]]}}}",
  "readme": "### Disclaimer\n\nThis template is only available on n8n self-hosted as it's making use of the community node for MCP Client.\n\n![Scrape Web Data with Bright Data  MCP Client.png](https://n8niostorageaccount.blob.core.windows.net/n8nio-strapi-blobs-prod/assets/Scrape_Web_Data_with_Bright_Data_and_MCP_Client_cd20e5d6a3.png)\n\n### Who this is for?\n\nThe Scrape Web Data with Bright Data and MCP Automated AI Agent workflow is built for professionals who need to automate large-scale, intelligent data extraction by utilizing the Bright Data MCP Server and Google Gemini.\n\nThis solution is ideal for:\n\n  1. **Data Analysts** \\- Who require structured, enriched datasets for analysis and reporting.\n\n  2. **Marketing Researchers** \\- Seeking fresh market intelligence from dynamic web sources.\n\n  3. **Product Managers** \\- Who want competitive product and feature insights from various websites.\n\n  4. **AI Developers** \\- Aiming to feed web data into downstream machine learning models.\n\n  5. **Growth Hackers** \\- Looking for high-quality data to fuel campaigns, research, or strategic targeting.\n\n\n\n\n### What problem is this workflow solving?\n\nManually scraping websites, cleaning raw HTML data, and generating useful insights from it can be slow, error-prone, and non-scalable.\n\nThis workflow solves these problems by:\n\n  1. Automating complex web data extraction through Bright Data’s MCP Server.\n\n  2. Reducing the human effort needed for cleaning, parsing, and analyzing unstructured web content.\n\n  3. Allowing seamless integration into further automation processes.\n\n\n\n\n### What this workflow does?\n\nThis n8n workflow performs the following steps:\n\n  1. **Trigger** : Start manually.\n\n  2. **Input URL(s)** : Specify the URL to perform the web scrapping.\n\n  3. **Web Scraping (Bright Data)** : Use Bright Data’s MCP Server tools to accomplish the web data scrapping with markdown and html format.\n\n  4. **Store / Output** : Save results into disk and also performs a Webhook notification.\n\n\n\n\n### Setup\n\n  1. Please make sure to setup n8n locally with MCP Servers by navigating to [n8n-nodes-mcp](https://www.youtube.com/watch?v=NUb73ErUCsA)\n  2. Please make sure to install the Bright Data MCP Server [@brightdata/mcp](https://www.npmjs.com/package/@brightdata/mcp) on your local machine.\n  3. Sign up at [Bright Data](https://brightdata.com/).\n  4. Create a Web Unlocker proxy zone called mcp_unlocker on Bright Data control panel.\n  5. Navigate to Proxies & Scraping and create a new Web Unlocker zone by selecting Web Unlocker API under Scraping Solutions.\n  6. In n8n, configure the Google Gemini(PaLM) Api account with the Google Gemini API key (or access through Vertex AI or proxy).\n  7. In n8n, configure the credentials to connect with MCP Client (STDIO) account with the Bright Data MCP Server as shown below.\n\n\n\n![MCPClientAccount.png](https://n8niostorageaccount.blob.core.windows.net/n8nio-strapi-blobs-prod/assets/MCP_Client_Account_d278429c64.png)\n\nMake sure to copy the Bright Data API_TOKEN within the Environments textbox above.  \n8\\. Update the LinkedIn URL person and company workflow.  \n9\\. Update the Webhook HTTP Request node with the Webhook endpoint of your choice.  \n10\\. Update the file name and path to persist on disk.\n\n### How to customize this workflow to your needs\n\n  1. **Different Inputs** : Instead of static URLs, accept URLs dynamically via webhook or form submissions.\n\n  2. **Outputs** : Update the Webhook endpoints to send the response to Slack channels, Airtable, Notion, CRM systems, etc.\n\n\n\n",
  "readme_html": "<!--[--><div data-v-50766329=\"\"><h3>Disclaimer</h3>\n<p>This template is only available on n8n self-hosted as it's making use of the community node for MCP Client.</p>\n<p><img src=\"https://n8niostorageaccount.blob.core.windows.net/n8nio-strapi-blobs-prod/assets/Scrape_Web_Data_with_Bright_Data_and_MCP_Client_cd20e5d6a3.png\" alt=\"Scrape Web Data with Bright Data  MCP Client.png\"></p>\n<h3>Who this is for?</h3>\n<p>The Scrape Web Data with Bright Data and MCP Automated AI Agent workflow is built for professionals who need to automate large-scale, intelligent data extraction by utilizing the Bright Data MCP Server and Google Gemini.</p>\n<p>This solution is ideal for:</p>\n<ol>\n<li>\n<p><strong>Data Analysts</strong> - Who require structured, enriched datasets for analysis and reporting.</p>\n</li>\n<li>\n<p><strong>Marketing Researchers</strong> - Seeking fresh market intelligence from dynamic web sources.</p>\n</li>\n<li>\n<p><strong>Product Managers</strong> - Who want competitive product and feature insights from various websites.</p>\n</li>\n<li>\n<p><strong>AI Developers</strong> - Aiming to feed web data into downstream machine learning models.</p>\n</li>\n<li>\n<p><strong>Growth Hackers</strong> - Looking for high-quality data to fuel campaigns, research, or strategic targeting.</p>\n</li>\n</ol>\n<h3>What problem is this workflow solving?</h3>\n<p>Manually scraping websites, cleaning raw HTML data, and generating useful insights from it can be slow, error-prone, and non-scalable.</p>\n<p>This workflow solves these problems by:</p>\n<ol>\n<li>\n<p>Automating complex web data extraction through Bright Data’s MCP Server.</p>\n</li>\n<li>\n<p>Reducing the human effort needed for cleaning, parsing, and analyzing unstructured web content.</p>\n</li>\n<li>\n<p>Allowing seamless integration into further automation processes.</p>\n</li>\n</ol>\n<h3>What this workflow does?</h3>\n<p>This n8n workflow performs the following steps:</p>\n<ol>\n<li>\n<p><strong>Trigger</strong>: Start manually.</p>\n</li>\n<li>\n<p><strong>Input URL(s)</strong>: Specify the URL to perform the web scrapping.</p>\n</li>\n<li>\n<p><strong>Web Scraping (Bright Data)</strong>: Use Bright Data’s MCP Server tools to accomplish the web data scrapping with markdown and html format.</p>\n</li>\n<li>\n<p><strong>Store / Output</strong>: Save results into disk and also performs a Webhook notification.</p>\n</li>\n</ol>\n<h3>Setup</h3>\n<ol>\n<li>Please make sure to setup n8n locally with MCP Servers by navigating to <a href=\"https://www.youtube.com/watch?v=NUb73ErUCsA\" rel=\"ugc nofollow\" target=\"_blank\">n8n-nodes-mcp</a></li>\n<li>Please make sure to install the Bright Data MCP Server <a href=\"https://www.npmjs.com/package/@brightdata/mcp\" rel=\"ugc nofollow\" target=\"_blank\">@brightdata/mcp</a>  on your local machine.</li>\n<li>Sign up at <a href=\"https://brightdata.com/\" rel=\"ugc nofollow\" target=\"_blank\">Bright Data</a>.</li>\n<li>Create a Web Unlocker proxy zone called mcp_unlocker on Bright Data control panel.</li>\n<li>Navigate to Proxies &amp; Scraping and create a new Web Unlocker zone by selecting Web Unlocker API under Scraping Solutions.</li>\n<li>In n8n, configure the Google Gemini(PaLM) Api account with the Google Gemini API key (or access through Vertex AI or proxy).</li>\n<li>In n8n, configure the credentials to connect with MCP Client (STDIO) account with the Bright Data MCP Server as shown below.</li>\n</ol>\n<p><img src=\"https://n8niostorageaccount.blob.core.windows.net/n8nio-strapi-blobs-prod/assets/MCP_Client_Account_d278429c64.png\" alt=\"MCPClientAccount.png\"></p>\n<p>Make sure to copy the Bright Data API_TOKEN within the Environments textbox above.<br>\n8. Update the LinkedIn URL person and company workflow.<br>\n9. Update the Webhook HTTP Request node with the Webhook endpoint of your choice.<br>\n10. Update the file name and path to persist on disk.</p>\n<h3>How to customize this workflow to your needs</h3>\n<ol>\n<li>\n<p><strong>Different Inputs</strong>: Instead of static URLs, accept URLs dynamically via webhook or form submissions.</p>\n</li>\n<li>\n<p><strong>Outputs</strong>: Update the Webhook endpoints to send the response to Slack channels, Airtable, Notion, CRM systems, etc.</p>\n</li>\n</ol>\n</div><!--]-->",
  "readme_zh": "### Disclaimer\n\nThis template is only available on n8n self-hosted as it's making use of the community node for MCP Client.\n\n![Scrape Web Data with Bright Data  MCP Client.png](https://n8niostorageaccount.blob.core.windows.net/n8nio-strapi-blobs-prod/assets/Scrape_Web_Data_with_Bright_Data_and_MCP_Client_cd20e5d6a3.png)\n\n### Who this is for?\n\nThe Scrape Web Data with Bright Data and MCP Automated AI Agent workflow is built for professionals who need to automate large-scale, intelligent data extraction by utilizing the Bright Data MCP Server and Google Gemini.\n\nThis solution is ideal for:\n\n  1. **Data Analysts** \\- Who require structured, enriched datasets for analysis and reporting.\n\n  2. **Marketing Researchers** \\- Seeking fresh market intelligence from dynamic web sources.\n\n  3. **Product Managers** \\- Who want competitive product and feature insights from various websites.\n\n  4. **AI Developers** \\- Aiming to feed web data into downstream machine learning models.\n\n  5. **Growth Hackers** \\- Looking for high-quality data to fuel campaigns, research, or strategic targeting.\n\n\n\n\n### What problem is this workflow solving?\n\nManually scraping websites, cleaning raw HTML data, and generating useful insights from it can be slow, error-prone, and non-scalable.\n\nThis workflow solves these problems by:\n\n  1. Automating complex web data extraction through Bright Data’s MCP Server.\n\n  2. Reducing the human effort needed for cleaning, parsing, and analyzing unstructured web content.\n\n  3. Allowing seamless integration into further automation processes.\n\n\n\n\n### What this workflow does?\n\nThis n8n workflow performs the following steps:\n\n  1. **Trigger** : Start manually.\n\n  2. **Input URL(s)** : Specify the URL to perform the web scrapping.\n\n  3. **Web Scraping (Bright Data)** : Use Bright Data’s MCP Server tools to accomplish the web data scrapping with markdown and html format.\n\n  4. **Store / Output** : Save results into disk and also performs a Webhook notification.\n\n\n\n\n### Setup\n\n  1. Please make sure to setup n8n locally with MCP Servers by navigating to [n8n-nodes-mcp](https://www.youtube.com/watch?v=NUb73ErUCsA)\n  2. Please make sure to install the Bright Data MCP Server [@brightdata/mcp](https://www.npmjs.com/package/@brightdata/mcp) on your local machine.\n  3. Sign up at [Bright Data](https://brightdata.com/).\n  4. Create a Web Unlocker proxy zone called mcp_unlocker on Bright Data control panel.\n  5. Navigate to Proxies & Scraping and create a new Web Unlocker zone by selecting Web Unlocker API under Scraping Solutions.\n  6. In n8n, configure the Google Gemini(PaLM) Api account with the Google Gemini API key (or access through Vertex AI or proxy).\n  7. In n8n, configure the credentials to connect with MCP Client (STDIO) account with the Bright Data MCP Server as shown below.\n\n\n\n![MCPClientAccount.png](https://n8niostorageaccount.blob.core.windows.net/n8nio-strapi-blobs-prod/assets/MCP_Client_Account_d278429c64.png)\n\nMake sure to copy the Bright Data API_TOKEN within the Environments textbox above.  \n8\\. Update the LinkedIn URL person and company workflow.  \n9\\. Update the Webhook HTTP Request node with the Webhook endpoint of your choice.  \n10\\. Update the file name and path to persist on disk.\n\n### How to customize this workflow to your needs\n\n  1. **Different Inputs** : Instead of static URLs, accept URLs dynamically via webhook or form submissions.\n\n  2. **Outputs** : Update the Webhook endpoints to send the response to Slack channels, Airtable, Notion, CRM systems, etc.\n\n\n\n",
  "title_zh": "使用Bright Data、Google Gemini和MCP自动化AI代理抓取网络数据",
  "publish_date_zh": "最后更新于10小时前",
  "workflow_json_zh": "{\n  \"id\": \"U6cY7PPR0vaRl1I0\",\n  \"meta\": {\n    \"instanceId\": \"885b4fb4a6a9c2cb5621429a7b972df0d05bb724c20ac7dac7171b62f1c7ef40\",\n    \"templateCredsSetupCompleted\": true\n  },\n  \"name\": \"Scrape Web Data with Bright Data, Google Gemini and MCP Automated AI Agent\",\n  \"tags\": [\n    {\n      \"id\": \"ZOwtAMLepQaGW76t\",\n      \"name\": \"Building Blocks\",\n      \"createdAt\": \"2025-04-13T15:23:40.462Z\",\n      \"updatedAt\": \"2025-04-13T15:23:40.462Z\"\n    },\n    {\n      \"id\": \"ddPkw7Hg5dZhQu2w\",\n      \"name\": \"AI\",\n      \"createdAt\": \"2025-04-13T05:38:08.053Z\",\n      \"updatedAt\": \"2025-04-13T05:38:08.053Z\"\n    }\n  ],\n  \"nodes\": [\n    {\n      \"id\": \"0c747f5b-ef72-4e00-a028-4a08461dae28\",\n      \"name\": \"AI Agent\",\n      \"type\": \"@n8n/n8n-nodes-langchain.agent\",\n      \"notes\": \"Bright Data Web Scraping Agent\",\n      \"position\": [\n        -140,\n        60\n      ],\n      \"parameters\": {\n        \"text\": \"=Scrape the web data as per the provided URL:  {{ $json.url }} using the format as {{ $json.format }}\",\n        \"options\": {\n          \"systemMessage\": \"=You are a helpful assistant.\"\n        },\n        \"promptType\": \"define\"\n      },\n      \"notesInFlow\": true,\n      \"typeVersion\": 1.8\n    },\n    {\n      \"id\": \"16c7cd90-39da-47a4-8020-a0aa8f87275a\",\n      \"name\": \"When clicking ‘Test workflow’\",\n      \"type\": \"n8n-nodes-base.manualTrigger\",\n      \"position\": [\n        -640,\n        -300\n      ],\n      \"parameters\": {},\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"7b544505-6b6b-4500-a2ad-f7cf62f98c13\",\n      \"name\": \"MCP Client list all tools for Bright Data\",\n      \"type\": \"n8n-nodes-mcp.mcpClient\",\n      \"position\": [\n        -380,\n        -300\n      ],\n      \"parameters\": {},\n      \"credentials\": {\n        \"mcpClientApi\": {\n          \"id\": \"JtatFSfA2kkwctYa\",\n          \"name\": \"MCP Client (STDIO) account\"\n        }\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"9f5bf319-9414-4974-bad2-ea24f09ae351\",\n      \"name\": \"Sticky Note1\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"position\": [\n        -220,\n        -400\n      ],\n      \"parameters\": {\n        \"color\": 3,\n        \"width\": 440,\n        \"height\": 320,\n        \"content\": \"## 亮数据网络爬虫\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"222e81cf-878e-42de-a325-6b6659145f98\",\n      \"name\": \"MCP Client List all tools\",\n      \"type\": \"n8n-nodes-mcp.mcpClientTool\",\n      \"position\": [\n        440,\n        420\n      ],\n      \"parameters\": {},\n      \"credentials\": {\n        \"mcpClientApi\": {\n          \"id\": \"JtatFSfA2kkwctYa\",\n          \"name\": \"MCP Client (STDIO) account\"\n        }\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"a10dfd4f-cadf-4952-8449-1865406358d4\",\n      \"name\": \"MCP Client Bright Data Web Scraper\",\n      \"type\": \"n8n-nodes-mcp.mcpClient\",\n      \"notes\": \"Scrape a single webpage URL with advanced options for content extraction and get back the results in MarkDown language.\",\n      \"position\": [\n        60,\n        -300\n      ],\n      \"parameters\": {\n        \"toolName\": \"=scrape_as_markdown\",\n        \"operation\": \"executeTool\",\n        \"toolParameters\": \"={\\n   \\\"url\\\": \\\"{{ $json.url }}\\\"\\n} \"\n      },\n      \"credentials\": {\n        \"mcpClientApi\": {\n          \"id\": \"JtatFSfA2kkwctYa\",\n          \"name\": \"MCP Client (STDIO) account\"\n        }\n      },\n      \"notesInFlow\": true,\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"0acbd4ff-ce4a-4ff2-b213-2d80dd91e302\",\n      \"name\": \"Webhook for web scraper\",\n      \"type\": \"n8n-nodes-base.httpRequest\",\n      \"position\": [\n        280,\n        -300\n      ],\n      \"parameters\": {\n        \"url\": \"=https://webhook.site/daf9d591-a130-4010-b1d3-0c66f8fcf467\",\n        \"options\": {},\n        \"sendBody\": true,\n        \"bodyParameters\": {\n          \"parameters\": [\n            {\n              \"name\": \"response\",\n              \"value\": \"={{ $json.result.content[0].text }}\"\n            }\n          ]\n        }\n      },\n      \"typeVersion\": 4.2\n    },\n    {\n      \"id\": \"009ac29f-8cad-4b58-9ca4-e75470a52dcc\",\n      \"name\": \"Set the URLs\",\n      \"type\": \"n8n-nodes-base.set\",\n      \"position\": [\n        -160,\n        -300\n      ],\n      \"parameters\": {\n        \"options\": {},\n        \"assignments\": {\n          \"assignments\": [\n            {\n              \"id\": \"214e61a0-3587-453f-baf5-eac013990857\",\n              \"name\": \"url\",\n              \"type\": \"string\",\n              \"value\": \"https://about.google/\"\n            },\n            {\n              \"id\": \"45014942-0a2e-4f46-b395-f82f97bfa93e\",\n              \"name\": \"webhook_url\",\n              \"type\": \"string\",\n              \"value\": \"https://webhook.site/ce41e056-c097-48c8-a096-9b876d3abbf7\"\n            }\n          ]\n        }\n      },\n      \"typeVersion\": 3.4\n    },\n    {\n      \"id\": \"104706dd-ae58-47fd-8fea-cefa986ae40c\",\n      \"name\": \"MCP Client to Scrape as Markdown\",\n      \"type\": \"n8n-nodes-mcp.mcpClientTool\",\n      \"notes\": \"Scrape a single webpage URL with advanced options for content extraction and get back the results in MarkDown language.\",\n      \"position\": [\n        -60,\n        400\n      ],\n      \"parameters\": {\n        \"toolName\": \"scrape_as_markdown\",\n        \"operation\": \"executeTool\",\n        \"toolParameters\": \"={\\n  \\\"url\\\": \\\"{{ $json.url }}\\\"\\n} \",\n        \"descriptionType\": \"manual\",\n        \"toolDescription\": \"Scrape a single webpage URL with advanced options for content extraction and get back the results in MarkDown language.\"\n      },\n      \"credentials\": {\n        \"mcpClientApi\": {\n          \"id\": \"JtatFSfA2kkwctYa\",\n          \"name\": \"MCP Client (STDIO) account\"\n        }\n      },\n      \"notesInFlow\": false,\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"c03c655e-45c8-4278-a01f-ba48282459c5\",\n      \"name\": \"MCP Client to Scrape as HTML\",\n      \"type\": \"n8n-nodes-mcp.mcpClientTool\",\n      \"notes\": \"Scrape a single webpage URL with advanced options for content extraction and get back the results in HTML.\",\n      \"position\": [\n        200,\n        400\n      ],\n      \"parameters\": {\n        \"toolName\": \"scrape_as_html\",\n        \"operation\": \"executeTool\",\n        \"toolParameters\": \"{\\n  \\\"url\\\": \\\"{{ $json.url }}\\\"\\n} \",\n        \"descriptionType\": \"manual\",\n        \"toolDescription\": \"Scrape a single webpage URL with advanced options for content extraction and get back the results in HTML.\"\n      },\n      \"credentials\": {\n        \"mcpClientApi\": {\n          \"id\": \"JtatFSfA2kkwctYa\",\n          \"name\": \"MCP Client (STDIO) account\"\n        }\n      },\n      \"notesInFlow\": true,\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"587300ff-44e5-4ff2-9dee-a4f8720ca26b\",\n      \"name\": \"Google Gemini Chat Model for AI Agent\",\n      \"type\": \"@n8n/n8n-nodes-langchain.lmChatGoogleGemini\",\n      \"position\": [\n        -520,\n        400\n      ],\n      \"parameters\": {\n        \"options\": {},\n        \"modelName\": \"models/gemini-2.0-flash-exp\"\n      },\n      \"credentials\": {\n        \"googlePalmApi\": {\n          \"id\": \"YeO7dHZnuGBVQKVZ\",\n          \"name\": \"Google Gemini(PaLM) Api account\"\n        }\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"38ba13a1-f8f7-48ce-a05d-2c2526de606d\",\n      \"name\": \"Sticky Note\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"position\": [\n        -140,\n        340\n      ],\n      \"parameters\": {\n        \"color\": 4,\n        \"width\": 480,\n        \"height\": 260,\n        \"content\": \"## 亮数据网络爬虫工具\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"e7c8d333-e256-4944-a584-575162072ca4\",\n      \"name\": \"Simple Memory\",\n      \"type\": \"@n8n/n8n-nodes-langchain.memoryBufferWindow\",\n      \"position\": [\n        -280,\n        400\n      ],\n      \"parameters\": {\n        \"sessionKey\": \"=Perform the web scraping for the below URL\\n\\n{{ $json.url }}\",\n        \"sessionIdType\": \"customKey\",\n        \"contextWindowLength\": 10\n      },\n      \"typeVersion\": 1.3\n    },\n    {\n      \"id\": \"5e89519e-8ee5-4c3b-807d-21cef6e36c32\",\n      \"name\": \"Webhook for Web Scraper AI Agent\",\n      \"type\": \"n8n-nodes-base.httpRequest\",\n      \"position\": [\n        260,\n        120\n      ],\n      \"parameters\": {\n        \"url\": \"={{ $('Set the URL with the Webhook URL and data format').item.json.webhook_url }}\",\n        \"options\": {},\n        \"sendBody\": true,\n        \"bodyParameters\": {\n          \"parameters\": [\n            {\n              \"name\": \"response\",\n              \"value\": \"={{ $json.output }}\"\n            }\n          ]\n        }\n      },\n      \"typeVersion\": 4.2\n    },\n    {\n      \"id\": \"2de093f4-15e5-4710-83d9-e6d9ed852873\",\n      \"name\": \"Set the URL with the Webhook URL and data format\",\n      \"type\": \"n8n-nodes-base.set\",\n      \"position\": [\n        -400,\n        60\n      ],\n      \"parameters\": {\n        \"options\": {},\n        \"assignments\": {\n          \"assignments\": [\n            {\n              \"id\": \"214e61a0-3587-453f-baf5-eac013990857\",\n              \"name\": \"url\",\n              \"type\": \"string\",\n              \"value\": \"https://about.google/\"\n            },\n            {\n              \"id\": \"45014942-0a2e-4f46-b395-f82f97bfa93e\",\n              \"name\": \"webhook_url\",\n              \"type\": \"string\",\n              \"value\": \"https://webhook.site/daf9d591-a130-4010-b1d3-0c66f8fcf467\"\n            },\n            {\n              \"id\": \"7f6c03f6-9fa3-45f9-bf81-243b7106bdac\",\n              \"name\": \"format\",\n              \"type\": \"string\",\n              \"value\": \"scrape_as_markdown\"\n            }\n          ]\n        }\n      },\n      \"typeVersion\": 3.4\n    },\n    {\n      \"id\": \"04a5b11f-1990-440e-be23-2fbcb985dd4a\",\n      \"name\": \"Create a binary data\",\n      \"type\": \"n8n-nodes-base.function\",\n      \"position\": [\n        260,\n        -80\n      ],\n      \"parameters\": {\n        \"functionCode\": \"items[0].binary = {\\n  data: {\\n    data: new Buffer(JSON.stringify(items[0].json, null, 2)).toString('base64')\\n  }\\n};\\nreturn items;\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"0765ffcd-4746-45f7-add8-f82d66709321\",\n      \"name\": \"Write the scraped content to disk\",\n      \"type\": \"n8n-nodes-base.readWriteFile\",\n      \"position\": [\n        460,\n        -80\n      ],\n      \"parameters\": {\n        \"options\": {},\n        \"fileName\": \"d:\\\\Scraped-Content.json\",\n        \"operation\": \"write\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"16cd9b48-765d-4f0d-8e78-6c41cfc50b03\",\n      \"name\": \"Sticky Note2\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"position\": [\n        -220,\n        -540\n      ],\n      \"parameters\": {\n        \"width\": 440,\n        \"height\": 120,\n        \"content\": \"## 免责声明\\n此模板仅适用于n8n自托管版本，因其使用了MCP客户端的社区节点。\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"ff4b9e9c-a0f0-4cdb-ad53-55dc412794fc\",\n      \"name\": \"Sticky Note3\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"position\": [\n        -1080,\n        -80\n      ],\n      \"parameters\": {\n        \"color\": 5,\n        \"width\": 480,\n        \"height\": 380,\n        \"content\": \"## 说明\\n该AI代理利用Bright Data的MCP工具，根据用户请求执行网络爬取任务。它能智能选择最适合的网络爬取工具来满足用户的查询需求。\\n\\n网络爬取完成后，AI代理的响应将：\\n\\n1. 用于触发webhook调用\\n\\n2. 持久化存储至磁盘以供后续参考\\n\\nAI代理通过Google Gemini来理解并解析用户查询。基于此解析结果，代理会调用相应的MCP客户端来执行所需的网络爬取任务。\\n\\n来源 - https://github.com/luminati-io/brightdata-mcp\"\n      },\n      \"typeVersion\": 1\n    }\n  ],\n  \"active\": false,\n  \"pinData\": {},\n  \"settings\": {\n    \"executionOrder\": \"v1\"\n  },\n  \"versionId\": \"ccf9f9af-82d5-4751-b06d-497c043c85fc\",\n  \"connections\": {\n    \"AI Agent\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Webhook for Web Scraper AI Agent\",\n            \"type\": \"main\",\n            \"index\": 0\n          },\n          {\n            \"node\": \"Create a binary data\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Set the URLs\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"MCP Client Bright Data Web Scraper\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Simple Memory\": {\n      \"ai_memory\": [\n        [\n          {\n            \"node\": \"AI Agent\",\n            \"type\": \"ai_memory\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Create a binary data\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Write the scraped content to disk\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"MCP Client List all tools\": {\n      \"ai_tool\": [\n        [\n          {\n            \"node\": \"AI Agent\",\n            \"type\": \"ai_tool\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"MCP Client to Scrape as HTML\": {\n      \"ai_tool\": [\n        [\n          {\n            \"node\": \"AI Agent\",\n            \"type\": \"ai_tool\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"MCP Client to Scrape as Markdown\": {\n      \"ai_tool\": [\n        [\n          {\n            \"node\": \"AI Agent\",\n            \"type\": \"ai_tool\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Webhook for Web Scraper AI Agent\": {\n      \"main\": [\n        []\n      ]\n    },\n    \"When clicking ‘Test workflow’\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"MCP Client list all tools for Bright Data\",\n            \"type\": \"main\",\n            \"index\": 0\n          },\n          {\n            \"node\": \"Set the URL with the Webhook URL and data format\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"MCP Client Bright Data Web Scraper\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Webhook for web scraper\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Google Gemini Chat Model for AI Agent\": {\n      \"ai_languageModel\": [\n        [\n          {\n            \"node\": \"AI Agent\",\n            \"type\": \"ai_languageModel\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"MCP Client list all tools for Bright Data\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Set the URLs\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Set the URL with the Webhook URL and data format\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"AI Agent\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    }\n  }\n}"
}