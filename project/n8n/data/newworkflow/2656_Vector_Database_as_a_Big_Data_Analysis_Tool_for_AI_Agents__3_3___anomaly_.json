{
  "url": "https://n8n.io/workflows/2656-vector-database-as-a-big-data-analysis-tool-for-ai-agents-33-anomaly/",
  "title": "Vector Database as a Big Data Analysis Tool for AI Agents [3/3 - anomaly]",
  "author": "Jenny",
  "publish_date": "Last update 5 months ago",
  "publish_date_absolute": "2024-12-26",
  "categories": [
    {
      "name": "AI"
    },
    {
      "name": "SecOps"
    }
  ],
  "workflow_json": "{\"id\":\"G8jRDBvwsMkkMiLN\",\"meta\":{\"instanceId\":\"205b3bc06c96f2dc835b4f00e1cbf9a937a74eeb3b47c99d0c30b0586dbf85aa\"},\"name\":\"[3/3] Anomaly detection tool (crops dataset)\",\"tags\":[{\"id\":\"spMntyrlE9ydvWFA\",\"name\":\"anomaly-detection\",\"createdAt\":\"2024-12-08T22:05:15.945Z\",\"updatedAt\":\"2024-12-09T12:50:19.287Z\"}],\"nodes\":[{\"id\":\"e01bafec-eb24-44c7-b3c4-a60f91666350\",\"name\":\"Sticky Note1\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[-1200,180],\"parameters\":{\"color\":6,\"width\":400,\"height\":740,\"content\":\"We are working here with crops dataset: \\nExisting (so not anomalies) crops images in dataset are:\\n- 'pearl_millet(bajra)',\\n- 'tobacco-plant',\\n- 'cherry',\\n- 'cotton',\\n- 'banana',\\n- 'cucumber',\\n- 'maize',\\n- 'wheat',\\n- 'clove',\\n- 'jowar',\\n- 'olive-tree',\\n- 'soyabean',\\n- 'coffee-plant',\\n- 'rice',\\n- 'lemon',\\n- 'mustard-oil',\\n- 'vigna-radiati(mung)',\\n- 'coconut',\\n- 'gram',\\n- 'pineapple',\\n- 'sugarcane',\\n- 'sunflower',\\n- 'chilli',\\n- 'fox_nut(makhana)',\\n- 'jute',\\n- 'papaya',\\n- 'tea',\\n- 'cardamom',\\n- 'almond'\\n\"},\"typeVersion\":1},{\"id\":\"b9943781-de1f-4129-9b81-ed836e9ebb11\",\"name\":\"Embed image\",\"type\":\"n8n-nodes-base.httpRequest\",\"position\":[680,60],\"parameters\":{\"url\":\"https://api.voyageai.com/v1/multimodalembeddings\",\"method\":\"POST\",\"options\":{},\"jsonBody\":\"={{\\n{\\n  \\\"inputs\\\": [\\n    {\\n      \\\"content\\\": [\\n        {\\n          \\\"type\\\": \\\"image_url\\\",\\n          \\\"image_url\\\": $('Image URL hardcode').first().json.imageURL\\n        }\\n      ]\\n    }\\n  ],\\n  \\\"model\\\": \\\"voyage-multimodal-3\\\",\\n  \\\"input_type\\\": \\\"document\\\"\\n}\\n}}\",\"sendBody\":true,\"specifyBody\":\"json\",\"authentication\":\"genericCredentialType\",\"genericAuthType\":\"httpHeaderAuth\"},\"credentials\":{\"httpHeaderAuth\":{\"id\":\"Vb0RNVDnIHmgnZOP\",\"name\":\"Voyage API\"}},\"typeVersion\":4.2},{\"id\":\"47b72bc2-4817-48c6-b517-c1328e402468\",\"name\":\"Get similarity of medoids\",\"type\":\"n8n-nodes-base.httpRequest\",\"position\":[940,60],\"parameters\":{\"url\":\"={{ $('Variables for medoids').first().json.qdrantCloudURL }}/collections/{{ $('Variables for medoids').first().json.collectionName }}/points/query\",\"method\":\"POST\",\"options\":{},\"jsonBody\":\"={{\\n{\\n  \\\"query\\\": $json.data[0].embedding,\\n  \\\"using\\\": \\\"voyage\\\",\\n  \\\"limit\\\": $('Info About Crop Labeled Clusters').first().json.cropsNumber,\\n  \\\"with_payload\\\": true,\\n  \\\"filter\\\": {\\n      \\\"must\\\": [\\n          {      \\n          \\\"key\\\": $('Variables for medoids').first().json.clusterCenterType,\\n          \\\"match\\\": {\\n              \\\"value\\\": true\\n              }\\n          }\\n      ]\\n  }\\n}\\n}}\",\"sendBody\":true,\"specifyBody\":\"json\",\"authentication\":\"predefinedCredentialType\",\"nodeCredentialType\":\"qdrantApi\"},\"credentials\":{\"qdrantApi\":{\"id\":\"it3j3hP9FICqhgX6\",\"name\":\"QdrantApi account\"}},\"typeVersion\":4.2},{\"id\":\"42d7eb27-ec38-4406-b5c4-27eb45358e93\",\"name\":\"Compare scores\",\"type\":\"n8n-nodes-base.code\",\"position\":[1140,60],\"parameters\":{\"language\":\"python\",\"pythonCode\":\"points = _input.first()['json']['result']['points']\\nthreshold_type = _('Variables for medoids').first()['json']['clusterThresholdCenterType']\\n\\nmax_score = -1\\ncrop_with_max_score = None\\nundefined = True\\n\\nfor center in points:\\n    if center['score'] >= center['payload'][threshold_type]:\\n        undefined = False\\n        if center['score'] > max_score:\\n            max_score = center['score']\\n            crop_with_max_score = center['payload']['crop_name']\\n\\nif undefined:\\n    result_message = \\\"ALERT, we might have a new undefined crop!\\\"\\nelse:\\n    result_message = f\\\"Looks similar to {crop_with_max_score}\\\"\\n\\nreturn [{\\n    \\\"json\\\": {\\n        \\\"result\\\": result_message\\n    }\\n}]\\n\"},\"typeVersion\":2},{\"id\":\"23aa604a-ff0b-4948-bcd5-af39300198c0\",\"name\":\"Sticky Note4\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[-1200,-220],\"parameters\":{\"width\":400,\"height\":380,\"content\":\"## Crop Anomaly Detection Tool\\n### This is the tool that can be used directly for anomalous crops detection. \\nIt takes as input (any) **image URL** and returns a **text message** telling if whatever this image depicts is anomalous to the crop dataset stored in Qdrant. \\n\\n* An Image URL is received via the Execute Workflow Trigger which is used to generate embedding vectors via the Voyage.ai Embeddings API.\\n* The returned vectors are used to query the Qdrant collection to determine if the given crop is known by comparing it to **threshold scores** of each image class (crop type).\\n* If the image scores lower than all thresholds, then the image is considered an anomaly for the dataset.\"},\"typeVersion\":1},{\"id\":\"3a79eca2-44f9-4aee-8a0d-9c7ca2f9149d\",\"name\":\"Variables for medoids\",\"type\":\"n8n-nodes-base.set\",\"position\":[-200,60],\"parameters\":{\"options\":{},\"assignments\":{\"assignments\":[{\"id\":\"dbbc1e7b-c63e-4ff1-9524-8ef3e9f6cd48\",\"name\":\"clusterCenterType\",\"type\":\"string\",\"value\":\"is_medoid\"},{\"id\":\"a994ce37-2530-4030-acfb-ec777a7ddb05\",\"name\":\"qdrantCloudURL\",\"type\":\"string\",\"value\":\"https://152bc6e2-832a-415c-a1aa-fb529f8baf8d.eu-central-1-0.aws.cloud.qdrant.io\"},{\"id\":\"12f0a9e6-686d-416e-a61b-72d034ec21ba\",\"name\":\"collectionName\",\"type\":\"string\",\"value\":\"=agricultural-crops\"},{\"id\":\"4c88a617-d44f-4776-b457-8a1dffb1d03c\",\"name\":\"clusterThresholdCenterType\",\"type\":\"string\",\"value\":\"is_medoid_cluster_threshold\"}]}},\"typeVersion\":3.4},{\"id\":\"13b25434-bd66-4293-93f1-26c67b9ec7dd\",\"name\":\"Sticky Note3\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[-340,260],\"parameters\":{\"color\":6,\"width\":360,\"height\":200,\"content\":\"**clusterCenterType** - either\\n* \\\"is_text_anchor_medoid\\\" or\\n* \\\"is_medoid\\\"\\n\\n\\n**clusterThresholdCenterType** - either\\n* \\\"is_text_anchor_medoid_cluster_threshold\\\" or\\n* \\\"is_medoid_cluster_threshold\\\"\"},\"typeVersion\":1},{\"id\":\"869b0962-6cae-487d-8230-539a0cc4c14c\",\"name\":\"Info About Crop Labeled Clusters\",\"type\":\"n8n-nodes-base.set\",\"position\":[440,60],\"parameters\":{\"options\":{},\"assignments\":{\"assignments\":[{\"id\":\"5327b254-b703-4a34-a398-f82edb1d6d6b\",\"name\":\"=cropsNumber\",\"type\":\"number\",\"value\":\"={{ $json.result.hits.length }}\"}]}},\"typeVersion\":3.4},{\"id\":\"5d3956f8-f43b-439e-b176-a594a21d8011\",\"name\":\"Total Points in Collection\",\"type\":\"n8n-nodes-base.httpRequest\",\"position\":[40,60],\"parameters\":{\"url\":\"={{ $json.qdrantCloudURL }}/collections/{{ $json.collectionName }}/points/count\",\"method\":\"POST\",\"options\":{},\"jsonBody\":\"={\\n  \\\"exact\\\": true\\n}\",\"sendBody\":true,\"specifyBody\":\"json\",\"authentication\":\"predefinedCredentialType\",\"nodeCredentialType\":\"qdrantApi\"},\"credentials\":{\"qdrantApi\":{\"id\":\"it3j3hP9FICqhgX6\",\"name\":\"QdrantApi account\"}},\"typeVersion\":4.2},{\"id\":\"14ba3db9-3965-4b20-b333-145616d45c3a\",\"name\":\"Each Crop Counts\",\"type\":\"n8n-nodes-base.httpRequest\",\"position\":[240,60],\"parameters\":{\"url\":\"={{ $('Variables for medoids').first().json.qdrantCloudURL }}/collections/{{ $('Variables for medoids').first().json.collectionName }}/facet\",\"method\":\"POST\",\"options\":{},\"jsonBody\":\"={{\\n{\\n  \\\"key\\\": \\\"crop_name\\\",\\n  \\\"limit\\\": $json.result.count,\\n  \\\"exact\\\": true\\n}\\n}}\",\"sendBody\":true,\"specifyBody\":\"json\",\"authentication\":\"predefinedCredentialType\",\"nodeCredentialType\":\"qdrantApi\"},\"credentials\":{\"qdrantApi\":{\"id\":\"it3j3hP9FICqhgX6\",\"name\":\"QdrantApi account\"}},\"typeVersion\":4.2},{\"id\":\"e37c6758-0556-4a56-ab14-d4df663cb53a\",\"name\":\"Image URL hardcode\",\"type\":\"n8n-nodes-base.set\",\"position\":[-480,60],\"parameters\":{\"options\":{},\"assignments\":{\"assignments\":[{\"id\":\"46ceba40-fb25-450c-8550-d43d8b8aa94c\",\"name\":\"imageURL\",\"type\":\"string\",\"value\":\"={{ $json.query.imageURL }}\"}]}},\"typeVersion\":3.4},{\"id\":\"b24ad1a7-0cf8-4acc-9c18-6fe9d58b10f2\",\"name\":\"Execute Workflow Trigger\",\"type\":\"n8n-nodes-base.executeWorkflowTrigger\",\"position\":[-720,60],\"parameters\":{},\"typeVersion\":1},{\"id\":\"50424f2b-6831-41bf-8de4-81f69d901ce1\",\"name\":\"Sticky Note2\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[-240,-80],\"parameters\":{\"width\":180,\"height\":120,\"content\":\"Variables to access Qdrant's collection we uploaded & prepared for  anomaly detection in 2 previous pipelines\\n\"},\"typeVersion\":1},{\"id\":\"2e8ed3ca-1bba-4214-b34b-376a237842ff\",\"name\":\"Sticky Note5\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[40,-120],\"parameters\":{\"width\":560,\"height\":140,\"content\":\"These three nodes are needed just to figure out how many different classes (crops) we have in our Qdrant collection: **cropsNumber** (needed in *\\\"Get similarity of medoids\\\"* node. \\n[Note] *\\\"Total Points in Collection\\\"* -> *\\\"Each Crop Counts\\\"* were used&explained already in *\\\"[2/4] Set up medoids (2 types) for anomaly detection (crops dataset)\\\"* pipeline.\\n\"},\"typeVersion\":1},{\"id\":\"e2fa5763-6e97-4ff5-8919-1cb85a3c6968\",\"name\":\"Sticky Note6\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[620,240],\"parameters\":{\"height\":120,\"content\":\"Here, we're embedding the image passed to this workflow tool with the Voyage embedding model to compare the image to all crop images in the database.\"},\"typeVersion\":1},{\"id\":\"cdb6b8d3-f7f4-4d66-850f-ce16c8ed98b9\",\"name\":\"Sticky Note7\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[920,220],\"parameters\":{\"width\":400,\"height\":180,\"content\":\"Checking how similar the image is to all the centres of clusters (crops).\\nIf it's more similar to the thresholds we set up and stored in centres in the previous workflow, the image probably belongs to this crop class; otherwise, it's anomalous to the class. \\nIf image is anomalous to all the classes, it's an anomaly.\"},\"typeVersion\":1},{\"id\":\"03b4699f-ba43-4f5f-ad69-6f81deea2641\",\"name\":\"Sticky Note22\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[-620,580],\"parameters\":{\"color\":4,\"width\":540,\"height\":300,\"content\":\"### For anomaly detection\\n1. The first pipeline is uploading (crops) dataset to Qdrant's collection.\\n2. The second pipeline sets up cluster (class) centres in this Qdrant collection & cluster (class) threshold scores.\\n3. **This is the anomaly detection tool, which takes any image as input and uses all preparatory work done with Qdrant (crops) collection.**\\n\\n### To recreate it\\nYou'll have to upload [crops](https://www.kaggle.com/datasets/mdwaquarazam/agricultural-crops-image-classification) dataset from Kaggle to your own Google Storage bucket, and re-create APIs/connections to [Qdrant Cloud](https://qdrant.tech/documentation/quickstart-cloud/) (you can use **Free Tier** cluster), Voyage AI API & Google Cloud Storage\\n\\n**In general, pipelines are adaptable to any dataset of images**\\n\"},\"typeVersion\":1}],\"active\":false,\"pinData\":{\"Execute Workflow Trigger\":[{\"json\":{\"query\":{\"imageURL\":\"https://storage.googleapis.com/n8n-qdrant-demo/agricultural-crops%2Fcotton%2Fimage%20(36).jpg\"}}}]},\"settings\":{\"executionOrder\":\"v1\"},\"versionId\":\"f67b764b-9e1a-4db0-b9f2-490077a62f74\",\"connections\":{\"Embed image\":{\"main\":[[{\"node\":\"Get similarity of medoids\",\"type\":\"main\",\"index\":0}]]},\"Each Crop Counts\":{\"main\":[[{\"node\":\"Info About Crop Labeled Clusters\",\"type\":\"main\",\"index\":0}]]},\"Image URL hardcode\":{\"main\":[[{\"node\":\"Variables for medoids\",\"type\":\"main\",\"index\":0}]]},\"Variables for medoids\":{\"main\":[[{\"node\":\"Total Points in Collection\",\"type\":\"main\",\"index\":0}]]},\"Execute Workflow Trigger\":{\"main\":[[{\"node\":\"Image URL hardcode\",\"type\":\"main\",\"index\":0}]]},\"Get similarity of medoids\":{\"main\":[[{\"node\":\"Compare scores\",\"type\":\"main\",\"index\":0}]]},\"Total Points in Collection\":{\"main\":[[{\"node\":\"Each Crop Counts\",\"type\":\"main\",\"index\":0}]]},\"Info About Crop Labeled Clusters\":{\"main\":[[{\"node\":\"Embed image\",\"type\":\"main\",\"index\":0}]]}}}",
  "readme": "# Vector Database as a Big Data Analysis Tool for AI Agents\n\nWorkflows from the webinar [\"Build production-ready AI Agents with Qdrant and n8n\"](https://www.youtube.com/watch?v=_BQTnXpuH-E).\n\nThis series of workflows shows how to build big data analysis tools for production-ready AI agents with the help of vector databases. These pipelines are adaptable to any dataset of images, hence, many production use cases.\n\n  1. [Uploading (image) datasets to Qdrant](https://n8n.io/workflows/2654-uploading-image-datasets-to-qdrant-13-anomaly12-knn/)\n  2. [Set up meta-variables for anomaly detection in Qdrant](https://n8n.io/workflows/2655-set-up-cluster-centresandthresholds-for-anomaly-detection-23-anomaly/)\n  3. **[Anomaly detection tool](https://n8n.io/workflows/2656-anomaly-images-detection-tool-33-anomaly/)**\n  4. [KNN classifier tool](https://n8n.io/workflows/2657-knn-images-classifier-tool-22-knn/)\n\n\n\n### For anomaly detection\n\n  1. The first pipeline to upload an image dataset to Qdrant.\n  2. The second pipeline is to set up cluster (class) centres & cluster (class) threshold scores needed for anomaly detection.  \n**3\\. This is the third pipeline --- the anomaly detection tool, which takes any image as input and uses all preparatory work done with Qdrant to detect if it's an anomaly to the uploaded dataset.**\n\n\n\n### For KNN (k nearest neighbours) classification\n\n  1. The first pipeline to upload an image dataset to Qdrant.\n  2. The second is the KNN classifier tool, which takes any image as input and classifies it on the uploaded to Qdrant dataset.\n\n\n\n### To recreate both\n\nYou'll have to upload [crops](https://www.kaggle.com/datasets/mdwaquarazam/agricultural-crops-image-classification) and [lands](https://www.kaggle.com/datasets/apollo2506/landuse-scene-classification) datasets from Kaggle to your own Google Storage bucket, and re-create APIs/connections to [Qdrant Cloud](https://qdrant.tech/documentation/quickstart-cloud/) (you can use [Free Tier](https://cloud.qdrant.io/login) cluster), [Voyage AI API](https://www.voyageai.com/) & Google Cloud Storage.\n\n## [This workflow] Anomaly Detection Tool\n\nThis is the tool that can be used directly for anomalous images (crops) detection.  \nIt takes as input (any) **image URL** and returns a **text message** telling if whatever this image depicts is anomalous to the crop dataset stored in Qdrant.\n\n  * An Image URL is received via the _Execute Workflow Trigger_ , which is used to generate embedding vectors using the Voyage AI Embeddings API.\n  * The returned vectors are used to query the Qdrant collection to determine if the given crop is known by comparing it to **threshold scores** of each image class (crop type).\n  * If the image scores lower than all thresholds, then the image is considered an anomaly for the dataset.\n\n\n",
  "crawled_at": "2025-05-26T01:37:15.131531",
  "readme_zh": "# 向量数据库作为AI代理的大数据分析工具\n\n来自网络研讨会[\"使用Qdrant和n8n构建生产级AI代理\"](https://www.youtube.com/watch?v=_BQTnXpuH-E)的工作流程。\n\n本系列工作流程展示了如何借助向量数据库为生产级AI代理构建大数据分析工具。这些管道适用于任何图像数据集，因此可应用于众多生产场景。\n\n  1. [将（图像）数据集上传至Qdrant](https://n8n.io/workflows/2654-uploading-image-datasets-to-qdrant-13-anomaly12-knn/)\n  2. [在Qdrant中设置异常检测的元变量](https://n8n.io/workflows/2655-set-up-cluster-centresandthresholds-for-anomaly-detection-23-anomaly/)\n  3. **[异常检测工具](https://n8n.io/workflows/2656-anomaly-images-detection-tool-33-anomaly/)**\n  4. [KNN分类器工具](https://n8n.io/workflows/2657-knn-images-classifier-tool-22-knn/)",
  "title_zh": "向量数据库作为AI代理的大数据分析工具 [3/3 - 异常检测]",
  "publish_date_zh": "最后更新于4个月前",
  "workflow_json_zh": "{\n  \"id\": \"G8jRDBvwsMkkMiLN\",\n  \"meta\": {\n    \"instanceId\": \"205b3bc06c96f2dc835b4f00e1cbf9a937a74eeb3b47c99d0c30b0586dbf85aa\"\n  },\n  \"name\": \"[3/3] Anomaly detection tool (crops dataset)\",\n  \"tags\": [\n    {\n      \"id\": \"spMntyrlE9ydvWFA\",\n      \"name\": \"anomaly-detection\",\n      \"createdAt\": \"2024-12-08T22:05:15.945Z\",\n      \"updatedAt\": \"2024-12-09T12:50:19.287Z\"\n    }\n  ],\n  \"nodes\": [\n    {\n      \"id\": \"e01bafec-eb24-44c7-b3c4-a60f91666350\",\n      \"name\": \"Sticky Note1\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"position\": [\n        -1200,\n        180\n      ],\n      \"parameters\": {\n        \"color\": 6,\n        \"width\": 400,\n        \"height\": 740,\n        \"content\": \"我们在此使用的是农作物数据集：  \\n数据集中现有的（非异常）农作物图像包括：  \\n- '珍珠粟（印度小米）',  \\n- '烟草',  \\n- '樱桃',  \\n- '棉花',  \\n- '香蕉',  \\n- '黄瓜',  \\n- '玉米',  \\n- '小麦',  \\n- '丁香',  \\n- '高粱',  \\n- '橄榄树',  \\n- '大豆',  \\n- '咖啡树',  \\n- '水稻',  \\n- '柠檬',  \\n- '芥菜籽',  \\n- '绿豆',  \\n- '椰子',  \\n- '鹰嘴豆',  \\n- '菠萝',  \\n- '甘蔗',  \\n- '向日葵',  \\n- '辣椒',  \\n- '芡实（玛卡纳）',  \\n- '黄麻',  \\n- '木瓜',  \\n- '茶树',  \\n- '豆蔻',  \\n- '杏仁'\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"b9943781-de1f-4129-9b81-ed836e9ebb11\",\n      \"name\": \"Embed image\",\n      \"type\": \"n8n-nodes-base.httpRequest\",\n      \"position\": [\n        680,\n        60\n      ],\n      \"parameters\": {\n        \"url\": \"https://api.voyageai.com/v1/multimodalembeddings\",\n        \"method\": \"POST\",\n        \"options\": {},\n        \"jsonBody\": \"={{\\n{\\n  \\\"inputs\\\": [\\n    {\\n      \\\"content\\\": [\\n        {\\n          \\\"type\\\": \\\"image_url\\\",\\n          \\\"image_url\\\": $('Image URL hardcode').first().json.imageURL\\n        }\\n      ]\\n    }\\n  ],\\n  \\\"model\\\": \\\"voyage-multimodal-3\\\",\\n  \\\"input_type\\\": \\\"document\\\"\\n}\\n}}\",\n        \"sendBody\": true,\n        \"specifyBody\": \"json\",\n        \"authentication\": \"genericCredentialType\",\n        \"genericAuthType\": \"httpHeaderAuth\"\n      },\n      \"credentials\": {\n        \"httpHeaderAuth\": {\n          \"id\": \"Vb0RNVDnIHmgnZOP\",\n          \"name\": \"Voyage API\"\n        }\n      },\n      \"typeVersion\": 4.2\n    },\n    {\n      \"id\": \"47b72bc2-4817-48c6-b517-c1328e402468\",\n      \"name\": \"Get similarity of medoids\",\n      \"type\": \"n8n-nodes-base.httpRequest\",\n      \"position\": [\n        940,\n        60\n      ],\n      \"parameters\": {\n        \"url\": \"={{ $('Variables for medoids').first().json.qdrantCloudURL }}/collections/{{ $('Variables for medoids').first().json.collectionName }}/points/query\",\n        \"method\": \"POST\",\n        \"options\": {},\n        \"jsonBody\": \"={{\\n{\\n  \\\"query\\\": $json.data[0].embedding,\\n  \\\"using\\\": \\\"voyage\\\",\\n  \\\"limit\\\": $('Info About Crop Labeled Clusters').first().json.cropsNumber,\\n  \\\"with_payload\\\": true,\\n  \\\"filter\\\": {\\n      \\\"must\\\": [\\n          {      \\n          \\\"key\\\": $('Variables for medoids').first().json.clusterCenterType,\\n          \\\"match\\\": {\\n              \\\"value\\\": true\\n              }\\n          }\\n      ]\\n  }\\n}\\n}}\",\n        \"sendBody\": true,\n        \"specifyBody\": \"json\",\n        \"authentication\": \"predefinedCredentialType\",\n        \"nodeCredentialType\": \"qdrantApi\"\n      },\n      \"credentials\": {\n        \"qdrantApi\": {\n          \"id\": \"it3j3hP9FICqhgX6\",\n          \"name\": \"QdrantApi account\"\n        }\n      },\n      \"typeVersion\": 4.2\n    },\n    {\n      \"id\": \"42d7eb27-ec38-4406-b5c4-27eb45358e93\",\n      \"name\": \"Compare scores\",\n      \"type\": \"n8n-nodes-base.code\",\n      \"position\": [\n        1140,\n        60\n      ],\n      \"parameters\": {\n        \"language\": \"python\",\n        \"pythonCode\": \"points = _input.first()['json']['result']['points']\\nthreshold_type = _('Variables for medoids').first()['json']['clusterThresholdCenterType']\\n\\nmax_score = -1\\ncrop_with_max_score = None\\nundefined = True\\n\\nfor center in points:\\n    if center['score'] >= center['payload'][threshold_type]:\\n        undefined = False\\n        if center['score'] > max_score:\\n            max_score = center['score']\\n            crop_with_max_score = center['payload']['crop_name']\\n\\nif undefined:\\n    result_message = \\\"ALERT, we might have a new undefined crop!\\\"\\nelse:\\n    result_message = f\\\"Looks similar to {crop_with_max_score}\\\"\\n\\nreturn [{\\n    \\\"json\\\": {\\n        \\\"result\\\": result_message\\n    }\\n}]\\n\"\n      },\n      \"typeVersion\": 2\n    },\n    {\n      \"id\": \"23aa604a-ff0b-4948-bcd5-af39300198c0\",\n      \"name\": \"Sticky Note4\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"position\": [\n        -1200,\n        -220\n      ],\n      \"parameters\": {\n        \"width\": 400,\n        \"height\": 380,\n        \"content\": \"## 作物异常检测工具\\n### 本工具可直接用于异常作物检测\\n该工具接收**任意图片URL**作为输入，并返回**文本信息**，告知该图片内容是否与存储在Qdrant中的作物数据集存在异常。\\n\\n* 通过\\\"执行工作流触发器\\\"接收图片URL，随后使用Voyage.ai嵌入API生成向量表征\\n* 返回的向量将用于查询Qdrant数据库，通过比对每类作物（作物类型）的**阈值分数**来判断该作物是否已知\\n* 若图片得分低于所有类别阈值，则判定该图片内容对当前数据集属于异常情况\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"3a79eca2-44f9-4aee-8a0d-9c7ca2f9149d\",\n      \"name\": \"Variables for medoids\",\n      \"type\": \"n8n-nodes-base.set\",\n      \"position\": [\n        -200,\n        60\n      ],\n      \"parameters\": {\n        \"options\": {},\n        \"assignments\": {\n          \"assignments\": [\n            {\n              \"id\": \"dbbc1e7b-c63e-4ff1-9524-8ef3e9f6cd48\",\n              \"name\": \"clusterCenterType\",\n              \"type\": \"string\",\n              \"value\": \"is_medoid\"\n            },\n            {\n              \"id\": \"a994ce37-2530-4030-acfb-ec777a7ddb05\",\n              \"name\": \"qdrantCloudURL\",\n              \"type\": \"string\",\n              \"value\": \"https://152bc6e2-832a-415c-a1aa-fb529f8baf8d.eu-central-1-0.aws.cloud.qdrant.io\"\n            },\n            {\n              \"id\": \"12f0a9e6-686d-416e-a61b-72d034ec21ba\",\n              \"name\": \"collectionName\",\n              \"type\": \"string\",\n              \"value\": \"=agricultural-crops\"\n            },\n            {\n              \"id\": \"4c88a617-d44f-4776-b457-8a1dffb1d03c\",\n              \"name\": \"clusterThresholdCenterType\",\n              \"type\": \"string\",\n              \"value\": \"is_medoid_cluster_threshold\"\n            }\n          ]\n        }\n      },\n      \"typeVersion\": 3.4\n    },\n    {\n      \"id\": \"13b25434-bd66-4293-93f1-26c67b9ec7dd\",\n      \"name\": \"Sticky Note3\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"position\": [\n        -340,\n        260\n      ],\n      \"parameters\": {\n        \"color\": 6,\n        \"width\": 360,\n        \"height\": 200,\n        \"content\": \"**clusterCenterType** - 可选值为\\n* \\\"is_text_anchor_medoid\\\" 或\\n* \\\"is_medoid\\\"\\n\\n\\n**clusterThresholdCenterType** - 可选值为\\n* \\\"is_text_anchor_medoid_cluster_threshold\\\" 或\\n* \\\"is_medoid_cluster_threshold\\\"\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"869b0962-6cae-487d-8230-539a0cc4c14c\",\n      \"name\": \"Info About Crop Labeled Clusters\",\n      \"type\": \"n8n-nodes-base.set\",\n      \"position\": [\n        440,\n        60\n      ],\n      \"parameters\": {\n        \"options\": {},\n        \"assignments\": {\n          \"assignments\": [\n            {\n              \"id\": \"5327b254-b703-4a34-a398-f82edb1d6d6b\",\n              \"name\": \"=cropsNumber\",\n              \"type\": \"number\",\n              \"value\": \"={{ $json.result.hits.length }}\"\n            }\n          ]\n        }\n      },\n      \"typeVersion\": 3.4\n    },\n    {\n      \"id\": \"5d3956f8-f43b-439e-b176-a594a21d8011\",\n      \"name\": \"Total Points in Collection\",\n      \"type\": \"n8n-nodes-base.httpRequest\",\n      \"position\": [\n        40,\n        60\n      ],\n      \"parameters\": {\n        \"url\": \"={{ $json.qdrantCloudURL }}/collections/{{ $json.collectionName }}/points/count\",\n        \"method\": \"POST\",\n        \"options\": {},\n        \"jsonBody\": \"={\\n  \\\"exact\\\": true\\n}\",\n        \"sendBody\": true,\n        \"specifyBody\": \"json\",\n        \"authentication\": \"predefinedCredentialType\",\n        \"nodeCredentialType\": \"qdrantApi\"\n      },\n      \"credentials\": {\n        \"qdrantApi\": {\n          \"id\": \"it3j3hP9FICqhgX6\",\n          \"name\": \"QdrantApi account\"\n        }\n      },\n      \"typeVersion\": 4.2\n    },\n    {\n      \"id\": \"14ba3db9-3965-4b20-b333-145616d45c3a\",\n      \"name\": \"Each Crop Counts\",\n      \"type\": \"n8n-nodes-base.httpRequest\",\n      \"position\": [\n        240,\n        60\n      ],\n      \"parameters\": {\n        \"url\": \"={{ $('Variables for medoids').first().json.qdrantCloudURL }}/collections/{{ $('Variables for medoids').first().json.collectionName }}/facet\",\n        \"method\": \"POST\",\n        \"options\": {},\n        \"jsonBody\": \"={{\\n{\\n  \\\"key\\\": \\\"crop_name\\\",\\n  \\\"limit\\\": $json.result.count,\\n  \\\"exact\\\": true\\n}\\n}}\",\n        \"sendBody\": true,\n        \"specifyBody\": \"json\",\n        \"authentication\": \"predefinedCredentialType\",\n        \"nodeCredentialType\": \"qdrantApi\"\n      },\n      \"credentials\": {\n        \"qdrantApi\": {\n          \"id\": \"it3j3hP9FICqhgX6\",\n          \"name\": \"QdrantApi account\"\n        }\n      },\n      \"typeVersion\": 4.2\n    },\n    {\n      \"id\": \"e37c6758-0556-4a56-ab14-d4df663cb53a\",\n      \"name\": \"Image URL hardcode\",\n      \"type\": \"n8n-nodes-base.set\",\n      \"position\": [\n        -480,\n        60\n      ],\n      \"parameters\": {\n        \"options\": {},\n        \"assignments\": {\n          \"assignments\": [\n            {\n              \"id\": \"46ceba40-fb25-450c-8550-d43d8b8aa94c\",\n              \"name\": \"imageURL\",\n              \"type\": \"string\",\n              \"value\": \"={{ $json.query.imageURL }}\"\n            }\n          ]\n        }\n      },\n      \"typeVersion\": 3.4\n    },\n    {\n      \"id\": \"b24ad1a7-0cf8-4acc-9c18-6fe9d58b10f2\",\n      \"name\": \"Execute Workflow Trigger\",\n      \"type\": \"n8n-nodes-base.executeWorkflowTrigger\",\n      \"position\": [\n        -720,\n        60\n      ],\n      \"parameters\": {},\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"50424f2b-6831-41bf-8de4-81f69d901ce1\",\n      \"name\": \"Sticky Note2\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"position\": [\n        -240,\n        -80\n      ],\n      \"parameters\": {\n        \"width\": 180,\n        \"height\": 120,\n        \"content\": \"用于访问我们在前两个流程中上传并准备用于异常检测的Qdrant集合的变量\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"2e8ed3ca-1bba-4214-b34b-376a237842ff\",\n      \"name\": \"Sticky Note5\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"position\": [\n        40,\n        -120\n      ],\n      \"parameters\": {\n        \"width\": 560,\n        \"height\": 140,\n        \"content\": \"这三个节点的作用仅在于确定我们的Qdrant集合中有多少不同的类别（作物）：**cropsNumber**（在*“获取质心相似度”*节点中需要使用）。  \\n[注] *“集合中的总点数”* -> *“每类作物计数”* 已在 *“[2/4] 设置异常检测质心（两种类型）（作物数据集）”* 流程中使用并解释过。\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"e2fa5763-6e97-4ff5-8919-1cb85a3c6968\",\n      \"name\": \"Sticky Note6\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"position\": [\n        620,\n        240\n      ],\n      \"parameters\": {\n        \"height\": 120,\n        \"content\": \"在此，我们利用Voyage嵌入模型对传入此工作流工具的图像进行编码，以便将其与数据库中所有作物图像进行比对。\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"cdb6b8d3-f7f4-4d66-850f-ce16c8ed98b9\",\n      \"name\": \"Sticky Note7\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"position\": [\n        920,\n        220\n      ],\n      \"parameters\": {\n        \"width\": 400,\n        \"height\": 180,\n        \"content\": \"检测图像与所有聚类中心（作物类别）的相似度。\\n若其相似度超过预设并存储于先前工作流程聚类中心的阈值，则该图像可能属于此作物类别；反之，则对该类别表现为异常。\\n若图像对所有类别均表现异常，则判定为异常样本。\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"03b4699f-ba43-4f5f-ad69-6f81deea2641\",\n      \"name\": \"Sticky Note22\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"position\": [\n        -620,\n        580\n      ],\n      \"parameters\": {\n        \"color\": 4,\n        \"width\": 540,\n        \"height\": 300,\n        \"content\": \"### 用于异常检测\\n1. 第一流程是将（作物）数据集上传至Qdrant集合\\n2. 第二流程是在该Qdrant集合中建立聚类（类别）中心点及聚类（类别）阈值分数\\n3. **此为异常检测工具，可接收任意图像输入，并利用Qdrant（作物）集合中已完成的所有准备工作**\\n\\n### 重建步骤\\n需将Kaggle上的[作物数据集](https://www.kaggle.com/datasets/mdwaquarazam/agricultural-crops-image-classification)上传至您的Google存储桶，并重新建立与[Qdrant云服务](https://qdrant.tech/documentation/quickstart-cloud/)（可使用**免费版**集群）、Voyage AI接口及Google云存储的连接\\n\\n**总体而言，这些流程可适配任何图像数据集**\"\n      },\n      \"typeVersion\": 1\n    }\n  ],\n  \"active\": false,\n  \"pinData\": {\n    \"Execute Workflow Trigger\": [\n      {\n        \"json\": {\n          \"query\": {\n            \"imageURL\": \"https://storage.googleapis.com/n8n-qdrant-demo/agricultural-crops%2Fcotton%2Fimage%20(36).jpg\"\n          }\n        }\n      }\n    ]\n  },\n  \"settings\": {\n    \"executionOrder\": \"v1\"\n  },\n  \"versionId\": \"f67b764b-9e1a-4db0-b9f2-490077a62f74\",\n  \"connections\": {\n    \"Embed image\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Get similarity of medoids\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Each Crop Counts\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Info About Crop Labeled Clusters\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Image URL hardcode\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Variables for medoids\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Variables for medoids\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Total Points in Collection\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Execute Workflow Trigger\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Image URL hardcode\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Get similarity of medoids\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Compare scores\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Total Points in Collection\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Each Crop Counts\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Info About Crop Labeled Clusters\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Embed image\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    }\n  }\n}"
}