{
  "url": "https://n8n.io/workflows/2729-private-and-local-ollama-self-hosted-ai-assistant/",
  "title": "🔐🦙🤖 Private & Local Ollama Self-Hosted AI Assistant",
  "author": "Joseph LePage",
  "publish_date": "Last update 4 months ago",
  "publish_date_absolute": "2025-01-26",
  "categories": [
    {
      "name": "AI"
    }
  ],
  "workflow_json": "{\"id\":\"Telr6HU0ltH7s9f7\",\"meta\":{\"instanceId\":\"31e69f7f4a77bf465b805824e303232f0227212ae922d12133a0f96ffeab4fef\"},\"name\":\"🗨️Ollama Chat\",\"tags\":[],\"nodes\":[{\"id\":\"9560e89b-ea08-49dc-924e-ec8b83477340\",\"name\":\"When chat message received\",\"type\":\"@n8n/n8n-nodes-langchain.chatTrigger\",\"position\":[280,60],\"webhookId\":\"4d06a912-2920-489c-a33c-0e3ea0b66745\",\"parameters\":{\"options\":{}},\"typeVersion\":1.1},{\"id\":\"c7919677-233f-4c48-ba01-ae923aef511e\",\"name\":\"Basic LLM Chain\",\"type\":\"@n8n/n8n-nodes-langchain.chainLlm\",\"onError\":\"continueErrorOutput\",\"position\":[640,60],\"parameters\":{\"text\":\"=Provide the users prompt and response as a JSON object with two fields:\\n- Prompt\\n- Response\\n\\nAvoid any preample or further explanation.\\n\\nThis is the question: {{ $json.chatInput }}\",\"promptType\":\"define\"},\"typeVersion\":1.5},{\"id\":\"b9676a8b-f790-4661-b8b9-3056c969bdf5\",\"name\":\"Ollama Model\",\"type\":\"@n8n/n8n-nodes-langchain.lmOllama\",\"position\":[740,340],\"parameters\":{\"model\":\"llama3.2:latest\",\"options\":{}},\"credentials\":{\"ollamaApi\":{\"id\":\"IsSBWGtcJbjRiKqD\",\"name\":\"Ollama account\"}},\"typeVersion\":1},{\"id\":\"61dfcda5-083c-43ff-8451-b2417f1e4be4\",\"name\":\"Sticky Note\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[-380,-380],\"parameters\":{\"color\":4,\"width\":520,\"height\":860,\"content\":\"# 🦙 Ollama Chat Workflow\\n\\nA simple N8N workflow that integrates Ollama LLM for chat message processing and returns a structured JSON object.\\n\\n## Overview\\nThis workflow creates a chat interface that processes messages using the Llama 3.2 model through Ollama. When a chat message is received, it gets processed through a basic LLM chain and returns a response.\\n\\n## Components\\n- **Trigger Node**\\n- **Processing Node**\\n- **Model Node**\\n- **JSON to Object Node**\\n- **Structured Response Node**\\n- **Error Response Node**\\n\\n## Workflow Structure\\n1. The chat trigger node receives incoming messages\\n2. Messages are passed to the Basic LLM Chain\\n3. The Ollama Model processes the input using Llama 3.2\\n4. Responses are returned through the chain\\n\\n## Prerequisites\\n- N8N installation\\n- Ollama setup with Llama 3.2 model\\n- Valid Ollama API credentials\\n\\n## Configuration\\n1. Set up the Ollama API credentials in N8N\\n2. Ensure the Llama 3.2 model is available in your Ollama installation\\n\\n\"},\"typeVersion\":1},{\"id\":\"64f60ee1-7870-461e-8fac-994c9c08b3f9\",\"name\":\"Sticky Note1\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[340,280],\"parameters\":{\"width\":560,\"height\":200,\"content\":\"## Model Node\\n- Name: Ollama Model\\n- Type: LangChain Ollama Integration\\n- Model: llama3.2:latest\\n- Purpose: Provides the language model capabilities\"},\"typeVersion\":1},{\"id\":\"bb46210d-450c-405b-a451-42458b3af4ae\",\"name\":\"Sticky Note2\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[200,-160],\"parameters\":{\"color\":6,\"width\":280,\"height\":400,\"content\":\"## Trigger Node\\n- Name: When chat message received\\n- Type: Chat Trigger\\n- Purpose: Initiates the workflow when a new chat message arrives\"},\"typeVersion\":1},{\"id\":\"7f21b9e6-6831-4117-a2e2-9c9fb6edc492\",\"name\":\"Sticky Note3\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[520,-380],\"parameters\":{\"color\":3,\"width\":500,\"height\":620,\"content\":\"## Processing Node\\n- Name: Basic LLM Chain\\n- Type: LangChain LLM Chain\\n- Purpose: Handles the processing of messages through the language model and returns a structured JSON object.\\n\\n\"},\"typeVersion\":1},{\"id\":\"871bac4e-002f-4a1d-b3f9-0b7d309db709\",\"name\":\"Sticky Note4\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[560,-200],\"parameters\":{\"color\":7,\"width\":420,\"height\":200,\"content\":\"### Prompt (Change this for your use case)\\nProvide the users prompt and response as a JSON object with two fields:\\n- Prompt\\n- Response\\n\\n\\nAvoid any preample or further explanation.\\nThis is the question: {{ $json.chatInput }}\"},\"typeVersion\":1},{\"id\":\"c9e1b2af-059b-4330-a194-45ae0161aa1c\",\"name\":\"Sticky Note5\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[1060,-280],\"parameters\":{\"color\":5,\"width\":420,\"height\":520,\"content\":\"## JSON to Object Node\\n- Type: Set Node\\n- Purpose: A node designed to transform and structure response data in a specific format before sending it through the workflow. It operates in manual mapping mode to allow precise control over the response format.\\n\\n**Key Features**\\n- Manual field mapping capabilities\\n- Object transformation and restructuring\\n- Support for JSON data formatting\\n- Field-to-field value mapping\\n- Includes option to add additional input fields\\n\"},\"typeVersion\":1},{\"id\":\"3fb912b8-86ac-42f7-a19c-45e59898a62e\",\"name\":\"Sticky Note6\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[1520,-180],\"parameters\":{\"color\":6,\"width\":460,\"height\":420,\"content\":\"## Structured Response Node\\n- Type: Set Node\\n- Purpose: Controls how the workflow responds to users chat prompt.\\n\\n**Response Mode**\\n- Manual Mapping: Allows custom formatting of response data\\n- Fields to Set: Specify which data fields to include in response\\n\\n\"},\"typeVersion\":1},{\"id\":\"fdfd1a5c-e1a6-4390-9807-ce665b96b9ae\",\"name\":\"Structured Response\",\"type\":\"n8n-nodes-base.set\",\"position\":[1700,60],\"parameters\":{\"options\":{},\"assignments\":{\"assignments\":[{\"id\":\"13c4058d-2d50-46b7-a5a6-c788828a1764\",\"name\":\"text\",\"type\":\"string\",\"value\":\"=Your prompt was: {{ $json.response.Prompt }}\\n\\nMy response is: {{ $json.response.Response }}\\n\\nThis is the JSON object:\\n\\n{{ $('Basic LLM Chain').item.json.text }}\"}]}},\"typeVersion\":3.4},{\"id\":\"76baa6fc-72dd-41f9-aef9-4fd718b526df\",\"name\":\"Error Response\",\"type\":\"n8n-nodes-base.set\",\"position\":[1460,660],\"parameters\":{\"options\":{},\"assignments\":{\"assignments\":[{\"id\":\"13c4058d-2d50-46b7-a5a6-c788828a1764\",\"name\":\"text\",\"type\":\"string\",\"value\":\"=There was an error.\"}]}},\"typeVersion\":3.4},{\"id\":\"bde3b9df-af55-451b-b287-1b5038f9936c\",\"name\":\"Sticky Note7\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[1240,280],\"parameters\":{\"color\":2,\"width\":540,\"height\":560,\"content\":\"## Error Response Node\\n- Type: Set Node\\n- Purpose: Handles error cases when the Basic LLM Chain fails to process the chat message properly. It provides a fallback response mechanism to ensure the workflow remains robust.\\n\\n**Key Features**\\n- Provides default error messaging\\n- Maintains consistent response structure\\n- Connects to the error output branch of the LLM Chain\\n- Ensures graceful failure handling\\n\\nThe Error Response node activates when the main processing chain encounters issues, ensuring users always receive feedback even when errors occur in the language model processing.\\n\"},\"typeVersion\":1},{\"id\":\"b9b2ab8d-9bea-457a-b7bf-51c8ef0de69f\",\"name\":\"JSON to Object\",\"type\":\"n8n-nodes-base.set\",\"position\":[1220,60],\"parameters\":{\"options\":{},\"assignments\":{\"assignments\":[{\"id\":\"12af1a54-62a2-44c3-9001-95bb0d7c769d\",\"name\":\"response\",\"type\":\"object\",\"value\":\"={{ $json.text }}\"}]}},\"typeVersion\":3.4}],\"active\":false,\"pinData\":{},\"settings\":{\"executionOrder\":\"v1\"},\"versionId\":\"5175454a-91b7-4c57-890d-629bd4e8d2fd\",\"connections\":{\"Ollama Model\":{\"ai_languageModel\":[[{\"node\":\"Basic LLM Chain\",\"type\":\"ai_languageModel\",\"index\":0}]]},\"JSON to Object\":{\"main\":[[{\"node\":\"Structured Response\",\"type\":\"main\",\"index\":0}]]},\"Basic LLM Chain\":{\"main\":[[{\"node\":\"JSON to Object\",\"type\":\"main\",\"index\":0}],[{\"node\":\"Error Response\",\"type\":\"main\",\"index\":0}]]},\"When chat message received\":{\"main\":[[{\"node\":\"Basic LLM Chain\",\"type\":\"main\",\"index\":0}]]}}}",
  "readme": "Transform your local N8N instance into a powerful chat interface using any local & private Ollama model, with zero cloud dependencies ☁️. This workflow creates a structured chat experience that processes messages locally through a language model chain and returns formatted responses 💬.\n\n## How it works 🔄\n\n  * 💭 Chat messages trigger the workflow\n  * 🧠 Messages are processed through Llama 3.2 via Ollama (or any other Ollama compatible model)\n  * 📊 Responses are formatted as structured JSON\n  * ⚡ Error handling ensures robust operation\n\n\n\n## Set up steps 🛠️\n\n  * 📥 Install N8N and Ollama\n  * ⚙️ Download Ollama 3.2 model (or other model)\n  * 🔑 Configure Ollama API credentials\n  * ✨ Import and activate workflow\n\n\n\nThis template provides a foundation for building AI-powered chat applications while maintaining full control over your data and infrastructure 🚀.\n",
  "crawled_at": "2025-05-26T01:49:23.310217",
  "readme_zh": "将您的本地N8N实例转变为强大的聊天界面，支持任意本地私有Ollama模型，完全脱离云端依赖☁️。该工作流打造结构化对话体验，通过语言模型链在本地处理消息并返回格式化响应💬。\n\n## 运行原理🔄\n\n  * 💭 聊天消息触发工作流\n  * 🧠 通过Ollama调用Llama 3.2处理消息（或兼容的其他Ollama模型）\n  * 📊 响应内容以结构化JSON格式返回\n  * ⚡ 错误处理机制保障稳定运行\n\n## 配置步骤🛠️\n\n  * 📥 安装N8N与Ollama\n  * ⚙️ 下载Ollama 3.2模型（或其他模型）\n  * 🔑 配置Ollama API凭证\n  * ✨ 导入并激活工作流\n\n该模板为构建AI驱动的聊天应用提供基础框架，同时让您全程掌控数据与基础设施🚀。",
  "title_zh": "🔐🦙🤖 私有化本地部署的Ollama自托管AI助手",
  "publish_date_zh": "最后更新于3个月前",
  "workflow_json_zh": "{\"id\":\"Telr6HU0ltH7s9f7\",\"meta\":{\"instanceId\":\"31e69f7f4a77bf465b805824e303232f0227212ae922d12133a0f96ffeab4fef\"},\"name\":\"🗨️Ollama Chat\",\"tags\":[],\"nodes\":[{\"id\":\"9560e89b-ea08-49dc-924e-ec8b83477340\",\"name\":\"When chat message received\",\"type\":\"@n8n/n8n-nodes-langchain.chatTrigger\",\"position\":[280,60],\"webhookId\":\"4d06a912-2920-489c-a33c-0e3ea0b66745\",\"parameters\":{\"options\":{}},\"typeVersion\":1.1},{\"id\":\"c7919677-233f-4c48-ba01-ae923aef511e\",\"name\":\"Basic LLM Chain\",\"type\":\"@n8n/n8n-nodes-langchain.chainLlm\",\"onError\":\"continueErrorOutput\",\"position\":[640,60],\"parameters\":{\"text\":\"=Provide the users prompt and response as a JSON object with two fields:\\n- Prompt\\n- Response\\n\\nAvoid any preample or further explanation.\\n\\nThis is the question: {{ $json.chatInput }}\",\"promptType\":\"define\"},\"typeVersion\":1.5},{\"id\":\"b9676a8b-f790-4661-b8b9-3056c969bdf5\",\"name\":\"Ollama Model\",\"type\":\"@n8n/n8n-nodes-langchain.lmOllama\",\"position\":[740,340],\"parameters\":{\"model\":\"llama3.2:latest\",\"options\":{}},\"credentials\":{\"ollamaApi\":{\"id\":\"IsSBWGtcJbjRiKqD\",\"name\":\"Ollama account\"}},\"typeVersion\":1},{\"id\":\"61dfcda5-083c-43ff-8451-b2417f1e4be4\",\"name\":\"Sticky Note\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[-380,-380],\"parameters\":{\"color\":4,\"width\":520,\"height\":860,\"content\":\"# 🦙 Ollama 聊天工作流\\n\\n一个简单的N8N工作流，集成Ollama大语言模型处理聊天消息并返回结构化JSON对象。\\n\\n## 概述\\n本工作流创建了一个通过Ollama调用Llama 3.2模型处理消息的聊天界面。当收到聊天消息时，会通过基础LLM链进行处理并返回响应。\\n\\n## 组件模块\\n- **触发器节点**\\n- **处理节点**\\n- **模型节点**\\n- **JSON转换节点**\\n- **结构化响应节点**\\n- **错误响应节点**\\n\\n## 工作流结构\\n1. 聊天触发器节点接收输入消息\\n2. 消息传递至基础LLM处理链\\n3. Ollama模型使用Llama 3.2处理输入内容\\n4. 响应结果通过处理链返回\\n\\n## 环境要求\\n- 已安装N8N平台\\n- 已配置含Llama 3.2模型的Ollama环境\\n- 有效的Ollama API凭证\\n\\n## 配置步骤\\n1. 在N8N中设置Ollama API凭证\\n2. 确保Ollama环境中已部署Llama 3.2模型\"},\"typeVersion\":1},{\"id\":\"64f60ee1-7870-461e-8fac-994c9c08b3f9\",\"name\":\"Sticky Note1\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[340,280],\"parameters\":{\"width\":560,\"height\":200,\"content\":\"## 模型节点\\n- 名称: Ollama模型\\n- 类型: LangChain Ollama集成\\n- 模型: llama3.2:latest\\n- 用途: 提供语言模型能力\"},\"typeVersion\":1},{\"id\":\"bb46210d-450c-405b-a451-42458b3af4ae\",\"name\":\"Sticky Note2\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[200,-160],\"parameters\":{\"color\":6,\"width\":280,\"height\":400,\"content\":\"## 触发节点\\n- 名称：当收到聊天消息时\\n- 类型：聊天触发器\\n- 功能：当新聊天消息到达时启动工作流程\"},\"typeVersion\":1},{\"id\":\"7f21b9e6-6831-4117-a2e2-9c9fb6edc492\",\"name\":\"Sticky Note3\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[520,-380],\"parameters\":{\"color\":3,\"width\":500,\"height\":620,\"content\":\"## 处理节点\\n- 名称：基础LLM链\\n- 类型：LangChain语言模型链\\n- 功能：通过语言模型处理消息并返回结构化的JSON对象\"},\"typeVersion\":1},{\"id\":\"871bac4e-002f-4a1d-b3f9-0b7d309db709\",\"name\":\"Sticky Note4\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[560,-200],\"parameters\":{\"color\":7,\"width\":420,\"height\":200,\"content\":\"### 提示（根据您的使用场景修改此处）\\n提供一个包含用户提示和响应的JSON对象，该对象包含两个字段：\\n- 提示\\n- 响应\\n\\n避免任何前言或进一步的解释。\\n问题是：{{ $json.chatInput }}\"},\"typeVersion\":1},{\"id\":\"c9e1b2af-059b-4330-a194-45ae0161aa1c\",\"name\":\"Sticky Note5\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[1060,-280],\"parameters\":{\"color\":5,\"width\":420,\"height\":520,\"content\":\"## JSON转对象节点\\n- 类型：集合节点\\n- 用途：专为在数据通过工作流发送前，对响应数据进行特定格式转换与结构化设计的节点。采用手动映射模式，可精准控制响应格式。\\n\\n**核心功能**\\n- 支持手动字段映射\\n- 实现对象转换与结构重组\\n- 兼容JSON数据格式化\\n- 提供字段间值映射功能\\n- 包含添加额外输入字段选项\"},\"typeVersion\":1},{\"id\":\"3fb912b8-86ac-42f7-a19c-45e59898a62e\",\"name\":\"Sticky Note6\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[1520,-180],\"parameters\":{\"color\":6,\"width\":460,\"height\":420,\"content\":\"## 结构化响应节点\\n- 类型：集合节点\\n- 功能：控制工作流对用户聊天提示的响应方式\\n\\n**响应模式**\\n- 手动映射：允许自定义响应数据的格式\\n- 待设定字段：指定响应中包含的数据字段\"},\"typeVersion\":1},{\"id\":\"fdfd1a5c-e1a6-4390-9807-ce665b96b9ae\",\"name\":\"Structured Response\",\"type\":\"n8n-nodes-base.set\",\"position\":[1700,60],\"parameters\":{\"options\":{},\"assignments\":{\"assignments\":[{\"id\":\"13c4058d-2d50-46b7-a5a6-c788828a1764\",\"name\":\"text\",\"type\":\"string\",\"value\":\"=Your prompt was: {{ $json.response.Prompt }}\\n\\nMy response is: {{ $json.response.Response }}\\n\\nThis is the JSON object:\\n\\n{{ $('Basic LLM Chain').item.json.text }}\"}]}},\"typeVersion\":3.4},{\"id\":\"76baa6fc-72dd-41f9-aef9-4fd718b526df\",\"name\":\"Error Response\",\"type\":\"n8n-nodes-base.set\",\"position\":[1460,660],\"parameters\":{\"options\":{},\"assignments\":{\"assignments\":[{\"id\":\"13c4058d-2d50-46b7-a5a6-c788828a1764\",\"name\":\"text\",\"type\":\"string\",\"value\":\"=There was an error.\"}]}},\"typeVersion\":3.4},{\"id\":\"bde3b9df-af55-451b-b287-1b5038f9936c\",\"name\":\"Sticky Note7\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[1240,280],\"parameters\":{\"color\":2,\"width\":540,\"height\":560,\"content\":\"## 错误响应节点\\n- 类型：设置节点\\n- 目的：当基础LLM链无法正确处理聊天消息时，处理错误情况。提供后备响应机制以确保工作流保持稳健。\\n\\n**核心特性**\\n- 提供默认错误信息\\n- 保持一致的响应结构\\n- 连接至LLM链的错误输出分支\\n- 确保优雅的故障处理\\n\\n当主处理链遇到问题时，错误响应节点将被激活，确保即使用户在语言模型处理过程中发生错误，也能始终获得反馈。\"},\"typeVersion\":1},{\"id\":\"b9b2ab8d-9bea-457a-b7bf-51c8ef0de69f\",\"name\":\"JSON to Object\",\"type\":\"n8n-nodes-base.set\",\"position\":[1220,60],\"parameters\":{\"options\":{},\"assignments\":{\"assignments\":[{\"id\":\"12af1a54-62a2-44c3-9001-95bb0d7c769d\",\"name\":\"response\",\"type\":\"object\",\"value\":\"={{ $json.text }}\"}]}},\"typeVersion\":3.4}],\"active\":false,\"pinData\":{},\"settings\":{\"executionOrder\":\"v1\"},\"versionId\":\"5175454a-91b7-4c57-890d-629bd4e8d2fd\",\"connections\":{\"Ollama Model\":{\"ai_languageModel\":[[{\"node\":\"Basic LLM Chain\",\"type\":\"ai_languageModel\",\"index\":0}]]},\"JSON to Object\":{\"main\":[[{\"node\":\"Structured Response\",\"type\":\"main\",\"index\":0}]]},\"Basic LLM Chain\":{\"main\":[[{\"node\":\"JSON to Object\",\"type\":\"main\",\"index\":0}],[{\"node\":\"Error Response\",\"type\":\"main\",\"index\":0}]]},\"When chat message received\":{\"main\":[[{\"node\":\"Basic LLM Chain\",\"type\":\"main\",\"index\":0}]]}}}"
}