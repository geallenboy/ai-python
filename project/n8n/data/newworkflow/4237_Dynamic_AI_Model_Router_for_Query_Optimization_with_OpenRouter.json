{
  "url": "https://n8n.io/workflows/4237-dynamic-ai-model-router-for-query-optimization-with-openrouter/",
  "title": "Dynamic AI Model Router for Query Optimization with OpenRouter",
  "author": "Davide",
  "publish_date": "Last update 6 days ago",
  "publish_date_absolute": "2025-05-20",
  "categories": [
    {
      "name": "Engineering"
    },
    {
      "name": "Building Blocks"
    },
    {
      "name": "AI"
    },
    {
      "name": "IT Ops"
    }
  ],
  "workflow_json": "",
  "readme": "The **Agent Decisioner** is a dynamic, AI-powered routing system that automatically selects the most appropriate large language model (LLM) to respond to a user's query based on the query’s content and purpose.\n\nThis workflow ensures **dynamic, optimized AI responses** by intelligently routing queries to the best-suited model.\n\n* * *\n\n### **Advantages**\n\n  * **🔁 Automatic Model Routing:**  \nAutomatically selects the best model for the job, improving efficiency and relevance of responses.\n\n  * **🎯 Optimized Use of Resources:**  \nAvoids overuse of expensive models like GPT-4 by routing simpler queries to lightweight models.\n\n  * **📚 Model-Aware Reasoning:**  \nUses detailed metadata about model capabilities (e.g., reasoning, coding, web search) for intelligent selection.\n\n  * **📥 Modular and Extendable:**  \nEasy to integrate with other tools or expand by adding more models or custom decision logic.\n\n  * **👨‍💻 Ideal for RAG and Multi-Agent Systems:**  \nCan serve as the brain behind more complex agent frameworks or Retrieval-Augmented Generation pipelines.\n\n\n\n\n* * *\n\n### **How It Works**\n\n  1. **Chat Trigger** : The workflow starts when a user sends a message, triggering the **Routing Agent**.\n  2. **Model Selection** : The **AI Agent** analyzes the query and selects the best-suited model from the available options (e.g., Claude 3.7 Sonnet for coding, Perplexity/Sonar for web searches, GPT-4o Mini for reasoning).\n  3. **Structured Output** : The agent returns a **JSON response** with the user’s prompt and the chosen model.\n  4. **Execution** : The selected model processes the query and generates a response, ensuring optimal performance for the task.\n\n\n\n### **Set Up Steps**\n\n  1. **Configure Nodes** :\n\n     * **Chat Trigger** : Set up the webhook to receive user messages.\n     * **Routing Agent (AI Agent)** : Define the system message with model strengths and JSON output rules.\n     * **OpenRouter Chat Model** : Connect to OpenRouter for model access.\n     * **Structured Output Parser** : Ensure it validates the JSON response format (`prompt` \\+ `model`).\n     * **Execution Agent (AI Agent1)** : Configure it to forward the prompt to the selected model.\n  2. **Connect Nodes** :\n\n     * Link the **Chat Trigger** to the **Routing Agent**.\n     * Connect the **OpenRouter Chat Model** and **Output Parser** to the **Routing Agent**.\n     * Route the parsed JSON to the **Execution Agent** , which uses the chosen model via **OpenRouter Chat Model1**.\n  3. **Credentials** :\n\n     * Ensure **OpenRouter API credentials** are correctly set for both chat model nodes.\n  4. **Test & Deploy**:\n\n     * Activate the workflow and test with sample queries to verify model selection logic.\n     * Adjust the routing rules if needed for better accuracy.\n\n\n\n* * *\n\n### **Need help customizing?**\n\n[Contact me](mailto:info@n3w.it) for consulting and support or add me on [Linkedin](https://www.linkedin.com/in/davideboizza/).\n",
  "crawled_at": "2025-05-26T07:23:42.728766",
  "readme_zh": "**智能路由决策器（Agent Decisioner）** 是一个动态的AI驱动路由系统，能根据查询内容与目的自动选择最适配的大语言模型（LLM）生成响应。\n\n该工作流通过智能路由机制实现**动态优化的AI响应**，确保每个查询都能匹配最佳模型。\n\n* * *\n\n### **核心优势**\n\n  * **🔄 自动模型路由**  \n智能选择最优模型，提升响应效率与精准度\n\n  * **🎯 资源优化配置**  \n将简单查询导向轻量级模型，避免GPT-4等高成本模型的过度消耗\n\n  * **📚 模型能力感知**  \n依据模型元数据（推理/编程/网络搜索等能力）进行智能筛选\n\n  * **📥 模块化扩展**  \n可轻松集成其他工具，支持添加新模型或自定义决策逻辑\n\n  * **👨‍💻 适配复杂系统**  \n可作为RAG框架或多智能体系统的核心调度中枢\n\n* * *\n\n### **运作原理**\n\n  1. **触发会话**：用户消息触发**路由代理**  \n  2. **模型选择**：AI代理分析查询内容，从候选模型库（如Claude 3.7 Sonnet处理编程/Perplexity/Sonar执行网络搜索/GPT-4o Mini负责推理）选取最优解  \n  3. **结构化输出**：返回含用户提示词与选定模型的**JSON响应**  \n  4. **执行响应**：目标模型处理查询并生成优化结果  \n\n### **配置指南**\n\n  1. **节点配置**  \n     - **聊天触发器**：设置接收用户消息的webhook  \n     - **路由代理**：编写包含模型能力说明与JSON输出规则的系统消息  \n     - **OpenRouter聊天模型**：接入模型服务平台  \n     - **结构化输出解析器**：校验JSON格式（`prompt`+`model`）  \n     - **执行代理**：配置转发机制至目标模型  \n  2. **节点连接**  \n     - 将**聊天触发器**接入**路由代理**  \n     - 关联**OpenRouter聊天模型**与**输出解析器**至路由代理  \n     - 将解析后的JSON路由至通过**OpenRouter Chat Model1**调用指定模型的**执行代理**  \n  3. **凭证设置**  \n     - 确保所有聊天模型节点已配置正确的**OpenRouter API凭证**  \n  4. **测试部署**  \n     - 激活工作流并通过样例查询验证路由逻辑  \n     - 按需调整选择规则以提升准确性  \n\n* * *\n\n### **需要定制化支持？**\n\n欢迎通过[邮件](mailto:info@n3w.it)咨询，或通过[领英](https://www.linkedin.com/in/davideboizza/)联系。",
  "title_zh": "用于OpenRouter查询优化的动态AI模型路由器",
  "publish_date_zh": "最后更新于6天前"
}