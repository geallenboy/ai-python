{
  "url": "https://n8n.io/workflows/4217-create-openai-compatible-api-using-github-models-for-free-ai-access/",
  "title": "Create OpenAI-Compatible API Using GitHub Models for Free AI Access",
  "author": "Jimleuk",
  "publish_date": "Last update 6 days ago",
  "publish_date_absolute": "2025-05-20",
  "categories": [
    {
      "name": "Engineering"
    },
    {
      "name": "AI"
    }
  ],
  "workflow_json": "{\"meta\":{\"instanceId\":\"408f9fb9940c3cb18ffdef0e0150fe342d6e655c3a9fac21f0f644e8bedabcd9\",\"templateCredsSetupCompleted\":true},\"nodes\":[{\"id\":\"f8831a38-92ef-44e5-99dd-0f410e9c0883\",\"name\":\"Aggregate\",\"type\":\"n8n-nodes-base.aggregate\",\"position\":[440,260],\"parameters\":{\"options\":{},\"aggregate\":\"aggregateAllItemData\"},\"typeVersion\":1},{\"id\":\"7c51c3f5-3d2f-4d7d-8fd8-30641b1b9516\",\"name\":\"Github Models\",\"type\":\"n8n-nodes-base.httpRequest\",\"position\":[240,260],\"parameters\":{\"url\":\"https://models.github.ai/catalog/models\",\"options\":{\"redirect\":{\"redirect\":{}}},\"sendHeaders\":true,\"authentication\":\"predefinedCredentialType\",\"headerParameters\":{\"parameters\":[{\"name\":\"Accept\",\"value\":\"application/vnd.github+json\"},{\"name\":\"X-GitHub-Api-Version\",\"value\":\"2022-11-28\"}]},\"nodeCredentialType\":\"githubApi\"},\"credentials\":{\"githubApi\":{\"id\":\"kA70YRmLeHDqZbXA\",\"name\":\"GitHub account\"}},\"typeVersion\":4.2},{\"id\":\"c9602915-e903-4891-b131-68b3190f637b\",\"name\":\"Github Chat Completions\",\"type\":\"n8n-nodes-base.httpRequest\",\"position\":[1120,320],\"parameters\":{\"url\":\"https://models.github.ai/inference/chat/completions\",\"method\":\"POST\",\"options\":{\"redirect\":{\"redirect\":{}}},\"jsonBody\":\"={{\\n{\\n  model: $json.body.model,\\n  messages: $json.body.messages,\\n  stream: $json.body.stream\\n}\\n}}\",\"sendBody\":true,\"sendHeaders\":true,\"specifyBody\":\"json\",\"authentication\":\"predefinedCredentialType\",\"headerParameters\":{\"parameters\":[{\"name\":\"Accept\",\"value\":\"application/vnd.github+json\"},{\"name\":\"X-GitHub-Api-Version\",\"value\":\"2022-11-28\"}]},\"nodeCredentialType\":\"githubApi\"},\"credentials\":{\"githubApi\":{\"id\":\"kA70YRmLeHDqZbXA\",\"name\":\"GitHub account\"}},\"typeVersion\":4.2},{\"id\":\"ccdfc4f2-53dd-409b-9887-6e191374e23c\",\"name\":\"n8n Webhooks\",\"type\":\"@n8n/n8n-nodes-langchain.lmChatOpenAi\",\"position\":[320,-160],\"parameters\":{\"model\":{\"__rl\":true,\"mode\":\"list\",\"value\":\"openai/gpt-4o-mini\",\"cachedResultName\":\"openai/gpt-4o-mini\"},\"options\":{}},\"credentials\":{\"openAiApi\":{\"id\":\"8VVdMPbWsLxTlgC0\",\"name\":\"n8n-router\"}},\"typeVersion\":1.2},{\"id\":\"29ed818b-fb54-4b55-b5ac-1d5220222558\",\"name\":\"Chat Response\",\"type\":\"n8n-nodes-base.respondToWebhook\",\"position\":[1540,400],\"parameters\":{\"options\":{},\"respondWith\":\"json\",\"responseBody\":\"={{ $json }}\"},\"typeVersion\":1.2},{\"id\":\"3c36a5c8-28da-4656-aa9d-8593926b3e77\",\"name\":\"Models Response\",\"type\":\"n8n-nodes-base.respondToWebhook\",\"position\":[640,260],\"parameters\":{\"options\":{},\"respondWith\":\"json\",\"responseBody\":\"={{\\n({\\n  \\\"object\\\": \\\"list\\\",\\n  \\\"data\\\":  $json.data.map(item => ({\\n    \\\"id\\\": item.id,\\n    \\\"object\\\": \\\"model\\\",\\n    \\\"created\\\": 1733945430,\\n    \\\"owned_by\\\": \\\"system\\\"\\n  }))\\n})\\n}}\"},\"executeOnce\":false,\"typeVersion\":1.2},{\"id\":\"3c1efb37-c04c-4426-acde-690dbaf54183\",\"name\":\"Powered By Github Models\",\"type\":\"@n8n/n8n-nodes-langchain.chainLlm\",\"position\":[240,-340],\"parameters\":{},\"typeVersion\":1.6},{\"id\":\"704e5aae-bda3-4238-b770-f3a1d2732311\",\"name\":\"When chat message received\",\"type\":\"@n8n/n8n-nodes-langchain.chatTrigger\",\"position\":[40,-340],\"webhookId\":\"6ec7783c-8f47-4fdf-9838-7846b1da4bfa\",\"parameters\":{\"options\":{}},\"typeVersion\":1.1},{\"id\":\"ed87f51d-c2bd-43c4-aabb-4f92b12b82f3\",\"name\":\"Sticky Note\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[560,-240],\"parameters\":{\"color\":5,\"width\":520,\"height\":220,\"content\":\"### LLM Models via N8N Webhooks\\n1. Create a new OpenAI Credential and call it \\\"n8n-webhook\\\"\\n2. Enter API key as anything you like eg. \\\"12345\\\"\\n3. Enter Base URL as \\\"https://<your_n8n_url>/webhook/github-models\\\"\\n4. Activate your workflow! This only really works with the production webhook URL.\\n\\nFeel free to change the names to whatever you want, just make sure the LLM node is able to reach it!\"},\"typeVersion\":1},{\"id\":\"c28b03cb-bd1b-41d5-ba1b-486a099afb92\",\"name\":\"GET models\",\"type\":\"n8n-nodes-base.webhook\",\"position\":[40,260],\"webhookId\":\"f88b9992-b7b9-4ab5-829c-7b89e9cc4775\",\"parameters\":{\"path\":\"github-models/models\",\"options\":{},\"responseMode\":\"responseNode\"},\"typeVersion\":2},{\"id\":\"02cb7e26-f992-4444-a886-dcaea1dbb63c\",\"name\":\"POST ChatCompletions\",\"type\":\"n8n-nodes-base.webhook\",\"position\":[920,320],\"webhookId\":\"e8c56164-1825-4ac4-9c23-d209f4907458\",\"parameters\":{\"path\":\"github-models/chat/completions\",\"options\":{},\"httpMethod\":\"POST\",\"responseMode\":\"responseNode\"},\"typeVersion\":2},{\"id\":\"be0e06be-2b0d-4167-ad70-84d188f5ca68\",\"name\":\"Sticky Note1\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[-20,-560],\"parameters\":{\"color\":7,\"width\":680,\"height\":580,\"content\":\"## 1. Create a New Custom OpenAI Credential\\n[Learn more about OpenAI Credentials](https://docs.n8n.io/integrations/builtin/credentials/openai/)\\n\\nTo use Github Models with our existing n8n nodes, one approach is to mimic an openAI compatible API connected through the OpenAI model subnode. Sounds complicated but don't worry, this template shows you how! The first step is to setup a new OpenAI credential so that we can change the Base URL.\"},\"typeVersion\":1},{\"id\":\"855c24f5-0758-4344-b780-523383b51de1\",\"name\":\"Sticky Note2\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[-20,60],\"parameters\":{\"color\":7,\"width\":840,\"height\":420,\"content\":\"## 2. Listing All Available Models \\n[Read more about the Webhook Trigger node](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.webhook/)\\n\\nOur first endpoint is for listing all models. The Github Models API how we can do this but the response requires some re-mapping to make it compatible with our LLM node.\"},\"typeVersion\":1},{\"id\":\"d5f0446d-2e59-47ee-a442-f66490d8759d\",\"name\":\"Sticky Note3\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[840,60],\"parameters\":{\"color\":7,\"width\":920,\"height\":540,\"content\":\"## 3. Request a Chat Completion \\n[Read more about the HTTP Request node](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.httprequest)\\n\\nOur second endpoint is for executing a chat completion. Note that depending on if you have connected with an agent, the response expected is a \\\"stream\\\" and returned data needs to be of type `text/plain`.\"},\"typeVersion\":1},{\"id\":\"e8a13b04-fd51-4031-90f3-7088871e6dfd\",\"name\":\"Sticky Note4\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[-520,-560],\"parameters\":{\"width\":420,\"height\":1280,\"content\":\"## Try It Out!\\n### This n8n template shows you how to connect [Github's Free Models](https://docs.github.com/en/github-models) to your existing n8n AI workflows.\\n\\nWhilst it is possible to use HTTP nodes to access Github Models, The aim of this template is to use it with existing n8n LLM nodes - saves the trouble of refactoring!\\n\\nPlease note, Github states their model APIs are not intended for production usage! If you need higher rate limits, you'll need to use a paid service.\\n\\n### How it works\\n* The approach builds a custom OpenAI compatible API around the Github Models API - all done in n8n!\\n* First, we attach an OpenAI subnode to our LLM node and configure a new OpenAI credential.\\n* Within this new OpenAI credential, we change the \\\"Base URL\\\" to point at a n8n webhook we've prepared as part of this template.\\n* Next, we create 2 webhooks which the LLM node will now attempt to connect with: \\\"models\\\" and \\\"chat completion\\\".\\n* The \\\"models\\\" webhook simply calls the Github Model's \\\"list all models\\\" endpoint and remaps the response to be compatible with our LLM node.\\n* The \\\"Chat Completion\\\" webhook does a similar task with Github's Chat Completion endpoint.\\n\\n### How to use\\n* Once connected, just open chat and ask away!\\n* Any LLM or AI agent node connected with this custom LLM subnode will send requests to the Github Models API. Allowing your to try out a range of SOTA models for free.\\n\\n### Requirements\\n* Github account and credentials for access to Models. If you've used the Github node previously, you can reuse this credential for this template.\\n\\n### Customising this workflow\\n* This template is just an example. Use the custom OpenAI credential for your other workflows to test Github models.\\n\\n### References\\n* [https://docs.github.com/en/github-models/prototyping-with-ai-models](https://docs.github.com/en/github-models/prototyping-with-ai-models)\\n* [https://docs.github.com/en/github-models](https://docs.github.com/en/github-models)\\n\\n### Need Help?\\nJoin the [Discord](https://discord.com/invite/XPKeKXeB7d) or ask in the [Forum](https://community.n8n.io/)!\\n\\nHappy Hacking!\"},\"typeVersion\":1},{\"id\":\"2a75f35d-695f-425d-8b8e-425c9075c702\",\"name\":\"Is Agent?\",\"type\":\"n8n-nodes-base.if\",\"position\":[1320,320],\"parameters\":{\"options\":{},\"conditions\":{\"options\":{\"version\":2,\"leftValue\":\"\",\"caseSensitive\":true,\"typeValidation\":\"strict\"},\"combinator\":\"and\",\"conditions\":[{\"id\":\"213702bf-d5c2-4a8a-b5c8-e55f804e4496\",\"operator\":{\"type\":\"boolean\",\"operation\":\"true\",\"singleValue\":true},\"leftValue\":\"={{ $('POST ChatCompletions').first().json.body.stream }}\",\"rightValue\":\"\"}]}},\"typeVersion\":2.2},{\"id\":\"31e0325d-ef82-40af-862b-9dcffbf650e6\",\"name\":\"Agent Response\",\"type\":\"n8n-nodes-base.respondToWebhook\",\"position\":[1540,240],\"parameters\":{\"options\":{},\"respondWith\":\"text\",\"responseBody\":\"={{ $json.data }}\"},\"typeVersion\":1.2}],\"pinData\":{},\"connections\":{\"Aggregate\":{\"main\":[[{\"node\":\"Models Response\",\"type\":\"main\",\"index\":0}]]},\"Is Agent?\":{\"main\":[[{\"node\":\"Agent Response\",\"type\":\"main\",\"index\":0}],[{\"node\":\"Chat Response\",\"type\":\"main\",\"index\":0}]]},\"GET models\":{\"main\":[[{\"node\":\"Github Models\",\"type\":\"main\",\"index\":0}]]},\"n8n Webhooks\":{\"ai_languageModel\":[[{\"node\":\"Powered By Github Models\",\"type\":\"ai_languageModel\",\"index\":0}]]},\"Github Models\":{\"main\":[[{\"node\":\"Aggregate\",\"type\":\"main\",\"index\":0}]]},\"POST ChatCompletions\":{\"main\":[[{\"node\":\"Github Chat Completions\",\"type\":\"main\",\"index\":0}]]},\"Github Chat Completions\":{\"main\":[[{\"node\":\"Is Agent?\",\"type\":\"main\",\"index\":0}]]},\"When chat message received\":{\"main\":[[{\"node\":\"Powered By Github Models\",\"type\":\"main\",\"index\":0}]]}}}",
  "readme": "### This n8n template shows you how to connect [Github's Free Models](https://docs.github.com/en/github-models) to your existing n8n AI workflows.\n\nWhilst it is possible to use HTTP nodes to access Github Models, The aim of this template is to use it with existing n8n LLM nodes - saves the trouble of refactoring!\n\nPlease note, Github states their model APIs are not intended for production usage! If you need higher rate limits, you'll need to use a paid service.\n\n### How it works\n\n  * The approach builds a custom OpenAI compatible API around the Github Models API - all done in n8n!\n  * First, we attach an OpenAI subnode to our LLM node and configure a new OpenAI credential.\n  * Within this new OpenAI credential, we change the \"Base URL\" to point at a n8n webhook we've prepared as part of this template.\n  * Next, we create 2 webhooks which the LLM node will now attempt to connect with: \"models\" and \"chat completion\".\n  * The \"models\" webhook simply calls the Github Model's \"list all models\" endpoint and remaps the response to be compatible with our LLM node.\n  * The \"Chat Completion\" webhook does a similar task with Github's Chat Completion endpoint.\n\n\n\n### How to use\n\n  * Once connected, just open chat and ask away!\n  * Any LLM or AI agent node connected with this custom LLM subnode will send requests to the Github Models API. Allowing your to try out a range of SOTA models for free.\n\n\n\n### Requirements\n\n  * Github account and credentials for access to Models. If you've used the Github node previously, you can reuse this credential for this template.\n\n\n\n### Customising this workflow\n\n  * This template is just an example. Use the custom OpenAI credential for your other workflows to test Github models.\n\n\n\n### References\n\n  * <https://docs.github.com/en/github-models/prototyping-with-ai-models>\n  * <https://docs.github.com/en/github-models>\n\n\n",
  "crawled_at": "2025-05-26T07:19:21.979826",
  "readme_zh": "### 本n8n模板演示如何将[Github免费模型](https://docs.github.com/en/github-models)接入现有n8n AI工作流\n\n虽然可通过HTTP节点访问Github模型，但本模板旨在与现有n8n LLM节点直接兼容——省去重构麻烦！\n\n请注意：Github声明其模型API不适用于生产环境！如需更高调用限额，请使用付费服务。\n\n### 实现原理\n\n* 通过n8n构建与OpenAI兼容的自定义API层对接Github模型API\n* 首先在LLM节点添加OpenAI子节点，配置新OpenAI凭证\n* 在该凭证中将\"Base URL\"指向模板预置的n8n webhook\n* 随后创建两个webhook供LLM节点调用：\"models\"与\"chat completion\"\n* \"models\" webhook调用Github模型列表接口并重构响应格式\n* \"Chat Completion\" webhook同理处理Github的对话补全接口\n\n### 使用方法\n\n* 连接成功后即可直接开启对话\n* 所有配置此自定义LLM子节点的AI代理都将请求转发至Github模型API，免费体验前沿模型\n\n### 前提条件\n\n* 需持有Github账号及模型访问凭证（可复用现有Github节点凭证）\n\n### 定制扩展\n\n* 本模板仅作示例，可将自定义OpenAI凭证应用于其他工作流测试Github模型\n\n### 参考文档\n\n* <https://docs.github.com/en/github-models/prototyping-with-ai-models>\n* <https://docs.github.com/en/github-models>",
  "title_zh": "利用GitHub模型创建兼容OpenAI的API以实现免费AI访问",
  "publish_date_zh": "最后更新于6天前",
  "workflow_json_zh": "{\n  \"meta\": {\n    \"instanceId\": \"408f9fb9940c3cb18ffdef0e0150fe342d6e655c3a9fac21f0f644e8bedabcd9\",\n    \"templateCredsSetupCompleted\": true\n  },\n  \"nodes\": [\n    {\n      \"id\": \"f8831a38-92ef-44e5-99dd-0f410e9c0883\",\n      \"name\": \"Aggregate\",\n      \"type\": \"n8n-nodes-base.aggregate\",\n      \"position\": [\n        440,\n        260\n      ],\n      \"parameters\": {\n        \"options\": {},\n        \"aggregate\": \"aggregateAllItemData\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"7c51c3f5-3d2f-4d7d-8fd8-30641b1b9516\",\n      \"name\": \"Github Models\",\n      \"type\": \"n8n-nodes-base.httpRequest\",\n      \"position\": [\n        240,\n        260\n      ],\n      \"parameters\": {\n        \"url\": \"https://models.github.ai/catalog/models\",\n        \"options\": {\n          \"redirect\": {\n            \"redirect\": {}\n          }\n        },\n        \"sendHeaders\": true,\n        \"authentication\": \"predefinedCredentialType\",\n        \"headerParameters\": {\n          \"parameters\": [\n            {\n              \"name\": \"Accept\",\n              \"value\": \"application/vnd.github+json\"\n            },\n            {\n              \"name\": \"X-GitHub-Api-Version\",\n              \"value\": \"2022-11-28\"\n            }\n          ]\n        },\n        \"nodeCredentialType\": \"githubApi\"\n      },\n      \"credentials\": {\n        \"githubApi\": {\n          \"id\": \"kA70YRmLeHDqZbXA\",\n          \"name\": \"GitHub account\"\n        }\n      },\n      \"typeVersion\": 4.2\n    },\n    {\n      \"id\": \"c9602915-e903-4891-b131-68b3190f637b\",\n      \"name\": \"Github Chat Completions\",\n      \"type\": \"n8n-nodes-base.httpRequest\",\n      \"position\": [\n        1120,\n        320\n      ],\n      \"parameters\": {\n        \"url\": \"https://models.github.ai/inference/chat/completions\",\n        \"method\": \"POST\",\n        \"options\": {\n          \"redirect\": {\n            \"redirect\": {}\n          }\n        },\n        \"jsonBody\": \"={{\\n{\\n  model: $json.body.model,\\n  messages: $json.body.messages,\\n  stream: $json.body.stream\\n}\\n}}\",\n        \"sendBody\": true,\n        \"sendHeaders\": true,\n        \"specifyBody\": \"json\",\n        \"authentication\": \"predefinedCredentialType\",\n        \"headerParameters\": {\n          \"parameters\": [\n            {\n              \"name\": \"Accept\",\n              \"value\": \"application/vnd.github+json\"\n            },\n            {\n              \"name\": \"X-GitHub-Api-Version\",\n              \"value\": \"2022-11-28\"\n            }\n          ]\n        },\n        \"nodeCredentialType\": \"githubApi\"\n      },\n      \"credentials\": {\n        \"githubApi\": {\n          \"id\": \"kA70YRmLeHDqZbXA\",\n          \"name\": \"GitHub account\"\n        }\n      },\n      \"typeVersion\": 4.2\n    },\n    {\n      \"id\": \"ccdfc4f2-53dd-409b-9887-6e191374e23c\",\n      \"name\": \"n8n Webhooks\",\n      \"type\": \"@n8n/n8n-nodes-langchain.lmChatOpenAi\",\n      \"position\": [\n        320,\n        -160\n      ],\n      \"parameters\": {\n        \"model\": {\n          \"__rl\": true,\n          \"mode\": \"list\",\n          \"value\": \"openai/gpt-4o-mini\",\n          \"cachedResultName\": \"openai/gpt-4o-mini\"\n        },\n        \"options\": {}\n      },\n      \"credentials\": {\n        \"openAiApi\": {\n          \"id\": \"8VVdMPbWsLxTlgC0\",\n          \"name\": \"n8n-router\"\n        }\n      },\n      \"typeVersion\": 1.2\n    },\n    {\n      \"id\": \"29ed818b-fb54-4b55-b5ac-1d5220222558\",\n      \"name\": \"Chat Response\",\n      \"type\": \"n8n-nodes-base.respondToWebhook\",\n      \"position\": [\n        1540,\n        400\n      ],\n      \"parameters\": {\n        \"options\": {},\n        \"respondWith\": \"json\",\n        \"responseBody\": \"={{ $json }}\"\n      },\n      \"typeVersion\": 1.2\n    },\n    {\n      \"id\": \"3c36a5c8-28da-4656-aa9d-8593926b3e77\",\n      \"name\": \"Models Response\",\n      \"type\": \"n8n-nodes-base.respondToWebhook\",\n      \"position\": [\n        640,\n        260\n      ],\n      \"parameters\": {\n        \"options\": {},\n        \"respondWith\": \"json\",\n        \"responseBody\": \"={{\\n({\\n  \\\"object\\\": \\\"list\\\",\\n  \\\"data\\\":  $json.data.map(item => ({\\n    \\\"id\\\": item.id,\\n    \\\"object\\\": \\\"model\\\",\\n    \\\"created\\\": 1733945430,\\n    \\\"owned_by\\\": \\\"system\\\"\\n  }))\\n})\\n}}\"\n      },\n      \"executeOnce\": false,\n      \"typeVersion\": 1.2\n    },\n    {\n      \"id\": \"3c1efb37-c04c-4426-acde-690dbaf54183\",\n      \"name\": \"Powered By Github Models\",\n      \"type\": \"@n8n/n8n-nodes-langchain.chainLlm\",\n      \"position\": [\n        240,\n        -340\n      ],\n      \"parameters\": {},\n      \"typeVersion\": 1.6\n    },\n    {\n      \"id\": \"704e5aae-bda3-4238-b770-f3a1d2732311\",\n      \"name\": \"When chat message received\",\n      \"type\": \"@n8n/n8n-nodes-langchain.chatTrigger\",\n      \"position\": [\n        40,\n        -340\n      ],\n      \"webhookId\": \"6ec7783c-8f47-4fdf-9838-7846b1da4bfa\",\n      \"parameters\": {\n        \"options\": {}\n      },\n      \"typeVersion\": 1.1\n    },\n    {\n      \"id\": \"ed87f51d-c2bd-43c4-aabb-4f92b12b82f3\",\n      \"name\": \"Sticky Note\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"position\": [\n        560,\n        -240\n      ],\n      \"parameters\": {\n        \"color\": 5,\n        \"width\": 520,\n        \"height\": 220,\n        \"content\": \"### 通过N8N Webhook接入LLM模型\\n1. 新建OpenAI凭证并命名为\\\"n8n-webhook\\\"\\n2. API密钥可随意填写（如\\\"12345\\\"）\\n3. 基础URL设置为\\\"https://<你的n8n域名>/webhook/github-models\\\"\\n4. 激活工作流！注意此功能仅在生产环境webhook URL下有效\\n\\n（所有命名均可自定义，只需确保LLM节点能正常访问该接口即可）\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"c28b03cb-bd1b-41d5-ba1b-486a099afb92\",\n      \"name\": \"GET models\",\n      \"type\": \"n8n-nodes-base.webhook\",\n      \"position\": [\n        40,\n        260\n      ],\n      \"webhookId\": \"f88b9992-b7b9-4ab5-829c-7b89e9cc4775\",\n      \"parameters\": {\n        \"path\": \"github-models/models\",\n        \"options\": {},\n        \"responseMode\": \"responseNode\"\n      },\n      \"typeVersion\": 2\n    },\n    {\n      \"id\": \"02cb7e26-f992-4444-a886-dcaea1dbb63c\",\n      \"name\": \"POST ChatCompletions\",\n      \"type\": \"n8n-nodes-base.webhook\",\n      \"position\": [\n        920,\n        320\n      ],\n      \"webhookId\": \"e8c56164-1825-4ac4-9c23-d209f4907458\",\n      \"parameters\": {\n        \"path\": \"github-models/chat/completions\",\n        \"options\": {},\n        \"httpMethod\": \"POST\",\n        \"responseMode\": \"responseNode\"\n      },\n      \"typeVersion\": 2\n    },\n    {\n      \"id\": \"be0e06be-2b0d-4167-ad70-84d188f5ca68\",\n      \"name\": \"Sticky Note1\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"position\": [\n        -20,\n        -560\n      ],\n      \"parameters\": {\n        \"color\": 7,\n        \"width\": 680,\n        \"height\": 580,\n        \"content\": \"## 1. 创建新的自定义OpenAI凭证  \\n[了解更多关于OpenAI凭证的信息](https://docs.n8n.io/integrations/builtin/credentials/openai/)  \\n\\n要在现有n8n节点中使用Github模型，一种方法是模拟通过OpenAI模型子节点连接的兼容API。听起来复杂但别担心，本模板将为您演示！第一步是设置一个新的OpenAI凭证，以便我们可以修改基础URL。\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"855c24f5-0758-4344-b780-523383b51de1\",\n      \"name\": \"Sticky Note2\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"position\": [\n        -20,\n        60\n      ],\n      \"parameters\": {\n        \"color\": 7,\n        \"width\": 840,\n        \"height\": 420,\n        \"content\": \"## 2. 列出所有可用模型\\n[详细了解Webhook触发器节点](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.webhook/)\\n\\n我们的第一个端点用于列出所有模型。Github Models API展示了如何实现此功能，但需要对响应进行重新映射以使其与我们的LLM节点兼容。\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"d5f0446d-2e59-47ee-a442-f66490d8759d\",\n      \"name\": \"Sticky Note3\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"position\": [\n        840,\n        60\n      ],\n      \"parameters\": {\n        \"color\": 7,\n        \"width\": 920,\n        \"height\": 540,\n        \"content\": \"## 3. 请求聊天补全  \\n[详细了解HTTP请求节点](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.httprequest)  \\n\\n我们的第二个端点用于执行聊天补全。请注意，根据是否已连接代理，预期响应为\\\"流\\\"形式，且返回数据需为`text/plain`类型。\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"e8a13b04-fd51-4031-90f3-7088871e6dfd\",\n      \"name\": \"Sticky Note4\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"position\": [\n        -520,\n        -560\n      ],\n      \"parameters\": {\n        \"width\": 420,\n        \"height\": 1280,\n        \"content\": \"## 动手试试吧！\\n### 本n8n模板演示如何将[Github免费模型](https://docs.github.com/en/github-models)接入现有n8n AI工作流\\n\\n虽然通过HTTP节点也能调用Github模型，但本模板旨在与n8n现有LLM节点无缝衔接——省去重构麻烦！\\n\\n请注意：Github声明其模型API不适用于生产环境！如需更高调用频次，请使用付费服务。\\n\\n### 实现原理\\n* 通过n8n构建兼容OpenAI的自定义API层对接Github模型API\\n* 首先为LLM节点添加OpenAI子节点，配置新的OpenAI凭证\\n* 在该凭证中将\\\"Base URL\\\"指向模板预置的n8n webhook\\n* 随后创建两个关键webhook：\\\"模型列表\\\"与\\\"对话补全\\\"\\n* \\\"模型列表\\\"webhook调用Github模型枚举接口并重构响应格式\\n* \\\"对话补全\\\"webhook同理适配Github的对话补全端点\\n\\n### 使用指南\\n* 完成配置后，直接开启对话即可体验！\\n* 所有连接该自定义LLM子节点的AI代理都将请求转发至Github模型API，免费体验前沿模型\\n\\n### 前提条件\\n* 需具备Github账号及模型访问凭证（若曾使用过Github节点，可复用原有凭证）\\n\\n### 定制扩展\\n* 本模板仅为示例，可将自定义OpenAI凭证应用于其他工作流测试Github模型\\n\\n### 参考文档\\n* [https://docs.github.com/en/github-models/prototyping-with-ai-models](https://docs.github.com/zh/github-models/prototyping-with-ai-models)\\n* [https://docs.github.com/en/github-models](https://docs.github.com/zh/github-models)\\n\\n### 获取帮助\\n加入[Discord社区](https://discord.com/invite/XPKeKXeB7d)或访问[官方论坛](https://community.n8n.io/)！\\n\\n祝您探索愉快！\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"2a75f35d-695f-425d-8b8e-425c9075c702\",\n      \"name\": \"Is Agent?\",\n      \"type\": \"n8n-nodes-base.if\",\n      \"position\": [\n        1320,\n        320\n      ],\n      \"parameters\": {\n        \"options\": {},\n        \"conditions\": {\n          \"options\": {\n            \"version\": 2,\n            \"leftValue\": \"\",\n            \"caseSensitive\": true,\n            \"typeValidation\": \"strict\"\n          },\n          \"combinator\": \"and\",\n          \"conditions\": [\n            {\n              \"id\": \"213702bf-d5c2-4a8a-b5c8-e55f804e4496\",\n              \"operator\": {\n                \"type\": \"boolean\",\n                \"operation\": \"true\",\n                \"singleValue\": true\n              },\n              \"leftValue\": \"={{ $('POST ChatCompletions').first().json.body.stream }}\",\n              \"rightValue\": \"\"\n            }\n          ]\n        }\n      },\n      \"typeVersion\": 2.2\n    },\n    {\n      \"id\": \"31e0325d-ef82-40af-862b-9dcffbf650e6\",\n      \"name\": \"Agent Response\",\n      \"type\": \"n8n-nodes-base.respondToWebhook\",\n      \"position\": [\n        1540,\n        240\n      ],\n      \"parameters\": {\n        \"options\": {},\n        \"respondWith\": \"text\",\n        \"responseBody\": \"={{ $json.data }}\"\n      },\n      \"typeVersion\": 1.2\n    }\n  ],\n  \"pinData\": {},\n  \"connections\": {\n    \"Aggregate\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Models Response\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Is Agent?\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Agent Response\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ],\n        [\n          {\n            \"node\": \"Chat Response\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"GET models\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Github Models\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"n8n Webhooks\": {\n      \"ai_languageModel\": [\n        [\n          {\n            \"node\": \"Powered By Github Models\",\n            \"type\": \"ai_languageModel\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Github Models\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Aggregate\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"POST ChatCompletions\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Github Chat Completions\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Github Chat Completions\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Is Agent?\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"When chat message received\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Powered By Github Models\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    }\n  }\n}"
}