{
  "url": "https://n8n.io/workflows/2812-scrape-any-web-page-into-structured-json-data-with-scrapeninja-and-ai/",
  "title": "Scrape any web page into structured JSON data with ScrapeNinja and AI",
  "author": "Anthony",
  "publish_date": "Last update 4 months ago",
  "publish_date_absolute": "2025-01-26",
  "categories": [],
  "workflow_json": "{\"id\":\"ALTwr1xWxmqGdCtZ\",\"meta\":{\"instanceId\":\"5b860a91d7844b5237bb51cc58691ca8c3dc5b576f42d4d6bbedfb8d43d58ece\",\"templateCredsSetupCompleted\":true},\"name\":\"ScrapeNinja: AI generated web scraper\",\"tags\":[],\"nodes\":[{\"id\":\"9dd743dd-4ee6-4aaf-820d-7e63ea31399c\",\"name\":\"ScrapeNinja\",\"type\":\"CUSTOM.scrapeNinja\",\"position\":[200,0],\"parameters\":{\"url\":\"https://news.ycombinator.com/\"},\"credentials\":{\"scrapeNinjaApi\":{\"id\":\"u7avPyHEwhTrfQX5\",\"name\":\"ScrapeNinja account\"}},\"typeVersion\":1},{\"id\":\"fbfe223d-e37f-473d-96c5-a5e89b19e2fc\",\"name\":\"Google Gemini Chat Model\",\"type\":\"@n8n/n8n-nodes-langchain.lmChatGoogleGemini\",\"position\":[680,280],\"parameters\":{\"options\":{},\"modelName\":\"models/gemini-exp-1206\"},\"credentials\":{\"googlePalmApi\":{\"id\":\"hojczN24FieC3tSg\",\"name\":\"Google Gemini(PaLM) Api account\"}},\"typeVersion\":1},{\"id\":\"75a9b517-f51e-4b84-90d5-d9352f5185cc\",\"name\":\"Generate custom web scraper\",\"type\":\"n8n-nodes-base.manualTrigger\",\"position\":[0,0],\"parameters\":{},\"typeVersion\":1},{\"id\":\"c1e4e096-ae88-45d4-aed0-d7b92b496b5a\",\"name\":\"Cleanup HTML\",\"type\":\"CUSTOM.scrapeNinja\",\"position\":[420,0],\"parameters\":{\"html\":\"={{ $json.body }}\",\"operation\":\"cleanup-html\"},\"typeVersion\":1},{\"id\":\"dccb1015-ce34-4c4c-b556-a31de8639baf\",\"name\":\"Generate JS eval code via LLM\",\"type\":\"@n8n/n8n-nodes-langchain.chainLlm\",\"position\":[640,0],\"parameters\":{\"text\":\"=write cheerio.js function to news items. your response MUST start with:\\n\\nfunction extract(html, cheerioInstance) {\\n// use cheerio to load html...\\n\\nreturn [{ url: \\\"item1\\\", \\\"title\\\": \\\"xxx\\\", \\\"score\\\": \\\"5\\\", comments: 6 }, ... ]\\n}\\ndo not use new URL() because this wont work in my env.\\nhtml:\\n{{ $json.html }}\",\"promptType\":\"define\"},\"typeVersion\":1.5},{\"id\":\"71c03255-9bb8-4ce8-b191-7b163326aa41\",\"name\":\"Eval generated code to extract data\",\"type\":\"CUSTOM.scrapeNinja\",\"position\":[1000,0],\"parameters\":{\"html\":\"={{ $('Cleanup HTML').item.json.html }}\",\"operation\":\"extract-custom\",\"extractionFunction\":\"={{ $json.text }}\"},\"typeVersion\":1}],\"active\":false,\"pinData\":{},\"settings\":{\"executionOrder\":\"v1\"},\"versionId\":\"2a2dd735-e805-4fda-8a1c-b0c6144e0804\",\"connections\":{\"ScrapeNinja\":{\"main\":[[{\"node\":\"Cleanup HTML\",\"type\":\"main\",\"index\":0}]]},\"Cleanup HTML\":{\"main\":[[{\"node\":\"Generate JS eval code via LLM\",\"type\":\"main\",\"index\":0}]]},\"Google Gemini Chat Model\":{\"ai_languageModel\":[[{\"node\":\"Generate JS eval code via LLM\",\"type\":\"ai_languageModel\",\"index\":0}]]},\"Generate custom web scraper\":{\"main\":[[{\"node\":\"ScrapeNinja\",\"type\":\"main\",\"index\":0}]]},\"Generate JS eval code via LLM\":{\"main\":[[{\"node\":\"Eval generated code to extract data\",\"type\":\"main\",\"index\":0}]]},\"Eval generated code to extract data\":{\"main\":[[]]}}}",
  "readme": "Disclaimer: This template only works on self-hosted for now, as it uses a community node.\n\n## Use Case\n\nWeb scrapers often break due to web page layout changes.  \nThis workflow attempts to mitigate this problem by auto-generating web scraping data extractor code via LLM.\n\n## How It Works\n\nThis workflow leverages ScrapeNinja n8n community node to:\n\n  * scrape webpage HTML,\n  * feed it into LLM (Google Gemini) and ask to write a JS extractor function code, then it\n  * executes the written JS extractor against scraped HTML to extract useful data from webpage (the code is safely executed in a sandbox)\n\n\n\n## Installation\n\nTo install ScrapeNinja n8n node, in your self-hosted instance, go to Settings -> Community nodes, enter \"n8n-nodes-scrapeninja\", and install.\n\nMake sure you are using at least v0.3.0.\n\nSee this in action:  \n<https://www.linkedin.com/feed/update/urn:li:activity:7289659870935490560/>\n",
  "crawled_at": "2025-05-26T02:04:34.843743",
  "readme_zh": "免责声明：此模板目前仅适用于自托管环境，因其使用了社区节点。\n\n## 应用场景\n\n网页爬虫常因页面布局变动失效。  \n本工作流通过LLM自动生成网页数据提取代码，尝试解决这一问题。\n\n## 运行原理\n\n该工作流利用ScrapeNinja的n8n社区节点实现：\n  * 抓取网页HTML\n  * 输入至LLM（Google Gemini）生成JS提取函数代码\n  * 在沙箱环境中安全执行生成的代码，从网页HTML中提取有效数据\n\n## 安装指南\n\n在自托管实例中安装ScrapeNinja节点：  \n进入Settings -> Community nodes，输入\"n8n-nodes-scrapeninja\"进行安装。  \n请确保使用v0.3.0及以上版本。\n\n实际效果演示：  \n<https://www.linkedin.com/feed/update/urn:li:activity:7289659870935490560/>",
  "title_zh": "使用ScrapeNinja和AI将任何网页抓取为结构化JSON数据",
  "publish_date_zh": "最后更新于4个月前",
  "workflow_json_zh": "{\"id\":\"ALTwr1xWxmqGdCtZ\",\"meta\":{\"instanceId\":\"5b860a91d7844b5237bb51cc58691ca8c3dc5b576f42d4d6bbedfb8d43d58ece\",\"templateCredsSetupCompleted\":true},\"name\":\"ScrapeNinja: AI generated web scraper\",\"tags\":[],\"nodes\":[{\"id\":\"9dd743dd-4ee6-4aaf-820d-7e63ea31399c\",\"name\":\"ScrapeNinja\",\"type\":\"CUSTOM.scrapeNinja\",\"position\":[200,0],\"parameters\":{\"url\":\"https://news.ycombinator.com/\"},\"credentials\":{\"scrapeNinjaApi\":{\"id\":\"u7avPyHEwhTrfQX5\",\"name\":\"ScrapeNinja account\"}},\"typeVersion\":1},{\"id\":\"fbfe223d-e37f-473d-96c5-a5e89b19e2fc\",\"name\":\"Google Gemini Chat Model\",\"type\":\"@n8n/n8n-nodes-langchain.lmChatGoogleGemini\",\"position\":[680,280],\"parameters\":{\"options\":{},\"modelName\":\"models/gemini-exp-1206\"},\"credentials\":{\"googlePalmApi\":{\"id\":\"hojczN24FieC3tSg\",\"name\":\"Google Gemini(PaLM) Api account\"}},\"typeVersion\":1},{\"id\":\"75a9b517-f51e-4b84-90d5-d9352f5185cc\",\"name\":\"Generate custom web scraper\",\"type\":\"n8n-nodes-base.manualTrigger\",\"position\":[0,0],\"parameters\":{},\"typeVersion\":1},{\"id\":\"c1e4e096-ae88-45d4-aed0-d7b92b496b5a\",\"name\":\"Cleanup HTML\",\"type\":\"CUSTOM.scrapeNinja\",\"position\":[420,0],\"parameters\":{\"html\":\"={{ $json.body }}\",\"operation\":\"cleanup-html\"},\"typeVersion\":1},{\"id\":\"dccb1015-ce34-4c4c-b556-a31de8639baf\",\"name\":\"Generate JS eval code via LLM\",\"type\":\"@n8n/n8n-nodes-langchain.chainLlm\",\"position\":[640,0],\"parameters\":{\"text\":\"=write cheerio.js function to news items. your response MUST start with:\\n\\nfunction extract(html, cheerioInstance) {\\n// use cheerio to load html...\\n\\nreturn [{ url: \\\"item1\\\", \\\"title\\\": \\\"xxx\\\", \\\"score\\\": \\\"5\\\", comments: 6 }, ... ]\\n}\\ndo not use new URL() because this wont work in my env.\\nhtml:\\n{{ $json.html }}\",\"promptType\":\"define\"},\"typeVersion\":1.5},{\"id\":\"71c03255-9bb8-4ce8-b191-7b163326aa41\",\"name\":\"Eval generated code to extract data\",\"type\":\"CUSTOM.scrapeNinja\",\"position\":[1000,0],\"parameters\":{\"html\":\"={{ $('Cleanup HTML').item.json.html }}\",\"operation\":\"extract-custom\",\"extractionFunction\":\"={{ $json.text }}\"},\"typeVersion\":1}],\"active\":false,\"pinData\":{},\"settings\":{\"executionOrder\":\"v1\"},\"versionId\":\"2a2dd735-e805-4fda-8a1c-b0c6144e0804\",\"connections\":{\"ScrapeNinja\":{\"main\":[[{\"node\":\"Cleanup HTML\",\"type\":\"main\",\"index\":0}]]},\"Cleanup HTML\":{\"main\":[[{\"node\":\"Generate JS eval code via LLM\",\"type\":\"main\",\"index\":0}]]},\"Google Gemini Chat Model\":{\"ai_languageModel\":[[{\"node\":\"Generate JS eval code via LLM\",\"type\":\"ai_languageModel\",\"index\":0}]]},\"Generate custom web scraper\":{\"main\":[[{\"node\":\"ScrapeNinja\",\"type\":\"main\",\"index\":0}]]},\"Generate JS eval code via LLM\":{\"main\":[[{\"node\":\"Eval generated code to extract data\",\"type\":\"main\",\"index\":0}]]},\"Eval generated code to extract data\":{\"main\":[[]]}}}"
}