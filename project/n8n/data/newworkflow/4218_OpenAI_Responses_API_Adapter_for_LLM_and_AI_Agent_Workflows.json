{
  "url": "https://n8n.io/workflows/4218-openai-responses-api-adapter-for-llm-and-ai-agent-workflows/",
  "title": "OpenAI Responses API Adapter for LLM and AI Agent Workflows",
  "author": "Jimleuk",
  "publish_date": "Last update 6 days ago",
  "publish_date_absolute": "2025-05-20",
  "categories": [
    {
      "name": "Engineering"
    },
    {
      "name": "AI"
    }
  ],
  "workflow_json": "{\"meta\":{\"instanceId\":\"408f9fb9940c3cb18ffdef0e0150fe342d6e655c3a9fac21f0f644e8bedabcd9\",\"templateCredsSetupCompleted\":true},\"nodes\":[{\"id\":\"8531ff8a-b247-4baa-a85b-11512fc2bb60\",\"name\":\"When chat message received\",\"type\":\"@n8n/n8n-nodes-langchain.chatTrigger\",\"position\":[-320,-500],\"webhookId\":\"f24f59f8-7ea5-4165-be02-d47bdcae52fa\",\"parameters\":{\"public\":true,\"options\":{\"allowFileUploads\":true}},\"typeVersion\":1.1},{\"id\":\"a039b516-a74a-4ea6-8583-abec9bf2a1f8\",\"name\":\"AI Agent\",\"type\":\"@n8n/n8n-nodes-langchain.agent\",\"position\":[-120,-500],\"parameters\":{\"options\":{\"passthroughBinaryImages\":true,\"returnIntermediateSteps\":true}},\"typeVersion\":1.9},{\"id\":\"454a16ea-9bcf-4cb8-a62d-95a1aedea974\",\"name\":\"Webhook\",\"type\":\"n8n-nodes-base.webhook\",\"position\":[-320,160],\"webhookId\":\"211b7574-f96a-429e-a2bf-c19c0fec5e9e\",\"parameters\":{\"path\":\"n8n-responses-api/models\",\"options\":{},\"responseMode\":\"responseNode\"},\"typeVersion\":2},{\"id\":\"3fca113b-f259-4495-a52c-89f3c09748c0\",\"name\":\"OpenAI Models\",\"type\":\"n8n-nodes-base.httpRequest\",\"position\":[-100,160],\"parameters\":{\"url\":\"https://api.openai.com/v1/models\",\"options\":{},\"authentication\":\"predefinedCredentialType\",\"nodeCredentialType\":\"openAiApi\"},\"credentials\":{\"openAiApi\":{\"id\":\"8gccIjcuf3gvaoEr\",\"name\":\"OpenAi account\"}},\"typeVersion\":4.2},{\"id\":\"bee5a8d3-e18a-4756-99ea-7d14fa08e2f5\",\"name\":\"POST ChatCompletions\",\"type\":\"n8n-nodes-base.webhook\",\"position\":[460,240],\"webhookId\":\"e8c56164-1825-4ac4-9c23-d209f4907458\",\"parameters\":{\"path\":\"n8n-responses-api/chat/completions\",\"options\":{},\"httpMethod\":\"POST\",\"responseMode\":\"responseNode\"},\"typeVersion\":2},{\"id\":\"974fd565-c1cf-468a-827f-391bd013e145\",\"name\":\"Models Response\",\"type\":\"n8n-nodes-base.respondToWebhook\",\"position\":[120,160],\"parameters\":{\"options\":{\"responseCode\":200,\"responseHeaders\":{\"entries\":[{\"name\":\"Content-Type\",\"value\":\"application/json\"}]}},\"respondWith\":\"json\",\"responseBody\":\"={{ $json }}\"},\"typeVersion\":1.2},{\"id\":\"6a4bfb20-5562-4500-9ee2-521f848d3825\",\"name\":\"Remap to Response API Schema\",\"type\":\"n8n-nodes-base.code\",\"position\":[680,240],\"parameters\":{\"mode\":\"runOnceForEachItem\",\"jsCode\":\"function tranformContent(content) {\\n  return [].concat(content).map(content => {\\n    if (typeof content === 'string') {\\n      return { type: \\\"input_text\\\", text: content };\\n    }\\n    return {\\n      type: getInputType(content.type),\\n      [content.type]: content[content.type].url\\n    }\\n  })\\n};\\n\\nfunction getInputType(type) {\\n  if (type === 'image_url') return 'input_image';\\n  if (type === 'file_url') return 'input_file';\\n  return 'input_text';\\n}\\n\\nconst input = $input.item.json.body.messages.map(message => ({\\n  role: message.role,\\n  content: tranformContent(message.content)\\n}));\\n\\nreturn { input };\"},\"typeVersion\":2},{\"id\":\"5f4f22c9-f333-469c-a915-8f5da6443e53\",\"name\":\"OpenAI Responses API\",\"type\":\"n8n-nodes-base.httpRequest\",\"position\":[900,240],\"parameters\":{\"url\":\"https://api.openai.com/v1/responses\",\"method\":\"POST\",\"options\":{},\"jsonBody\":\"={{\\n{\\n  model: $('POST ChatCompletions').first().json.body.model,\\n  stream: $('POST ChatCompletions').first().json.body.stream,\\n  input: $json.input,\\n}\\n}}\",\"sendBody\":true,\"specifyBody\":\"json\",\"authentication\":\"predefinedCredentialType\",\"nodeCredentialType\":\"openAiApi\"},\"credentials\":{\"openAiApi\":{\"id\":\"8gccIjcuf3gvaoEr\",\"name\":\"OpenAi account\"}},\"typeVersion\":4.2},{\"id\":\"5242a76d-9649-469b-ba91-e33d0f42850e\",\"name\":\"Is Agent?\",\"type\":\"n8n-nodes-base.if\",\"position\":[1100,240],\"parameters\":{\"options\":{},\"conditions\":{\"options\":{\"version\":2,\"leftValue\":\"\",\"caseSensitive\":true,\"typeValidation\":\"strict\"},\"combinator\":\"and\",\"conditions\":[{\"id\":\"213702bf-d5c2-4a8a-b5c8-e55f804e4496\",\"operator\":{\"type\":\"boolean\",\"operation\":\"true\",\"singleValue\":true},\"leftValue\":\"={{ $('POST ChatCompletions').first().json.body.stream }}\",\"rightValue\":\"\"}]}},\"typeVersion\":2.2},{\"id\":\"4ecc0ec2-4637-48d9-9157-0a6dc39bab9e\",\"name\":\"n8n Webhook\",\"type\":\"@n8n/n8n-nodes-langchain.lmChatOpenAi\",\"position\":[-140,-320],\"parameters\":{\"model\":{\"__rl\":true,\"mode\":\"list\",\"value\":\"gpt-4o-mini\"},\"options\":{}},\"credentials\":{\"openAiApi\":{\"id\":\"PeoQjbPq9TxC5Fnf\",\"name\":\"n8n Document Understanding\"}},\"typeVersion\":1.2},{\"id\":\"d050bfc1-ce7a-4ae2-b4b1-763be76b8061\",\"name\":\"Sticky Note1\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[-400,-740],\"parameters\":{\"color\":7,\"width\":700,\"height\":580,\"content\":\"## 1. Create a New Custom OpenAI Credential\\n[Learn more about OpenAI Credentials](https://docs.n8n.io/integrations/builtin/credentials/openai/)\\n\\nTo use Github Models with our existing n8n nodes, one approach is to mimic an openAI compatible API connected through the OpenAI model subnode. Sounds complicated but don't worry, this template shows you how! The first step is to setup a new OpenAI credential so that we can change the Base URL.\"},\"typeVersion\":1},{\"id\":\"7703f756-652b-44e4-81b3-021323b08e18\",\"name\":\"Sticky Note\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[180,-380],\"parameters\":{\"color\":5,\"width\":540,\"height\":240,\"content\":\"### LLM Models via N8N Webhooks\\n1. Create a new OpenAI Credential and call it \\\"n8n-responses-api\\\"\\n2. Enter API key as anything you like eg. \\\"12345\\\"\\n3. Enter Base URL as \\\"https://<your_n8n_url>/webhook/n8n-reponses-api\\\"\\n4. Activate your workflow! This only really works with the production webhook URL.\\n\\n\\nFeel free to change the names to whatever you want, just make sure the LLM node is able to reach it!\"},\"typeVersion\":1},{\"id\":\"a6bc3bcc-d1e9-4d7a-947b-faeddda59507\",\"name\":\"Sticky Note2\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[-400,-40],\"parameters\":{\"color\":7,\"width\":740,\"height\":420,\"content\":\"## 2. Listing All Available Models \\n[Read more about the Webhook Trigger node](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.webhook/)\\n\\nOur first endpoint is for listing all models. The Github Models API how we can do this but the response requires some re-mapping to make it compatible with our LLM node.\"},\"typeVersion\":1},{\"id\":\"54e0b20a-1a3d-4068-b76a-9b6d10fa0fc2\",\"name\":\"Format Completion Response\",\"type\":\"n8n-nodes-base.code\",\"position\":[1320,340],\"parameters\":{\"mode\":\"runOnceForEachItem\",\"jsCode\":\"return {\\n  \\\"id\\\": $json.id,\\n  \\\"object\\\": \\\"chat.completion\\\",\\n  \\\"created\\\": $json.created_at,\\n  \\\"model\\\": $json.model,\\n  \\\"choices\\\": $json.output.flatMap((item,idx) => (\\n    item.content.map((content) => ({\\n      index: idx,\\n      finish_reason: \\\"stop\\\",\\n      \\\"message\\\": {\\n        \\\"annotations\\\": content.annotations,\\n        \\\"content\\\": content.text,\\n        \\\"refusal\\\": null,\\n        \\\"role\\\": item.role\\n      }\\n    }))\\n  )),\\n  \\\"usage\\\": {\\n    \\\"completion_tokens\\\": $json.usage.output_tokens,\\n    \\\"completion_tokens_details\\\": $json.usage.output_tokens_details,\\n    \\\"prompt_tokens\\\": $json.usage.input_tokens_details,\\n    \\\"prompt_tokens_details\\\": $json.usage.input_tokens_details,\\n    \\\"total_tokens\\\": $json.usage.total_tokens\\n  },\\n  \\\"service_tier\\\": $json.service_tier,\\n  \\\"system_fingerprint\\\": $json.id\\n}\"},\"typeVersion\":2},{\"id\":\"a7f2daa8-b4be-4571-b210-3d7ffd7481a3\",\"name\":\"JSON Response\",\"type\":\"n8n-nodes-base.respondToWebhook\",\"position\":[1520,340],\"parameters\":{\"options\":{},\"respondWith\":\"json\",\"responseBody\":\"={{ $json }}\"},\"typeVersion\":1.2},{\"id\":\"4d64850a-3125-47eb-a892-1beddbb371fb\",\"name\":\"Text Response\",\"type\":\"n8n-nodes-base.respondToWebhook\",\"position\":[1520,140],\"parameters\":{\"options\":{},\"respondWith\":\"text\",\"responseBody\":\"={{ $json.data }}\"},\"typeVersion\":1.2},{\"id\":\"a9352379-8001-4ff2-a76a-cd927e9f47a2\",\"name\":\"Sticky Note3\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[380,-40],\"parameters\":{\"color\":7,\"width\":1360,\"height\":580,\"content\":\"## 3. Remap OpenAI Responses API for Langchain Compatibility\\n[Learn more about the HTTP request node](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.httprequest)\\n\\nOpenAI's Responses API is a massive upgrade in terms of capability and support for multimodal use-cases. Unfortunately, this means\\nthe API responses are now so fundamentally different, it's not that quite straightforward to use them with Langchain.\\nHere, we show it's possible to map the output for compatibility but does so loses out on newer features of the API.\"},\"typeVersion\":1},{\"id\":\"cd8859ef-9d74-4272-a580-d0db59ce1a43\",\"name\":\"Format Stream Response\",\"type\":\"n8n-nodes-base.code\",\"position\":[1320,140],\"parameters\":{\"mode\":\"runOnceForEachItem\",\"jsCode\":\"const items = $input.item.json.data.split(/^\\\\n/mg);\\nconst events = items.map(item => {\\n  const [event, data] = item.split('\\\\n');\\n  return {\\n    event: event?.split(':')[1]?.trim() ?? null,\\n    data: data?.substring(data.indexOf(':')+1,data.length)?.trim() ?? null\\n  }\\n});\\n\\nconst done = events.find(item => item.event === 'response.completed');\\nconst res = JSON.parse(done.data).response;\\n\\nconst chunk = {\\n  id: res.id,\\n  object:\\\"chat.completion.chunk\\\",\\n  created: res.created_at,\\n  model: res.model,\\n  service_tier: res.service_tier,\\n  system_fingerprint: res.id,\\n  choices: [{\\n    index: 0,\\n     delta: { content: res.output[0].content[0].text }\\n  }],\\n  \\\"usage\\\": {\\n    \\\"completion_tokens\\\": res.usage.output_tokens,\\n    \\\"completion_tokens_details\\\": res.usage.output_tokens_details,\\n    \\\"prompt_tokens\\\": res.usage.input_tokens_details,\\n    \\\"prompt_tokens_details\\\": res.usage.input_tokens_details,\\n    \\\"total_tokens\\\": res.usage.total_tokens\\n  }\\n};\\n\\nconst data = [\\n  `data: ${JSON.stringify(chunk)}`,\\n  `data: [DONE]`\\n].join('\\\\n\\\\n');\\n\\nreturn { data };\"},\"typeVersion\":2},{\"id\":\"e1cb299d-3301-41d9-aa99-9b740105f377\",\"name\":\"Sticky Note4\",\"type\":\"n8n-nodes-base.stickyNote\",\"position\":[-880,-740],\"parameters\":{\"width\":420,\"height\":1180,\"content\":\"## Try It Out!\\n### This n8n template demonstrates how to use OpenAI's Responses API with existing LLM and AI Agent nodes.\\n\\nThough I would recommend just waiting for official support, if you're impatient and would like a round-about way to integrate OpenAI's responses API into your existing AI workflows then this template is sure to satisfy!\\n\\nThis approach implements a simple API wrapper for the Responses API using n8n's builtin webhooks. When the base url is pointed to these webhooks using a custom OpenAI credential, it's possible to intercept the request and remap for compatibility.\\n\\n### How it works\\n* An OpenAI subnode is attached to our agent but has a special custom credential where the base_url is changed to point at this template's webhooks.\\n* When executing a query, the agent's request is forwarded to our mini chat completion workflow.\\n* Here, we take the default request and remap the values to use with a HTTP node which is set to query the Responses API.\\n* Once a response is received, we'll need to remap the output for Langchain compatibility. This just means the LLM or Agent node can parse it and respond to the user.\\n* There are two response formats, one for streaming and one for non-streaming responses.\\n\\n### How to use\\n* You must activate this workflow to be able to use the webhooks.\\n* Create the custom OpenAI credential as instructed.\\n* Go to your existing AI workflows and replace the LLM node with the custom OpenAI credential. You do not need to copy anything else over to the existing template.\\n\\n### Requirements\\n* OpenAI account for Responses API\\n\\n### Customising this workflow\\n* Feel free to experiment with other LLMs using this same technique!\\n* Keep up to date with the Responses API announcements and make modifications as required.\\n\\n### Need Help?\\nJoin the [Discord](https://discord.com/invite/XPKeKXeB7d) or ask in the [Forum](https://community.n8n.io/)!\\n\\nHappy Hacking!\"},\"typeVersion\":1}],\"pinData\":{},\"connections\":{\"Webhook\":{\"main\":[[{\"node\":\"OpenAI Models\",\"type\":\"main\",\"index\":0}]]},\"Is Agent?\":{\"main\":[[{\"node\":\"Format Stream Response\",\"type\":\"main\",\"index\":0}],[{\"node\":\"Format Completion Response\",\"type\":\"main\",\"index\":0}]]},\"n8n Webhook\":{\"ai_languageModel\":[[{\"node\":\"AI Agent\",\"type\":\"ai_languageModel\",\"index\":0}]]},\"OpenAI Models\":{\"main\":[[{\"node\":\"Models Response\",\"type\":\"main\",\"index\":0}]]},\"OpenAI Responses API\":{\"main\":[[{\"node\":\"Is Agent?\",\"type\":\"main\",\"index\":0}]]},\"POST ChatCompletions\":{\"main\":[[{\"node\":\"Remap to Response API Schema\",\"type\":\"main\",\"index\":0}]]},\"Format Stream Response\":{\"main\":[[{\"node\":\"Text Response\",\"type\":\"main\",\"index\":0}]]},\"Format Completion Response\":{\"main\":[[{\"node\":\"JSON Response\",\"type\":\"main\",\"index\":0}]]},\"When chat message received\":{\"main\":[[{\"node\":\"AI Agent\",\"type\":\"main\",\"index\":0}]]},\"Remap to Response API Schema\":{\"main\":[[{\"node\":\"OpenAI Responses API\",\"type\":\"main\",\"index\":0}]]}}}",
  "readme": "### This n8n template demonstrates how to use OpenAI's Responses API with existing LLM and AI Agent nodes.\n\nThough I would recommend just waiting for official support, if you're impatient and would like a round-about way to integrate OpenAI's responses API into your existing AI workflows then this template is sure to satisfy!\n\nThis approach implements a simple API wrapper for the Responses API using n8n's builtin webhooks. When the base url is pointed to these webhooks using a custom OpenAI credential, it's possible to intercept the request and remap for compatibility.\n\n### How it works\n\n  * An OpenAI subnode is attached to our agent but has a special custom credential where the base_url is changed to point at this template's webhooks.\n  * When executing a query, the agent's request is forwarded to our mini chat completion workflow.\n  * Here, we take the default request and remap the values to use with a HTTP node which is set to query the Responses API.\n  * Once a response is received, we'll need to remap the output for Langchain compatibility. This just means the LLM or Agent node can parse it and respond to the user.\n  * There are two response formats, one for streaming and one for non-streaming responses.\n\n\n\n### How to use\n\n  * You must activate this workflow to be able to use the webhooks.\n  * Create the custom OpenAI credential as instructed.\n  * Go to your existing AI workflows and replace the LLM node with the custom OpenAI credential. You do not need to copy anything else over to the existing template.\n\n\n\n### Requirements\n\n  * OpenAI account for Responses API\n\n\n\n### Customising this workflow\n\n  * Feel free to experiment with other LLMs using this same technique!\n  * Keep up to date with the Responses API announcements and make modifications as required.\n\n\n",
  "crawled_at": "2025-05-26T07:19:40.436982",
  "readme_zh": "### 该n8n模板演示了如何将OpenAI的Responses API与现有LLM及AI代理节点结合使用\n\n虽然我建议直接等待官方支持，但如果您迫不及待想通过迂回方式将OpenAI的Responses API集成到现有AI工作流中，这个模板绝对能满足需求！\n\n本方案利用n8n内置的webhook为Responses API实现了一个简易封装层。当通过自定义OpenAI凭证将基础URL指向这些webhook时，即可拦截请求并重新映射以实现兼容。\n\n### 实现原理\n* 代理节点连接了一个特殊配置的OpenAI子节点，其凭证中的base_url被重定向至本模板的webhook\n* 执行查询时，代理请求会被转发到我们的小型聊天补全工作流\n* 在此将标准请求参数重新映射，通过HTTP节点调用Responses API\n* 收到响应后需将输出格式转换为Langchain兼容结构，确保LLM或代理节点能正常解析并响应用户\n* 包含流式和非流式两种响应格式处理\n\n### 使用指南\n* 必须激活本工作流才能使webhook生效\n* 按指引创建自定义OpenAI凭证\n* 在现有AI工作流中将LLM节点替换为使用该自定义凭证的节点，无需迁移其他内容\n\n### 前提条件\n* 需具备OpenAI账号以使用Responses API\n\n### 定制建议\n* 欢迎尝试将此技术应用于其他LLM模型\n* 请持续关注Responses API更新公告，及时调整适配方案\n\n（注：技术术语保持英文原词如webhook/LLM/Langchain等，符合技术文档惯例；\"round-about way\"译为\"迂回方式\"既保留比喻又准确达意；长难句如\"remap the output for Langchain compatibility\"拆分为两个短句，符合中文表达习惯）",
  "title_zh": "面向LLM与AI代理工作流程的OpenAI响应API适配器",
  "publish_date_zh": "最后更新于6天前",
  "workflow_json_zh": "{\n  \"meta\": {\n    \"instanceId\": \"408f9fb9940c3cb18ffdef0e0150fe342d6e655c3a9fac21f0f644e8bedabcd9\",\n    \"templateCredsSetupCompleted\": true\n  },\n  \"nodes\": [\n    {\n      \"id\": \"8531ff8a-b247-4baa-a85b-11512fc2bb60\",\n      \"name\": \"When chat message received\",\n      \"type\": \"@n8n/n8n-nodes-langchain.chatTrigger\",\n      \"position\": [\n        -320,\n        -500\n      ],\n      \"webhookId\": \"f24f59f8-7ea5-4165-be02-d47bdcae52fa\",\n      \"parameters\": {\n        \"public\": true,\n        \"options\": {\n          \"allowFileUploads\": true\n        }\n      },\n      \"typeVersion\": 1.1\n    },\n    {\n      \"id\": \"a039b516-a74a-4ea6-8583-abec9bf2a1f8\",\n      \"name\": \"AI Agent\",\n      \"type\": \"@n8n/n8n-nodes-langchain.agent\",\n      \"position\": [\n        -120,\n        -500\n      ],\n      \"parameters\": {\n        \"options\": {\n          \"passthroughBinaryImages\": true,\n          \"returnIntermediateSteps\": true\n        }\n      },\n      \"typeVersion\": 1.9\n    },\n    {\n      \"id\": \"454a16ea-9bcf-4cb8-a62d-95a1aedea974\",\n      \"name\": \"Webhook\",\n      \"type\": \"n8n-nodes-base.webhook\",\n      \"position\": [\n        -320,\n        160\n      ],\n      \"webhookId\": \"211b7574-f96a-429e-a2bf-c19c0fec5e9e\",\n      \"parameters\": {\n        \"path\": \"n8n-responses-api/models\",\n        \"options\": {},\n        \"responseMode\": \"responseNode\"\n      },\n      \"typeVersion\": 2\n    },\n    {\n      \"id\": \"3fca113b-f259-4495-a52c-89f3c09748c0\",\n      \"name\": \"OpenAI Models\",\n      \"type\": \"n8n-nodes-base.httpRequest\",\n      \"position\": [\n        -100,\n        160\n      ],\n      \"parameters\": {\n        \"url\": \"https://api.openai.com/v1/models\",\n        \"options\": {},\n        \"authentication\": \"predefinedCredentialType\",\n        \"nodeCredentialType\": \"openAiApi\"\n      },\n      \"credentials\": {\n        \"openAiApi\": {\n          \"id\": \"8gccIjcuf3gvaoEr\",\n          \"name\": \"OpenAi account\"\n        }\n      },\n      \"typeVersion\": 4.2\n    },\n    {\n      \"id\": \"bee5a8d3-e18a-4756-99ea-7d14fa08e2f5\",\n      \"name\": \"POST ChatCompletions\",\n      \"type\": \"n8n-nodes-base.webhook\",\n      \"position\": [\n        460,\n        240\n      ],\n      \"webhookId\": \"e8c56164-1825-4ac4-9c23-d209f4907458\",\n      \"parameters\": {\n        \"path\": \"n8n-responses-api/chat/completions\",\n        \"options\": {},\n        \"httpMethod\": \"POST\",\n        \"responseMode\": \"responseNode\"\n      },\n      \"typeVersion\": 2\n    },\n    {\n      \"id\": \"974fd565-c1cf-468a-827f-391bd013e145\",\n      \"name\": \"Models Response\",\n      \"type\": \"n8n-nodes-base.respondToWebhook\",\n      \"position\": [\n        120,\n        160\n      ],\n      \"parameters\": {\n        \"options\": {\n          \"responseCode\": 200,\n          \"responseHeaders\": {\n            \"entries\": [\n              {\n                \"name\": \"Content-Type\",\n                \"value\": \"application/json\"\n              }\n            ]\n          }\n        },\n        \"respondWith\": \"json\",\n        \"responseBody\": \"={{ $json }}\"\n      },\n      \"typeVersion\": 1.2\n    },\n    {\n      \"id\": \"6a4bfb20-5562-4500-9ee2-521f848d3825\",\n      \"name\": \"Remap to Response API Schema\",\n      \"type\": \"n8n-nodes-base.code\",\n      \"position\": [\n        680,\n        240\n      ],\n      \"parameters\": {\n        \"mode\": \"runOnceForEachItem\",\n        \"jsCode\": \"function tranformContent(content) {\\n  return [].concat(content).map(content => {\\n    if (typeof content === 'string') {\\n      return { type: \\\"input_text\\\", text: content };\\n    }\\n    return {\\n      type: getInputType(content.type),\\n      [content.type]: content[content.type].url\\n    }\\n  })\\n};\\n\\nfunction getInputType(type) {\\n  if (type === 'image_url') return 'input_image';\\n  if (type === 'file_url') return 'input_file';\\n  return 'input_text';\\n}\\n\\nconst input = $input.item.json.body.messages.map(message => ({\\n  role: message.role,\\n  content: tranformContent(message.content)\\n}));\\n\\nreturn { input };\"\n      },\n      \"typeVersion\": 2\n    },\n    {\n      \"id\": \"5f4f22c9-f333-469c-a915-8f5da6443e53\",\n      \"name\": \"OpenAI Responses API\",\n      \"type\": \"n8n-nodes-base.httpRequest\",\n      \"position\": [\n        900,\n        240\n      ],\n      \"parameters\": {\n        \"url\": \"https://api.openai.com/v1/responses\",\n        \"method\": \"POST\",\n        \"options\": {},\n        \"jsonBody\": \"={{\\n{\\n  model: $('POST ChatCompletions').first().json.body.model,\\n  stream: $('POST ChatCompletions').first().json.body.stream,\\n  input: $json.input,\\n}\\n}}\",\n        \"sendBody\": true,\n        \"specifyBody\": \"json\",\n        \"authentication\": \"predefinedCredentialType\",\n        \"nodeCredentialType\": \"openAiApi\"\n      },\n      \"credentials\": {\n        \"openAiApi\": {\n          \"id\": \"8gccIjcuf3gvaoEr\",\n          \"name\": \"OpenAi account\"\n        }\n      },\n      \"typeVersion\": 4.2\n    },\n    {\n      \"id\": \"5242a76d-9649-469b-ba91-e33d0f42850e\",\n      \"name\": \"Is Agent?\",\n      \"type\": \"n8n-nodes-base.if\",\n      \"position\": [\n        1100,\n        240\n      ],\n      \"parameters\": {\n        \"options\": {},\n        \"conditions\": {\n          \"options\": {\n            \"version\": 2,\n            \"leftValue\": \"\",\n            \"caseSensitive\": true,\n            \"typeValidation\": \"strict\"\n          },\n          \"combinator\": \"and\",\n          \"conditions\": [\n            {\n              \"id\": \"213702bf-d5c2-4a8a-b5c8-e55f804e4496\",\n              \"operator\": {\n                \"type\": \"boolean\",\n                \"operation\": \"true\",\n                \"singleValue\": true\n              },\n              \"leftValue\": \"={{ $('POST ChatCompletions').first().json.body.stream }}\",\n              \"rightValue\": \"\"\n            }\n          ]\n        }\n      },\n      \"typeVersion\": 2.2\n    },\n    {\n      \"id\": \"4ecc0ec2-4637-48d9-9157-0a6dc39bab9e\",\n      \"name\": \"n8n Webhook\",\n      \"type\": \"@n8n/n8n-nodes-langchain.lmChatOpenAi\",\n      \"position\": [\n        -140,\n        -320\n      ],\n      \"parameters\": {\n        \"model\": {\n          \"__rl\": true,\n          \"mode\": \"list\",\n          \"value\": \"gpt-4o-mini\"\n        },\n        \"options\": {}\n      },\n      \"credentials\": {\n        \"openAiApi\": {\n          \"id\": \"PeoQjbPq9TxC5Fnf\",\n          \"name\": \"n8n Document Understanding\"\n        }\n      },\n      \"typeVersion\": 1.2\n    },\n    {\n      \"id\": \"d050bfc1-ce7a-4ae2-b4b1-763be76b8061\",\n      \"name\": \"Sticky Note1\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"position\": [\n        -400,\n        -740\n      ],\n      \"parameters\": {\n        \"color\": 7,\n        \"width\": 700,\n        \"height\": 580,\n        \"content\": \"## 1. 创建新的自定义OpenAI凭证  \\n[了解更多关于OpenAI凭证的信息](https://docs.n8n.io/integrations/builtin/credentials/openai/)  \\n\\n要在现有n8n节点中使用Github模型，一种方法是模拟通过OpenAI模型子节点连接的兼容OpenAI的API。听起来复杂，但别担心，本模板将为您演示具体操作！第一步是设置一个新的OpenAI凭证，以便我们可以修改基础URL。\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"7703f756-652b-44e4-81b3-021323b08e18\",\n      \"name\": \"Sticky Note\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"position\": [\n        180,\n        -380\n      ],\n      \"parameters\": {\n        \"color\": 5,\n        \"width\": 540,\n        \"height\": 240,\n        \"content\": \"### 通过N8N Webhook使用LLM模型\\n1. 新建一个OpenAI凭证，命名为\\\"n8n-responses-api\\\"\\n2. API密钥可随意填写（例如\\\"12345\\\"）\\n3. 基础URL设置为\\\"https://<你的n8n域名>/webhook/n8n-reponses-api\\\"\\n4. 激活工作流！注意此功能仅在生产环境webhook URL下有效\\n\\n（所有命名均可自定义，只需确保LLM节点能够正常访问该接口即可）\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"a6bc3bcc-d1e9-4d7a-947b-faeddda59507\",\n      \"name\": \"Sticky Note2\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"position\": [\n        -400,\n        -40\n      ],\n      \"parameters\": {\n        \"color\": 7,\n        \"width\": 740,\n        \"height\": 420,\n        \"content\": \"## 2. 列出所有可用模型\\n[详细了解Webhook触发器节点](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.webhook/)\\n\\n我们的第一个端点用于列出所有模型。Github Models API展示了实现方式，但需要对响应进行重新映射以兼容我们的LLM节点。\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"54e0b20a-1a3d-4068-b76a-9b6d10fa0fc2\",\n      \"name\": \"Format Completion Response\",\n      \"type\": \"n8n-nodes-base.code\",\n      \"position\": [\n        1320,\n        340\n      ],\n      \"parameters\": {\n        \"mode\": \"runOnceForEachItem\",\n        \"jsCode\": \"return {\\n  \\\"id\\\": $json.id,\\n  \\\"object\\\": \\\"chat.completion\\\",\\n  \\\"created\\\": $json.created_at,\\n  \\\"model\\\": $json.model,\\n  \\\"choices\\\": $json.output.flatMap((item,idx) => (\\n    item.content.map((content) => ({\\n      index: idx,\\n      finish_reason: \\\"stop\\\",\\n      \\\"message\\\": {\\n        \\\"annotations\\\": content.annotations,\\n        \\\"content\\\": content.text,\\n        \\\"refusal\\\": null,\\n        \\\"role\\\": item.role\\n      }\\n    }))\\n  )),\\n  \\\"usage\\\": {\\n    \\\"completion_tokens\\\": $json.usage.output_tokens,\\n    \\\"completion_tokens_details\\\": $json.usage.output_tokens_details,\\n    \\\"prompt_tokens\\\": $json.usage.input_tokens_details,\\n    \\\"prompt_tokens_details\\\": $json.usage.input_tokens_details,\\n    \\\"total_tokens\\\": $json.usage.total_tokens\\n  },\\n  \\\"service_tier\\\": $json.service_tier,\\n  \\\"system_fingerprint\\\": $json.id\\n}\"\n      },\n      \"typeVersion\": 2\n    },\n    {\n      \"id\": \"a7f2daa8-b4be-4571-b210-3d7ffd7481a3\",\n      \"name\": \"JSON Response\",\n      \"type\": \"n8n-nodes-base.respondToWebhook\",\n      \"position\": [\n        1520,\n        340\n      ],\n      \"parameters\": {\n        \"options\": {},\n        \"respondWith\": \"json\",\n        \"responseBody\": \"={{ $json }}\"\n      },\n      \"typeVersion\": 1.2\n    },\n    {\n      \"id\": \"4d64850a-3125-47eb-a892-1beddbb371fb\",\n      \"name\": \"Text Response\",\n      \"type\": \"n8n-nodes-base.respondToWebhook\",\n      \"position\": [\n        1520,\n        140\n      ],\n      \"parameters\": {\n        \"options\": {},\n        \"respondWith\": \"text\",\n        \"responseBody\": \"={{ $json.data }}\"\n      },\n      \"typeVersion\": 1.2\n    },\n    {\n      \"id\": \"a9352379-8001-4ff2-a76a-cd927e9f47a2\",\n      \"name\": \"Sticky Note3\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"position\": [\n        380,\n        -40\n      ],\n      \"parameters\": {\n        \"color\": 7,\n        \"width\": 1360,\n        \"height\": 580,\n        \"content\": \"## 3. 重映射OpenAI响应API以实现Langchain兼容性\\n[了解更多关于HTTP请求节点的信息](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.httprequest)\\n\\nOpenAI的响应API在功能和对多模态用例的支持方面实现了重大升级。然而，这也意味着API的响应现在有了根本性的不同，直接将其与Langchain结合使用并不那么直观。在此，我们展示了如何通过映射输出来实现兼容性，但这样做会牺牲API的一些新特性。\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"cd8859ef-9d74-4272-a580-d0db59ce1a43\",\n      \"name\": \"Format Stream Response\",\n      \"type\": \"n8n-nodes-base.code\",\n      \"position\": [\n        1320,\n        140\n      ],\n      \"parameters\": {\n        \"mode\": \"runOnceForEachItem\",\n        \"jsCode\": \"const items = $input.item.json.data.split(/^\\\\n/mg);\\nconst events = items.map(item => {\\n  const [event, data] = item.split('\\\\n');\\n  return {\\n    event: event?.split(':')[1]?.trim() ?? null,\\n    data: data?.substring(data.indexOf(':')+1,data.length)?.trim() ?? null\\n  }\\n});\\n\\nconst done = events.find(item => item.event === 'response.completed');\\nconst res = JSON.parse(done.data).response;\\n\\nconst chunk = {\\n  id: res.id,\\n  object:\\\"chat.completion.chunk\\\",\\n  created: res.created_at,\\n  model: res.model,\\n  service_tier: res.service_tier,\\n  system_fingerprint: res.id,\\n  choices: [{\\n    index: 0,\\n     delta: { content: res.output[0].content[0].text }\\n  }],\\n  \\\"usage\\\": {\\n    \\\"completion_tokens\\\": res.usage.output_tokens,\\n    \\\"completion_tokens_details\\\": res.usage.output_tokens_details,\\n    \\\"prompt_tokens\\\": res.usage.input_tokens_details,\\n    \\\"prompt_tokens_details\\\": res.usage.input_tokens_details,\\n    \\\"total_tokens\\\": res.usage.total_tokens\\n  }\\n};\\n\\nconst data = [\\n  `data: ${JSON.stringify(chunk)}`,\\n  `data: [DONE]`\\n].join('\\\\n\\\\n');\\n\\nreturn { data };\"\n      },\n      \"typeVersion\": 2\n    },\n    {\n      \"id\": \"e1cb299d-3301-41d9-aa99-9b740105f377\",\n      \"name\": \"Sticky Note4\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"position\": [\n        -880,\n        -740\n      ],\n      \"parameters\": {\n        \"width\": 420,\n        \"height\": 1180,\n        \"content\": \"## 试试看吧！\\n### 本n8n模板演示如何将OpenAI的Responses API与现有LLM及AI代理节点结合使用\\n\\n虽然我建议直接等待官方支持，但如果你迫不及待想通过迂回方式将OpenAI的Responses API集成到现有AI工作流中，这个模板绝对能满足需求！\\n\\n该方法利用n8n内置的webhook为Responses API实现了一个简易封装层。当通过自定义OpenAI凭证将基础URL指向这些webhook时，即可拦截请求并重新映射以实现兼容。\\n\\n### 实现原理\\n* 在代理节点上挂载OpenAI子节点，并使用特殊自定义凭证——其base_url被修改为指向本模板的webhook\\n* 执行查询时，代理请求会被转发到迷你聊天补全工作流\\n* 在此我们将标准请求重新映射，通过配置好的HTTP节点向Responses API发起查询\\n* 收到响应后，需重新调整输出格式以确保Langchain兼容性，使LLM或代理节点能够解析并响应用户\\n* 包含两种响应格式：流式与非流式\\n\\n### 使用指南\\n* 必须激活本工作流才能使用webhook功能\\n* 按指引创建自定义OpenAI凭证\\n* 前往现有AI工作流，将LLM节点替换为使用该自定义凭证的节点，无需迁移其他内容\\n\\n### 前提条件\\n* 拥有OpenAI账号以使用Responses API\\n\\n### 自定义拓展\\n* 欢迎用相同技术尝试其他LLM模型！\\n* 及时关注Responses API动态并按需调整\\n\\n### 需要帮助？\\n加入[Discord](https://discord.com/invite/XPKeKXeB7d)或访问[论坛](https://community.n8n.io/)提问！\\n\\n祝探索愉快！\"\n      },\n      \"typeVersion\": 1\n    }\n  ],\n  \"pinData\": {},\n  \"connections\": {\n    \"Webhook\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"OpenAI Models\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Is Agent?\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Format Stream Response\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ],\n        [\n          {\n            \"node\": \"Format Completion Response\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"n8n Webhook\": {\n      \"ai_languageModel\": [\n        [\n          {\n            \"node\": \"AI Agent\",\n            \"type\": \"ai_languageModel\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"OpenAI Models\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Models Response\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"OpenAI Responses API\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Is Agent?\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"POST ChatCompletions\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Remap to Response API Schema\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Format Stream Response\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Text Response\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Format Completion Response\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"JSON Response\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"When chat message received\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"AI Agent\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Remap to Response API Schema\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"OpenAI Responses API\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    }\n  }\n}"
}