#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
è¯¥è„šæœ¬åˆ›å»ºä¸€ä¸ªStreamlité¡µé¢ï¼Œç”¨äºå±•ç¤ºdata/workflowç›®å½•ä¸‹çš„æ‰€æœ‰JSONæ–‡ä»¶å†…å®¹ã€‚
åŠŸèƒ½åŒ…æ‹¬ï¼šæ–‡ä»¶æœç´¢ã€åˆ†ç±»è¿‡æ»¤ã€é¢„è§ˆå±•ç¤ºã€åˆ†é¡µæµè§ˆå’Œæ–‡ä»¶å†…å®¹ä¸‹è½½ã€‚
"""

import os
import json
import streamlit as st
import pandas as pd
from pathlib import Path
import math
import base64
import re
from datetime import datetime
import n8n_json_to_context

# è®¾ç½®é¡µé¢æ ‡é¢˜å’Œé…ç½®
st.set_page_config(page_title="N8Nå·¥ä½œæµæŸ¥çœ‹å™¨", page_icon="ğŸ”„", layout="wide", initial_sidebar_state="expanded")
st.title("N8Nå·¥ä½œæµæ•°æ®æŸ¥çœ‹")

# å®šä¹‰æ•°æ®ç›®å½•è·¯å¾„
current_dir = Path(__file__).parent
data_dir = current_dir / "data" / "workflow"

# è®¾ç½®ä¼šè¯çŠ¶æ€å˜é‡
if 'page_number' not in st.session_state:
    st.session_state.page_number = 1

def extract_json_info(json_path):
    """ä»JSONæ–‡ä»¶ä¸­æå–å…³é”®ä¿¡æ¯"""
    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        info = {
            "filename": json_path.name,
            "path": json_path,
            "title": data.get("title", ""),
            "title_zh": data.get("title_zh", ""),
            "tags": data.get("tags", []),
            "category": data.get("category", "æœªåˆ†ç±»"),  # æ·»åŠ åˆ†ç±»å­—æ®µ
            "category_url": data.get("category_url", ""),  # æ·»åŠ åˆ†ç±»URLå­—æ®µ
            "publish_date": data.get("publish_date", ""),
            "has_workflow_json": "workflow_json" in data and bool(data["workflow_json"]),
            "has_workflow_json_zh": "workflow_json_zh" in data and bool(data["workflow_json_zh"]),
            "has_readme": "readme" in data and bool(data["readme"]),
            "has_readme_zh": "readme_zh" in data and bool(data["readme_zh"])
        }
        return info
    except Exception as e:
        st.error(f"æå–æ–‡ä»¶ä¿¡æ¯å‡ºé”™ {json_path.name}: {e}")
        return None

def get_all_json_files(directory, query="", tag_filter=None, category_filter="å…¨éƒ¨", has_translation=None):
    """è·å–ç›®å½•åŠå…¶å­ç›®å½•ä¸‹çš„æ‰€æœ‰JSONæ–‡ä»¶è·¯å¾„"""
    all_files = []
    all_info = []
    
    if not directory.exists():
        st.error(f"ç›®å½•ä¸å­˜åœ¨: {directory}")
        return all_files, all_info
    
    # éå†ç›®å½•åŠå­ç›®å½•
    for path in directory.glob('**/*.json'):
        if path.is_file() and path.name != "n8n_categories.json":  # è·³è¿‡åˆ†ç±»æ–‡ä»¶
            file_info = extract_json_info(path)
            if file_info:
                # åº”ç”¨æœç´¢å’Œè¿‡æ»¤
                if query:
                    # åœ¨æ–‡ä»¶åæˆ–æ ‡é¢˜ä¸­æœç´¢
                    title = file_info["title"] + " " + file_info["title_zh"]
                    if not (query.lower() in path.name.lower() or query.lower() in title.lower()):
                        continue
                
                # æ ‡ç­¾è¿‡æ»¤
                if tag_filter and not any(tag in file_info.get("tags", []) for tag in tag_filter):
                    continue
                
                # åˆ†ç±»è¿‡æ»¤
                if category_filter != "å…¨éƒ¨" and file_info.get("category", "æœªåˆ†ç±»") != category_filter:
                    continue
                
                # ç¿»è¯‘çŠ¶æ€è¿‡æ»¤
                if has_translation is not None:
                    if has_translation and not file_info.get("has_workflow_json_zh", False):
                        continue
                    elif not has_translation and file_info.get("has_workflow_json_zh", False):
                        continue
                
                all_files.append(path)
                all_info.append(file_info)
    
    # å¯¹æ–‡ä»¶æŒ‰å‘å¸ƒæ—¥æœŸè¿›è¡Œæ’åº
    if all_info:
        # åˆ›å»ºæ’åºé”®å‡½æ•°
        def get_date_sort_key(info):
            # é¦–å…ˆæ£€æŸ¥æ˜¯å¦æœ‰ç²¾ç¡®æ—¥æœŸå­—æ®µ
            date_str = info.get("publish_date_absolute", "")
            if not date_str:
                date_str = info.get("publish_date", "")
            
            # å°è¯•è§£ææ—¥æœŸ
            try:
                # å¦‚æœæ—¥æœŸå­—ç¬¦ä¸²åŒ…å«"hours ago"ã€"days ago"ç­‰ç›¸å¯¹æ—¶é—´ä¿¡æ¯
                if "ago" in date_str.lower():
                    # å¯¹äºç›¸å¯¹æ—¶é—´ï¼Œæˆ‘ä»¬å¯ä»¥ç»™å®ƒä¸€ä¸ªè¾ƒæ–°çš„è¯„åˆ†
                    if "hour" in date_str.lower():
                        return datetime.now().timestamp() - 3600  # å°æ—¶å‰ï¼Œéå¸¸æ–°
                    elif "day" in date_str.lower():
                        return datetime.now().timestamp() - 86400  # å¤©å‰ï¼Œè¾ƒæ–°
                    elif "week" in date_str.lower():
                        return datetime.now().timestamp() - 604800  # å‘¨å‰
                    elif "month" in date_str.lower():
                        return datetime.now().timestamp() - 2592000  # æœˆå‰
                    else:
                        return 0  # é»˜è®¤å¾ˆæ—§
                
                # å°è¯•è§£æç²¾ç¡®æ—¥æœŸ
                for fmt in ["%Y-%m-%dT%H:%M:%S.%fZ", "%Y-%m-%d %H:%M:%S", "%Y-%m-%d", "%B %d, %Y"]:
                    try:
                        dt = datetime.strptime(date_str, fmt)
                        return dt.timestamp()
                    except ValueError:
                        continue
                
                return 0  # å¦‚æœæ— æ³•è§£æï¼Œé»˜è®¤ä¸ºå¾ˆæ—§
            except:
                return 0
        
        # å¯¹æ–‡ä»¶ä¿¡æ¯å’Œè·¯å¾„åŒæ—¶è¿›è¡Œæ’åº
        sorted_pairs = sorted(zip(all_info, all_files), key=lambda x: get_date_sort_key(x[0]), reverse=True)
        all_info, all_files = zip(*sorted_pairs) if sorted_pairs else ([], [])
        
        # è½¬æ¢å›åˆ—è¡¨
        all_info = list(all_info)
        all_files = list(all_files)
    
    return all_files, all_info

def get_download_link(content, filename, text):
    """ç”Ÿæˆä¸‹è½½é“¾æ¥"""
    # å°†å†…å®¹è½¬æ¢ä¸ºbytes
    if isinstance(content, str):
        content_bytes = content.encode('utf-8')
    else:
        content_bytes = json.dumps(content, ensure_ascii=False, indent=2).encode('utf-8')
    
    b64 = base64.b64encode(content_bytes).decode()
    href = f'<a href="data:application/json;base64,{b64}" download="{filename}" class="download-btn">{text}</a>'
    return href

def format_datetime(date_str):
    """æ ¼å¼åŒ–æ—¥æœŸæ—¶é—´å­—ç¬¦ä¸²"""
    if not date_str:
        return ""
    
    try:
        # å°è¯•ä¸åŒçš„æ—¥æœŸæ ¼å¼
        formats = [
            "%Y-%m-%dT%H:%M:%S.%fZ",  # ISOæ ¼å¼
            "%Y-%m-%d %H:%M:%S",       # æ ‡å‡†æ ¼å¼
            "%Y-%m-%d",                # ä»…æ—¥æœŸ
            "%B %d, %Y"                # è‹±æ–‡æœˆä»½æ ¼å¼
        ]
        
        for fmt in formats:
            try:
                dt = datetime.strptime(date_str, fmt)
                return dt.strftime("%Y-%m-%d")
            except ValueError:
                continue
                
        return date_str
    except Exception:
        return date_str

def display_json_content(json_path, index):
    """å±•ç¤ºå•ä¸ªJSONæ–‡ä»¶çš„å†…å®¹"""
    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # æå–é¢„è§ˆä¿¡æ¯ - ä¿®æ”¹è¿™éƒ¨åˆ†ï¼Œä¼˜å…ˆä½¿ç”¨ä¸­æ–‡æ ‡é¢˜
        title_zh = data.get("title_zh", "")
        title_en = data.get("title", "")
        # ä¼˜å…ˆæ˜¾ç¤ºä¸­æ–‡æ ‡é¢˜ï¼Œå¦‚æœæ²¡æœ‰ä¸­æ–‡æ ‡é¢˜åˆ™ä½¿ç”¨è‹±æ–‡æ ‡é¢˜
        display_title = title_zh if title_zh else title_en if title_en else json_path.name
        
        publish_date = format_datetime(data.get("publish_date", ""))
        tags = data.get("tags", [])
        tag_display = " ".join([f"<span class='tag'>{tag}</span>" for tag in tags]) if tags else ""
        
        # åˆ›å»ºå¯æŠ˜å åŒºåŸŸ - ä½¿ç”¨ä¼˜å…ˆæ˜¾ç¤ºçš„ä¸­æ–‡æ ‡é¢˜
        with st.expander(f"#{index} - {display_title} {publish_date}", expanded=False):
            # é¡¶éƒ¨ä¿¡æ¯æ 
            if tag_display:
                st.markdown(f"<div class='tags-container'>{tag_display}</div>", unsafe_allow_html=True)
            
            # æ˜¾ç¤ºæ–‡ä»¶è·¯å¾„
            st.caption(f"æ–‡ä»¶è·¯å¾„: {json_path}")
            
            # åˆ›å»ºé€‰é¡¹å¡ - æ·»åŠ å·¥ä½œæµåˆ†æé€‰é¡¹å¡
            tab1, tab2, tab3, tab4 = st.tabs(["åŸºæœ¬ä¿¡æ¯", "å·¥ä½œæµæ•°æ®", "å·¥ä½œæµåˆ†æ", "åŸå§‹JSON"])
            
            with tab1:
                # åˆ›å»ºåŸºæœ¬ä¿¡æ¯å­é€‰é¡¹å¡ï¼Œåˆ†ä¸ºä¸­æ–‡å’Œè‹±æ–‡ï¼Œæ³¨æ„é¡ºåºè°ƒæ•´ï¼Œå…ˆæ˜¾ç¤ºä¸­æ–‡
                info_tab_zh, info_tab_en = st.tabs(["ä¸­æ–‡ä¿¡æ¯", "è‹±æ–‡ä¿¡æ¯"])
                
                with info_tab_zh:
                    # æ˜¾ç¤ºä¸­æ–‡æ ‡é¢˜
                    if "title_zh" in data and data["title_zh"]:
                        st.write("**ä¸­æ–‡æ ‡é¢˜:** ", data["title_zh"])
                    elif "title" in data and data["title"]:
                        st.write("**ä¸­æ–‡æ ‡é¢˜:** ", "(æœªç¿»è¯‘)")
                        
                    # æ˜¾ç¤ºä¸­æ–‡å‘å¸ƒæ—¥æœŸ
                    if "publish_date_zh" in data and data["publish_date_zh"]:
                        st.write("**ä¸­æ–‡æ—¥æœŸ:** ", data["publish_date_zh"])
                    elif "publish_date" in data and data["publish_date"]:
                        st.write("**ä¸­æ–‡æ—¥æœŸ:** ", "(æœªç¿»è¯‘)")
                    
                    # æ˜¾ç¤ºæ ‡ç­¾ (æ ‡ç­¾é€šå¸¸ä¸ç¿»è¯‘)
                    if tags:
                        st.write("**æ ‡ç­¾:** ", ", ".join(tags))
                    
                    # æ˜¾ç¤ºä¸­æ–‡readme
                    if "readme_zh" in data and data["readme_zh"]:
                        st.markdown("### ä¸­æ–‡æè¿°")
                        st.markdown(data["readme_zh"])
                    elif "readme" in data and data["readme"]:
                        st.markdown("### ä¸­æ–‡æè¿°")
                        st.write("(å†…å®¹æœªç¿»è¯‘)")
                
                with info_tab_en:
                    # æ˜¾ç¤ºåŸå§‹æ ‡é¢˜
                    if "title" in data and data["title"]:
                        st.write("**æ ‡é¢˜ (Title):** ", data["title"])
                        
                    # æ˜¾ç¤ºåŸå§‹å‘å¸ƒæ—¥æœŸ
                    if "publish_date" in data and data["publish_date"]:
                        st.write("**å‘å¸ƒæ—¥æœŸ (Publish Date):** ", publish_date)
                    
                    # æ˜¾ç¤ºæ ‡ç­¾
                    if tags:
                        st.write("**æ ‡ç­¾ (Tags):** ", ", ".join(tags))
                    
                    # æ˜¾ç¤ºè‹±æ–‡readmeå†…å®¹
                    if "readme" in data and data["readme"]:
                        st.markdown("### æè¿° (Description)")
                        st.markdown(data["readme"])
            
            with tab2:
                # æ˜¾ç¤ºå·¥ä½œæµæ•°æ®
                if "workflow_json" in data and data["workflow_json"]:
                    col1, col2 = st.columns([3, 1])
                    with col1:
                        st.write("**åŸå§‹å·¥ä½œæµæ•°æ®:**")
                    with col2:
                        filename = f"{os.path.splitext(json_path.name)[0]}_workflow_json.json"
                        download_link = get_download_link(data["workflow_json"], filename, "ğŸ“¥ ä¸‹è½½åŸå§‹å·¥ä½œæµ")
                        st.markdown(download_link, unsafe_allow_html=True)
                    
                    # æ˜¾ç¤ºå·¥ä½œæµé¢„è§ˆä¿¡æ¯
                    try:
                        workflow = json.loads(data["workflow_json"]) if isinstance(data["workflow_json"], str) else data["workflow_json"]
                        st.write(f"å·¥ä½œæµåç§°: {workflow.get('name', 'æœªå‘½å')}")
                        st.write(f"èŠ‚ç‚¹æ•°é‡: {len(workflow.get('nodes', []))}")
                    except:
                        st.write("æ— æ³•è§£æå·¥ä½œæµæ•°æ®")
                
                # æ˜¾ç¤ºä¸­æ–‡å·¥ä½œæµæ•°æ®
                if "workflow_json_zh" in data and data["workflow_json_zh"]:
                    col1, col2, col3 = st.columns([2.5, 1, 1])
                    with col1:
                        st.write("**ä¸­æ–‡å·¥ä½œæµæ•°æ®:**")
                    with col2:
                        filename = f"{os.path.splitext(json_path.name)[0]}_workflow_json_zh.json"
                        download_link = get_download_link(data["workflow_json_zh"], filename, "ğŸ“¥ ä¸‹è½½ä¸­æ–‡å·¥ä½œæµ")
                        st.markdown(download_link, unsafe_allow_html=True)
                    with col3:
                        # æ·»åŠ åˆ†ææŒ‰é’®ï¼Œä½¿ç”¨ä¾§è¾¹æ ä¸­é€‰æ‹©çš„æ¨¡å‹
                        if st.button("ğŸ” åˆ†æå·¥ä½œæµ", key=f"analyze_{index}"):
                            # è·å–ç”¨æˆ·åœ¨ä¾§è¾¹æ é€‰æ‹©çš„æ¨¡å‹
                            selected_model = st.session_state.selected_model
                            model_name = selected_model.split("/")[-1].replace("-", " ").title()
                            
                            with st.spinner(f"ä½¿ç”¨ {model_name} åˆ†æå·¥ä½œæµ..."):
                                # ä½¿ç”¨æ–°æ¨¡å—åˆ†æå·¥ä½œæµ
                                workflow_json = data["workflow_json_zh"] if "workflow_json_zh" in data else data["workflow_json"]
                                analysis = n8n_json_to_context.get_workflow_analysis(workflow_json, model=selected_model)
                                
                                # ä¿å­˜åˆ†æç»“æœåˆ°æ–‡ä»¶
                                success = n8n_json_to_context.save_workflow_file(json_path, analysis)
                                
                                if success:
                                    st.success("åˆ†æå®Œæˆå¹¶å·²ä¿å­˜")
                                    # é‡æ–°åŠ è½½æ–‡ä»¶ä»¥æ˜¾ç¤ºåˆ†æç»“æœ
                                    with open(json_path, 'r', encoding='utf-8') as f:
                                        data = json.load(f)
                                else:
                                    st.error("ä¿å­˜åˆ†æç»“æœå¤±è´¥")
            
            # æ–°å¢çš„å·¥ä½œæµåˆ†ææ ‡ç­¾é¡µ
            with tab3:
                # æ˜¾ç¤ºå·¥ä½œæµåˆ†æç»“æœ
                if "workflow_analysis" in data and data["workflow_analysis"]:
                    st.markdown(data["workflow_analysis"])
                    # æ·»åŠ é‡æ–°åˆ†æçš„é€‰é¡¹
                    st.write("---")
                    
                    # æ·»åŠ é‡æ–°åˆ†ææŒ‰é’®ï¼Œä½¿ç”¨ä¾§è¾¹æ ä¸­é€‰æ‹©çš„æ¨¡å‹
                    if st.button("ğŸ”„ ä½¿ç”¨å½“å‰é€‰æ‹©çš„æ¨¡å‹é‡æ–°åˆ†æ", key=f"reanalyze_{index}"):
                        selected_model = st.session_state.selected_model
                        model_name = selected_model.split("/")[-1].replace("-", " ").title()
                        
                        with st.spinner(f"ä½¿ç”¨ {model_name} é‡æ–°åˆ†æå·¥ä½œæµ..."):
                            workflow_json = data["workflow_json_zh"] if "workflow_json_zh" in data else data["workflow_json"]
                            analysis = n8n_json_to_context.get_workflow_analysis(workflow_json, model=selected_model)
                            
                            # ä¿å­˜åˆ†æç»“æœåˆ°æ–‡ä»¶
                            success = n8n_json_to_context.save_workflow_file(json_path, analysis)
                            
                            if success:
                                st.success("åˆ†æå®Œæˆå¹¶å·²ä¿å­˜")
                                # é‡æ–°åŠ è½½æ–‡ä»¶ä»¥æ˜¾ç¤ºåˆ†æç»“æœ
                                with open(json_path, 'r', encoding='utf-8') as f:
                                    data = json.load(f)
                                # æ˜¾ç¤ºæ–°çš„åˆ†æç»“æœ
                                st.markdown(analysis)
                            else:
                                st.error("ä¿å­˜åˆ†æç»“æœå¤±è´¥")
                else:
                    st.info("è¯¥å·¥ä½œæµå°šæœªè¿›è¡Œåˆ†æã€‚")
                    
                    # å¦‚æœæœ‰å·¥ä½œæµæ•°æ®ï¼Œæä¾›ç›´æ¥åˆ†ææŒ‰é’®
                    if ("workflow_json" in data and data["workflow_json"]) or ("workflow_json_zh" in data and data["workflow_json_zh"]):
                        # æ·»åŠ åˆ†ææŒ‰é’®ï¼Œä½¿ç”¨ä¾§è¾¹æ ä¸­é€‰æ‹©çš„æ¨¡å‹
                        if st.button("ğŸ” ä½¿ç”¨å½“å‰é€‰æ‹©çš„æ¨¡å‹åˆ†æ", key=f"analyze_direct_{index}"):
                            selected_model = st.session_state.selected_model
                            model_name = selected_model.split("/")[-1].replace("-", " ").title()
                            
                            with st.spinner(f"ä½¿ç”¨ {model_name} åˆ†æå·¥ä½œæµ..."):
                                workflow_json = data["workflow_json_zh"] if "workflow_json_zh" in data else data["workflow_json"]
                                analysis = n8n_json_to_context.get_workflow_analysis(workflow_json, model=selected_model)
                                
                                # ä¿å­˜åˆ†æç»“æœåˆ°æ–‡ä»¶
                                success = n8n_json_to_context.save_workflow_file(json_path, analysis)
                                
                                if success:
                                    st.success("åˆ†æå®Œæˆå¹¶å·²ä¿å­˜")
                                    # æ˜¾ç¤ºåˆ†æç»“æœ
                                    st.markdown(analysis)
                                else:
                                    st.error("ä¿å­˜åˆ†æç»“æœå¤±è´¥")
                    else:
                        st.warning("æ­¤æ–‡ä»¶ä¸åŒ…å«å·¥ä½œæµæ•°æ®ï¼Œæ— æ³•è¿›è¡Œåˆ†æã€‚")
            
            with tab4:
                # æ˜¾ç¤ºå®Œæ•´JSONå†…å®¹
                st.json(data)
                
    except Exception as e:
        st.error(f"è¯»å–æ–‡ä»¶ {json_path.name} æ—¶å‡ºé”™: {e}")

def get_unique_tags(file_infos):
    """ä»æ–‡ä»¶ä¿¡æ¯åˆ—è¡¨ä¸­æå–æ‰€æœ‰å”¯ä¸€æ ‡ç­¾"""
    all_tags = set()
    for info in file_infos:
        tags = info.get("tags", [])
        if tags:
            all_tags.update(tags)
    return sorted(list(all_tags))

def load_categories():
    """ä»n8n_categories.jsonåŠ è½½åˆ†ç±»ä¿¡æ¯"""
    # ä¿®æ”¹è¿™ä¸€è¡Œï¼Œå°†è·¯å¾„ä» data/n8n_categories.json æ”¹ä¸º data/workflow/n8n_categories.json
    categories_file = Path(__file__).parent / "data" / "workflow" / "n8n_categories.json"
    
    if not categories_file.exists():
        st.warning("æœªæ‰¾åˆ°åˆ†ç±»æ•°æ®æ–‡ä»¶ n8n_categories.json")
        return [{"category_name": "å…¨éƒ¨", "category_url": ""}]
    
    try:
        with open(categories_file, 'r', encoding='utf-8') as f:
            categories_data = json.load(f)
        
        # ç¡®ä¿åŒ…å«"å…¨éƒ¨"é€‰é¡¹
        categories = [{"category_name": "å…¨éƒ¨", "category_url": ""}]
        
        # æ·»åŠ ä»æ–‡ä»¶åŠ è½½çš„åˆ†ç±»
        for item in categories_data:
            if isinstance(item, dict) and "category_name" in item and "category_url" in item:
                categories.append(item)
        
        return categories
    except Exception as e:
        st.error(f"åŠ è½½åˆ†ç±»æ•°æ®å‡ºé”™: {e}")
        return [{"category_name": "å…¨éƒ¨", "category_url": ""}]

def main():
    # æ·»åŠ è‡ªå®šä¹‰CSS
    st.markdown("""
    <style>
    .download-btn {
        display: inline-block;
        padding: 0.3rem 0.6rem;
        background-color: #4CAF50;
        color: white !important;
        text-decoration: none;
        border-radius: 4px;
        text-align: center;
        transition: background-color 0.3s;
    }
    .download-btn:hover {
        background-color: #45a049;
        text-decoration: none;
    }
    .tag {
        display: inline-block;
        background-color: #f1f1f1;
        padding: 2px 6px;
        margin: 2px;
        border-radius: 3px;
        font-size: 0.8rem;
    }
    .tags-container {
        margin-bottom: 10px;
    }
    .category-badge {
        background-color: #e8f0fe;
        color: #1967d2;
        padding: 3px 8px;
        border-radius: 12px;
        font-size: 0.85rem;
        display: inline-block;
        margin-right: 5px;
    }
    </style>
    """, unsafe_allow_html=True)
    
    # åŠ è½½åˆ†ç±»æ•°æ®
    categories = load_categories()
    category_names = [cat["category_name"] for cat in categories]
    
    # ä¾§è¾¹æ è¿‡æ»¤å’Œæœç´¢é€‰é¡¹
    with st.sidebar:
        st.header("æœç´¢å’Œè¿‡æ»¤")
        
        # æœç´¢æ¡†
        search_query = st.text_input("æœç´¢æ–‡ä»¶åæˆ–æ ‡é¢˜", "")
        
        # åˆ†ç±»é€‰æ‹©
        selected_category = st.selectbox("æŒ‰åˆ†ç±»è¿‡æ»¤", category_names)
        
        # è·å–æ‰€æœ‰JSONæ–‡ä»¶çš„åŸºæœ¬ä¿¡æ¯(ä¸è¿‡æ»¤)
        _, all_info = get_all_json_files(data_dir)
        
        # æå–æ‰€æœ‰å”¯ä¸€æ ‡ç­¾
        unique_tags = get_unique_tags(all_info)
        
        # æ ‡ç­¾å¤šé€‰
        selected_tags = st.multiselect("æŒ‰æ ‡ç­¾è¿‡æ»¤", unique_tags)
        
        # ç¿»è¯‘çŠ¶æ€è¿‡æ»¤
        translation_options = ["å…¨éƒ¨", "å·²ç¿»è¯‘", "æœªç¿»è¯‘"]
        translation_filter = st.radio("ç¿»è¯‘çŠ¶æ€", translation_options)
        
        has_translation = None
        if translation_filter == "å·²ç¿»è¯‘":
            has_translation = True
        elif translation_filter == "æœªç¿»è¯‘":
            has_translation = False
        
        # æ¯é¡µæ˜¾ç¤ºæ•°é‡
        items_per_page = st.slider("æ¯é¡µæ˜¾ç¤ºæ•°é‡", 5, 50, 10, 5)
        
        # é‡ç½®æŒ‰é’®
        if st.button("é‡ç½®è¿‡æ»¤å™¨"):
            search_query = ""
            selected_tags = []
            selected_category = "å…¨éƒ¨"
            translation_filter = "å…¨éƒ¨"
            has_translation = None
            items_per_page = 10
            st.session_state.page_number = 1
            st.rerun()
            
        # æ·»åŠ æ¨¡å‹é€‰æ‹©éƒ¨åˆ†
        st.header("AI æ¨¡å‹é€‰æ‹©")
        
        # è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨
        model_list = n8n_json_to_context.get_available_models()
        
        # è½¬æ¢ä¸ºæ˜“äºæ˜¾ç¤ºçš„æ ¼å¼
        model_options = {model["id"]: f"{model['name']} ({model.get('context_length', 0)//1000}K)" for model in model_list}
        
        # å¦‚æœåˆ—è¡¨ä¸ºç©ºæˆ–å‡ºé”™ï¼Œä½¿ç”¨é»˜è®¤æ¨¡å‹åˆ—è¡¨
        if not model_options:
            model_options = {
                "anthropic/claude-3-7-sonnet": "Claude 3.7 Sonnet (æ¨è)",
                "anthropic/claude-3-5-sonnet": "Claude 3.5 Sonnet",
                "anthropic/claude-3-haiku": "Claude 3 Haiku (å¿«é€Ÿ)",
                "anthropic/claude-3-opus": "Claude 3 Opus (é«˜è´¨é‡)",
                "openai/gpt-4o": "GPT-4o",
                "openai/gpt-4-turbo": "GPT-4 Turbo",
            }
            
        # æŸ¥æ‰¾é»˜è®¤é€‰æ‹©çš„ç´¢å¼• (Claude 3.7 Sonnet)
        default_model = "anthropic/claude-3-7-sonnet"
        default_index = list(model_options.keys()).index(default_model) if default_model in model_options else 0
        
        # å°†é€‰æ‹©çš„æ¨¡å‹ä¿å­˜åˆ°ä¼šè¯çŠ¶æ€ï¼Œä»¥ä¾¿åœ¨æ•´ä¸ªåº”ç”¨ä¸­ä½¿ç”¨
        if 'selected_model' not in st.session_state:
            st.session_state.selected_model = list(model_options.keys())[default_index]
        
        st.session_state.selected_model = st.selectbox(
            "åˆ†æå·¥ä½œæµä½¿ç”¨çš„æ¨¡å‹", 
            options=list(model_options.keys()),
            format_func=lambda x: model_options[x],
            index=list(model_options.keys()).index(st.session_state.selected_model) if st.session_state.selected_model in model_options else default_index
        )
        
        # æ˜¾ç¤ºå½“å‰é€‰æ‹©çš„æ¨¡å‹ä¿¡æ¯
        st.info(f"å½“å‰é€‰æ‹©: {model_options[st.session_state.selected_model]}")
    
    # ä»¥ä¸‹æ˜¯ä¸»å†…å®¹åŒºåŸŸçš„ä»£ç ï¼Œéœ€è¦æ·»åŠ å›æ¥
    
    # è·å–è¿‡æ»¤åçš„JSONæ–‡ä»¶åˆ—è¡¨
    json_files, file_infos = get_all_json_files(
        data_dir, 
        query=search_query, 
        tag_filter=selected_tags, 
        category_filter=selected_category,
        has_translation=has_translation
    )
    
    # æ˜¾ç¤ºæ–‡ä»¶æ€»æ•°å’Œè¿‡æ»¤ç»“æœ
    st.write(f"å…±æ‰¾åˆ° {len(json_files)} ä¸ªæ–‡ä»¶")
    
    # å¦‚æœæ²¡æœ‰æ–‡ä»¶ï¼Œæ˜¾ç¤ºæç¤ºä¿¡æ¯
    if not json_files:
        st.info("æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆè¿‡æ»¤æ¡ä»¶çš„æ–‡ä»¶ã€‚è¯·å°è¯•è°ƒæ•´è¿‡æ»¤å™¨æˆ–æœç´¢æ¡ä»¶ã€‚")
        return
    
    # åˆ†é¡µé€»è¾‘
    total_pages = math.ceil(len(json_files) / items_per_page)
    
    # ç¡®ä¿é¡µç åœ¨æœ‰æ•ˆèŒƒå›´å†…
    if st.session_state.page_number < 1:
        st.session_state.page_number = 1
    elif st.session_state.page_number > total_pages:
        st.session_state.page_number = total_pages
    
    # è®¡ç®—å½“å‰é¡µçš„æ–‡ä»¶èŒƒå›´
    start_idx = (st.session_state.page_number - 1) * items_per_page
    end_idx = min(start_idx + items_per_page, len(json_files))
    
    # æ˜¾ç¤ºåˆ†é¡µä¿¡æ¯
    st.write(f"ç¬¬ {st.session_state.page_number} é¡µï¼Œå…± {total_pages} é¡µ")
    
    # åˆ†é¡µæ§åˆ¶
    col1, col2, col3 = st.columns([1, 3, 1])
    with col1:
        if st.session_state.page_number > 1:
            if st.button("ä¸Šä¸€é¡µ"):
                st.session_state.page_number -= 1
                st.rerun()
    
    with col2:
        # æ˜¾ç¤ºé¡µç é€‰æ‹©å™¨
        page_options = list(range(1, total_pages + 1))
        selected_page = st.selectbox("è·³è½¬åˆ°é¡µ", page_options, index=st.session_state.page_number - 1)
        if selected_page != st.session_state.page_number:
            st.session_state.page_number = selected_page
            st.rerun()
    
    with col3:
        if st.session_state.page_number < total_pages:
            if st.button("ä¸‹ä¸€é¡µ"):
                st.session_state.page_number += 1
                st.rerun()
    
    # æ˜¾ç¤ºå½“å‰é¡µçš„æ–‡ä»¶
    for i, json_path in enumerate(json_files[start_idx:end_idx], start=start_idx+1):
        display_json_content(json_path, i)

# è°ƒç”¨ä¸»å‡½æ•°
if __name__ == "__main__":
    main()