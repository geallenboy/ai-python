#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
è¯¥è„šæœ¬åˆ›å»ºä¸€ä¸ªStreamlité¡µé¢ï¼Œç”¨äºå±•ç¤ºdata/workflowç›®å½•ä¸‹çš„æ‰€æœ‰JSONæ–‡ä»¶å†…å®¹ã€‚
åŠŸèƒ½åŒ…æ‹¬ï¼šæ–‡ä»¶æœç´¢ã€åˆ†ç±»è¿‡æ»¤ã€é¢„è§ˆå±•ç¤ºã€åˆ†é¡µæµè§ˆå’Œæ–‡ä»¶å†…å®¹ä¸‹è½½ã€‚
"""

import os
import json
import streamlit as st
import pandas as pd
from pathlib import Path
import math
import base64
import re
from datetime import datetime

# è®¾ç½®é¡µé¢æ ‡é¢˜å’Œé…ç½®
st.set_page_config(page_title="N8Nå·¥ä½œæµæŸ¥çœ‹å™¨", page_icon="ğŸ”„", layout="wide", initial_sidebar_state="expanded")
st.title("N8Nå·¥ä½œæµæ•°æ®æŸ¥çœ‹")

# å®šä¹‰æ•°æ®ç›®å½•è·¯å¾„
current_dir = Path(__file__).parent
data_dir = current_dir / "data" / "workflow"

# è®¾ç½®ä¼šè¯çŠ¶æ€å˜é‡
if 'page_number' not in st.session_state:
    st.session_state.page_number = 1

def extract_json_info(json_path):
    """ä»JSONæ–‡ä»¶ä¸­æå–å…³é”®ä¿¡æ¯"""
    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        info = {
            "filename": json_path.name,
            "path": json_path,
            "title": data.get("title", ""),
            "title_zh": data.get("title_zh", ""),
            "tags": data.get("tags", []),
            "publish_date": data.get("publish_date", ""),
            "has_workflow_json": "workflow_json" in data and bool(data["workflow_json"]),
            "has_workflow_json_zh": "workflow_json_zh" in data and bool(data["workflow_json_zh"]),
            "has_readme": "readme" in data and bool(data["readme"]),
            "has_readme_zh": "readme_zh" in data and bool(data["readme_zh"])
        }
        return info
    except Exception as e:
        st.error(f"æå–æ–‡ä»¶ä¿¡æ¯å‡ºé”™ {json_path.name}: {e}")
        return None

def get_all_json_files(directory, query="", tag_filter=None, has_translation=None):
    """è·å–ç›®å½•åŠå…¶å­ç›®å½•ä¸‹çš„æ‰€æœ‰JSONæ–‡ä»¶è·¯å¾„"""
    all_files = []
    all_info = []
    
    if not directory.exists():
        st.error(f"ç›®å½•ä¸å­˜åœ¨: {directory}")
        return all_files, all_info
    
    # éå†ç›®å½•åŠå­ç›®å½•
    for path in directory.glob('**/*.json'):
        if path.is_file():
            file_info = extract_json_info(path)
            if file_info:
                # åº”ç”¨æœç´¢å’Œè¿‡æ»¤
                if query:
                    # åœ¨æ–‡ä»¶åæˆ–æ ‡é¢˜ä¸­æœç´¢
                    title = file_info["title"] + " " + file_info["title_zh"]
                    if not (query.lower() in path.name.lower() or query.lower() in title.lower()):
                        continue
                
                # æ ‡ç­¾è¿‡æ»¤
                if tag_filter and not any(tag in file_info.get("tags", []) for tag in tag_filter):
                    continue
                
                # ç¿»è¯‘çŠ¶æ€è¿‡æ»¤
                if has_translation is not None:
                    if has_translation and not file_info.get("has_workflow_json_zh", False):
                        continue
                    elif not has_translation and file_info.get("has_workflow_json_zh", False):
                        continue
                
                all_files.append(path)
                all_info.append(file_info)
    
    return all_files, all_info

def get_download_link(content, filename, text):
    """ç”Ÿæˆä¸‹è½½é“¾æ¥"""
    # å°†å†…å®¹è½¬æ¢ä¸ºbytes
    if isinstance(content, str):
        content_bytes = content.encode('utf-8')
    else:
        content_bytes = json.dumps(content, ensure_ascii=False, indent=2).encode('utf-8')
    
    b64 = base64.b64encode(content_bytes).decode()
    href = f'<a href="data:application/json;base64,{b64}" download="{filename}" class="download-btn">{text}</a>'
    return href

def format_datetime(date_str):
    """æ ¼å¼åŒ–æ—¥æœŸæ—¶é—´å­—ç¬¦ä¸²"""
    if not date_str:
        return ""
    
    try:
        # å°è¯•ä¸åŒçš„æ—¥æœŸæ ¼å¼
        formats = [
            "%Y-%m-%dT%H:%M:%S.%fZ",  # ISOæ ¼å¼
            "%Y-%m-%d %H:%M:%S",       # æ ‡å‡†æ ¼å¼
            "%Y-%m-%d",                # ä»…æ—¥æœŸ
            "%B %d, %Y"                # è‹±æ–‡æœˆä»½æ ¼å¼
        ]
        
        for fmt in formats:
            try:
                dt = datetime.strptime(date_str, fmt)
                return dt.strftime("%Y-%m-%d")
            except ValueError:
                continue
                
        return date_str
    except Exception:
        return date_str

def display_json_content(json_path, index):
    """å±•ç¤ºå•ä¸ªJSONæ–‡ä»¶çš„å†…å®¹"""
    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # æå–é¢„è§ˆä¿¡æ¯
        title = data.get("title", "") or data.get("title_zh", "") or json_path.name
        publish_date = format_datetime(data.get("publish_date", ""))
        tags = data.get("tags", [])
        tag_display = " ".join([f"<span class='tag'>{tag}</span>" for tag in tags]) if tags else ""
        
        # åˆ›å»ºå¯æŠ˜å åŒºåŸŸ
        with st.expander(f"#{index} - {title} {publish_date}", expanded=False):
            # é¡¶éƒ¨ä¿¡æ¯æ 
            if tag_display:
                st.markdown(f"<div class='tags-container'>{tag_display}</div>", unsafe_allow_html=True)
            
            # æ˜¾ç¤ºæ–‡ä»¶è·¯å¾„
            st.caption(f"æ–‡ä»¶è·¯å¾„: {json_path}")
            
            # åˆ›å»ºé€‰é¡¹å¡
            tab1, tab2, tab3 = st.tabs(["åŸºæœ¬ä¿¡æ¯", "å·¥ä½œæµæ•°æ®", "åŸå§‹JSON"])
            
            with tab1:
                # åˆ›å»ºåŸºæœ¬ä¿¡æ¯å­é€‰é¡¹å¡ï¼Œåˆ†ä¸ºè‹±æ–‡å’Œä¸­æ–‡
                info_tab_en, info_tab_zh = st.tabs(["è‹±æ–‡ä¿¡æ¯", "ä¸­æ–‡ä¿¡æ¯"])
                
                with info_tab_en:
                    # æ˜¾ç¤ºåŸå§‹æ ‡é¢˜
                    if "title" in data and data["title"]:
                        st.write("**æ ‡é¢˜ (Title):** ", data["title"])
                        
                    # æ˜¾ç¤ºåŸå§‹å‘å¸ƒæ—¥æœŸ
                    if "publish_date" in data and data["publish_date"]:
                        st.write("**å‘å¸ƒæ—¥æœŸ (Publish Date):** ", publish_date)
                    
                    # æ˜¾ç¤ºæ ‡ç­¾
                    if tags:
                        st.write("**æ ‡ç­¾ (Tags):** ", ", ".join(tags))
                    
                    # æ˜¾ç¤ºè‹±æ–‡readmeå†…å®¹
                    if "readme" in data and data["readme"]:
                        st.markdown("### æè¿° (Description)")
                        st.markdown(data["readme"])
                
                with info_tab_zh:
                    # æ˜¾ç¤ºä¸­æ–‡æ ‡é¢˜
                    if "title_zh" in data and data["title_zh"]:
                        st.write("**ä¸­æ–‡æ ‡é¢˜:** ", data["title_zh"])
                    elif "title" in data and data["title"]:
                        st.write("**ä¸­æ–‡æ ‡é¢˜:** ", "(æœªç¿»è¯‘)")
                        
                    # æ˜¾ç¤ºä¸­æ–‡å‘å¸ƒæ—¥æœŸ
                    if "publish_date_zh" in data and data["publish_date_zh"]:
                        st.write("**ä¸­æ–‡æ—¥æœŸ:** ", data["publish_date_zh"])
                    elif "publish_date" in data and data["publish_date"]:
                        st.write("**ä¸­æ–‡æ—¥æœŸ:** ", "(æœªç¿»è¯‘)")
                    
                    # æ˜¾ç¤ºæ ‡ç­¾ (æ ‡ç­¾é€šå¸¸ä¸ç¿»è¯‘)
                    if tags:
                        st.write("**æ ‡ç­¾:** ", ", ".join(tags))
                    
                    # æ˜¾ç¤ºä¸­æ–‡readme
                    if "readme_zh" in data and data["readme_zh"]:
                        st.markdown("### ä¸­æ–‡æè¿°")
                        st.markdown(data["readme_zh"])
                    elif "readme" in data and data["readme"]:
                        st.markdown("### ä¸­æ–‡æè¿°")
                        st.write("(å†…å®¹æœªç¿»è¯‘)")
            
            with tab2:
                # æ˜¾ç¤ºå·¥ä½œæµæ•°æ®
                if "workflow_json" in data and data["workflow_json"]:
                    col1, col2 = st.columns([3, 1])
                    with col1:
                        st.write("**åŸå§‹å·¥ä½œæµæ•°æ®:**")
                    with col2:
                        filename = f"{os.path.splitext(json_path.name)[0]}_workflow_json.json"
                        download_link = get_download_link(data["workflow_json"], filename, "ğŸ“¥ ä¸‹è½½åŸå§‹å·¥ä½œæµ")
                        st.markdown(download_link, unsafe_allow_html=True)
                    
                    # æ˜¾ç¤ºå·¥ä½œæµé¢„è§ˆä¿¡æ¯
                    try:
                        workflow = json.loads(data["workflow_json"]) if isinstance(data["workflow_json"], str) else data["workflow_json"]
                        st.write(f"å·¥ä½œæµåç§°: {workflow.get('name', 'æœªå‘½å')}")
                        st.write(f"èŠ‚ç‚¹æ•°é‡: {len(workflow.get('nodes', []))}")
                    except:
                        st.write("æ— æ³•è§£æå·¥ä½œæµæ•°æ®")
                
                # æ˜¾ç¤ºä¸­æ–‡å·¥ä½œæµæ•°æ®
                if "workflow_json_zh" in data and data["workflow_json_zh"]:
                    col1, col2 = st.columns([3, 1])
                    with col1:
                        st.write("**ä¸­æ–‡å·¥ä½œæµæ•°æ®:**")
                    with col2:
                        filename = f"{os.path.splitext(json_path.name)[0]}_workflow_json_zh.json"
                        download_link = get_download_link(data["workflow_json_zh"], filename, "ğŸ“¥ ä¸‹è½½ä¸­æ–‡å·¥ä½œæµ")
                        st.markdown(download_link, unsafe_allow_html=True)
                    
                    # æ˜¾ç¤ºä¸­æ–‡å·¥ä½œæµé¢„è§ˆä¿¡æ¯
                    try:
                        workflow_zh = json.loads(data["workflow_json_zh"]) if isinstance(data["workflow_json_zh"], str) else data["workflow_json_zh"]
                        st.write(f"ä¸­æ–‡å·¥ä½œæµåç§°: {workflow_zh.get('name', 'æœªå‘½å')}")
                    except:
                        st.write("æ— æ³•è§£æä¸­æ–‡å·¥ä½œæµæ•°æ®")
            
            with tab3:
                # æ˜¾ç¤ºå®Œæ•´JSONå†…å®¹
                st.json(data)
                
    except Exception as e:
        st.error(f"è¯»å–æ–‡ä»¶ {json_path.name} æ—¶å‡ºé”™: {e}")

def get_unique_tags(file_infos):
    """ä»æ–‡ä»¶ä¿¡æ¯åˆ—è¡¨ä¸­æå–æ‰€æœ‰å”¯ä¸€æ ‡ç­¾"""
    all_tags = set()
    for info in file_infos:
        tags = info.get("tags", [])
        if tags:
            all_tags.update(tags)
    return sorted(list(all_tags))

def main():
    # æ·»åŠ è‡ªå®šä¹‰CSS
    st.markdown("""
    <style>
    .download-btn {
        display: inline-block;
        padding: 0.3rem 0.6rem;
        background-color: #4CAF50;
        color: white !important;
        text-decoration: none;
        border-radius: 4px;
        text-align: center;
        transition: background-color 0.3s;
    }
    .download-btn:hover {
        background-color: #45a049;
        text-decoration: none;
    }
    .tag {
        display: inline-block;
        background-color: #f1f1f1;
        padding: 2px 6px;
        margin: 2px;
        border-radius: 3px;
        font-size: 0.8rem;
    }
    .tags-container {
        margin-bottom: 10px;
    }
    </style>
    """, unsafe_allow_html=True)
    
    # ä¾§è¾¹æ è¿‡æ»¤å’Œæœç´¢é€‰é¡¹
    with st.sidebar:
        st.header("æœç´¢å’Œè¿‡æ»¤")
        
        # æœç´¢æ¡†
        search_query = st.text_input("æœç´¢æ–‡ä»¶åæˆ–æ ‡é¢˜", "")
        
        # è·å–æ‰€æœ‰JSONæ–‡ä»¶çš„åŸºæœ¬ä¿¡æ¯(ä¸è¿‡æ»¤)
        _, all_info = get_all_json_files(data_dir)
        
        # æå–æ‰€æœ‰å”¯ä¸€æ ‡ç­¾
        unique_tags = get_unique_tags(all_info)
        
        # æ ‡ç­¾å¤šé€‰
        selected_tags = st.multiselect("æŒ‰æ ‡ç­¾è¿‡æ»¤", unique_tags)
        
        # ç¿»è¯‘çŠ¶æ€è¿‡æ»¤
        translation_options = ["å…¨éƒ¨", "å·²ç¿»è¯‘", "æœªç¿»è¯‘"]
        translation_filter = st.radio("ç¿»è¯‘çŠ¶æ€", translation_options)
        
        has_translation = None
        if translation_filter == "å·²ç¿»è¯‘":
            has_translation = True
        elif translation_filter == "æœªç¿»è¯‘":
            has_translation = False
        
        # æ¯é¡µæ˜¾ç¤ºæ•°é‡
        items_per_page = st.slider("æ¯é¡µæ˜¾ç¤ºæ•°é‡", 5, 50, 10, 5)
        
        # é‡ç½®æŒ‰é’®
        if st.button("é‡ç½®è¿‡æ»¤å™¨"):
            search_query = ""
            selected_tags = []
            translation_filter = "å…¨éƒ¨"
            has_translation = None
            items_per_page = 10
            st.session_state.page_number = 1
            st.experimental_rerun()
    
    # åº”ç”¨è¿‡æ»¤å¹¶è·å–æ–‡ä»¶
    all_json_files, file_infos = get_all_json_files(data_dir, search_query, selected_tags, has_translation)
    
    # æ˜¾ç¤ºç»“æœç»Ÿè®¡
    st.write(f"å…±æ‰¾åˆ° {len(all_json_files)} ä¸ªå·¥ä½œæµæ–‡ä»¶")
    
    # å¦‚æœæ²¡æœ‰æ–‡ä»¶ï¼Œæ˜¾ç¤ºæç¤ºå¹¶é€€å‡º
    if not all_json_files:
        st.warning("æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„æ–‡ä»¶ï¼Œè¯·å°è¯•è°ƒæ•´æœç´¢æˆ–è¿‡æ»¤æ¡ä»¶ã€‚")
        return
    
    # åˆ†é¡µå‚æ•°
    total_pages = math.ceil(len(all_json_files) / items_per_page)
    
    # ç¡®ä¿é¡µç åœ¨æœ‰æ•ˆèŒƒå›´å†…
    if st.session_state.page_number < 1:
        st.session_state.page_number = 1
    elif st.session_state.page_number > total_pages:
        st.session_state.page_number = total_pages
    
    # æ·»åŠ åˆ†é¡µå¯¼èˆª
    col1, col2, col3, col4 = st.columns([1, 1, 2, 1])
    with col1:
        if st.button("Â« é¦–é¡µ"):
            st.session_state.page_number = 1
            st.experimental_rerun()
    with col2:
        if st.button("â€¹ ä¸Šä¸€é¡µ", disabled=(st.session_state.page_number <= 1)):
            st.session_state.page_number -= 1
            st.experimental_rerun()
    with col3:
        page_number = st.number_input(
            "é¡µç ", 
            min_value=1, 
            max_value=total_pages if total_pages > 0 else 1, 
            value=st.session_state.page_number,
            step=1,
            key="page_input"
        )
        # å½“é¡µç è¾“å…¥æ¡†å€¼å˜åŒ–æ—¶æ›´æ–°session state
        if page_number != st.session_state.page_number:
            st.session_state.page_number = page_number
            st.experimental_rerun()
    with col4:
        if st.button("ä¸‹ä¸€é¡µ â€º", disabled=(st.session_state.page_number >= total_pages)):
            st.session_state.page_number += 1
            st.experimental_rerun()
    
    # è®¡ç®—å½“å‰é¡µçš„æ–‡ä»¶ç´¢å¼•èŒƒå›´
    start_idx = (st.session_state.page_number - 1) * items_per_page
    end_idx = min(start_idx + items_per_page, len(all_json_files))
    
    # æ˜¾ç¤ºå½“å‰é¡µä¿¡æ¯
    st.write(f"å½“å‰æ˜¾ç¤º: {start_idx + 1} - {end_idx} / {len(all_json_files)}")
    
    # æ˜¾ç¤ºå½“å‰é¡µçš„æ–‡ä»¶å†…å®¹
    for i, json_file in enumerate(all_json_files[start_idx:end_idx], start=start_idx + 1):
        display_json_content(json_file, i)
    
    # åº•éƒ¨åˆ†é¡µå¯¼èˆª(é‡å¤é¡¶éƒ¨çš„åˆ†é¡µå¯¼èˆª)
    if len(all_json_files) > 5:
        st.write("---")
        col1, col2, col3, col4 = st.columns([1, 1, 2, 1])
        with col1:
            if st.button("Â« é¦–é¡µ", key="bottom_first"):
                st.session_state.page_number = 1
                st.experimental_rerun()
        with col2:
            if st.button("â€¹ ä¸Šä¸€é¡µ", key="bottom_prev", disabled=(st.session_state.page_number <= 1)):
                st.session_state.page_number -= 1
                st.experimental_rerun()
        with col3:
            st.write(f"ç¬¬ {st.session_state.page_number} é¡µï¼Œå…± {total_pages} é¡µ")
        with col4:
            if st.button("ä¸‹ä¸€é¡µ â€º", key="bottom_next", disabled=(st.session_state.page_number >= total_pages)):
                st.session_state.page_number += 1
                st.experimental_rerun()

if __name__ == "__main__":
    main()